{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6M9P_qhyziaf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yc_NizP43xvF",
    "outputId": "b57f8ca1-74f6-4b2b-f654-b893b6cbc901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index      Date  Mkt-RF   idxd  Return  Returndmy  Year\n",
      "0          0  19270103   -0.79    151   -0.79          0  1927\n",
      "1          1  19270104    0.31    152    0.31          1  1927\n",
      "2          2  19270105    0.14    153    0.14          1  1927\n",
      "3          3  19270106   -0.17    154   -0.17          0  1927\n",
      "4          4  19270107    0.30    155    0.30          1  1927\n",
      "...      ...       ...     ...    ...     ...        ...   ...\n",
      "25325  25325  20230424    0.00  25476    0.00          0  2023\n",
      "25326  25326  20230425   -1.76  25477   -1.76          0  2023\n",
      "25327  25327  20230426   -0.41  25478   -0.41          0  2023\n",
      "25328  25328  20230427    1.85  25479    1.85          1  2023\n",
      "25329  25329  20230428    0.77  25480    0.77          1  2023\n",
      "\n",
      "[25330 rows x 7 columns]\n",
      "Maximum value: 15.76 at index: 1836\n",
      "Minimum value: -17.44 at index: 16377\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Return   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     58.13\n",
      "Date:                Fri, 14 Mar 2025   Prob (F-statistic):           2.54e-14\n",
      "Time:                        17:07:03   Log-Likelihood:                -37976.\n",
      "No. Observations:               25329   AIC:                         7.596e+04\n",
      "Df Residuals:                   25327   BIC:                         7.597e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0284      0.007      4.171      0.000       0.015       0.042\n",
      "Return         0.0479      0.006      7.624      0.000       0.036       0.060\n",
      "==============================================================================\n",
      "Omnibus:                     5696.574   Durbin-Watson:                   1.997\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           281957.646\n",
      "Skew:                          -0.108   Prob(JB):                         0.00\n",
      "Kurtosis:                      19.344   Cond. No.                         1.09\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "dfs = pd.read_csv('/Users/ryanhuang/Developer/transformers/FFdaily.CSV')\n",
    "#dfs = pd.read_csv('FFdaily.CSV')\n",
    "\n",
    "dfs['Return'] = dfs['Mkt-RF']\n",
    "# Drop rows with missing values\n",
    "# Replace -inf with NaN\n",
    "dfs.replace(-np.inf, np.nan, inplace=True)\n",
    "dfs.replace(np.inf, np.nan, inplace=True)\n",
    "dfs.dropna(inplace=True)\n",
    "dfs['Returndmy'] = dfs['Return'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Assuming your dataset is stored in a pandas DataFrame called 'data'\n",
    "dfs['Date'] = dfs['Date'].astype(str)  # Convert 'Date' column to string\n",
    "dfs['Year'] = dfs['Date'].str[:4]  # Extract the first 4 digits as the year\n",
    "dfs['Year'] = pd.to_numeric(dfs['Year'])  # Convert 'Year' column to numeric\n",
    "dfs['Date'] = pd.to_numeric(dfs['Date'])  # Convert 'Year' column to numeric\n",
    "\n",
    "dfs = dfs[dfs['Year'] >= 1927]\n",
    "\n",
    "# dfs = dfs[dfs['Year'] <= 1932]\n",
    "\n",
    "# Drop the last 400 rows\n",
    "#dfs = dfs.drop(dfs.index[-(4360):])\n",
    "#dfs = dfs.drop(dfs.index[-(250*1):])\n",
    "\n",
    "# Reset the index of the dataframe\n",
    "dfs = dfs.reset_index(drop=True)\n",
    "dfs = dfs.reset_index()\n",
    "df = dfs\n",
    "df0 = dfs\n",
    "print(df0)\n",
    "\n",
    "# Maximum value and its index in the column\n",
    "max_value = df['Return'].max()\n",
    "max_index = df['Return'].idxmax()\n",
    "\n",
    "# Minimum value and its index in the column\n",
    "min_value = df['Return'].min()\n",
    "min_index = df['Return'].idxmin()\n",
    "\n",
    "print(\"Maximum value:\", max_value, \"at index:\", max_index)\n",
    "print(\"Minimum value:\", min_value, \"at index:\", min_index)\n",
    "\n",
    "# # Extract the column for AR(1) modeling\n",
    "column_data = df['Return']  # Replace 'Return' with the actual column name from your DataFrame\n",
    "\n",
    "# Create lagged values of the column\n",
    "lagged_data = column_data.shift(1).dropna()\n",
    "\n",
    "# Add a constant column to the lagged data\n",
    "lagged_data = sm.add_constant(lagged_data)\n",
    "\n",
    "# Fit the AR(1) model using OLS\n",
    "ar_ols_model = sm.OLS(column_data[1:], lagged_data)\n",
    "ar_ols_result = ar_ols_model.fit()\n",
    "\n",
    "# Display summary of coefficients\n",
    "print(ar_ols_result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network OneShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after cleaning: (25330, 6)\n",
      "       Date  Mkt-RF  idxd  Return  Returndmy  Year\n",
      "0  19270103   -0.79   151   -0.79          0  1927\n",
      "1  19270104    0.31   152    0.31          1  1927\n",
      "2  19270105    0.14   153    0.14          1  1927\n",
      "3  19270106   -0.17   154   -0.17          0  1927\n",
      "4  19270107    0.30   155    0.30          1  1927\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 2) Load and clean your dataset\n",
    "# ---------------------------------------------------------\n",
    "dfs = pd.read_csv('/Users/ryanhuang/Developer/transformers/FFdaily.CSV')\n",
    "dfs['Return'] = dfs['Mkt-RF']\n",
    "dfs.replace([-np.inf, np.inf], np.nan, inplace=True)\n",
    "dfs.dropna(inplace=True)\n",
    "dfs['Returndmy'] = dfs['Return'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Convert 'Date' to string, then extract year and finally convert Date to int \n",
    "# (if needed, you can later convert it back to datetime)\n",
    "dfs['Date'] = dfs['Date'].astype(str)\n",
    "dfs['Year'] = dfs['Date'].str[:4].astype(int)\n",
    "dfs['Date'] = dfs['Date'].astype(int)\n",
    "\n",
    "# Filter from 1927 onward\n",
    "dfs = dfs[dfs['Year'] >= 1927].copy()\n",
    "dfs.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Sort by date\n",
    "dfs = dfs.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# If you have an 'idxd' column, note it for alignment\n",
    "idxd_col_exists = ('idxd' in dfs.columns)\n",
    "\n",
    "print(\"Data shape after cleaning:\", dfs.shape)\n",
    "print(dfs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with 5 lags:\n",
      "   idxd      Date  Mkt-RF  Return  Returndmy  Year  lag_1  lag_2  lag_3  \\\n",
      "5   156  19270108    0.39    0.39          1  1927   0.30  -0.17   0.14   \n",
      "6   157  19270110    0.14    0.14          1  1927   0.39   0.30  -0.17   \n",
      "7   158  19270111   -0.28   -0.28          0  1927   0.14   0.39   0.30   \n",
      "8   159  19270112    0.07    0.07          1  1927  -0.28   0.14   0.39   \n",
      "9   160  19270113   -0.04   -0.04          0  1927   0.07  -0.28   0.14   \n",
      "\n",
      "   lag_4  lag_5  \n",
      "5   0.31  -0.79  \n",
      "6   0.14   0.31  \n",
      "7  -0.17   0.14  \n",
      "8   0.30  -0.17  \n",
      "9   0.39   0.30  \n"
     ]
    }
   ],
   "source": [
    "# Dataset with 5 lags (using past values)\n",
    "df_lags5 = dfs.sort_values('idxd').copy()\n",
    "df_lags5.set_index('idxd', inplace=True)\n",
    "\n",
    "# Create lag columns for lags 1 through 5 using the 'Return' column.\n",
    "for i in range(1, 6):\n",
    "    df_lags5[f'lag_{i}'] = df_lags5['Return'].shift(i)\n",
    "\n",
    "# Reset the index to bring 'idxd' back as a column.\n",
    "df_lags5 = df_lags5.reset_index()\n",
    "\n",
    "# Drop rows where any of the 5 lag columns contain NaN values.\n",
    "df_lags5 = df_lags5.dropna(subset=[f'lag_{i}' for i in range(1, 6)])\n",
    "\n",
    "print(\"Dataset with 5 lags:\")\n",
    "print(df_lags5.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.linear2 = nn.Linear(hidden_size, 32)\n",
    "        self.linear3 = nn.Linear(32, 16)\n",
    "        self.linear4 = nn.Linear(16, 8)\n",
    "        self.linear5 = nn.Linear(8, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # Layer 2\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # Layer 3\n",
    "        out = self.linear3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # Layer 4\n",
    "        out = self.linear4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # Output\n",
    "        out = self.linear5(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_model(num_epochs,\n",
    "                hidden_size,\n",
    "                dropout_rate,\n",
    "                learning_rate,\n",
    "                X_train_fold,\n",
    "                y_train_fold,\n",
    "                X_val_fold,\n",
    "                y_val_fold,\n",
    "                device='cpu'):\n",
    "    \"\"\"\n",
    "    Trains a PyTorch MLP with the given hyperparams on (X_train_fold, y_train_fold),\n",
    "    then returns the validation MSE on (X_val_fold, y_val_fold).\n",
    "    \"\"\"\n",
    "    input_dim = X_train_fold.shape[1]\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_t = torch.tensor(X_train_fold.values, dtype=torch.float32).to(device)\n",
    "    y_train_t = torch.tensor(y_train_fold.values.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "    X_val_t   = torch.tensor(X_val_fold.values,   dtype=torch.float32).to(device)\n",
    "    y_val_t   = torch.tensor(y_val_fold.values.reshape(-1, 1),   dtype=torch.float32).to(device)\n",
    "    \n",
    "    model = SimpleNN(input_dim, hidden_size, dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        y_pred = model(X_train_t)\n",
    "        loss = criterion(y_pred, y_train_t)\n",
    "\n",
    "        # Backprop and update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # (Optional) check progress every 100 epochs\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            # Evaluate on validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_pred = model(X_val_t)\n",
    "                val_loss = criterion(val_pred, y_val_t)\n",
    "            model.train()\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {loss.item():.6f} | Val Loss: {val_loss.item():.6f}\")\n",
    "\n",
    "    # Final validation MSE\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = model(X_val_t)\n",
    "    mse_val = mean_squared_error(y_val_fold, val_pred.cpu().numpy())\n",
    "\n",
    "    return model, mse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/500] | Train Loss: 0.260135 | Val Loss: 0.531476\n",
      "Epoch [200/500] | Train Loss: 0.197307 | Val Loss: 0.581761\n",
      "Epoch [300/500] | Train Loss: 0.200111 | Val Loss: 0.632990\n",
      "Epoch [400/500] | Train Loss: 0.151793 | Val Loss: 0.655815\n",
      "Epoch [500/500] | Train Loss: 0.156948 | Val Loss: 0.655757\n",
      "Epoch [100/500] | Train Loss: 0.390132 | Val Loss: 0.856215\n",
      "Epoch [200/500] | Train Loss: 0.360550 | Val Loss: 0.874559\n",
      "Epoch [300/500] | Train Loss: 0.342784 | Val Loss: 0.863543\n",
      "Epoch [400/500] | Train Loss: 0.317804 | Val Loss: 0.879505\n",
      "Epoch [500/500] | Train Loss: 0.294335 | Val Loss: 0.893375\n",
      "Epoch [100/500] | Train Loss: 0.543151 | Val Loss: 4.573287\n",
      "Epoch [200/500] | Train Loss: 0.516792 | Val Loss: 4.449750\n",
      "Epoch [300/500] | Train Loss: 0.479005 | Val Loss: 5.309966\n",
      "Epoch [400/500] | Train Loss: 0.449880 | Val Loss: 5.846119\n",
      "Epoch [500/500] | Train Loss: 0.432281 | Val Loss: 5.831481\n",
      "Epoch [100/500] | Train Loss: 1.232120 | Val Loss: 2.771364\n",
      "Epoch [200/500] | Train Loss: 0.871461 | Val Loss: 2.734623\n",
      "Epoch [300/500] | Train Loss: 0.885058 | Val Loss: 2.792325\n",
      "Epoch [400/500] | Train Loss: 0.830675 | Val Loss: 2.798996\n",
      "Epoch [500/500] | Train Loss: 0.872103 | Val Loss: 2.857800\n",
      "Epoch [100/500] | Train Loss: 1.463823 | Val Loss: 5.559622\n",
      "Epoch [200/500] | Train Loss: 1.167268 | Val Loss: 5.736485\n",
      "Epoch [300/500] | Train Loss: 1.156636 | Val Loss: 5.775503\n",
      "Epoch [400/500] | Train Loss: 1.053089 | Val Loss: 6.066261\n",
      "Epoch [500/500] | Train Loss: 0.987050 | Val Loss: 6.108432\n",
      "Epoch [100/500] | Train Loss: 0.178896 | Val Loss: 0.636430\n",
      "Epoch [200/500] | Train Loss: 0.138984 | Val Loss: 0.665509\n",
      "Epoch [300/500] | Train Loss: 0.102979 | Val Loss: 0.613000\n",
      "Epoch [400/500] | Train Loss: 0.087779 | Val Loss: 0.661398\n",
      "Epoch [500/500] | Train Loss: 0.105149 | Val Loss: 0.682662\n",
      "Epoch [100/500] | Train Loss: 0.281123 | Val Loss: 1.029286\n",
      "Epoch [200/500] | Train Loss: 0.234895 | Val Loss: 1.002293\n",
      "Epoch [300/500] | Train Loss: 0.216910 | Val Loss: 1.133029\n",
      "Epoch [400/500] | Train Loss: 0.206100 | Val Loss: 1.052462\n",
      "Epoch [500/500] | Train Loss: 0.183686 | Val Loss: 1.141056\n",
      "Epoch [100/500] | Train Loss: 0.380886 | Val Loss: 8.631828\n",
      "Epoch [200/500] | Train Loss: 0.342882 | Val Loss: 7.776117\n",
      "Epoch [300/500] | Train Loss: 0.311695 | Val Loss: 8.120818\n",
      "Epoch [400/500] | Train Loss: 0.306993 | Val Loss: 8.527886\n",
      "Epoch [500/500] | Train Loss: 0.334578 | Val Loss: 6.502419\n",
      "Epoch [100/500] | Train Loss: 0.755371 | Val Loss: 2.601589\n",
      "Epoch [200/500] | Train Loss: 0.826932 | Val Loss: 2.879204\n",
      "Epoch [300/500] | Train Loss: 0.653167 | Val Loss: 2.827898\n",
      "Epoch [400/500] | Train Loss: 0.645087 | Val Loss: 3.173956\n",
      "Epoch [500/500] | Train Loss: 0.546241 | Val Loss: 3.217273\n",
      "Epoch [100/500] | Train Loss: 1.100755 | Val Loss: 5.317701\n",
      "Epoch [200/500] | Train Loss: 0.898072 | Val Loss: 6.249145\n",
      "Epoch [300/500] | Train Loss: 0.768185 | Val Loss: 6.086157\n",
      "Epoch [400/500] | Train Loss: 0.790008 | Val Loss: 5.693141\n",
      "Epoch [500/500] | Train Loss: 0.795817 | Val Loss: 6.594484\n",
      "Epoch [100/500] | Train Loss: 0.260081 | Val Loss: 0.534800\n",
      "Epoch [200/500] | Train Loss: 0.234260 | Val Loss: 0.557591\n",
      "Epoch [300/500] | Train Loss: 0.199712 | Val Loss: 0.575214\n",
      "Epoch [400/500] | Train Loss: 0.201967 | Val Loss: 0.585473\n",
      "Epoch [500/500] | Train Loss: 0.196914 | Val Loss: 0.584266\n",
      "Epoch [100/500] | Train Loss: 0.394970 | Val Loss: 0.862413\n",
      "Epoch [200/500] | Train Loss: 0.388216 | Val Loss: 0.838925\n",
      "Epoch [300/500] | Train Loss: 0.385696 | Val Loss: 0.835983\n",
      "Epoch [400/500] | Train Loss: 0.358004 | Val Loss: 0.845994\n",
      "Epoch [500/500] | Train Loss: 0.328496 | Val Loss: 0.862418\n",
      "Epoch [100/500] | Train Loss: 0.560695 | Val Loss: 4.575611\n",
      "Epoch [200/500] | Train Loss: 0.548267 | Val Loss: 4.558432\n",
      "Epoch [300/500] | Train Loss: 0.523779 | Val Loss: 4.432235\n",
      "Epoch [400/500] | Train Loss: 0.492184 | Val Loss: 4.483091\n",
      "Epoch [500/500] | Train Loss: 0.441328 | Val Loss: 4.648670\n",
      "Epoch [100/500] | Train Loss: 1.380321 | Val Loss: 2.564300\n",
      "Epoch [200/500] | Train Loss: 1.034744 | Val Loss: 2.632323\n",
      "Epoch [300/500] | Train Loss: 0.958914 | Val Loss: 2.678924\n",
      "Epoch [400/500] | Train Loss: 0.910682 | Val Loss: 2.699608\n",
      "Epoch [500/500] | Train Loss: 0.868684 | Val Loss: 2.673906\n",
      "Epoch [100/500] | Train Loss: 1.653951 | Val Loss: 5.106154\n",
      "Epoch [200/500] | Train Loss: 1.480018 | Val Loss: 5.298971\n",
      "Epoch [300/500] | Train Loss: 1.142117 | Val Loss: 5.237483\n",
      "Epoch [400/500] | Train Loss: 1.105852 | Val Loss: 5.236343\n",
      "Epoch [500/500] | Train Loss: 1.146433 | Val Loss: 5.226163\n",
      "Epoch [100/500] | Train Loss: 0.177417 | Val Loss: 0.624460\n",
      "Epoch [200/500] | Train Loss: 0.142892 | Val Loss: 0.584676\n",
      "Epoch [300/500] | Train Loss: 0.120765 | Val Loss: 0.586233\n",
      "Epoch [400/500] | Train Loss: 0.146909 | Val Loss: 0.590061\n",
      "Epoch [500/500] | Train Loss: 0.107889 | Val Loss: 0.596569\n",
      "Epoch [100/500] | Train Loss: 0.331813 | Val Loss: 0.899616\n",
      "Epoch [200/500] | Train Loss: 0.293756 | Val Loss: 0.914606\n",
      "Epoch [300/500] | Train Loss: 0.252350 | Val Loss: 0.940910\n",
      "Epoch [400/500] | Train Loss: 0.234212 | Val Loss: 0.971769\n",
      "Epoch [500/500] | Train Loss: 0.235033 | Val Loss: 1.034110\n",
      "Epoch [100/500] | Train Loss: 0.438796 | Val Loss: 5.304574\n",
      "Epoch [200/500] | Train Loss: 0.417372 | Val Loss: 5.655149\n",
      "Epoch [300/500] | Train Loss: 0.391964 | Val Loss: 5.080721\n",
      "Epoch [400/500] | Train Loss: 0.388956 | Val Loss: 5.590180\n",
      "Epoch [500/500] | Train Loss: 0.377751 | Val Loss: 5.777011\n",
      "Epoch [100/500] | Train Loss: 0.910439 | Val Loss: 2.778836\n",
      "Epoch [200/500] | Train Loss: 0.964733 | Val Loss: 2.584102\n",
      "Epoch [300/500] | Train Loss: 1.019662 | Val Loss: 2.621318\n",
      "Epoch [400/500] | Train Loss: 0.820294 | Val Loss: 2.993191\n",
      "Epoch [500/500] | Train Loss: 0.762704 | Val Loss: 2.577918\n",
      "Epoch [100/500] | Train Loss: 1.280037 | Val Loss: 5.451559\n",
      "Epoch [200/500] | Train Loss: 1.142944 | Val Loss: 5.536815\n",
      "Epoch [300/500] | Train Loss: 1.145194 | Val Loss: 5.694459\n",
      "Epoch [400/500] | Train Loss: 1.104783 | Val Loss: 5.410469\n",
      "Epoch [500/500] | Train Loss: 0.977757 | Val Loss: 5.568106\n",
      "Epoch [100/500] | Train Loss: 0.256291 | Val Loss: 0.539352\n",
      "Epoch [200/500] | Train Loss: 0.199804 | Val Loss: 0.595657\n",
      "Epoch [300/500] | Train Loss: 0.177753 | Val Loss: 0.652845\n",
      "Epoch [400/500] | Train Loss: 0.132356 | Val Loss: 0.672770\n",
      "Epoch [500/500] | Train Loss: 0.113468 | Val Loss: 0.674166\n",
      "Epoch [100/500] | Train Loss: 0.391576 | Val Loss: 0.864223\n",
      "Epoch [200/500] | Train Loss: 0.362005 | Val Loss: 0.885476\n",
      "Epoch [300/500] | Train Loss: 0.331301 | Val Loss: 0.904065\n",
      "Epoch [400/500] | Train Loss: 0.273203 | Val Loss: 0.923564\n",
      "Epoch [500/500] | Train Loss: 0.227033 | Val Loss: 1.006551\n",
      "Epoch [100/500] | Train Loss: 0.531576 | Val Loss: 4.222788\n",
      "Epoch [200/500] | Train Loss: 0.464804 | Val Loss: 4.921777\n",
      "Epoch [300/500] | Train Loss: 0.382784 | Val Loss: 6.598042\n",
      "Epoch [400/500] | Train Loss: 0.361047 | Val Loss: 6.848675\n",
      "Epoch [500/500] | Train Loss: 0.344412 | Val Loss: 7.505642\n",
      "Epoch [100/500] | Train Loss: 1.087204 | Val Loss: 2.726611\n",
      "Epoch [200/500] | Train Loss: 0.884899 | Val Loss: 2.816654\n",
      "Epoch [300/500] | Train Loss: 0.951620 | Val Loss: 2.898120\n",
      "Epoch [400/500] | Train Loss: 0.754644 | Val Loss: 2.821387\n",
      "Epoch [500/500] | Train Loss: 0.674193 | Val Loss: 2.906121\n",
      "Epoch [100/500] | Train Loss: 1.329642 | Val Loss: 5.331878\n",
      "Epoch [200/500] | Train Loss: 1.139323 | Val Loss: 5.465416\n",
      "Epoch [300/500] | Train Loss: 1.097719 | Val Loss: 5.761704\n",
      "Epoch [400/500] | Train Loss: 0.980441 | Val Loss: 5.892011\n",
      "Epoch [500/500] | Train Loss: 0.930866 | Val Loss: 6.067098\n",
      "Epoch [100/500] | Train Loss: 0.142858 | Val Loss: 0.637909\n",
      "Epoch [200/500] | Train Loss: 0.103572 | Val Loss: 0.704724\n",
      "Epoch [300/500] | Train Loss: 0.072956 | Val Loss: 0.679332\n",
      "Epoch [400/500] | Train Loss: 0.072451 | Val Loss: 0.683390\n",
      "Epoch [500/500] | Train Loss: 0.075117 | Val Loss: 0.659344\n",
      "Epoch [100/500] | Train Loss: 0.230442 | Val Loss: 1.024311\n",
      "Epoch [200/500] | Train Loss: 0.200862 | Val Loss: 1.063402\n",
      "Epoch [300/500] | Train Loss: 0.168563 | Val Loss: 1.143829\n",
      "Epoch [400/500] | Train Loss: 0.152563 | Val Loss: 1.062622\n",
      "Epoch [500/500] | Train Loss: 0.147105 | Val Loss: 1.085291\n",
      "Epoch [100/500] | Train Loss: 0.361387 | Val Loss: 6.534264\n",
      "Epoch [200/500] | Train Loss: 0.286395 | Val Loss: 6.039927\n",
      "Epoch [300/500] | Train Loss: 0.267406 | Val Loss: 6.311227\n",
      "Epoch [400/500] | Train Loss: 0.238759 | Val Loss: 6.334400\n",
      "Epoch [500/500] | Train Loss: 0.251380 | Val Loss: 5.669441\n",
      "Epoch [100/500] | Train Loss: 0.859827 | Val Loss: 2.499347\n",
      "Epoch [200/500] | Train Loss: 0.664621 | Val Loss: 2.708095\n",
      "Epoch [300/500] | Train Loss: 0.652464 | Val Loss: 2.936009\n",
      "Epoch [400/500] | Train Loss: 0.589604 | Val Loss: 3.052054\n",
      "Epoch [500/500] | Train Loss: 0.608867 | Val Loss: 3.347168\n",
      "Epoch [100/500] | Train Loss: 0.962273 | Val Loss: 6.360542\n",
      "Epoch [200/500] | Train Loss: 0.865766 | Val Loss: 6.185517\n",
      "Epoch [300/500] | Train Loss: 0.781056 | Val Loss: 6.000010\n",
      "Epoch [400/500] | Train Loss: 0.726660 | Val Loss: 7.126822\n",
      "Epoch [500/500] | Train Loss: 0.638652 | Val Loss: 6.672311\n",
      "Epoch [100/500] | Train Loss: 0.241963 | Val Loss: 0.543102\n",
      "Epoch [200/500] | Train Loss: 0.193843 | Val Loss: 0.577013\n",
      "Epoch [300/500] | Train Loss: 0.189200 | Val Loss: 0.596195\n",
      "Epoch [400/500] | Train Loss: 0.156797 | Val Loss: 0.602935\n",
      "Epoch [500/500] | Train Loss: 0.154689 | Val Loss: 0.589018\n",
      "Epoch [100/500] | Train Loss: 0.383635 | Val Loss: 0.882942\n",
      "Epoch [200/500] | Train Loss: 0.334241 | Val Loss: 0.889747\n",
      "Epoch [300/500] | Train Loss: 0.321161 | Val Loss: 0.922386\n",
      "Epoch [400/500] | Train Loss: 0.311295 | Val Loss: 0.935876\n",
      "Epoch [500/500] | Train Loss: 0.283358 | Val Loss: 0.944531\n",
      "Epoch [100/500] | Train Loss: 0.550051 | Val Loss: 4.358773\n",
      "Epoch [200/500] | Train Loss: 0.503043 | Val Loss: 4.597660\n",
      "Epoch [300/500] | Train Loss: 0.469658 | Val Loss: 5.037462\n",
      "Epoch [400/500] | Train Loss: 0.430370 | Val Loss: 5.654169\n",
      "Epoch [500/500] | Train Loss: 0.436186 | Val Loss: 5.826653\n",
      "Epoch [100/500] | Train Loss: 1.233290 | Val Loss: 2.527807\n",
      "Epoch [200/500] | Train Loss: 0.958441 | Val Loss: 2.844393\n",
      "Epoch [300/500] | Train Loss: 0.937214 | Val Loss: 2.814260\n",
      "Epoch [400/500] | Train Loss: 0.863839 | Val Loss: 2.717699\n",
      "Epoch [500/500] | Train Loss: 0.842060 | Val Loss: 2.787856\n",
      "Epoch [100/500] | Train Loss: 1.577261 | Val Loss: 5.359674\n",
      "Epoch [200/500] | Train Loss: 1.362906 | Val Loss: 5.491139\n",
      "Epoch [300/500] | Train Loss: 1.195595 | Val Loss: 5.559437\n",
      "Epoch [400/500] | Train Loss: 1.159718 | Val Loss: 5.549547\n",
      "Epoch [500/500] | Train Loss: 1.111869 | Val Loss: 5.628561\n",
      "Epoch [100/500] | Train Loss: 0.199250 | Val Loss: 0.610211\n",
      "Epoch [200/500] | Train Loss: 0.133128 | Val Loss: 0.608933\n",
      "Epoch [300/500] | Train Loss: 0.137156 | Val Loss: 0.613100\n",
      "Epoch [400/500] | Train Loss: 0.126151 | Val Loss: 0.608735\n",
      "Epoch [500/500] | Train Loss: 0.114035 | Val Loss: 0.644451\n",
      "Epoch [100/500] | Train Loss: 0.310900 | Val Loss: 0.875103\n",
      "Epoch [200/500] | Train Loss: 0.254665 | Val Loss: 0.923088\n",
      "Epoch [300/500] | Train Loss: 0.230903 | Val Loss: 0.997284\n",
      "Epoch [400/500] | Train Loss: 0.237853 | Val Loss: 1.017663\n",
      "Epoch [500/500] | Train Loss: 0.212643 | Val Loss: 0.987050\n",
      "Epoch [100/500] | Train Loss: 0.474891 | Val Loss: 4.932321\n",
      "Epoch [200/500] | Train Loss: 0.399303 | Val Loss: 6.133777\n",
      "Epoch [300/500] | Train Loss: 0.382237 | Val Loss: 4.820012\n",
      "Epoch [400/500] | Train Loss: 0.328558 | Val Loss: 4.766430\n",
      "Epoch [500/500] | Train Loss: 0.378171 | Val Loss: 4.910572\n",
      "Epoch [100/500] | Train Loss: 1.007318 | Val Loss: 2.552721\n",
      "Epoch [200/500] | Train Loss: 0.780695 | Val Loss: 2.619569\n",
      "Epoch [300/500] | Train Loss: 0.856941 | Val Loss: 2.668105\n",
      "Epoch [400/500] | Train Loss: 0.842377 | Val Loss: 2.653341\n",
      "Epoch [500/500] | Train Loss: 0.710178 | Val Loss: 2.830349\n",
      "Epoch [100/500] | Train Loss: 1.214302 | Val Loss: 5.665944\n",
      "Epoch [200/500] | Train Loss: 1.034578 | Val Loss: 5.950707\n",
      "Epoch [300/500] | Train Loss: 0.921001 | Val Loss: 5.734068\n",
      "Epoch [400/500] | Train Loss: 0.962889 | Val Loss: 5.831054\n",
      "Epoch [500/500] | Train Loss: 1.027218 | Val Loss: 5.621042\n",
      "[Year=1932] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=2.799084 Test MSE=8.607568\n",
      "Year 1932 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.538705 | Val Loss: 1.008582\n",
      "Epoch [200/500] | Train Loss: 0.489830 | Val Loss: 1.013080\n",
      "Epoch [300/500] | Train Loss: 0.431139 | Val Loss: 1.106509\n",
      "Epoch [400/500] | Train Loss: 0.385565 | Val Loss: 1.141137\n",
      "Epoch [500/500] | Train Loss: 0.334328 | Val Loss: 1.164287\n",
      "Epoch [100/500] | Train Loss: 0.705665 | Val Loss: 4.968359\n",
      "Epoch [200/500] | Train Loss: 0.612231 | Val Loss: 6.015040\n",
      "Epoch [300/500] | Train Loss: 0.523779 | Val Loss: 6.654384\n",
      "Epoch [400/500] | Train Loss: 0.542158 | Val Loss: 6.835985\n",
      "Epoch [500/500] | Train Loss: 0.530971 | Val Loss: 6.937707\n",
      "Epoch [100/500] | Train Loss: 1.739267 | Val Loss: 2.295768\n",
      "Epoch [200/500] | Train Loss: 1.302834 | Val Loss: 2.125531\n",
      "Epoch [300/500] | Train Loss: 1.143675 | Val Loss: 2.112842\n",
      "Epoch [400/500] | Train Loss: 1.086725 | Val Loss: 2.084855\n",
      "Epoch [500/500] | Train Loss: 1.067410 | Val Loss: 2.123900\n",
      "Epoch [100/500] | Train Loss: 1.833596 | Val Loss: 6.274522\n",
      "Epoch [200/500] | Train Loss: 1.513369 | Val Loss: 6.272893\n",
      "Epoch [300/500] | Train Loss: 1.440516 | Val Loss: 6.538172\n",
      "Epoch [400/500] | Train Loss: 1.376183 | Val Loss: 6.658519\n",
      "Epoch [500/500] | Train Loss: 1.370249 | Val Loss: 6.782248\n",
      "Epoch [100/500] | Train Loss: 2.759145 | Val Loss: 8.032654\n",
      "Epoch [200/500] | Train Loss: 2.595424 | Val Loss: 8.503010\n",
      "Epoch [300/500] | Train Loss: 2.324995 | Val Loss: 8.384928\n",
      "Epoch [400/500] | Train Loss: 2.108064 | Val Loss: 8.759962\n",
      "Epoch [500/500] | Train Loss: 1.964905 | Val Loss: 8.853093\n",
      "Epoch [100/500] | Train Loss: 0.347866 | Val Loss: 1.226078\n",
      "Epoch [200/500] | Train Loss: 0.249128 | Val Loss: 1.221648\n",
      "Epoch [300/500] | Train Loss: 0.234834 | Val Loss: 1.296173\n",
      "Epoch [400/500] | Train Loss: 0.219561 | Val Loss: 1.371584\n",
      "Epoch [500/500] | Train Loss: 0.164022 | Val Loss: 1.230579\n",
      "Epoch [100/500] | Train Loss: 0.525856 | Val Loss: 7.028729\n",
      "Epoch [200/500] | Train Loss: 0.460338 | Val Loss: 6.692894\n",
      "Epoch [300/500] | Train Loss: 0.397145 | Val Loss: 6.503680\n",
      "Epoch [400/500] | Train Loss: 0.379558 | Val Loss: 7.193029\n",
      "Epoch [500/500] | Train Loss: 0.348872 | Val Loss: 6.581549\n",
      "Epoch [100/500] | Train Loss: 1.114491 | Val Loss: 2.206820\n",
      "Epoch [200/500] | Train Loss: 1.007505 | Val Loss: 2.254922\n",
      "Epoch [300/500] | Train Loss: 0.817828 | Val Loss: 2.473712\n",
      "Epoch [400/500] | Train Loss: 0.802350 | Val Loss: 2.535971\n",
      "Epoch [500/500] | Train Loss: 0.778106 | Val Loss: 2.580435\n",
      "Epoch [100/500] | Train Loss: 1.446381 | Val Loss: 6.395746\n",
      "Epoch [200/500] | Train Loss: 1.284760 | Val Loss: 7.062840\n",
      "Epoch [300/500] | Train Loss: 1.060508 | Val Loss: 7.729971\n",
      "Epoch [400/500] | Train Loss: 1.038296 | Val Loss: 7.658775\n",
      "Epoch [500/500] | Train Loss: 0.928304 | Val Loss: 7.692409\n",
      "Epoch [100/500] | Train Loss: 2.035505 | Val Loss: 8.945713\n",
      "Epoch [200/500] | Train Loss: 1.776979 | Val Loss: 9.412182\n",
      "Epoch [300/500] | Train Loss: 1.606606 | Val Loss: 9.632358\n",
      "Epoch [400/500] | Train Loss: 1.790930 | Val Loss: 9.916929\n",
      "Epoch [500/500] | Train Loss: 1.628384 | Val Loss: 9.792202\n",
      "Epoch [100/500] | Train Loss: 0.539300 | Val Loss: 0.990313\n",
      "Epoch [200/500] | Train Loss: 0.544625 | Val Loss: 0.980928\n",
      "Epoch [300/500] | Train Loss: 0.495563 | Val Loss: 0.984734\n",
      "Epoch [400/500] | Train Loss: 0.466221 | Val Loss: 0.995558\n",
      "Epoch [500/500] | Train Loss: 0.415697 | Val Loss: 1.001103\n",
      "Epoch [100/500] | Train Loss: 0.747693 | Val Loss: 4.908147\n",
      "Epoch [200/500] | Train Loss: 0.697843 | Val Loss: 4.910403\n",
      "Epoch [300/500] | Train Loss: 0.661084 | Val Loss: 5.351105\n",
      "Epoch [400/500] | Train Loss: 0.620546 | Val Loss: 6.245955\n",
      "Epoch [500/500] | Train Loss: 0.603145 | Val Loss: 6.390594\n",
      "Epoch [100/500] | Train Loss: 1.824749 | Val Loss: 2.293087\n",
      "Epoch [200/500] | Train Loss: 1.500220 | Val Loss: 2.197623\n",
      "Epoch [300/500] | Train Loss: 1.421940 | Val Loss: 2.155371\n",
      "Epoch [400/500] | Train Loss: 1.295168 | Val Loss: 2.104187\n",
      "Epoch [500/500] | Train Loss: 1.293326 | Val Loss: 2.095981\n",
      "Epoch [100/500] | Train Loss: 2.003901 | Val Loss: 6.101970\n",
      "Epoch [200/500] | Train Loss: 1.754809 | Val Loss: 6.178029\n",
      "Epoch [300/500] | Train Loss: 1.546286 | Val Loss: 6.098595\n",
      "Epoch [400/500] | Train Loss: 1.471829 | Val Loss: 6.282431\n",
      "Epoch [500/500] | Train Loss: 1.332574 | Val Loss: 6.246876\n",
      "Epoch [100/500] | Train Loss: 2.724417 | Val Loss: 7.673958\n",
      "Epoch [200/500] | Train Loss: 2.426372 | Val Loss: 8.045310\n",
      "Epoch [300/500] | Train Loss: 2.525341 | Val Loss: 8.386226\n",
      "Epoch [400/500] | Train Loss: 2.371187 | Val Loss: 8.581565\n",
      "Epoch [500/500] | Train Loss: 2.209783 | Val Loss: 8.651024\n",
      "Epoch [100/500] | Train Loss: 0.440653 | Val Loss: 1.061062\n",
      "Epoch [200/500] | Train Loss: 0.321380 | Val Loss: 1.167539\n",
      "Epoch [300/500] | Train Loss: 0.282576 | Val Loss: 1.101012\n",
      "Epoch [400/500] | Train Loss: 0.283143 | Val Loss: 1.116989\n",
      "Epoch [500/500] | Train Loss: 0.275540 | Val Loss: 1.122844\n",
      "Epoch [100/500] | Train Loss: 0.677706 | Val Loss: 5.027029\n",
      "Epoch [200/500] | Train Loss: 0.616705 | Val Loss: 5.496997\n",
      "Epoch [300/500] | Train Loss: 0.546220 | Val Loss: 5.658797\n",
      "Epoch [400/500] | Train Loss: 0.529756 | Val Loss: 5.228741\n",
      "Epoch [500/500] | Train Loss: 0.570286 | Val Loss: 5.322893\n",
      "Epoch [100/500] | Train Loss: 1.506840 | Val Loss: 2.107755\n",
      "Epoch [200/500] | Train Loss: 1.589590 | Val Loss: 2.114091\n",
      "Epoch [300/500] | Train Loss: 1.137618 | Val Loss: 2.144486\n",
      "Epoch [400/500] | Train Loss: 1.294885 | Val Loss: 2.230327\n",
      "Epoch [500/500] | Train Loss: 0.966604 | Val Loss: 2.168759\n",
      "Epoch [100/500] | Train Loss: 1.505833 | Val Loss: 6.511761\n",
      "Epoch [200/500] | Train Loss: 1.414032 | Val Loss: 6.672322\n",
      "Epoch [300/500] | Train Loss: 1.292343 | Val Loss: 6.645483\n",
      "Epoch [400/500] | Train Loss: 1.299993 | Val Loss: 6.861700\n",
      "Epoch [500/500] | Train Loss: 1.264747 | Val Loss: 6.837099\n",
      "Epoch [100/500] | Train Loss: 2.355083 | Val Loss: 8.498195\n",
      "Epoch [200/500] | Train Loss: 2.150976 | Val Loss: 9.361447\n",
      "Epoch [300/500] | Train Loss: 1.957248 | Val Loss: 10.038578\n",
      "Epoch [400/500] | Train Loss: 1.922784 | Val Loss: 9.688568\n",
      "Epoch [500/500] | Train Loss: 1.824584 | Val Loss: 9.050097\n",
      "Epoch [100/500] | Train Loss: 0.497489 | Val Loss: 0.991797\n",
      "Epoch [200/500] | Train Loss: 0.371165 | Val Loss: 1.136809\n",
      "Epoch [300/500] | Train Loss: 0.326560 | Val Loss: 1.233437\n",
      "Epoch [400/500] | Train Loss: 0.274402 | Val Loss: 1.314539\n",
      "Epoch [500/500] | Train Loss: 0.258759 | Val Loss: 1.298782\n",
      "Epoch [100/500] | Train Loss: 0.725022 | Val Loss: 4.974354\n",
      "Epoch [200/500] | Train Loss: 0.659567 | Val Loss: 5.277864\n",
      "Epoch [300/500] | Train Loss: 0.612321 | Val Loss: 5.389274\n",
      "Epoch [400/500] | Train Loss: 0.541661 | Val Loss: 5.376270\n",
      "Epoch [500/500] | Train Loss: 0.582796 | Val Loss: 5.318985\n",
      "Epoch [100/500] | Train Loss: 1.581617 | Val Loss: 2.355690\n",
      "Epoch [200/500] | Train Loss: 1.206343 | Val Loss: 2.227175\n",
      "Epoch [300/500] | Train Loss: 1.235333 | Val Loss: 2.185092\n",
      "Epoch [400/500] | Train Loss: 1.026898 | Val Loss: 2.219074\n",
      "Epoch [500/500] | Train Loss: 1.108539 | Val Loss: 2.264473\n",
      "Epoch [100/500] | Train Loss: 1.647578 | Val Loss: 6.437383\n",
      "Epoch [200/500] | Train Loss: 1.439764 | Val Loss: 6.723439\n",
      "Epoch [300/500] | Train Loss: 1.299373 | Val Loss: 7.108742\n",
      "Epoch [400/500] | Train Loss: 1.259755 | Val Loss: 7.109469\n",
      "Epoch [500/500] | Train Loss: 1.335330 | Val Loss: 7.029173\n",
      "Epoch [100/500] | Train Loss: 2.506201 | Val Loss: 8.249222\n",
      "Epoch [200/500] | Train Loss: 2.173412 | Val Loss: 9.127253\n",
      "Epoch [300/500] | Train Loss: 2.023614 | Val Loss: 9.638295\n",
      "Epoch [400/500] | Train Loss: 1.972289 | Val Loss: 9.606333\n",
      "Epoch [500/500] | Train Loss: 1.802788 | Val Loss: 9.818486\n",
      "Epoch [100/500] | Train Loss: 0.240587 | Val Loss: 1.257919\n",
      "Epoch [200/500] | Train Loss: 0.177231 | Val Loss: 1.242856\n",
      "Epoch [300/500] | Train Loss: 0.145859 | Val Loss: 1.198638\n",
      "Epoch [400/500] | Train Loss: 0.128770 | Val Loss: 1.192622\n",
      "Epoch [500/500] | Train Loss: 0.118406 | Val Loss: 1.244672\n",
      "Epoch [100/500] | Train Loss: 0.458522 | Val Loss: 6.283776\n",
      "Epoch [200/500] | Train Loss: 0.423078 | Val Loss: 5.939427\n",
      "Epoch [300/500] | Train Loss: 0.345220 | Val Loss: 6.154479\n",
      "Epoch [400/500] | Train Loss: 0.311311 | Val Loss: 6.063013\n",
      "Epoch [500/500] | Train Loss: 0.259413 | Val Loss: 6.074943\n",
      "Epoch [100/500] | Train Loss: 1.226084 | Val Loss: 2.265690\n",
      "Epoch [200/500] | Train Loss: 1.015829 | Val Loss: 2.334012\n",
      "Epoch [300/500] | Train Loss: 0.925235 | Val Loss: 2.510133\n",
      "Epoch [400/500] | Train Loss: 0.773779 | Val Loss: 2.569611\n",
      "Epoch [500/500] | Train Loss: 0.684120 | Val Loss: 2.640653\n",
      "Epoch [100/500] | Train Loss: 1.216902 | Val Loss: 7.520847\n",
      "Epoch [200/500] | Train Loss: 1.016446 | Val Loss: 7.781620\n",
      "Epoch [300/500] | Train Loss: 0.954820 | Val Loss: 7.841842\n",
      "Epoch [400/500] | Train Loss: 1.073961 | Val Loss: 9.044959\n",
      "Epoch [500/500] | Train Loss: 0.779479 | Val Loss: 8.477950\n",
      "Epoch [100/500] | Train Loss: 1.906971 | Val Loss: 9.537587\n",
      "Epoch [200/500] | Train Loss: 1.682897 | Val Loss: 10.220252\n",
      "Epoch [300/500] | Train Loss: 1.546340 | Val Loss: 10.782405\n",
      "Epoch [400/500] | Train Loss: 1.434195 | Val Loss: 10.645922\n",
      "Epoch [500/500] | Train Loss: 1.339486 | Val Loss: 10.327367\n",
      "Epoch [100/500] | Train Loss: 0.502271 | Val Loss: 0.996796\n",
      "Epoch [200/500] | Train Loss: 0.450815 | Val Loss: 1.061152\n",
      "Epoch [300/500] | Train Loss: 0.401453 | Val Loss: 1.134154\n",
      "Epoch [400/500] | Train Loss: 0.338065 | Val Loss: 1.142298\n",
      "Epoch [500/500] | Train Loss: 0.303061 | Val Loss: 1.189292\n",
      "Epoch [100/500] | Train Loss: 0.731035 | Val Loss: 4.869978\n",
      "Epoch [200/500] | Train Loss: 0.655526 | Val Loss: 5.477871\n",
      "Epoch [300/500] | Train Loss: 0.605367 | Val Loss: 5.859399\n",
      "Epoch [400/500] | Train Loss: 0.583122 | Val Loss: 6.284069\n",
      "Epoch [500/500] | Train Loss: 0.549527 | Val Loss: 6.887770\n",
      "Epoch [100/500] | Train Loss: 1.906247 | Val Loss: 2.270567\n",
      "Epoch [200/500] | Train Loss: 1.394505 | Val Loss: 2.277848\n",
      "Epoch [300/500] | Train Loss: 1.408454 | Val Loss: 2.245801\n",
      "Epoch [400/500] | Train Loss: 1.153664 | Val Loss: 2.226137\n",
      "Epoch [500/500] | Train Loss: 1.160848 | Val Loss: 2.253921\n",
      "Epoch [100/500] | Train Loss: 1.735241 | Val Loss: 6.218151\n",
      "Epoch [200/500] | Train Loss: 1.589469 | Val Loss: 6.495112\n",
      "Epoch [300/500] | Train Loss: 1.388810 | Val Loss: 6.667510\n",
      "Epoch [400/500] | Train Loss: 1.305266 | Val Loss: 6.780628\n",
      "Epoch [500/500] | Train Loss: 1.351719 | Val Loss: 7.078728\n",
      "Epoch [100/500] | Train Loss: 2.792143 | Val Loss: 7.944587\n",
      "Epoch [200/500] | Train Loss: 2.466624 | Val Loss: 8.499153\n",
      "Epoch [300/500] | Train Loss: 2.395106 | Val Loss: 8.755821\n",
      "Epoch [400/500] | Train Loss: 2.167074 | Val Loss: 9.073134\n",
      "Epoch [500/500] | Train Loss: 2.064045 | Val Loss: 8.750550\n",
      "Epoch [100/500] | Train Loss: 0.314695 | Val Loss: 1.270954\n",
      "Epoch [200/500] | Train Loss: 0.347461 | Val Loss: 1.299083\n",
      "Epoch [300/500] | Train Loss: 0.258513 | Val Loss: 1.232759\n",
      "Epoch [400/500] | Train Loss: 0.231752 | Val Loss: 1.250937\n",
      "Epoch [500/500] | Train Loss: 0.297279 | Val Loss: 1.203100\n",
      "Epoch [100/500] | Train Loss: 0.625131 | Val Loss: 5.845016\n",
      "Epoch [200/500] | Train Loss: 0.486095 | Val Loss: 6.356863\n",
      "Epoch [300/500] | Train Loss: 0.448314 | Val Loss: 6.192551\n",
      "Epoch [400/500] | Train Loss: 0.395494 | Val Loss: 6.195987\n",
      "Epoch [500/500] | Train Loss: 0.394810 | Val Loss: 5.856480\n",
      "Epoch [100/500] | Train Loss: 1.285649 | Val Loss: 2.173363\n",
      "Epoch [200/500] | Train Loss: 1.225804 | Val Loss: 2.290448\n",
      "Epoch [300/500] | Train Loss: 1.171074 | Val Loss: 2.251410\n",
      "Epoch [400/500] | Train Loss: 1.107693 | Val Loss: 2.265476\n",
      "Epoch [500/500] | Train Loss: 1.111822 | Val Loss: 2.507973\n",
      "Epoch [100/500] | Train Loss: 1.452790 | Val Loss: 6.733368\n",
      "Epoch [200/500] | Train Loss: 1.305855 | Val Loss: 7.225255\n",
      "Epoch [300/500] | Train Loss: 1.283557 | Val Loss: 7.080084\n",
      "Epoch [400/500] | Train Loss: 1.142557 | Val Loss: 7.282870\n",
      "Epoch [500/500] | Train Loss: 1.190259 | Val Loss: 7.738712\n",
      "Epoch [100/500] | Train Loss: 2.201947 | Val Loss: 8.322864\n",
      "Epoch [200/500] | Train Loss: 1.920247 | Val Loss: 8.916028\n",
      "Epoch [300/500] | Train Loss: 1.739585 | Val Loss: 8.946366\n",
      "Epoch [400/500] | Train Loss: 1.772474 | Val Loss: 8.839650\n",
      "Epoch [500/500] | Train Loss: 1.723644 | Val Loss: 8.982168\n",
      "[Year=1933] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=4.877116 Test MSE=6.882683\n",
      "Year 1933 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.359430 | Val Loss: 3.744514\n",
      "Epoch [200/500] | Train Loss: 1.049980 | Val Loss: 4.552968\n",
      "Epoch [300/500] | Train Loss: 1.035291 | Val Loss: 4.861077\n",
      "Epoch [400/500] | Train Loss: 0.915405 | Val Loss: 4.991970\n",
      "Epoch [500/500] | Train Loss: 0.861202 | Val Loss: 5.539755\n",
      "Epoch [100/500] | Train Loss: 2.520977 | Val Loss: 2.829980\n",
      "Epoch [200/500] | Train Loss: 1.696690 | Val Loss: 2.685948\n",
      "Epoch [300/500] | Train Loss: 1.444790 | Val Loss: 2.654572\n",
      "Epoch [400/500] | Train Loss: 1.546150 | Val Loss: 2.710042\n",
      "Epoch [500/500] | Train Loss: 1.295920 | Val Loss: 2.725077\n",
      "Epoch [100/500] | Train Loss: 2.501854 | Val Loss: 6.491833\n",
      "Epoch [200/500] | Train Loss: 2.042117 | Val Loss: 6.522917\n",
      "Epoch [300/500] | Train Loss: 1.807590 | Val Loss: 6.375746\n",
      "Epoch [400/500] | Train Loss: 1.709860 | Val Loss: 6.709802\n",
      "Epoch [500/500] | Train Loss: 1.578874 | Val Loss: 6.625072\n",
      "Epoch [100/500] | Train Loss: 3.295659 | Val Loss: 7.913413\n",
      "Epoch [200/500] | Train Loss: 2.901652 | Val Loss: 8.341743\n",
      "Epoch [300/500] | Train Loss: 2.678050 | Val Loss: 8.502961\n",
      "Epoch [400/500] | Train Loss: 2.575874 | Val Loss: 8.720371\n",
      "Epoch [500/500] | Train Loss: 2.535327 | Val Loss: 8.771052\n",
      "Epoch [100/500] | Train Loss: 4.243124 | Val Loss: 7.352754\n",
      "Epoch [200/500] | Train Loss: 4.096622 | Val Loss: 7.609944\n",
      "Epoch [300/500] | Train Loss: 3.639566 | Val Loss: 7.757237\n",
      "Epoch [400/500] | Train Loss: 3.391325 | Val Loss: 7.710018\n",
      "Epoch [500/500] | Train Loss: 3.431237 | Val Loss: 7.584153\n",
      "Epoch [100/500] | Train Loss: 1.432471 | Val Loss: 5.132415\n",
      "Epoch [200/500] | Train Loss: 0.760735 | Val Loss: 5.038052\n",
      "Epoch [300/500] | Train Loss: 0.761988 | Val Loss: 5.001955\n",
      "Epoch [400/500] | Train Loss: 0.607897 | Val Loss: 4.449131\n",
      "Epoch [500/500] | Train Loss: 0.617356 | Val Loss: 4.593633\n",
      "Epoch [100/500] | Train Loss: 1.547211 | Val Loss: 2.742749\n",
      "Epoch [200/500] | Train Loss: 1.163563 | Val Loss: 3.127627\n",
      "Epoch [300/500] | Train Loss: 1.067726 | Val Loss: 3.307587\n",
      "Epoch [400/500] | Train Loss: 0.996309 | Val Loss: 3.306623\n",
      "Epoch [500/500] | Train Loss: 0.845047 | Val Loss: 3.573354\n",
      "Epoch [100/500] | Train Loss: 1.781292 | Val Loss: 6.378018\n",
      "Epoch [200/500] | Train Loss: 1.482014 | Val Loss: 7.206418\n",
      "Epoch [300/500] | Train Loss: 1.538283 | Val Loss: 7.493242\n",
      "Epoch [400/500] | Train Loss: 1.347531 | Val Loss: 7.831170\n",
      "Epoch [500/500] | Train Loss: 1.181112 | Val Loss: 7.527970\n",
      "Epoch [100/500] | Train Loss: 2.334163 | Val Loss: 8.662731\n",
      "Epoch [200/500] | Train Loss: 2.163997 | Val Loss: 8.706869\n",
      "Epoch [300/500] | Train Loss: 2.107674 | Val Loss: 8.801882\n",
      "Epoch [400/500] | Train Loss: 1.966405 | Val Loss: 9.266692\n",
      "Epoch [500/500] | Train Loss: 1.536304 | Val Loss: 9.332516\n",
      "Epoch [100/500] | Train Loss: 3.538544 | Val Loss: 7.650975\n",
      "Epoch [200/500] | Train Loss: 3.072694 | Val Loss: 7.974798\n",
      "Epoch [300/500] | Train Loss: 2.844549 | Val Loss: 8.151260\n",
      "Epoch [400/500] | Train Loss: 2.616633 | Val Loss: 8.148094\n",
      "Epoch [500/500] | Train Loss: 2.403896 | Val Loss: 8.223634\n",
      "Epoch [100/500] | Train Loss: 1.506222 | Val Loss: 4.086816\n",
      "Epoch [200/500] | Train Loss: 1.384460 | Val Loss: 4.393972\n",
      "Epoch [300/500] | Train Loss: 1.064566 | Val Loss: 4.131089\n",
      "Epoch [400/500] | Train Loss: 1.246748 | Val Loss: 4.224615\n",
      "Epoch [500/500] | Train Loss: 1.240924 | Val Loss: 4.230299\n",
      "Epoch [100/500] | Train Loss: 2.669015 | Val Loss: 2.743220\n",
      "Epoch [200/500] | Train Loss: 1.924485 | Val Loss: 2.704554\n",
      "Epoch [300/500] | Train Loss: 1.773316 | Val Loss: 2.633457\n",
      "Epoch [400/500] | Train Loss: 2.018512 | Val Loss: 2.652359\n",
      "Epoch [500/500] | Train Loss: 1.607937 | Val Loss: 2.647526\n",
      "Epoch [100/500] | Train Loss: 2.528056 | Val Loss: 6.131441\n",
      "Epoch [200/500] | Train Loss: 2.295640 | Val Loss: 6.147819\n",
      "Epoch [300/500] | Train Loss: 2.162948 | Val Loss: 6.068749\n",
      "Epoch [400/500] | Train Loss: 2.001139 | Val Loss: 6.174589\n",
      "Epoch [500/500] | Train Loss: 1.796831 | Val Loss: 6.271899\n",
      "Epoch [100/500] | Train Loss: 3.472950 | Val Loss: 7.533361\n",
      "Epoch [200/500] | Train Loss: 3.040487 | Val Loss: 8.025480\n",
      "Epoch [300/500] | Train Loss: 2.735948 | Val Loss: 8.179328\n",
      "Epoch [400/500] | Train Loss: 2.798166 | Val Loss: 8.308266\n",
      "Epoch [500/500] | Train Loss: 2.624389 | Val Loss: 8.300200\n",
      "Epoch [100/500] | Train Loss: 4.265028 | Val Loss: 7.329297\n",
      "Epoch [200/500] | Train Loss: 4.229515 | Val Loss: 7.433750\n",
      "Epoch [300/500] | Train Loss: 4.015467 | Val Loss: 7.580050\n",
      "Epoch [400/500] | Train Loss: 3.742822 | Val Loss: 7.554065\n",
      "Epoch [500/500] | Train Loss: 3.684060 | Val Loss: 7.524999\n",
      "Epoch [100/500] | Train Loss: 1.265787 | Val Loss: 4.331910\n",
      "Epoch [200/500] | Train Loss: 0.973939 | Val Loss: 4.890293\n",
      "Epoch [300/500] | Train Loss: 0.863504 | Val Loss: 4.026258\n",
      "Epoch [400/500] | Train Loss: 0.923142 | Val Loss: 4.069173\n",
      "Epoch [500/500] | Train Loss: 0.716775 | Val Loss: 4.009747\n",
      "Epoch [100/500] | Train Loss: 2.022204 | Val Loss: 2.630361\n",
      "Epoch [200/500] | Train Loss: 1.813916 | Val Loss: 2.749401\n",
      "Epoch [300/500] | Train Loss: 1.464078 | Val Loss: 2.792609\n",
      "Epoch [400/500] | Train Loss: 1.997003 | Val Loss: 2.761005\n",
      "Epoch [500/500] | Train Loss: 1.532052 | Val Loss: 2.820154\n",
      "Epoch [100/500] | Train Loss: 1.924440 | Val Loss: 6.215366\n",
      "Epoch [200/500] | Train Loss: 1.766926 | Val Loss: 6.311618\n",
      "Epoch [300/500] | Train Loss: 1.864418 | Val Loss: 6.304614\n",
      "Epoch [400/500] | Train Loss: 1.784112 | Val Loss: 6.613626\n",
      "Epoch [500/500] | Train Loss: 1.659104 | Val Loss: 6.324706\n",
      "Epoch [100/500] | Train Loss: 2.952829 | Val Loss: 8.375814\n",
      "Epoch [200/500] | Train Loss: 2.603563 | Val Loss: 8.679926\n",
      "Epoch [300/500] | Train Loss: 2.612581 | Val Loss: 8.388738\n",
      "Epoch [400/500] | Train Loss: 2.440644 | Val Loss: 8.337893\n",
      "Epoch [500/500] | Train Loss: 2.253602 | Val Loss: 8.569872\n",
      "Epoch [100/500] | Train Loss: 3.808302 | Val Loss: 7.800088\n",
      "Epoch [200/500] | Train Loss: 3.585357 | Val Loss: 7.977808\n",
      "Epoch [300/500] | Train Loss: 3.423446 | Val Loss: 7.703436\n",
      "Epoch [400/500] | Train Loss: 3.414032 | Val Loss: 7.840283\n",
      "Epoch [500/500] | Train Loss: 3.298151 | Val Loss: 7.763237\n",
      "Epoch [100/500] | Train Loss: 1.240859 | Val Loss: 4.519405\n",
      "Epoch [200/500] | Train Loss: 1.062689 | Val Loss: 4.592445\n",
      "Epoch [300/500] | Train Loss: 1.143654 | Val Loss: 4.476103\n",
      "Epoch [400/500] | Train Loss: 0.897253 | Val Loss: 5.061283\n",
      "Epoch [500/500] | Train Loss: 0.763141 | Val Loss: 4.749784\n",
      "Epoch [100/500] | Train Loss: 2.207953 | Val Loss: 2.668370\n",
      "Epoch [200/500] | Train Loss: 1.630530 | Val Loss: 2.693071\n",
      "Epoch [300/500] | Train Loss: 1.531915 | Val Loss: 2.849713\n",
      "Epoch [400/500] | Train Loss: 1.337075 | Val Loss: 2.942176\n",
      "Epoch [500/500] | Train Loss: 1.202164 | Val Loss: 2.988872\n",
      "Epoch [100/500] | Train Loss: 2.194556 | Val Loss: 6.530874\n",
      "Epoch [200/500] | Train Loss: 1.843874 | Val Loss: 6.641147\n",
      "Epoch [300/500] | Train Loss: 1.708946 | Val Loss: 6.965796\n",
      "Epoch [400/500] | Train Loss: 1.674343 | Val Loss: 6.847575\n",
      "Epoch [500/500] | Train Loss: 1.734289 | Val Loss: 7.069229\n",
      "Epoch [100/500] | Train Loss: 3.053175 | Val Loss: 8.144903\n",
      "Epoch [200/500] | Train Loss: 2.625311 | Val Loss: 8.704127\n",
      "Epoch [300/500] | Train Loss: 2.424014 | Val Loss: 8.925159\n",
      "Epoch [400/500] | Train Loss: 2.228284 | Val Loss: 8.930245\n",
      "Epoch [500/500] | Train Loss: 2.307782 | Val Loss: 9.125009\n",
      "Epoch [100/500] | Train Loss: 4.068351 | Val Loss: 7.427292\n",
      "Epoch [200/500] | Train Loss: 3.581405 | Val Loss: 7.752970\n",
      "Epoch [300/500] | Train Loss: 3.246202 | Val Loss: 8.191303\n",
      "Epoch [400/500] | Train Loss: 3.051371 | Val Loss: 8.356766\n",
      "Epoch [500/500] | Train Loss: 3.028706 | Val Loss: 8.673901\n",
      "Epoch [100/500] | Train Loss: 0.824697 | Val Loss: 4.165596\n",
      "Epoch [200/500] | Train Loss: 0.625110 | Val Loss: 4.002821\n",
      "Epoch [300/500] | Train Loss: 0.431622 | Val Loss: 4.576411\n",
      "Epoch [400/500] | Train Loss: 0.465484 | Val Loss: 4.302915\n",
      "Epoch [500/500] | Train Loss: 0.570956 | Val Loss: 4.592801\n",
      "Epoch [100/500] | Train Loss: 1.214483 | Val Loss: 2.873097\n",
      "Epoch [200/500] | Train Loss: 1.084096 | Val Loss: 3.095555\n",
      "Epoch [300/500] | Train Loss: 0.830838 | Val Loss: 3.309436\n",
      "Epoch [400/500] | Train Loss: 0.783476 | Val Loss: 3.364284\n",
      "Epoch [500/500] | Train Loss: 0.764868 | Val Loss: 3.419869\n",
      "Epoch [100/500] | Train Loss: 1.769554 | Val Loss: 7.073868\n",
      "Epoch [200/500] | Train Loss: 1.441228 | Val Loss: 7.670127\n",
      "Epoch [300/500] | Train Loss: 1.257762 | Val Loss: 8.177402\n",
      "Epoch [400/500] | Train Loss: 1.117712 | Val Loss: 8.199533\n",
      "Epoch [500/500] | Train Loss: 1.017884 | Val Loss: 8.675491\n",
      "Epoch [100/500] | Train Loss: 2.261711 | Val Loss: 9.224643\n",
      "Epoch [200/500] | Train Loss: 1.809638 | Val Loss: 8.678244\n",
      "Epoch [300/500] | Train Loss: 1.618108 | Val Loss: 9.408926\n",
      "Epoch [400/500] | Train Loss: 1.444023 | Val Loss: 9.517673\n",
      "Epoch [500/500] | Train Loss: 1.389254 | Val Loss: 9.563172\n",
      "Epoch [100/500] | Train Loss: 3.144191 | Val Loss: 8.439583\n",
      "Epoch [200/500] | Train Loss: 2.706834 | Val Loss: 8.766317\n",
      "Epoch [300/500] | Train Loss: 2.452252 | Val Loss: 9.147691\n",
      "Epoch [400/500] | Train Loss: 2.422978 | Val Loss: 8.785442\n",
      "Epoch [500/500] | Train Loss: 2.192118 | Val Loss: 9.007009\n",
      "Epoch [100/500] | Train Loss: 1.733700 | Val Loss: 3.876956\n",
      "Epoch [200/500] | Train Loss: 1.264658 | Val Loss: 3.728894\n",
      "Epoch [300/500] | Train Loss: 1.349555 | Val Loss: 4.039693\n",
      "Epoch [400/500] | Train Loss: 1.180018 | Val Loss: 3.797845\n",
      "Epoch [500/500] | Train Loss: 0.916718 | Val Loss: 4.150417\n",
      "Epoch [100/500] | Train Loss: 2.555631 | Val Loss: 2.611780\n",
      "Epoch [200/500] | Train Loss: 1.915652 | Val Loss: 2.729170\n",
      "Epoch [300/500] | Train Loss: 1.760588 | Val Loss: 2.698051\n",
      "Epoch [400/500] | Train Loss: 1.918823 | Val Loss: 2.769814\n",
      "Epoch [500/500] | Train Loss: 1.498574 | Val Loss: 2.829146\n",
      "Epoch [100/500] | Train Loss: 2.619441 | Val Loss: 6.175340\n",
      "Epoch [200/500] | Train Loss: 2.070830 | Val Loss: 6.278469\n",
      "Epoch [300/500] | Train Loss: 1.962687 | Val Loss: 6.342951\n",
      "Epoch [400/500] | Train Loss: 1.851861 | Val Loss: 6.447993\n",
      "Epoch [500/500] | Train Loss: 1.735041 | Val Loss: 6.402304\n",
      "Epoch [100/500] | Train Loss: 3.521451 | Val Loss: 7.554605\n",
      "Epoch [200/500] | Train Loss: 3.036673 | Val Loss: 8.229767\n",
      "Epoch [300/500] | Train Loss: 2.856000 | Val Loss: 8.531782\n",
      "Epoch [400/500] | Train Loss: 2.598134 | Val Loss: 8.651864\n",
      "Epoch [500/500] | Train Loss: 2.654771 | Val Loss: 8.529518\n",
      "Epoch [100/500] | Train Loss: 4.193296 | Val Loss: 7.449562\n",
      "Epoch [200/500] | Train Loss: 3.945887 | Val Loss: 7.675110\n",
      "Epoch [300/500] | Train Loss: 3.663453 | Val Loss: 7.858066\n",
      "Epoch [400/500] | Train Loss: 3.700927 | Val Loss: 7.730965\n",
      "Epoch [500/500] | Train Loss: 3.400998 | Val Loss: 7.726409\n",
      "Epoch [100/500] | Train Loss: 1.170499 | Val Loss: 5.064178\n",
      "Epoch [200/500] | Train Loss: 0.888699 | Val Loss: 4.640714\n",
      "Epoch [300/500] | Train Loss: 0.769531 | Val Loss: 4.422477\n",
      "Epoch [400/500] | Train Loss: 0.832238 | Val Loss: 5.278039\n",
      "Epoch [500/500] | Train Loss: 0.737259 | Val Loss: 3.961987\n",
      "Epoch [100/500] | Train Loss: 2.037659 | Val Loss: 2.599383\n",
      "Epoch [200/500] | Train Loss: 1.351490 | Val Loss: 2.652969\n",
      "Epoch [300/500] | Train Loss: 1.195159 | Val Loss: 2.698943\n",
      "Epoch [400/500] | Train Loss: 1.482461 | Val Loss: 2.836910\n",
      "Epoch [500/500] | Train Loss: 1.157923 | Val Loss: 2.912395\n",
      "Epoch [100/500] | Train Loss: 1.825256 | Val Loss: 6.348033\n",
      "Epoch [200/500] | Train Loss: 1.632341 | Val Loss: 6.563633\n",
      "Epoch [300/500] | Train Loss: 1.649179 | Val Loss: 6.475693\n",
      "Epoch [400/500] | Train Loss: 1.448246 | Val Loss: 6.530689\n",
      "Epoch [500/500] | Train Loss: 1.467685 | Val Loss: 6.611706\n",
      "Epoch [100/500] | Train Loss: 2.700026 | Val Loss: 8.180913\n",
      "Epoch [200/500] | Train Loss: 2.344198 | Val Loss: 8.680376\n",
      "Epoch [300/500] | Train Loss: 2.392875 | Val Loss: 9.023073\n",
      "Epoch [400/500] | Train Loss: 2.287675 | Val Loss: 8.497920\n",
      "Epoch [500/500] | Train Loss: 2.064972 | Val Loss: 9.162804\n",
      "Epoch [100/500] | Train Loss: 3.642266 | Val Loss: 7.589241\n",
      "Epoch [200/500] | Train Loss: 3.207108 | Val Loss: 7.609371\n",
      "Epoch [300/500] | Train Loss: 3.192582 | Val Loss: 7.922131\n",
      "Epoch [400/500] | Train Loss: 3.045118 | Val Loss: 8.119822\n",
      "Epoch [500/500] | Train Loss: 3.001956 | Val Loss: 8.332710\n",
      "[Year=1934] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=5.794985 Test MSE=1.903509\n",
      "Year 1934 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.525867 | Val Loss: 2.529265\n",
      "Epoch [200/500] | Train Loss: 1.222667 | Val Loss: 2.801271\n",
      "Epoch [300/500] | Train Loss: 1.025465 | Val Loss: 3.083292\n",
      "Epoch [400/500] | Train Loss: 1.057708 | Val Loss: 3.305076\n",
      "Epoch [500/500] | Train Loss: 0.857163 | Val Loss: 3.466971\n",
      "Epoch [100/500] | Train Loss: 2.015724 | Val Loss: 7.209610\n",
      "Epoch [200/500] | Train Loss: 1.734348 | Val Loss: 7.437873\n",
      "Epoch [300/500] | Train Loss: 1.629017 | Val Loss: 7.859306\n",
      "Epoch [400/500] | Train Loss: 1.439893 | Val Loss: 7.937784\n",
      "Epoch [500/500] | Train Loss: 1.476450 | Val Loss: 8.239313\n",
      "Epoch [100/500] | Train Loss: 3.519409 | Val Loss: 8.942049\n",
      "Epoch [200/500] | Train Loss: 3.157913 | Val Loss: 9.324167\n",
      "Epoch [300/500] | Train Loss: 2.906187 | Val Loss: 9.450465\n",
      "Epoch [400/500] | Train Loss: 2.823350 | Val Loss: 9.798517\n",
      "Epoch [500/500] | Train Loss: 2.703478 | Val Loss: 9.944474\n",
      "Epoch [100/500] | Train Loss: 4.798742 | Val Loss: 5.220039\n",
      "Epoch [200/500] | Train Loss: 4.399698 | Val Loss: 5.184862\n",
      "Epoch [300/500] | Train Loss: 4.024628 | Val Loss: 5.283447\n",
      "Epoch [400/500] | Train Loss: 3.874723 | Val Loss: 5.402542\n",
      "Epoch [500/500] | Train Loss: 3.871478 | Val Loss: 5.338524\n",
      "Epoch [100/500] | Train Loss: 4.827239 | Val Loss: 1.778066\n",
      "Epoch [200/500] | Train Loss: 4.537769 | Val Loss: 1.913479\n",
      "Epoch [300/500] | Train Loss: 4.455876 | Val Loss: 2.035241\n",
      "Epoch [400/500] | Train Loss: 4.129675 | Val Loss: 2.036976\n",
      "Epoch [500/500] | Train Loss: 4.010575 | Val Loss: 2.063384\n",
      "Epoch [100/500] | Train Loss: 0.775348 | Val Loss: 3.079059\n",
      "Epoch [200/500] | Train Loss: 0.738185 | Val Loss: 3.153997\n",
      "Epoch [300/500] | Train Loss: 0.602792 | Val Loss: 3.245243\n",
      "Epoch [400/500] | Train Loss: 0.360189 | Val Loss: 3.298542\n",
      "Epoch [500/500] | Train Loss: 0.374268 | Val Loss: 3.263638\n",
      "Epoch [100/500] | Train Loss: 1.500897 | Val Loss: 8.129242\n",
      "Epoch [200/500] | Train Loss: 1.276127 | Val Loss: 8.195501\n",
      "Epoch [300/500] | Train Loss: 1.017617 | Val Loss: 8.865142\n",
      "Epoch [400/500] | Train Loss: 1.048005 | Val Loss: 8.621890\n",
      "Epoch [500/500] | Train Loss: 0.971387 | Val Loss: 8.555468\n",
      "Epoch [100/500] | Train Loss: 2.508287 | Val Loss: 9.149995\n",
      "Epoch [200/500] | Train Loss: 2.155412 | Val Loss: 10.409272\n",
      "Epoch [300/500] | Train Loss: 2.025077 | Val Loss: 10.663931\n",
      "Epoch [400/500] | Train Loss: 2.076918 | Val Loss: 10.707760\n",
      "Epoch [500/500] | Train Loss: 2.058827 | Val Loss: 10.720668\n",
      "Epoch [100/500] | Train Loss: 3.830904 | Val Loss: 5.505048\n",
      "Epoch [200/500] | Train Loss: 3.339009 | Val Loss: 5.449655\n",
      "Epoch [300/500] | Train Loss: 3.104232 | Val Loss: 5.397359\n",
      "Epoch [400/500] | Train Loss: 2.823818 | Val Loss: 5.751709\n",
      "Epoch [500/500] | Train Loss: 2.728167 | Val Loss: 5.566195\n",
      "Epoch [100/500] | Train Loss: 4.091809 | Val Loss: 1.972093\n",
      "Epoch [200/500] | Train Loss: 3.502841 | Val Loss: 2.115613\n",
      "Epoch [300/500] | Train Loss: 3.410479 | Val Loss: 2.089349\n",
      "Epoch [400/500] | Train Loss: 3.067836 | Val Loss: 2.143371\n",
      "Epoch [500/500] | Train Loss: 2.832317 | Val Loss: 2.005174\n",
      "Epoch [100/500] | Train Loss: 1.544433 | Val Loss: 2.574645\n",
      "Epoch [200/500] | Train Loss: 1.434617 | Val Loss: 2.600953\n",
      "Epoch [300/500] | Train Loss: 1.417431 | Val Loss: 2.619532\n",
      "Epoch [400/500] | Train Loss: 1.330400 | Val Loss: 2.622303\n",
      "Epoch [500/500] | Train Loss: 1.198575 | Val Loss: 2.722476\n",
      "Epoch [100/500] | Train Loss: 2.052482 | Val Loss: 7.055458\n",
      "Epoch [200/500] | Train Loss: 2.009738 | Val Loss: 7.222198\n",
      "Epoch [300/500] | Train Loss: 1.813134 | Val Loss: 7.310408\n",
      "Epoch [400/500] | Train Loss: 1.768501 | Val Loss: 7.400290\n",
      "Epoch [500/500] | Train Loss: 1.717177 | Val Loss: 7.525138\n",
      "Epoch [100/500] | Train Loss: 3.634552 | Val Loss: 8.541666\n",
      "Epoch [200/500] | Train Loss: 3.489548 | Val Loss: 8.879004\n",
      "Epoch [300/500] | Train Loss: 3.352968 | Val Loss: 9.096460\n",
      "Epoch [400/500] | Train Loss: 3.222563 | Val Loss: 9.186651\n",
      "Epoch [500/500] | Train Loss: 2.970387 | Val Loss: 9.267282\n",
      "Epoch [100/500] | Train Loss: 4.760014 | Val Loss: 5.159930\n",
      "Epoch [200/500] | Train Loss: 4.586120 | Val Loss: 5.124226\n",
      "Epoch [300/500] | Train Loss: 4.545914 | Val Loss: 5.092586\n",
      "Epoch [400/500] | Train Loss: 4.488834 | Val Loss: 5.033443\n",
      "Epoch [500/500] | Train Loss: 4.364163 | Val Loss: 5.038060\n",
      "Epoch [100/500] | Train Loss: 4.906760 | Val Loss: 1.756921\n",
      "Epoch [200/500] | Train Loss: 4.706468 | Val Loss: 1.826399\n",
      "Epoch [300/500] | Train Loss: 4.708235 | Val Loss: 1.868049\n",
      "Epoch [400/500] | Train Loss: 4.332005 | Val Loss: 1.901775\n",
      "Epoch [500/500] | Train Loss: 4.370410 | Val Loss: 1.882366\n",
      "Epoch [100/500] | Train Loss: 1.497981 | Val Loss: 2.816426\n",
      "Epoch [200/500] | Train Loss: 1.054482 | Val Loss: 2.982014\n",
      "Epoch [300/500] | Train Loss: 1.037693 | Val Loss: 2.856480\n",
      "Epoch [400/500] | Train Loss: 0.819236 | Val Loss: 2.863984\n",
      "Epoch [500/500] | Train Loss: 0.781694 | Val Loss: 3.040572\n",
      "Epoch [100/500] | Train Loss: 1.736952 | Val Loss: 7.439970\n",
      "Epoch [200/500] | Train Loss: 1.393756 | Val Loss: 8.246209\n",
      "Epoch [300/500] | Train Loss: 1.316492 | Val Loss: 8.802882\n",
      "Epoch [400/500] | Train Loss: 1.281426 | Val Loss: 8.116162\n",
      "Epoch [500/500] | Train Loss: 1.230317 | Val Loss: 8.426349\n",
      "Epoch [100/500] | Train Loss: 3.058624 | Val Loss: 8.982763\n",
      "Epoch [200/500] | Train Loss: 2.789078 | Val Loss: 9.495111\n",
      "Epoch [300/500] | Train Loss: 2.952736 | Val Loss: 9.265062\n",
      "Epoch [400/500] | Train Loss: 2.631577 | Val Loss: 9.493332\n",
      "Epoch [500/500] | Train Loss: 2.544681 | Val Loss: 9.635878\n",
      "Epoch [100/500] | Train Loss: 4.421873 | Val Loss: 5.248513\n",
      "Epoch [200/500] | Train Loss: 3.841091 | Val Loss: 5.407025\n",
      "Epoch [300/500] | Train Loss: 3.925721 | Val Loss: 5.337000\n",
      "Epoch [400/500] | Train Loss: 3.552574 | Val Loss: 5.489826\n",
      "Epoch [500/500] | Train Loss: 3.707118 | Val Loss: 5.405629\n",
      "Epoch [100/500] | Train Loss: 4.366752 | Val Loss: 1.869731\n",
      "Epoch [200/500] | Train Loss: 3.992600 | Val Loss: 1.904034\n",
      "Epoch [300/500] | Train Loss: 3.929467 | Val Loss: 1.917381\n",
      "Epoch [400/500] | Train Loss: 3.922539 | Val Loss: 1.988299\n",
      "Epoch [500/500] | Train Loss: 3.997396 | Val Loss: 1.963914\n",
      "Epoch [100/500] | Train Loss: 1.276165 | Val Loss: 2.710388\n",
      "Epoch [200/500] | Train Loss: 1.094757 | Val Loss: 2.890176\n",
      "Epoch [300/500] | Train Loss: 0.797493 | Val Loss: 3.048465\n",
      "Epoch [400/500] | Train Loss: 0.700083 | Val Loss: 3.199609\n",
      "Epoch [500/500] | Train Loss: 0.617058 | Val Loss: 3.530802\n",
      "Epoch [100/500] | Train Loss: 1.882722 | Val Loss: 7.062909\n",
      "Epoch [200/500] | Train Loss: 1.630761 | Val Loss: 7.478770\n",
      "Epoch [300/500] | Train Loss: 1.495499 | Val Loss: 7.835593\n",
      "Epoch [400/500] | Train Loss: 1.362118 | Val Loss: 8.147929\n",
      "Epoch [500/500] | Train Loss: 1.230841 | Val Loss: 8.658962\n",
      "Epoch [100/500] | Train Loss: 3.550169 | Val Loss: 8.694023\n",
      "Epoch [200/500] | Train Loss: 3.132901 | Val Loss: 9.006360\n",
      "Epoch [300/500] | Train Loss: 2.812279 | Val Loss: 9.061323\n",
      "Epoch [400/500] | Train Loss: 2.494838 | Val Loss: 9.614782\n",
      "Epoch [500/500] | Train Loss: 2.350590 | Val Loss: 10.045009\n",
      "Epoch [100/500] | Train Loss: 4.588157 | Val Loss: 5.188947\n",
      "Epoch [200/500] | Train Loss: 3.967670 | Val Loss: 5.223072\n",
      "Epoch [300/500] | Train Loss: 3.933569 | Val Loss: 5.232585\n",
      "Epoch [400/500] | Train Loss: 3.684550 | Val Loss: 5.322905\n",
      "Epoch [500/500] | Train Loss: 3.491694 | Val Loss: 5.487190\n",
      "Epoch [100/500] | Train Loss: 4.601789 | Val Loss: 1.804106\n",
      "Epoch [200/500] | Train Loss: 4.319329 | Val Loss: 1.923049\n",
      "Epoch [300/500] | Train Loss: 3.948787 | Val Loss: 2.031514\n",
      "Epoch [400/500] | Train Loss: 3.882823 | Val Loss: 2.085384\n",
      "Epoch [500/500] | Train Loss: 3.470958 | Val Loss: 2.127873\n",
      "Epoch [100/500] | Train Loss: 0.735297 | Val Loss: 3.250759\n",
      "Epoch [200/500] | Train Loss: 0.522753 | Val Loss: 3.329346\n",
      "Epoch [300/500] | Train Loss: 0.290263 | Val Loss: 3.411486\n",
      "Epoch [400/500] | Train Loss: 0.378994 | Val Loss: 3.590487\n",
      "Epoch [500/500] | Train Loss: 0.392490 | Val Loss: 3.650486\n",
      "Epoch [100/500] | Train Loss: 1.247451 | Val Loss: 8.635150\n",
      "Epoch [200/500] | Train Loss: 0.835432 | Val Loss: 8.582434\n",
      "Epoch [300/500] | Train Loss: 0.786674 | Val Loss: 8.916689\n",
      "Epoch [400/500] | Train Loss: 0.743949 | Val Loss: 9.135871\n",
      "Epoch [500/500] | Train Loss: 0.646076 | Val Loss: 8.381609\n",
      "Epoch [100/500] | Train Loss: 2.632365 | Val Loss: 10.052269\n",
      "Epoch [200/500] | Train Loss: 1.938600 | Val Loss: 9.932927\n",
      "Epoch [300/500] | Train Loss: 1.846710 | Val Loss: 10.350386\n",
      "Epoch [400/500] | Train Loss: 1.837526 | Val Loss: 10.488996\n",
      "Epoch [500/500] | Train Loss: 1.513682 | Val Loss: 10.861030\n",
      "Epoch [100/500] | Train Loss: 3.969291 | Val Loss: 5.418896\n",
      "Epoch [200/500] | Train Loss: 3.123123 | Val Loss: 5.897267\n",
      "Epoch [300/500] | Train Loss: 2.540641 | Val Loss: 6.378077\n",
      "Epoch [400/500] | Train Loss: 2.398339 | Val Loss: 6.328680\n",
      "Epoch [500/500] | Train Loss: 2.480071 | Val Loss: 6.296696\n",
      "Epoch [100/500] | Train Loss: 3.745904 | Val Loss: 1.919952\n",
      "Epoch [200/500] | Train Loss: 3.399831 | Val Loss: 2.052868\n",
      "Epoch [300/500] | Train Loss: 2.979791 | Val Loss: 2.047564\n",
      "Epoch [400/500] | Train Loss: 3.028622 | Val Loss: 2.071953\n",
      "Epoch [500/500] | Train Loss: 2.714252 | Val Loss: 2.167621\n",
      "Epoch [100/500] | Train Loss: 1.556434 | Val Loss: 2.534553\n",
      "Epoch [200/500] | Train Loss: 1.322960 | Val Loss: 2.571061\n",
      "Epoch [300/500] | Train Loss: 1.070138 | Val Loss: 2.682606\n",
      "Epoch [400/500] | Train Loss: 1.091749 | Val Loss: 2.772197\n",
      "Epoch [500/500] | Train Loss: 0.866945 | Val Loss: 2.871495\n",
      "Epoch [100/500] | Train Loss: 1.985902 | Val Loss: 7.130352\n",
      "Epoch [200/500] | Train Loss: 1.820735 | Val Loss: 7.331994\n",
      "Epoch [300/500] | Train Loss: 1.587356 | Val Loss: 7.569747\n",
      "Epoch [400/500] | Train Loss: 1.540531 | Val Loss: 8.045582\n",
      "Epoch [500/500] | Train Loss: 1.325453 | Val Loss: 8.162819\n",
      "Epoch [100/500] | Train Loss: 3.629846 | Val Loss: 8.608120\n",
      "Epoch [200/500] | Train Loss: 3.282114 | Val Loss: 8.809772\n",
      "Epoch [300/500] | Train Loss: 3.145204 | Val Loss: 8.813733\n",
      "Epoch [400/500] | Train Loss: 2.821937 | Val Loss: 9.244439\n",
      "Epoch [500/500] | Train Loss: 2.711546 | Val Loss: 9.235314\n",
      "Epoch [100/500] | Train Loss: 4.681264 | Val Loss: 5.240027\n",
      "Epoch [200/500] | Train Loss: 4.367402 | Val Loss: 5.252549\n",
      "Epoch [300/500] | Train Loss: 4.201778 | Val Loss: 5.338386\n",
      "Epoch [400/500] | Train Loss: 3.975389 | Val Loss: 5.445937\n",
      "Epoch [500/500] | Train Loss: 3.907728 | Val Loss: 5.498011\n",
      "Epoch [100/500] | Train Loss: 4.784717 | Val Loss: 1.806543\n",
      "Epoch [200/500] | Train Loss: 4.489697 | Val Loss: 1.905757\n",
      "Epoch [300/500] | Train Loss: 4.353223 | Val Loss: 1.960186\n",
      "Epoch [400/500] | Train Loss: 4.222571 | Val Loss: 1.994398\n",
      "Epoch [500/500] | Train Loss: 4.134960 | Val Loss: 2.015614\n",
      "Epoch [100/500] | Train Loss: 0.986662 | Val Loss: 2.808861\n",
      "Epoch [200/500] | Train Loss: 0.893774 | Val Loss: 3.068283\n",
      "Epoch [300/500] | Train Loss: 0.720946 | Val Loss: 3.034119\n",
      "Epoch [400/500] | Train Loss: 0.564584 | Val Loss: 3.047804\n",
      "Epoch [500/500] | Train Loss: 0.616230 | Val Loss: 3.142797\n",
      "Epoch [100/500] | Train Loss: 1.457291 | Val Loss: 7.672501\n",
      "Epoch [200/500] | Train Loss: 1.291129 | Val Loss: 8.126544\n",
      "Epoch [300/500] | Train Loss: 1.277602 | Val Loss: 8.087128\n",
      "Epoch [400/500] | Train Loss: 1.130331 | Val Loss: 8.018898\n",
      "Epoch [500/500] | Train Loss: 1.116283 | Val Loss: 8.072055\n",
      "Epoch [100/500] | Train Loss: 3.128443 | Val Loss: 9.230931\n",
      "Epoch [200/500] | Train Loss: 2.582149 | Val Loss: 9.620392\n",
      "Epoch [300/500] | Train Loss: 2.360480 | Val Loss: 9.737420\n",
      "Epoch [400/500] | Train Loss: 2.122244 | Val Loss: 9.724626\n",
      "Epoch [500/500] | Train Loss: 2.044175 | Val Loss: 10.350842\n",
      "Epoch [100/500] | Train Loss: 4.000529 | Val Loss: 5.404170\n",
      "Epoch [200/500] | Train Loss: 3.484365 | Val Loss: 5.460411\n",
      "Epoch [300/500] | Train Loss: 3.338758 | Val Loss: 5.616342\n",
      "Epoch [400/500] | Train Loss: 3.185278 | Val Loss: 5.802274\n",
      "Epoch [500/500] | Train Loss: 3.041292 | Val Loss: 5.813640\n",
      "Epoch [100/500] | Train Loss: 4.240543 | Val Loss: 1.941110\n",
      "Epoch [200/500] | Train Loss: 3.912928 | Val Loss: 1.921310\n",
      "Epoch [300/500] | Train Loss: 3.863101 | Val Loss: 1.961048\n",
      "Epoch [400/500] | Train Loss: 3.531458 | Val Loss: 1.940765\n",
      "Epoch [500/500] | Train Loss: 3.341951 | Val Loss: 1.899561\n",
      "[Year=1935] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=5.287065 Test MSE=0.882330\n",
      "Year 1935 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 3.574791 | Val Loss: 6.818789\n",
      "Epoch [200/500] | Train Loss: 3.265372 | Val Loss: 6.879048\n",
      "Epoch [300/500] | Train Loss: 2.574510 | Val Loss: 7.584674\n",
      "Epoch [400/500] | Train Loss: 2.549094 | Val Loss: 7.774463\n",
      "Epoch [500/500] | Train Loss: 1.817341 | Val Loss: 7.738730\n",
      "Epoch [100/500] | Train Loss: 4.957726 | Val Loss: 7.892620\n",
      "Epoch [200/500] | Train Loss: 4.254748 | Val Loss: 8.214084\n",
      "Epoch [300/500] | Train Loss: 4.007996 | Val Loss: 8.477013\n",
      "Epoch [400/500] | Train Loss: 3.677832 | Val Loss: 8.525001\n",
      "Epoch [500/500] | Train Loss: 3.537137 | Val Loss: 8.729365\n",
      "Epoch [100/500] | Train Loss: 5.703901 | Val Loss: 4.331614\n",
      "Epoch [200/500] | Train Loss: 5.343350 | Val Loss: 4.582878\n",
      "Epoch [300/500] | Train Loss: 5.041386 | Val Loss: 4.835630\n",
      "Epoch [400/500] | Train Loss: 4.782649 | Val Loss: 4.752452\n",
      "Epoch [500/500] | Train Loss: 4.565385 | Val Loss: 4.944154\n",
      "Epoch [100/500] | Train Loss: 5.404864 | Val Loss: 1.700824\n",
      "Epoch [200/500] | Train Loss: 5.146724 | Val Loss: 1.864562\n",
      "Epoch [300/500] | Train Loss: 4.730667 | Val Loss: 1.957208\n",
      "Epoch [400/500] | Train Loss: 4.669368 | Val Loss: 1.979751\n",
      "Epoch [500/500] | Train Loss: 4.424219 | Val Loss: 2.035830\n",
      "Epoch [100/500] | Train Loss: 4.741426 | Val Loss: 0.860345\n",
      "Epoch [200/500] | Train Loss: 4.328970 | Val Loss: 0.895359\n",
      "Epoch [300/500] | Train Loss: 4.196369 | Val Loss: 0.883453\n",
      "Epoch [400/500] | Train Loss: 4.048628 | Val Loss: 0.874302\n",
      "Epoch [500/500] | Train Loss: 3.904457 | Val Loss: 0.887369\n",
      "Epoch [100/500] | Train Loss: 2.103683 | Val Loss: 7.994808\n",
      "Epoch [200/500] | Train Loss: 1.272176 | Val Loss: 8.259430\n",
      "Epoch [300/500] | Train Loss: 1.231631 | Val Loss: 8.584798\n",
      "Epoch [400/500] | Train Loss: 1.159814 | Val Loss: 8.262292\n",
      "Epoch [500/500] | Train Loss: 1.014869 | Val Loss: 8.949286\n",
      "Epoch [100/500] | Train Loss: 3.563329 | Val Loss: 8.680106\n",
      "Epoch [200/500] | Train Loss: 2.724284 | Val Loss: 8.919048\n",
      "Epoch [300/500] | Train Loss: 2.447131 | Val Loss: 8.994482\n",
      "Epoch [400/500] | Train Loss: 2.073587 | Val Loss: 9.378183\n",
      "Epoch [500/500] | Train Loss: 2.313209 | Val Loss: 9.626915\n",
      "Epoch [100/500] | Train Loss: 4.443883 | Val Loss: 4.661333\n",
      "Epoch [200/500] | Train Loss: 3.632121 | Val Loss: 4.909475\n",
      "Epoch [300/500] | Train Loss: 3.375925 | Val Loss: 4.996953\n",
      "Epoch [400/500] | Train Loss: 3.062516 | Val Loss: 5.017900\n",
      "Epoch [500/500] | Train Loss: 3.170540 | Val Loss: 5.385344\n",
      "Epoch [100/500] | Train Loss: 4.653508 | Val Loss: 1.966848\n",
      "Epoch [200/500] | Train Loss: 3.824972 | Val Loss: 2.041724\n",
      "Epoch [300/500] | Train Loss: 3.285843 | Val Loss: 2.147562\n",
      "Epoch [400/500] | Train Loss: 3.310529 | Val Loss: 2.214228\n",
      "Epoch [500/500] | Train Loss: 3.321496 | Val Loss: 2.050802\n",
      "Epoch [100/500] | Train Loss: 4.134150 | Val Loss: 0.857975\n",
      "Epoch [200/500] | Train Loss: 3.754718 | Val Loss: 0.864703\n",
      "Epoch [300/500] | Train Loss: 3.457329 | Val Loss: 0.849977\n",
      "Epoch [400/500] | Train Loss: 3.083149 | Val Loss: 0.863966\n",
      "Epoch [500/500] | Train Loss: 3.095100 | Val Loss: 0.884352\n",
      "Epoch [100/500] | Train Loss: 3.768589 | Val Loss: 6.758958\n",
      "Epoch [200/500] | Train Loss: 3.122279 | Val Loss: 6.675422\n",
      "Epoch [300/500] | Train Loss: 2.674688 | Val Loss: 6.774874\n",
      "Epoch [400/500] | Train Loss: 2.591876 | Val Loss: 6.944342\n",
      "Epoch [500/500] | Train Loss: 2.442137 | Val Loss: 6.907413\n",
      "Epoch [100/500] | Train Loss: 5.025393 | Val Loss: 7.947761\n",
      "Epoch [200/500] | Train Loss: 4.823721 | Val Loss: 8.151493\n",
      "Epoch [300/500] | Train Loss: 4.609534 | Val Loss: 8.174638\n",
      "Epoch [400/500] | Train Loss: 4.360144 | Val Loss: 8.261662\n",
      "Epoch [500/500] | Train Loss: 4.101532 | Val Loss: 8.500340\n",
      "Epoch [100/500] | Train Loss: 5.906775 | Val Loss: 4.363259\n",
      "Epoch [200/500] | Train Loss: 5.680725 | Val Loss: 4.333206\n",
      "Epoch [300/500] | Train Loss: 5.424072 | Val Loss: 4.246138\n",
      "Epoch [400/500] | Train Loss: 5.303206 | Val Loss: 4.223883\n",
      "Epoch [500/500] | Train Loss: 5.081518 | Val Loss: 4.259920\n",
      "Epoch [100/500] | Train Loss: 5.609643 | Val Loss: 1.683116\n",
      "Epoch [200/500] | Train Loss: 5.422804 | Val Loss: 1.762698\n",
      "Epoch [300/500] | Train Loss: 5.227262 | Val Loss: 1.775103\n",
      "Epoch [400/500] | Train Loss: 5.141075 | Val Loss: 1.818629\n",
      "Epoch [500/500] | Train Loss: 5.069859 | Val Loss: 1.800478\n",
      "Epoch [100/500] | Train Loss: 4.781839 | Val Loss: 0.851963\n",
      "Epoch [200/500] | Train Loss: 4.650319 | Val Loss: 0.886567\n",
      "Epoch [300/500] | Train Loss: 4.530184 | Val Loss: 0.890112\n",
      "Epoch [400/500] | Train Loss: 4.378214 | Val Loss: 0.899289\n",
      "Epoch [500/500] | Train Loss: 4.227059 | Val Loss: 0.914102\n",
      "Epoch [100/500] | Train Loss: 2.551390 | Val Loss: 6.941382\n",
      "Epoch [200/500] | Train Loss: 2.113972 | Val Loss: 7.508918\n",
      "Epoch [300/500] | Train Loss: 1.801491 | Val Loss: 7.629792\n",
      "Epoch [400/500] | Train Loss: 1.877590 | Val Loss: 8.074713\n",
      "Epoch [500/500] | Train Loss: 1.877797 | Val Loss: 7.694324\n",
      "Epoch [100/500] | Train Loss: 4.287825 | Val Loss: 8.062717\n",
      "Epoch [200/500] | Train Loss: 3.817819 | Val Loss: 8.053593\n",
      "Epoch [300/500] | Train Loss: 3.890635 | Val Loss: 8.388446\n",
      "Epoch [400/500] | Train Loss: 3.347747 | Val Loss: 8.455993\n",
      "Epoch [500/500] | Train Loss: 3.210943 | Val Loss: 8.840871\n",
      "Epoch [100/500] | Train Loss: 5.075435 | Val Loss: 4.625597\n",
      "Epoch [200/500] | Train Loss: 4.934505 | Val Loss: 4.824561\n",
      "Epoch [300/500] | Train Loss: 4.521036 | Val Loss: 5.031359\n",
      "Epoch [400/500] | Train Loss: 4.120163 | Val Loss: 5.358429\n",
      "Epoch [500/500] | Train Loss: 4.164132 | Val Loss: 5.154597\n",
      "Epoch [100/500] | Train Loss: 5.026258 | Val Loss: 1.777104\n",
      "Epoch [200/500] | Train Loss: 4.761315 | Val Loss: 1.904021\n",
      "Epoch [300/500] | Train Loss: 4.482941 | Val Loss: 1.850595\n",
      "Epoch [400/500] | Train Loss: 4.643668 | Val Loss: 1.851451\n",
      "Epoch [500/500] | Train Loss: 4.385930 | Val Loss: 1.837120\n",
      "Epoch [100/500] | Train Loss: 4.347947 | Val Loss: 0.874051\n",
      "Epoch [200/500] | Train Loss: 4.011462 | Val Loss: 0.907701\n",
      "Epoch [300/500] | Train Loss: 3.923224 | Val Loss: 0.938145\n",
      "Epoch [400/500] | Train Loss: 3.840464 | Val Loss: 0.960664\n",
      "Epoch [500/500] | Train Loss: 3.697352 | Val Loss: 0.955590\n",
      "Epoch [100/500] | Train Loss: 3.070573 | Val Loss: 6.997332\n",
      "Epoch [200/500] | Train Loss: 2.451344 | Val Loss: 7.347550\n",
      "Epoch [300/500] | Train Loss: 2.015450 | Val Loss: 7.809107\n",
      "Epoch [400/500] | Train Loss: 1.939987 | Val Loss: 7.989847\n",
      "Epoch [500/500] | Train Loss: 1.404282 | Val Loss: 8.103140\n",
      "Epoch [100/500] | Train Loss: 4.940028 | Val Loss: 8.199168\n",
      "Epoch [200/500] | Train Loss: 4.428331 | Val Loss: 8.516198\n",
      "Epoch [300/500] | Train Loss: 3.857186 | Val Loss: 8.987965\n",
      "Epoch [400/500] | Train Loss: 3.439977 | Val Loss: 9.405035\n",
      "Epoch [500/500] | Train Loss: 3.082694 | Val Loss: 10.061951\n",
      "Epoch [100/500] | Train Loss: 5.669342 | Val Loss: 4.200404\n",
      "Epoch [200/500] | Train Loss: 5.228719 | Val Loss: 4.325255\n",
      "Epoch [300/500] | Train Loss: 4.690920 | Val Loss: 4.525813\n",
      "Epoch [400/500] | Train Loss: 4.594412 | Val Loss: 4.719232\n",
      "Epoch [500/500] | Train Loss: 4.455408 | Val Loss: 4.729782\n",
      "Epoch [100/500] | Train Loss: 5.333763 | Val Loss: 1.695158\n",
      "Epoch [200/500] | Train Loss: 4.935934 | Val Loss: 1.868614\n",
      "Epoch [300/500] | Train Loss: 4.572740 | Val Loss: 1.943294\n",
      "Epoch [400/500] | Train Loss: 4.325366 | Val Loss: 2.012426\n",
      "Epoch [500/500] | Train Loss: 4.169393 | Val Loss: 2.079440\n",
      "Epoch [100/500] | Train Loss: 4.633805 | Val Loss: 0.869143\n",
      "Epoch [200/500] | Train Loss: 4.228121 | Val Loss: 0.888126\n",
      "Epoch [300/500] | Train Loss: 3.949132 | Val Loss: 0.883520\n",
      "Epoch [400/500] | Train Loss: 3.700716 | Val Loss: 0.899194\n",
      "Epoch [500/500] | Train Loss: 3.591658 | Val Loss: 0.926856\n",
      "Epoch [100/500] | Train Loss: 1.818801 | Val Loss: 8.190516\n",
      "Epoch [200/500] | Train Loss: 1.400067 | Val Loss: 8.651790\n",
      "Epoch [300/500] | Train Loss: 1.164557 | Val Loss: 8.544466\n",
      "Epoch [400/500] | Train Loss: 0.888919 | Val Loss: 8.684831\n",
      "Epoch [500/500] | Train Loss: 0.756638 | Val Loss: 8.329644\n",
      "Epoch [100/500] | Train Loss: 3.289383 | Val Loss: 9.074807\n",
      "Epoch [200/500] | Train Loss: 2.305454 | Val Loss: 9.813901\n",
      "Epoch [300/500] | Train Loss: 2.156146 | Val Loss: 10.264143\n",
      "Epoch [400/500] | Train Loss: 1.893746 | Val Loss: 10.416830\n",
      "Epoch [500/500] | Train Loss: 2.162017 | Val Loss: 9.904962\n",
      "Epoch [100/500] | Train Loss: 4.339829 | Val Loss: 4.775964\n",
      "Epoch [200/500] | Train Loss: 3.579385 | Val Loss: 4.837561\n",
      "Epoch [300/500] | Train Loss: 3.556904 | Val Loss: 4.967267\n",
      "Epoch [400/500] | Train Loss: 2.972195 | Val Loss: 5.018265\n",
      "Epoch [500/500] | Train Loss: 2.829713 | Val Loss: 4.958203\n",
      "Epoch [100/500] | Train Loss: 4.105849 | Val Loss: 1.975320\n",
      "Epoch [200/500] | Train Loss: 3.543384 | Val Loss: 2.057314\n",
      "Epoch [300/500] | Train Loss: 3.111984 | Val Loss: 2.155543\n",
      "Epoch [400/500] | Train Loss: 2.839818 | Val Loss: 2.311532\n",
      "Epoch [500/500] | Train Loss: 2.747237 | Val Loss: 2.312502\n",
      "Epoch [100/500] | Train Loss: 3.890682 | Val Loss: 0.877175\n",
      "Epoch [200/500] | Train Loss: 3.266324 | Val Loss: 0.853058\n",
      "Epoch [300/500] | Train Loss: 2.953240 | Val Loss: 0.937051\n",
      "Epoch [400/500] | Train Loss: 2.922605 | Val Loss: 0.935531\n",
      "Epoch [500/500] | Train Loss: 2.695959 | Val Loss: 0.894690\n",
      "Epoch [100/500] | Train Loss: 3.795255 | Val Loss: 6.804425\n",
      "Epoch [200/500] | Train Loss: 3.308401 | Val Loss: 6.965565\n",
      "Epoch [300/500] | Train Loss: 2.884953 | Val Loss: 7.333736\n",
      "Epoch [400/500] | Train Loss: 2.335427 | Val Loss: 7.636680\n",
      "Epoch [500/500] | Train Loss: 2.227142 | Val Loss: 7.530840\n",
      "Epoch [100/500] | Train Loss: 5.300651 | Val Loss: 7.714909\n",
      "Epoch [200/500] | Train Loss: 4.719878 | Val Loss: 8.087563\n",
      "Epoch [300/500] | Train Loss: 4.302959 | Val Loss: 8.333982\n",
      "Epoch [400/500] | Train Loss: 4.052345 | Val Loss: 8.456553\n",
      "Epoch [500/500] | Train Loss: 3.811779 | Val Loss: 8.585188\n",
      "Epoch [100/500] | Train Loss: 5.800431 | Val Loss: 4.383190\n",
      "Epoch [200/500] | Train Loss: 5.569817 | Val Loss: 4.395462\n",
      "Epoch [300/500] | Train Loss: 5.392187 | Val Loss: 4.475115\n",
      "Epoch [400/500] | Train Loss: 5.040329 | Val Loss: 4.415596\n",
      "Epoch [500/500] | Train Loss: 4.951949 | Val Loss: 4.364038\n",
      "Epoch [100/500] | Train Loss: 5.557756 | Val Loss: 1.659161\n",
      "Epoch [200/500] | Train Loss: 5.248666 | Val Loss: 1.783266\n",
      "Epoch [300/500] | Train Loss: 5.128307 | Val Loss: 1.829728\n",
      "Epoch [400/500] | Train Loss: 4.948394 | Val Loss: 1.785862\n",
      "Epoch [500/500] | Train Loss: 4.708512 | Val Loss: 1.855388\n",
      "Epoch [100/500] | Train Loss: 4.782749 | Val Loss: 0.850412\n",
      "Epoch [200/500] | Train Loss: 4.527112 | Val Loss: 0.862311\n",
      "Epoch [300/500] | Train Loss: 4.293295 | Val Loss: 0.874673\n",
      "Epoch [400/500] | Train Loss: 4.205771 | Val Loss: 0.871686\n",
      "Epoch [500/500] | Train Loss: 4.177044 | Val Loss: 0.901812\n",
      "Epoch [100/500] | Train Loss: 2.600378 | Val Loss: 7.764765\n",
      "Epoch [200/500] | Train Loss: 2.062519 | Val Loss: 7.870352\n",
      "Epoch [300/500] | Train Loss: 1.664898 | Val Loss: 7.695986\n",
      "Epoch [400/500] | Train Loss: 1.655137 | Val Loss: 8.044308\n",
      "Epoch [500/500] | Train Loss: 1.443036 | Val Loss: 8.507030\n",
      "Epoch [100/500] | Train Loss: 4.374280 | Val Loss: 7.972849\n",
      "Epoch [200/500] | Train Loss: 3.652744 | Val Loss: 8.183732\n",
      "Epoch [300/500] | Train Loss: 3.262865 | Val Loss: 8.087295\n",
      "Epoch [400/500] | Train Loss: 3.047120 | Val Loss: 8.618322\n",
      "Epoch [500/500] | Train Loss: 3.144953 | Val Loss: 8.756576\n",
      "Epoch [100/500] | Train Loss: 5.148016 | Val Loss: 4.538741\n",
      "Epoch [200/500] | Train Loss: 4.336926 | Val Loss: 4.647765\n",
      "Epoch [300/500] | Train Loss: 4.059315 | Val Loss: 4.537586\n",
      "Epoch [400/500] | Train Loss: 3.799349 | Val Loss: 4.764931\n",
      "Epoch [500/500] | Train Loss: 3.892867 | Val Loss: 4.659243\n",
      "Epoch [100/500] | Train Loss: 4.858237 | Val Loss: 1.808850\n",
      "Epoch [200/500] | Train Loss: 4.180641 | Val Loss: 1.933566\n",
      "Epoch [300/500] | Train Loss: 3.955775 | Val Loss: 2.069987\n",
      "Epoch [400/500] | Train Loss: 3.615922 | Val Loss: 2.069992\n",
      "Epoch [500/500] | Train Loss: 3.492566 | Val Loss: 2.303116\n",
      "Epoch [100/500] | Train Loss: 4.237083 | Val Loss: 0.845026\n",
      "Epoch [200/500] | Train Loss: 4.049629 | Val Loss: 0.861807\n",
      "Epoch [300/500] | Train Loss: 3.840383 | Val Loss: 0.856690\n",
      "Epoch [400/500] | Train Loss: 3.444673 | Val Loss: 0.867349\n",
      "Epoch [500/500] | Train Loss: 3.727632 | Val Loss: 0.900008\n",
      "[Year=1936] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=4.476451 Test MSE=0.772208\n",
      "Year 1936 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 7.337883 | Val Loss: 6.794752\n",
      "Epoch [200/500] | Train Loss: 6.214023 | Val Loss: 7.443528\n",
      "Epoch [300/500] | Train Loss: 6.127702 | Val Loss: 7.750319\n",
      "Epoch [400/500] | Train Loss: 5.483287 | Val Loss: 7.890597\n",
      "Epoch [500/500] | Train Loss: 4.776765 | Val Loss: 7.788911\n",
      "Epoch [100/500] | Train Loss: 6.976364 | Val Loss: 3.305695\n",
      "Epoch [200/500] | Train Loss: 6.250894 | Val Loss: 3.771173\n",
      "Epoch [300/500] | Train Loss: 5.923847 | Val Loss: 3.805215\n",
      "Epoch [400/500] | Train Loss: 5.565338 | Val Loss: 3.847304\n",
      "Epoch [500/500] | Train Loss: 5.081733 | Val Loss: 3.969510\n",
      "Epoch [100/500] | Train Loss: 5.689435 | Val Loss: 1.545002\n",
      "Epoch [200/500] | Train Loss: 5.318709 | Val Loss: 1.704808\n",
      "Epoch [300/500] | Train Loss: 4.916883 | Val Loss: 1.757710\n",
      "Epoch [400/500] | Train Loss: 4.896767 | Val Loss: 1.756446\n",
      "Epoch [500/500] | Train Loss: 4.645811 | Val Loss: 1.816400\n",
      "Epoch [100/500] | Train Loss: 4.645727 | Val Loss: 0.768415\n",
      "Epoch [200/500] | Train Loss: 4.252499 | Val Loss: 0.781096\n",
      "Epoch [300/500] | Train Loss: 4.061471 | Val Loss: 0.794585\n",
      "Epoch [400/500] | Train Loss: 3.939653 | Val Loss: 0.808186\n",
      "Epoch [500/500] | Train Loss: 3.736324 | Val Loss: 0.842676\n",
      "Epoch [100/500] | Train Loss: 3.816304 | Val Loss: 0.818703\n",
      "Epoch [200/500] | Train Loss: 3.559722 | Val Loss: 0.846870\n",
      "Epoch [300/500] | Train Loss: 3.343203 | Val Loss: 0.854744\n",
      "Epoch [400/500] | Train Loss: 3.226784 | Val Loss: 0.849357\n",
      "Epoch [500/500] | Train Loss: 3.270532 | Val Loss: 0.858021\n",
      "Epoch [100/500] | Train Loss: 5.196576 | Val Loss: 8.110962\n",
      "Epoch [200/500] | Train Loss: 3.650823 | Val Loss: 8.744005\n",
      "Epoch [300/500] | Train Loss: 3.677477 | Val Loss: 9.001612\n",
      "Epoch [400/500] | Train Loss: 2.739384 | Val Loss: 9.314342\n",
      "Epoch [500/500] | Train Loss: 2.547257 | Val Loss: 9.383921\n",
      "Epoch [100/500] | Train Loss: 5.348471 | Val Loss: 4.027338\n",
      "Epoch [200/500] | Train Loss: 4.607584 | Val Loss: 4.723639\n",
      "Epoch [300/500] | Train Loss: 3.630030 | Val Loss: 4.986937\n",
      "Epoch [400/500] | Train Loss: 3.301367 | Val Loss: 5.175035\n",
      "Epoch [500/500] | Train Loss: 3.409846 | Val Loss: 5.183024\n",
      "Epoch [100/500] | Train Loss: 4.700610 | Val Loss: 1.851633\n",
      "Epoch [200/500] | Train Loss: 4.077910 | Val Loss: 1.962310\n",
      "Epoch [300/500] | Train Loss: 3.921381 | Val Loss: 1.932895\n",
      "Epoch [400/500] | Train Loss: 3.196437 | Val Loss: 2.109219\n",
      "Epoch [500/500] | Train Loss: 3.070823 | Val Loss: 2.100908\n",
      "Epoch [100/500] | Train Loss: 3.735588 | Val Loss: 0.801261\n",
      "Epoch [200/500] | Train Loss: 3.210370 | Val Loss: 0.803925\n",
      "Epoch [300/500] | Train Loss: 3.043684 | Val Loss: 0.788364\n",
      "Epoch [400/500] | Train Loss: 2.771884 | Val Loss: 0.905809\n",
      "Epoch [500/500] | Train Loss: 2.992434 | Val Loss: 0.957801\n",
      "Epoch [100/500] | Train Loss: 3.320971 | Val Loss: 0.845810\n",
      "Epoch [200/500] | Train Loss: 2.719235 | Val Loss: 0.875614\n",
      "Epoch [300/500] | Train Loss: 2.536557 | Val Loss: 0.868486\n",
      "Epoch [400/500] | Train Loss: 2.443704 | Val Loss: 0.947286\n",
      "Epoch [500/500] | Train Loss: 2.541694 | Val Loss: 0.941163\n",
      "Epoch [100/500] | Train Loss: 7.680172 | Val Loss: 6.835706\n",
      "Epoch [200/500] | Train Loss: 7.051365 | Val Loss: 6.862697\n",
      "Epoch [300/500] | Train Loss: 6.862272 | Val Loss: 7.035745\n",
      "Epoch [400/500] | Train Loss: 5.923985 | Val Loss: 7.217836\n",
      "Epoch [500/500] | Train Loss: 6.054476 | Val Loss: 7.354929\n",
      "Epoch [100/500] | Train Loss: 7.086920 | Val Loss: 3.191503\n",
      "Epoch [200/500] | Train Loss: 6.797588 | Val Loss: 3.315114\n",
      "Epoch [300/500] | Train Loss: 6.329930 | Val Loss: 3.469913\n",
      "Epoch [400/500] | Train Loss: 6.266646 | Val Loss: 3.638574\n",
      "Epoch [500/500] | Train Loss: 5.919815 | Val Loss: 3.803222\n",
      "Epoch [100/500] | Train Loss: 5.801396 | Val Loss: 1.432725\n",
      "Epoch [200/500] | Train Loss: 5.655688 | Val Loss: 1.527778\n",
      "Epoch [300/500] | Train Loss: 5.294896 | Val Loss: 1.565948\n",
      "Epoch [400/500] | Train Loss: 5.139627 | Val Loss: 1.626601\n",
      "Epoch [500/500] | Train Loss: 5.061225 | Val Loss: 1.609852\n",
      "Epoch [100/500] | Train Loss: 4.800933 | Val Loss: 0.752324\n",
      "Epoch [200/500] | Train Loss: 4.556851 | Val Loss: 0.780087\n",
      "Epoch [300/500] | Train Loss: 4.633858 | Val Loss: 0.794928\n",
      "Epoch [400/500] | Train Loss: 4.387719 | Val Loss: 0.777391\n",
      "Epoch [500/500] | Train Loss: 4.323373 | Val Loss: 0.793621\n",
      "Epoch [100/500] | Train Loss: 3.948588 | Val Loss: 0.801856\n",
      "Epoch [200/500] | Train Loss: 3.904702 | Val Loss: 0.813065\n",
      "Epoch [300/500] | Train Loss: 3.817533 | Val Loss: 0.818644\n",
      "Epoch [400/500] | Train Loss: 3.591500 | Val Loss: 0.819020\n",
      "Epoch [500/500] | Train Loss: 3.581982 | Val Loss: 0.820679\n",
      "Epoch [100/500] | Train Loss: 6.447549 | Val Loss: 7.037107\n",
      "Epoch [200/500] | Train Loss: 6.237009 | Val Loss: 7.385190\n",
      "Epoch [300/500] | Train Loss: 4.853851 | Val Loss: 8.138187\n",
      "Epoch [400/500] | Train Loss: 4.320857 | Val Loss: 8.444729\n",
      "Epoch [500/500] | Train Loss: 4.149227 | Val Loss: 8.175426\n",
      "Epoch [100/500] | Train Loss: 6.384537 | Val Loss: 3.739385\n",
      "Epoch [200/500] | Train Loss: 5.539771 | Val Loss: 3.908919\n",
      "Epoch [300/500] | Train Loss: 4.704939 | Val Loss: 3.619067\n",
      "Epoch [400/500] | Train Loss: 5.391671 | Val Loss: 3.749929\n",
      "Epoch [500/500] | Train Loss: 4.425567 | Val Loss: 3.844393\n",
      "Epoch [100/500] | Train Loss: 5.439871 | Val Loss: 1.533677\n",
      "Epoch [200/500] | Train Loss: 4.636967 | Val Loss: 1.701596\n",
      "Epoch [300/500] | Train Loss: 4.379802 | Val Loss: 1.679004\n",
      "Epoch [400/500] | Train Loss: 4.071980 | Val Loss: 1.778658\n",
      "Epoch [500/500] | Train Loss: 3.982003 | Val Loss: 1.840922\n",
      "Epoch [100/500] | Train Loss: 4.387606 | Val Loss: 0.768754\n",
      "Epoch [200/500] | Train Loss: 3.655850 | Val Loss: 0.809741\n",
      "Epoch [300/500] | Train Loss: 3.600408 | Val Loss: 0.856619\n",
      "Epoch [400/500] | Train Loss: 3.624043 | Val Loss: 0.829937\n",
      "Epoch [500/500] | Train Loss: 3.567807 | Val Loss: 0.779878\n",
      "Epoch [100/500] | Train Loss: 3.651748 | Val Loss: 0.846795\n",
      "Epoch [200/500] | Train Loss: 3.459018 | Val Loss: 0.853476\n",
      "Epoch [300/500] | Train Loss: 3.282684 | Val Loss: 0.884110\n",
      "Epoch [400/500] | Train Loss: 3.184114 | Val Loss: 0.852040\n",
      "Epoch [500/500] | Train Loss: 3.195688 | Val Loss: 0.861392\n",
      "Epoch [100/500] | Train Loss: 6.923735 | Val Loss: 6.916479\n",
      "Epoch [200/500] | Train Loss: 5.575369 | Val Loss: 7.557164\n",
      "Epoch [300/500] | Train Loss: 5.037552 | Val Loss: 7.946422\n",
      "Epoch [400/500] | Train Loss: 4.153429 | Val Loss: 7.930364\n",
      "Epoch [500/500] | Train Loss: 3.745799 | Val Loss: 8.324347\n",
      "Epoch [100/500] | Train Loss: 6.747884 | Val Loss: 3.326909\n",
      "Epoch [200/500] | Train Loss: 5.619513 | Val Loss: 3.864901\n",
      "Epoch [300/500] | Train Loss: 5.267450 | Val Loss: 4.101507\n",
      "Epoch [400/500] | Train Loss: 4.449189 | Val Loss: 4.376112\n",
      "Epoch [500/500] | Train Loss: 4.169952 | Val Loss: 4.398059\n",
      "Epoch [100/500] | Train Loss: 5.571693 | Val Loss: 1.548035\n",
      "Epoch [200/500] | Train Loss: 4.978906 | Val Loss: 1.608867\n",
      "Epoch [300/500] | Train Loss: 4.670035 | Val Loss: 1.702718\n",
      "Epoch [400/500] | Train Loss: 4.336718 | Val Loss: 1.856366\n",
      "Epoch [500/500] | Train Loss: 4.017041 | Val Loss: 1.923062\n",
      "Epoch [100/500] | Train Loss: 4.526169 | Val Loss: 0.773567\n",
      "Epoch [200/500] | Train Loss: 4.093515 | Val Loss: 0.771989\n",
      "Epoch [300/500] | Train Loss: 3.907507 | Val Loss: 0.773253\n",
      "Epoch [400/500] | Train Loss: 3.601096 | Val Loss: 0.763264\n",
      "Epoch [500/500] | Train Loss: 3.394309 | Val Loss: 0.805756\n",
      "Epoch [100/500] | Train Loss: 3.723536 | Val Loss: 0.824675\n",
      "Epoch [200/500] | Train Loss: 3.554027 | Val Loss: 0.901513\n",
      "Epoch [300/500] | Train Loss: 3.094896 | Val Loss: 0.913307\n",
      "Epoch [400/500] | Train Loss: 3.127314 | Val Loss: 0.895732\n",
      "Epoch [500/500] | Train Loss: 2.892293 | Val Loss: 0.887216\n",
      "Epoch [100/500] | Train Loss: 4.025316 | Val Loss: 8.254949\n",
      "Epoch [200/500] | Train Loss: 2.864363 | Val Loss: 9.262885\n",
      "Epoch [300/500] | Train Loss: 2.081499 | Val Loss: 9.373336\n",
      "Epoch [400/500] | Train Loss: 1.841276 | Val Loss: 8.830357\n",
      "Epoch [500/500] | Train Loss: 1.746217 | Val Loss: 9.351397\n",
      "Epoch [100/500] | Train Loss: 4.163363 | Val Loss: 4.331458\n",
      "Epoch [200/500] | Train Loss: 2.935175 | Val Loss: 4.498541\n",
      "Epoch [300/500] | Train Loss: 2.795706 | Val Loss: 5.248397\n",
      "Epoch [400/500] | Train Loss: 2.217880 | Val Loss: 5.255820\n",
      "Epoch [500/500] | Train Loss: 1.868487 | Val Loss: 5.112401\n",
      "Epoch [100/500] | Train Loss: 4.321575 | Val Loss: 1.979554\n",
      "Epoch [200/500] | Train Loss: 3.145101 | Val Loss: 2.061001\n",
      "Epoch [300/500] | Train Loss: 3.005738 | Val Loss: 2.085011\n",
      "Epoch [400/500] | Train Loss: 2.770113 | Val Loss: 2.092380\n",
      "Epoch [500/500] | Train Loss: 2.652482 | Val Loss: 2.029987\n",
      "Epoch [100/500] | Train Loss: 3.356271 | Val Loss: 0.789928\n",
      "Epoch [200/500] | Train Loss: 2.897007 | Val Loss: 0.849304\n",
      "Epoch [300/500] | Train Loss: 2.542811 | Val Loss: 0.839099\n",
      "Epoch [400/500] | Train Loss: 2.424991 | Val Loss: 0.952985\n",
      "Epoch [500/500] | Train Loss: 2.184245 | Val Loss: 1.025488\n",
      "Epoch [100/500] | Train Loss: 3.013888 | Val Loss: 0.902185\n",
      "Epoch [200/500] | Train Loss: 2.450719 | Val Loss: 0.963623\n",
      "Epoch [300/500] | Train Loss: 2.498950 | Val Loss: 1.036726\n",
      "Epoch [400/500] | Train Loss: 2.171407 | Val Loss: 1.126606\n",
      "Epoch [500/500] | Train Loss: 2.154276 | Val Loss: 1.120695\n",
      "Epoch [100/500] | Train Loss: 7.394204 | Val Loss: 6.675157\n",
      "Epoch [200/500] | Train Loss: 6.741712 | Val Loss: 6.555695\n",
      "Epoch [300/500] | Train Loss: 6.178256 | Val Loss: 6.875467\n",
      "Epoch [400/500] | Train Loss: 5.913662 | Val Loss: 7.022354\n",
      "Epoch [500/500] | Train Loss: 5.049520 | Val Loss: 7.155842\n",
      "Epoch [100/500] | Train Loss: 6.998415 | Val Loss: 3.263658\n",
      "Epoch [200/500] | Train Loss: 6.780815 | Val Loss: 3.491669\n",
      "Epoch [300/500] | Train Loss: 5.961570 | Val Loss: 3.649086\n",
      "Epoch [400/500] | Train Loss: 5.890752 | Val Loss: 3.703892\n",
      "Epoch [500/500] | Train Loss: 5.396431 | Val Loss: 3.930734\n",
      "Epoch [100/500] | Train Loss: 5.791576 | Val Loss: 1.485309\n",
      "Epoch [200/500] | Train Loss: 5.518851 | Val Loss: 1.551867\n",
      "Epoch [300/500] | Train Loss: 5.229796 | Val Loss: 1.603956\n",
      "Epoch [400/500] | Train Loss: 4.941390 | Val Loss: 1.629493\n",
      "Epoch [500/500] | Train Loss: 4.704407 | Val Loss: 1.674225\n",
      "Epoch [100/500] | Train Loss: 4.685668 | Val Loss: 0.759582\n",
      "Epoch [200/500] | Train Loss: 4.453495 | Val Loss: 0.764637\n",
      "Epoch [300/500] | Train Loss: 4.244385 | Val Loss: 0.756334\n",
      "Epoch [400/500] | Train Loss: 3.996661 | Val Loss: 0.762621\n",
      "Epoch [500/500] | Train Loss: 3.779600 | Val Loss: 0.769836\n",
      "Epoch [100/500] | Train Loss: 3.987540 | Val Loss: 0.814639\n",
      "Epoch [200/500] | Train Loss: 3.831393 | Val Loss: 0.839674\n",
      "Epoch [300/500] | Train Loss: 3.606415 | Val Loss: 0.857616\n",
      "Epoch [400/500] | Train Loss: 3.404657 | Val Loss: 0.855443\n",
      "Epoch [500/500] | Train Loss: 3.216722 | Val Loss: 0.852816\n",
      "Epoch [100/500] | Train Loss: 5.691320 | Val Loss: 8.029613\n",
      "Epoch [200/500] | Train Loss: 4.087167 | Val Loss: 8.367906\n",
      "Epoch [300/500] | Train Loss: 3.727532 | Val Loss: 8.387302\n",
      "Epoch [400/500] | Train Loss: 2.884583 | Val Loss: 8.731400\n",
      "Epoch [500/500] | Train Loss: 2.964643 | Val Loss: 8.684562\n",
      "Epoch [100/500] | Train Loss: 4.909260 | Val Loss: 3.928411\n",
      "Epoch [200/500] | Train Loss: 4.603930 | Val Loss: 4.211823\n",
      "Epoch [300/500] | Train Loss: 4.299442 | Val Loss: 4.105352\n",
      "Epoch [400/500] | Train Loss: 3.916295 | Val Loss: 4.523488\n",
      "Epoch [500/500] | Train Loss: 3.584802 | Val Loss: 4.002274\n",
      "Epoch [100/500] | Train Loss: 4.839012 | Val Loss: 1.671193\n",
      "Epoch [200/500] | Train Loss: 4.565572 | Val Loss: 1.771467\n",
      "Epoch [300/500] | Train Loss: 3.934904 | Val Loss: 1.875411\n",
      "Epoch [400/500] | Train Loss: 4.061581 | Val Loss: 1.932696\n",
      "Epoch [500/500] | Train Loss: 3.454466 | Val Loss: 2.000204\n",
      "Epoch [100/500] | Train Loss: 4.088707 | Val Loss: 0.805510\n",
      "Epoch [200/500] | Train Loss: 3.745322 | Val Loss: 0.810440\n",
      "Epoch [300/500] | Train Loss: 3.525118 | Val Loss: 0.874261\n",
      "Epoch [400/500] | Train Loss: 3.401382 | Val Loss: 0.841498\n",
      "Epoch [500/500] | Train Loss: 3.276889 | Val Loss: 0.876865\n",
      "Epoch [100/500] | Train Loss: 3.343698 | Val Loss: 0.836447\n",
      "Epoch [200/500] | Train Loss: 3.024048 | Val Loss: 0.875622\n",
      "Epoch [300/500] | Train Loss: 2.777109 | Val Loss: 0.886996\n",
      "Epoch [400/500] | Train Loss: 2.559334 | Val Loss: 0.956116\n",
      "Epoch [500/500] | Train Loss: 2.593407 | Val Loss: 0.989001\n",
      "[Year=1937] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=2.876461 Test MSE=2.813825\n",
      "Year 1937 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 6.557518 | Val Loss: 2.373904\n",
      "Epoch [200/500] | Train Loss: 5.606683 | Val Loss: 2.870368\n",
      "Epoch [300/500] | Train Loss: 4.599686 | Val Loss: 3.220809\n",
      "Epoch [400/500] | Train Loss: 4.989345 | Val Loss: 3.335092\n",
      "Epoch [500/500] | Train Loss: 4.004774 | Val Loss: 3.483119\n",
      "Epoch [100/500] | Train Loss: 4.454364 | Val Loss: 0.921235\n",
      "Epoch [200/500] | Train Loss: 4.079077 | Val Loss: 0.932730\n",
      "Epoch [300/500] | Train Loss: 3.578409 | Val Loss: 0.970557\n",
      "Epoch [400/500] | Train Loss: 3.537441 | Val Loss: 1.018653\n",
      "Epoch [500/500] | Train Loss: 3.328697 | Val Loss: 1.050602\n",
      "Epoch [100/500] | Train Loss: 3.303533 | Val Loss: 0.942153\n",
      "Epoch [200/500] | Train Loss: 2.886108 | Val Loss: 0.965829\n",
      "Epoch [300/500] | Train Loss: 2.819302 | Val Loss: 1.001716\n",
      "Epoch [400/500] | Train Loss: 2.627590 | Val Loss: 1.017591\n",
      "Epoch [500/500] | Train Loss: 2.386363 | Val Loss: 1.011647\n",
      "Epoch [100/500] | Train Loss: 2.730670 | Val Loss: 0.548953\n",
      "Epoch [200/500] | Train Loss: 2.473362 | Val Loss: 0.589578\n",
      "Epoch [300/500] | Train Loss: 2.285324 | Val Loss: 0.599228\n",
      "Epoch [400/500] | Train Loss: 2.154294 | Val Loss: 0.592434\n",
      "Epoch [500/500] | Train Loss: 2.079745 | Val Loss: 0.580552\n",
      "Epoch [100/500] | Train Loss: 2.284378 | Val Loss: 3.181617\n",
      "Epoch [200/500] | Train Loss: 2.156499 | Val Loss: 3.243011\n",
      "Epoch [300/500] | Train Loss: 2.012616 | Val Loss: 3.373087\n",
      "Epoch [400/500] | Train Loss: 1.981422 | Val Loss: 3.341390\n",
      "Epoch [500/500] | Train Loss: 1.864132 | Val Loss: 3.288120\n",
      "Epoch [100/500] | Train Loss: 4.294902 | Val Loss: 3.433736\n",
      "Epoch [200/500] | Train Loss: 2.717087 | Val Loss: 3.973821\n",
      "Epoch [300/500] | Train Loss: 2.012645 | Val Loss: 3.626324\n",
      "Epoch [400/500] | Train Loss: 2.629689 | Val Loss: 4.037382\n",
      "Epoch [500/500] | Train Loss: 1.834025 | Val Loss: 4.311348\n",
      "Epoch [100/500] | Train Loss: 3.592240 | Val Loss: 1.047637\n",
      "Epoch [200/500] | Train Loss: 2.560550 | Val Loss: 1.132460\n",
      "Epoch [300/500] | Train Loss: 2.325840 | Val Loss: 1.260782\n",
      "Epoch [400/500] | Train Loss: 2.226115 | Val Loss: 1.342467\n",
      "Epoch [500/500] | Train Loss: 2.020679 | Val Loss: 1.427450\n",
      "Epoch [100/500] | Train Loss: 2.450652 | Val Loss: 1.037925\n",
      "Epoch [200/500] | Train Loss: 2.100887 | Val Loss: 1.072002\n",
      "Epoch [300/500] | Train Loss: 1.879694 | Val Loss: 1.076389\n",
      "Epoch [400/500] | Train Loss: 1.670687 | Val Loss: 1.171840\n",
      "Epoch [500/500] | Train Loss: 1.597303 | Val Loss: 1.196490\n",
      "Epoch [100/500] | Train Loss: 2.097297 | Val Loss: 0.590389\n",
      "Epoch [200/500] | Train Loss: 1.903974 | Val Loss: 0.619967\n",
      "Epoch [300/500] | Train Loss: 1.699033 | Val Loss: 0.599812\n",
      "Epoch [400/500] | Train Loss: 1.608275 | Val Loss: 0.585952\n",
      "Epoch [500/500] | Train Loss: 1.589600 | Val Loss: 0.618871\n",
      "Epoch [100/500] | Train Loss: 1.871860 | Val Loss: 3.639506\n",
      "Epoch [200/500] | Train Loss: 1.576246 | Val Loss: 3.712846\n",
      "Epoch [300/500] | Train Loss: 1.562561 | Val Loss: 3.550720\n",
      "Epoch [400/500] | Train Loss: 1.422786 | Val Loss: 3.290697\n",
      "Epoch [500/500] | Train Loss: 1.347536 | Val Loss: 3.452482\n",
      "Epoch [100/500] | Train Loss: 7.002784 | Val Loss: 2.176151\n",
      "Epoch [200/500] | Train Loss: 6.383810 | Val Loss: 2.288628\n",
      "Epoch [300/500] | Train Loss: 6.489032 | Val Loss: 2.522361\n",
      "Epoch [400/500] | Train Loss: 5.803307 | Val Loss: 2.582263\n",
      "Epoch [500/500] | Train Loss: 5.254569 | Val Loss: 2.738451\n",
      "Epoch [100/500] | Train Loss: 4.522839 | Val Loss: 0.919866\n",
      "Epoch [200/500] | Train Loss: 4.376147 | Val Loss: 0.961348\n",
      "Epoch [300/500] | Train Loss: 4.299211 | Val Loss: 0.973918\n",
      "Epoch [400/500] | Train Loss: 3.997787 | Val Loss: 0.972836\n",
      "Epoch [500/500] | Train Loss: 3.980656 | Val Loss: 0.970795\n",
      "Epoch [100/500] | Train Loss: 3.372925 | Val Loss: 0.946577\n",
      "Epoch [200/500] | Train Loss: 3.287960 | Val Loss: 0.938856\n",
      "Epoch [300/500] | Train Loss: 3.140829 | Val Loss: 0.953735\n",
      "Epoch [400/500] | Train Loss: 3.008684 | Val Loss: 0.964028\n",
      "Epoch [500/500] | Train Loss: 2.911683 | Val Loss: 0.974767\n",
      "Epoch [100/500] | Train Loss: 2.788776 | Val Loss: 0.538203\n",
      "Epoch [200/500] | Train Loss: 2.758438 | Val Loss: 0.552359\n",
      "Epoch [300/500] | Train Loss: 2.656603 | Val Loss: 0.557725\n",
      "Epoch [400/500] | Train Loss: 2.455941 | Val Loss: 0.559810\n",
      "Epoch [500/500] | Train Loss: 2.473702 | Val Loss: 0.563400\n",
      "Epoch [100/500] | Train Loss: 2.365439 | Val Loss: 3.161394\n",
      "Epoch [200/500] | Train Loss: 2.286671 | Val Loss: 3.205358\n",
      "Epoch [300/500] | Train Loss: 2.202368 | Val Loss: 3.225668\n",
      "Epoch [400/500] | Train Loss: 2.112177 | Val Loss: 3.250483\n",
      "Epoch [500/500] | Train Loss: 2.018641 | Val Loss: 3.292817\n",
      "Epoch [100/500] | Train Loss: 5.951486 | Val Loss: 2.703623\n",
      "Epoch [200/500] | Train Loss: 8.010064 | Val Loss: 2.739755\n",
      "Epoch [300/500] | Train Loss: 3.747336 | Val Loss: 3.238192\n",
      "Epoch [400/500] | Train Loss: 3.758765 | Val Loss: 3.076891\n",
      "Epoch [500/500] | Train Loss: 3.807256 | Val Loss: 3.140892\n",
      "Epoch [100/500] | Train Loss: 3.710303 | Val Loss: 0.941188\n",
      "Epoch [200/500] | Train Loss: 3.715962 | Val Loss: 0.960100\n",
      "Epoch [300/500] | Train Loss: 3.112629 | Val Loss: 1.029288\n",
      "Epoch [400/500] | Train Loss: 2.906947 | Val Loss: 1.007077\n",
      "Epoch [500/500] | Train Loss: 3.135973 | Val Loss: 1.066024\n",
      "Epoch [100/500] | Train Loss: 3.058723 | Val Loss: 0.970756\n",
      "Epoch [200/500] | Train Loss: 2.563412 | Val Loss: 0.969891\n",
      "Epoch [300/500] | Train Loss: 2.608053 | Val Loss: 1.033329\n",
      "Epoch [400/500] | Train Loss: 2.350054 | Val Loss: 0.984997\n",
      "Epoch [500/500] | Train Loss: 2.546355 | Val Loss: 1.076159\n",
      "Epoch [100/500] | Train Loss: 2.578517 | Val Loss: 0.566523\n",
      "Epoch [200/500] | Train Loss: 2.538084 | Val Loss: 0.561721\n",
      "Epoch [300/500] | Train Loss: 2.031703 | Val Loss: 0.580392\n",
      "Epoch [400/500] | Train Loss: 2.003190 | Val Loss: 0.574258\n",
      "Epoch [500/500] | Train Loss: 1.988037 | Val Loss: 0.593601\n",
      "Epoch [100/500] | Train Loss: 2.010120 | Val Loss: 3.427821\n",
      "Epoch [200/500] | Train Loss: 1.929365 | Val Loss: 3.177191\n",
      "Epoch [300/500] | Train Loss: 1.568202 | Val Loss: 3.244739\n",
      "Epoch [400/500] | Train Loss: 1.734984 | Val Loss: 3.473679\n",
      "Epoch [500/500] | Train Loss: 1.584828 | Val Loss: 3.283592\n",
      "Epoch [100/500] | Train Loss: 6.376494 | Val Loss: 2.406071\n",
      "Epoch [200/500] | Train Loss: 5.466397 | Val Loss: 2.844713\n",
      "Epoch [300/500] | Train Loss: 4.444567 | Val Loss: 3.075447\n",
      "Epoch [400/500] | Train Loss: 3.759015 | Val Loss: 3.451537\n",
      "Epoch [500/500] | Train Loss: 3.208558 | Val Loss: 3.550874\n",
      "Epoch [100/500] | Train Loss: 4.374253 | Val Loss: 0.947498\n",
      "Epoch [200/500] | Train Loss: 3.985084 | Val Loss: 0.975806\n",
      "Epoch [300/500] | Train Loss: 3.461241 | Val Loss: 1.017474\n",
      "Epoch [400/500] | Train Loss: 3.080371 | Val Loss: 1.038618\n",
      "Epoch [500/500] | Train Loss: 2.796077 | Val Loss: 1.092051\n",
      "Epoch [100/500] | Train Loss: 3.274700 | Val Loss: 0.958293\n",
      "Epoch [200/500] | Train Loss: 2.922489 | Val Loss: 0.987601\n",
      "Epoch [300/500] | Train Loss: 2.693825 | Val Loss: 1.031880\n",
      "Epoch [400/500] | Train Loss: 2.526675 | Val Loss: 1.022034\n",
      "Epoch [500/500] | Train Loss: 2.218399 | Val Loss: 1.033665\n",
      "Epoch [100/500] | Train Loss: 2.611426 | Val Loss: 0.558828\n",
      "Epoch [200/500] | Train Loss: 2.385244 | Val Loss: 0.591185\n",
      "Epoch [300/500] | Train Loss: 2.163050 | Val Loss: 0.604684\n",
      "Epoch [400/500] | Train Loss: 2.091963 | Val Loss: 0.600239\n",
      "Epoch [500/500] | Train Loss: 1.991024 | Val Loss: 0.607838\n",
      "Epoch [100/500] | Train Loss: 2.261925 | Val Loss: 3.359482\n",
      "Epoch [200/500] | Train Loss: 2.029129 | Val Loss: 3.488684\n",
      "Epoch [300/500] | Train Loss: 1.880575 | Val Loss: 3.589116\n",
      "Epoch [400/500] | Train Loss: 1.672051 | Val Loss: 3.629578\n",
      "Epoch [500/500] | Train Loss: 1.646697 | Val Loss: 3.691612\n",
      "Epoch [100/500] | Train Loss: 3.262020 | Val Loss: 3.145769\n",
      "Epoch [200/500] | Train Loss: 2.391949 | Val Loss: 3.979843\n",
      "Epoch [300/500] | Train Loss: 2.312178 | Val Loss: 4.817090\n",
      "Epoch [400/500] | Train Loss: 1.802967 | Val Loss: 4.536898\n",
      "Epoch [500/500] | Train Loss: 2.042916 | Val Loss: 4.368832\n",
      "Epoch [100/500] | Train Loss: 3.033799 | Val Loss: 1.053481\n",
      "Epoch [200/500] | Train Loss: 2.303071 | Val Loss: 1.276527\n",
      "Epoch [300/500] | Train Loss: 1.942554 | Val Loss: 1.452757\n",
      "Epoch [400/500] | Train Loss: 1.713254 | Val Loss: 1.602186\n",
      "Epoch [500/500] | Train Loss: 1.741398 | Val Loss: 1.754252\n",
      "Epoch [100/500] | Train Loss: 2.406463 | Val Loss: 1.015022\n",
      "Epoch [200/500] | Train Loss: 1.847838 | Val Loss: 1.210398\n",
      "Epoch [300/500] | Train Loss: 1.633832 | Val Loss: 1.214183\n",
      "Epoch [400/500] | Train Loss: 1.581004 | Val Loss: 1.341622\n",
      "Epoch [500/500] | Train Loss: 1.424898 | Val Loss: 1.471673\n",
      "Epoch [100/500] | Train Loss: 1.993173 | Val Loss: 0.564575\n",
      "Epoch [200/500] | Train Loss: 1.800739 | Val Loss: 0.622510\n",
      "Epoch [300/500] | Train Loss: 1.627324 | Val Loss: 0.663949\n",
      "Epoch [400/500] | Train Loss: 1.414611 | Val Loss: 0.645099\n",
      "Epoch [500/500] | Train Loss: 1.340807 | Val Loss: 0.661272\n",
      "Epoch [100/500] | Train Loss: 1.693179 | Val Loss: 3.460563\n",
      "Epoch [200/500] | Train Loss: 1.585519 | Val Loss: 3.216097\n",
      "Epoch [300/500] | Train Loss: 1.409262 | Val Loss: 3.610785\n",
      "Epoch [400/500] | Train Loss: 1.264926 | Val Loss: 3.328171\n",
      "Epoch [500/500] | Train Loss: 1.229894 | Val Loss: 3.332162\n",
      "Epoch [100/500] | Train Loss: 6.886366 | Val Loss: 2.287409\n",
      "Epoch [200/500] | Train Loss: 6.392674 | Val Loss: 2.617738\n",
      "Epoch [300/500] | Train Loss: 5.768851 | Val Loss: 2.809516\n",
      "Epoch [400/500] | Train Loss: 4.437566 | Val Loss: 3.056703\n",
      "Epoch [500/500] | Train Loss: 4.506762 | Val Loss: 3.177458\n",
      "Epoch [100/500] | Train Loss: 4.698658 | Val Loss: 0.925518\n",
      "Epoch [200/500] | Train Loss: 4.367798 | Val Loss: 0.971591\n",
      "Epoch [300/500] | Train Loss: 4.071199 | Val Loss: 0.984550\n",
      "Epoch [400/500] | Train Loss: 3.942666 | Val Loss: 0.973533\n",
      "Epoch [500/500] | Train Loss: 3.652601 | Val Loss: 1.007061\n",
      "Epoch [100/500] | Train Loss: 3.362272 | Val Loss: 0.966171\n",
      "Epoch [200/500] | Train Loss: 3.141156 | Val Loss: 0.944050\n",
      "Epoch [300/500] | Train Loss: 2.976510 | Val Loss: 0.972126\n",
      "Epoch [400/500] | Train Loss: 2.623765 | Val Loss: 0.986786\n",
      "Epoch [500/500] | Train Loss: 2.767808 | Val Loss: 1.001255\n",
      "Epoch [100/500] | Train Loss: 2.751262 | Val Loss: 0.544510\n",
      "Epoch [200/500] | Train Loss: 2.638843 | Val Loss: 0.561130\n",
      "Epoch [300/500] | Train Loss: 2.453396 | Val Loss: 0.573854\n",
      "Epoch [400/500] | Train Loss: 2.472780 | Val Loss: 0.577773\n",
      "Epoch [500/500] | Train Loss: 2.210999 | Val Loss: 0.574749\n",
      "Epoch [100/500] | Train Loss: 2.308797 | Val Loss: 3.117437\n",
      "Epoch [200/500] | Train Loss: 2.251132 | Val Loss: 3.275156\n",
      "Epoch [300/500] | Train Loss: 2.099175 | Val Loss: 3.410940\n",
      "Epoch [400/500] | Train Loss: 2.027600 | Val Loss: 3.472100\n",
      "Epoch [500/500] | Train Loss: 2.006239 | Val Loss: 3.411144\n",
      "Epoch [100/500] | Train Loss: 5.880594 | Val Loss: 2.418581\n",
      "Epoch [200/500] | Train Loss: 5.824707 | Val Loss: 2.644605\n",
      "Epoch [300/500] | Train Loss: 4.989357 | Val Loss: 3.175313\n",
      "Epoch [400/500] | Train Loss: 4.325492 | Val Loss: 3.414103\n",
      "Epoch [500/500] | Train Loss: 4.448792 | Val Loss: 3.598440\n",
      "Epoch [100/500] | Train Loss: 3.314265 | Val Loss: 1.036147\n",
      "Epoch [200/500] | Train Loss: 2.805047 | Val Loss: 1.024609\n",
      "Epoch [300/500] | Train Loss: 2.704740 | Val Loss: 1.150928\n",
      "Epoch [400/500] | Train Loss: 2.941638 | Val Loss: 1.121686\n",
      "Epoch [500/500] | Train Loss: 2.483917 | Val Loss: 1.112875\n",
      "Epoch [100/500] | Train Loss: 2.672544 | Val Loss: 0.971716\n",
      "Epoch [200/500] | Train Loss: 2.486241 | Val Loss: 1.014486\n",
      "Epoch [300/500] | Train Loss: 2.527213 | Val Loss: 1.103679\n",
      "Epoch [400/500] | Train Loss: 2.334107 | Val Loss: 1.040447\n",
      "Epoch [500/500] | Train Loss: 2.177215 | Val Loss: 1.126736\n",
      "Epoch [100/500] | Train Loss: 2.265128 | Val Loss: 0.573304\n",
      "Epoch [200/500] | Train Loss: 1.890415 | Val Loss: 0.664172\n",
      "Epoch [300/500] | Train Loss: 1.866868 | Val Loss: 0.699929\n",
      "Epoch [400/500] | Train Loss: 1.716355 | Val Loss: 0.636068\n",
      "Epoch [500/500] | Train Loss: 1.788338 | Val Loss: 0.697035\n",
      "Epoch [100/500] | Train Loss: 1.854624 | Val Loss: 3.393201\n",
      "Epoch [200/500] | Train Loss: 1.747114 | Val Loss: 3.398251\n",
      "Epoch [300/500] | Train Loss: 1.608121 | Val Loss: 3.386448\n",
      "Epoch [400/500] | Train Loss: 1.460033 | Val Loss: 3.493533\n",
      "Epoch [500/500] | Train Loss: 1.519507 | Val Loss: 3.646053\n",
      "[Year=1938] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.708046 Test MSE=2.841651\n",
      "Year 1938 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.825590 | Val Loss: 0.917515\n",
      "Epoch [200/500] | Train Loss: 1.497108 | Val Loss: 1.018117\n",
      "Epoch [300/500] | Train Loss: 1.356350 | Val Loss: 1.064497\n",
      "Epoch [400/500] | Train Loss: 1.255125 | Val Loss: 1.106933\n",
      "Epoch [500/500] | Train Loss: 1.114274 | Val Loss: 1.139372\n",
      "Epoch [100/500] | Train Loss: 1.340774 | Val Loss: 0.919517\n",
      "Epoch [200/500] | Train Loss: 1.254074 | Val Loss: 0.971355\n",
      "Epoch [300/500] | Train Loss: 1.152878 | Val Loss: 1.025702\n",
      "Epoch [400/500] | Train Loss: 1.073897 | Val Loss: 1.083805\n",
      "Epoch [500/500] | Train Loss: 0.985455 | Val Loss: 1.117527\n",
      "Epoch [100/500] | Train Loss: 1.180186 | Val Loss: 0.697361\n",
      "Epoch [200/500] | Train Loss: 1.088961 | Val Loss: 0.675660\n",
      "Epoch [300/500] | Train Loss: 1.021215 | Val Loss: 0.665067\n",
      "Epoch [400/500] | Train Loss: 0.981224 | Val Loss: 0.659290\n",
      "Epoch [500/500] | Train Loss: 0.910503 | Val Loss: 0.680452\n",
      "Epoch [100/500] | Train Loss: 1.082302 | Val Loss: 3.436454\n",
      "Epoch [200/500] | Train Loss: 1.031680 | Val Loss: 3.543708\n",
      "Epoch [300/500] | Train Loss: 0.950830 | Val Loss: 3.557670\n",
      "Epoch [400/500] | Train Loss: 0.913823 | Val Loss: 3.637072\n",
      "Epoch [500/500] | Train Loss: 0.876509 | Val Loss: 3.665465\n",
      "Epoch [100/500] | Train Loss: 1.503370 | Val Loss: 2.708626\n",
      "Epoch [200/500] | Train Loss: 1.357801 | Val Loss: 2.605832\n",
      "Epoch [300/500] | Train Loss: 1.309302 | Val Loss: 2.643694\n",
      "Epoch [400/500] | Train Loss: 1.202523 | Val Loss: 2.666511\n",
      "Epoch [500/500] | Train Loss: 1.195729 | Val Loss: 2.679581\n",
      "Epoch [100/500] | Train Loss: 1.045527 | Val Loss: 1.183024\n",
      "Epoch [200/500] | Train Loss: 0.863573 | Val Loss: 1.299690\n",
      "Epoch [300/500] | Train Loss: 0.600878 | Val Loss: 1.432980\n",
      "Epoch [400/500] | Train Loss: 0.645135 | Val Loss: 1.447804\n",
      "Epoch [500/500] | Train Loss: 0.544506 | Val Loss: 1.422069\n",
      "Epoch [100/500] | Train Loss: 1.021825 | Val Loss: 1.043641\n",
      "Epoch [200/500] | Train Loss: 0.841260 | Val Loss: 1.102875\n",
      "Epoch [300/500] | Train Loss: 0.718023 | Val Loss: 1.024046\n",
      "Epoch [400/500] | Train Loss: 0.720510 | Val Loss: 1.162113\n",
      "Epoch [500/500] | Train Loss: 0.622348 | Val Loss: 1.168601\n",
      "Epoch [100/500] | Train Loss: 0.876602 | Val Loss: 0.719923\n",
      "Epoch [200/500] | Train Loss: 0.765046 | Val Loss: 0.817906\n",
      "Epoch [300/500] | Train Loss: 0.737040 | Val Loss: 0.840532\n",
      "Epoch [400/500] | Train Loss: 0.723298 | Val Loss: 0.900788\n",
      "Epoch [500/500] | Train Loss: 0.661602 | Val Loss: 0.858067\n",
      "Epoch [100/500] | Train Loss: 0.924353 | Val Loss: 3.989671\n",
      "Epoch [200/500] | Train Loss: 0.778817 | Val Loss: 3.716064\n",
      "Epoch [300/500] | Train Loss: 0.745983 | Val Loss: 3.779440\n",
      "Epoch [400/500] | Train Loss: 0.759105 | Val Loss: 3.623985\n",
      "Epoch [500/500] | Train Loss: 0.715086 | Val Loss: 3.544922\n",
      "Epoch [100/500] | Train Loss: 1.320789 | Val Loss: 2.762356\n",
      "Epoch [200/500] | Train Loss: 1.129832 | Val Loss: 2.712872\n",
      "Epoch [300/500] | Train Loss: 1.091422 | Val Loss: 2.870979\n",
      "Epoch [400/500] | Train Loss: 0.929351 | Val Loss: 2.879722\n",
      "Epoch [500/500] | Train Loss: 0.907677 | Val Loss: 2.818729\n",
      "Epoch [100/500] | Train Loss: 1.958035 | Val Loss: 0.871768\n",
      "Epoch [200/500] | Train Loss: 1.839109 | Val Loss: 0.901980\n",
      "Epoch [300/500] | Train Loss: 1.761022 | Val Loss: 0.924810\n",
      "Epoch [400/500] | Train Loss: 1.484816 | Val Loss: 0.940052\n",
      "Epoch [500/500] | Train Loss: 1.428110 | Val Loss: 0.961346\n",
      "Epoch [100/500] | Train Loss: 1.387495 | Val Loss: 0.904808\n",
      "Epoch [200/500] | Train Loss: 1.350396 | Val Loss: 0.921692\n",
      "Epoch [300/500] | Train Loss: 1.267620 | Val Loss: 0.948146\n",
      "Epoch [400/500] | Train Loss: 1.263028 | Val Loss: 0.982524\n",
      "Epoch [500/500] | Train Loss: 1.166332 | Val Loss: 1.022403\n",
      "Epoch [100/500] | Train Loss: 1.228385 | Val Loss: 0.702969\n",
      "Epoch [200/500] | Train Loss: 1.181799 | Val Loss: 0.694459\n",
      "Epoch [300/500] | Train Loss: 1.115522 | Val Loss: 0.701237\n",
      "Epoch [400/500] | Train Loss: 1.077569 | Val Loss: 0.704767\n",
      "Epoch [500/500] | Train Loss: 1.038967 | Val Loss: 0.716619\n",
      "Epoch [100/500] | Train Loss: 1.104955 | Val Loss: 3.324736\n",
      "Epoch [200/500] | Train Loss: 1.072808 | Val Loss: 3.404461\n",
      "Epoch [300/500] | Train Loss: 1.028333 | Val Loss: 3.459880\n",
      "Epoch [400/500] | Train Loss: 1.022656 | Val Loss: 3.520031\n",
      "Epoch [500/500] | Train Loss: 1.016551 | Val Loss: 3.532227\n",
      "Epoch [100/500] | Train Loss: 1.544596 | Val Loss: 2.725462\n",
      "Epoch [200/500] | Train Loss: 1.497832 | Val Loss: 2.704965\n",
      "Epoch [300/500] | Train Loss: 1.461061 | Val Loss: 2.702107\n",
      "Epoch [400/500] | Train Loss: 1.416339 | Val Loss: 2.682379\n",
      "Epoch [500/500] | Train Loss: 1.360774 | Val Loss: 2.645866\n",
      "Epoch [100/500] | Train Loss: 1.447511 | Val Loss: 1.027859\n",
      "Epoch [200/500] | Train Loss: 1.335724 | Val Loss: 1.087126\n",
      "Epoch [300/500] | Train Loss: 1.079368 | Val Loss: 1.109520\n",
      "Epoch [400/500] | Train Loss: 1.025428 | Val Loss: 1.150719\n",
      "Epoch [500/500] | Train Loss: 0.951412 | Val Loss: 1.126406\n",
      "Epoch [100/500] | Train Loss: 1.152681 | Val Loss: 0.962213\n",
      "Epoch [200/500] | Train Loss: 0.985136 | Val Loss: 1.054714\n",
      "Epoch [300/500] | Train Loss: 0.899992 | Val Loss: 1.090003\n",
      "Epoch [400/500] | Train Loss: 0.942423 | Val Loss: 1.042915\n",
      "Epoch [500/500] | Train Loss: 0.781540 | Val Loss: 1.075038\n",
      "Epoch [100/500] | Train Loss: 1.079325 | Val Loss: 0.684729\n",
      "Epoch [200/500] | Train Loss: 0.994388 | Val Loss: 0.735311\n",
      "Epoch [300/500] | Train Loss: 0.995569 | Val Loss: 0.764323\n",
      "Epoch [400/500] | Train Loss: 0.931695 | Val Loss: 0.747256\n",
      "Epoch [500/500] | Train Loss: 0.908324 | Val Loss: 0.757792\n",
      "Epoch [100/500] | Train Loss: 1.051205 | Val Loss: 3.760689\n",
      "Epoch [200/500] | Train Loss: 0.897278 | Val Loss: 3.890905\n",
      "Epoch [300/500] | Train Loss: 0.911950 | Val Loss: 3.802047\n",
      "Epoch [400/500] | Train Loss: 0.828632 | Val Loss: 3.840236\n",
      "Epoch [500/500] | Train Loss: 0.833163 | Val Loss: 3.972260\n",
      "Epoch [100/500] | Train Loss: 1.376483 | Val Loss: 2.679055\n",
      "Epoch [200/500] | Train Loss: 1.248313 | Val Loss: 2.656118\n",
      "Epoch [300/500] | Train Loss: 1.240825 | Val Loss: 2.617143\n",
      "Epoch [400/500] | Train Loss: 1.253844 | Val Loss: 2.615674\n",
      "Epoch [500/500] | Train Loss: 1.196904 | Val Loss: 2.637787\n",
      "Epoch [100/500] | Train Loss: 1.676648 | Val Loss: 0.961942\n",
      "Epoch [200/500] | Train Loss: 1.341475 | Val Loss: 1.010880\n",
      "Epoch [300/500] | Train Loss: 1.066531 | Val Loss: 1.137766\n",
      "Epoch [400/500] | Train Loss: 0.911885 | Val Loss: 1.218225\n",
      "Epoch [500/500] | Train Loss: 0.837980 | Val Loss: 1.245829\n",
      "Epoch [100/500] | Train Loss: 1.292582 | Val Loss: 0.940294\n",
      "Epoch [200/500] | Train Loss: 1.201687 | Val Loss: 1.031542\n",
      "Epoch [300/500] | Train Loss: 1.074620 | Val Loss: 1.097122\n",
      "Epoch [400/500] | Train Loss: 0.865376 | Val Loss: 1.105088\n",
      "Epoch [500/500] | Train Loss: 0.796922 | Val Loss: 1.130500\n",
      "Epoch [100/500] | Train Loss: 1.179529 | Val Loss: 0.686859\n",
      "Epoch [200/500] | Train Loss: 1.033326 | Val Loss: 0.686969\n",
      "Epoch [300/500] | Train Loss: 0.972279 | Val Loss: 0.714671\n",
      "Epoch [400/500] | Train Loss: 0.864223 | Val Loss: 0.736834\n",
      "Epoch [500/500] | Train Loss: 0.869771 | Val Loss: 0.757778\n",
      "Epoch [100/500] | Train Loss: 1.046545 | Val Loss: 3.587193\n",
      "Epoch [200/500] | Train Loss: 0.958879 | Val Loss: 3.851068\n",
      "Epoch [300/500] | Train Loss: 0.890417 | Val Loss: 3.898485\n",
      "Epoch [400/500] | Train Loss: 0.837075 | Val Loss: 4.003294\n",
      "Epoch [500/500] | Train Loss: 0.754419 | Val Loss: 4.019085\n",
      "Epoch [100/500] | Train Loss: 1.490535 | Val Loss: 2.725388\n",
      "Epoch [200/500] | Train Loss: 1.342506 | Val Loss: 2.699908\n",
      "Epoch [300/500] | Train Loss: 1.210292 | Val Loss: 2.716860\n",
      "Epoch [400/500] | Train Loss: 1.160889 | Val Loss: 2.749717\n",
      "Epoch [500/500] | Train Loss: 1.131752 | Val Loss: 2.852347\n",
      "Epoch [100/500] | Train Loss: 1.157593 | Val Loss: 1.125970\n",
      "Epoch [200/500] | Train Loss: 0.799467 | Val Loss: 1.457406\n",
      "Epoch [300/500] | Train Loss: 0.591061 | Val Loss: 1.536598\n",
      "Epoch [400/500] | Train Loss: 0.562608 | Val Loss: 1.654952\n",
      "Epoch [500/500] | Train Loss: 0.337574 | Val Loss: 1.496143\n",
      "Epoch [100/500] | Train Loss: 0.896035 | Val Loss: 1.069448\n",
      "Epoch [200/500] | Train Loss: 0.687049 | Val Loss: 1.291211\n",
      "Epoch [300/500] | Train Loss: 0.653386 | Val Loss: 1.375750\n",
      "Epoch [400/500] | Train Loss: 0.615732 | Val Loss: 1.402401\n",
      "Epoch [500/500] | Train Loss: 0.516660 | Val Loss: 1.367585\n",
      "Epoch [100/500] | Train Loss: 0.979845 | Val Loss: 0.704931\n",
      "Epoch [200/500] | Train Loss: 0.835011 | Val Loss: 0.789313\n",
      "Epoch [300/500] | Train Loss: 0.703811 | Val Loss: 0.774701\n",
      "Epoch [400/500] | Train Loss: 0.704240 | Val Loss: 0.786914\n",
      "Epoch [500/500] | Train Loss: 0.729758 | Val Loss: 0.838149\n",
      "Epoch [100/500] | Train Loss: 0.802975 | Val Loss: 3.877684\n",
      "Epoch [200/500] | Train Loss: 0.686399 | Val Loss: 4.080370\n",
      "Epoch [300/500] | Train Loss: 0.635181 | Val Loss: 4.341202\n",
      "Epoch [400/500] | Train Loss: 0.581054 | Val Loss: 4.369345\n",
      "Epoch [500/500] | Train Loss: 0.556666 | Val Loss: 4.409529\n",
      "Epoch [100/500] | Train Loss: 1.153262 | Val Loss: 2.654421\n",
      "Epoch [200/500] | Train Loss: 1.044165 | Val Loss: 2.794028\n",
      "Epoch [300/500] | Train Loss: 0.935663 | Val Loss: 2.831713\n",
      "Epoch [400/500] | Train Loss: 0.929827 | Val Loss: 2.817480\n",
      "Epoch [500/500] | Train Loss: 0.889670 | Val Loss: 2.920403\n",
      "Epoch [100/500] | Train Loss: 1.955326 | Val Loss: 0.884876\n",
      "Epoch [200/500] | Train Loss: 1.773764 | Val Loss: 0.923277\n",
      "Epoch [300/500] | Train Loss: 1.581749 | Val Loss: 0.906577\n",
      "Epoch [400/500] | Train Loss: 1.386458 | Val Loss: 0.905180\n",
      "Epoch [500/500] | Train Loss: 1.460211 | Val Loss: 0.933186\n",
      "Epoch [100/500] | Train Loss: 1.368308 | Val Loss: 0.904954\n",
      "Epoch [200/500] | Train Loss: 1.276743 | Val Loss: 0.933687\n",
      "Epoch [300/500] | Train Loss: 1.166379 | Val Loss: 0.960273\n",
      "Epoch [400/500] | Train Loss: 1.131879 | Val Loss: 0.982844\n",
      "Epoch [500/500] | Train Loss: 1.061267 | Val Loss: 1.015637\n",
      "Epoch [100/500] | Train Loss: 1.212896 | Val Loss: 0.699205\n",
      "Epoch [200/500] | Train Loss: 1.171919 | Val Loss: 0.696344\n",
      "Epoch [300/500] | Train Loss: 1.094367 | Val Loss: 0.690861\n",
      "Epoch [400/500] | Train Loss: 1.007470 | Val Loss: 0.695304\n",
      "Epoch [500/500] | Train Loss: 1.000695 | Val Loss: 0.677568\n",
      "Epoch [100/500] | Train Loss: 1.108639 | Val Loss: 3.323747\n",
      "Epoch [200/500] | Train Loss: 1.061327 | Val Loss: 3.470945\n",
      "Epoch [300/500] | Train Loss: 0.991454 | Val Loss: 3.613995\n",
      "Epoch [400/500] | Train Loss: 0.964663 | Val Loss: 3.594496\n",
      "Epoch [500/500] | Train Loss: 0.930860 | Val Loss: 3.607550\n",
      "Epoch [100/500] | Train Loss: 1.517168 | Val Loss: 2.692634\n",
      "Epoch [200/500] | Train Loss: 1.446886 | Val Loss: 2.653221\n",
      "Epoch [300/500] | Train Loss: 1.365786 | Val Loss: 2.618602\n",
      "Epoch [400/500] | Train Loss: 1.317348 | Val Loss: 2.675709\n",
      "Epoch [500/500] | Train Loss: 1.214040 | Val Loss: 2.723267\n",
      "Epoch [100/500] | Train Loss: 1.102090 | Val Loss: 1.064680\n",
      "Epoch [200/500] | Train Loss: 0.954437 | Val Loss: 1.200900\n",
      "Epoch [300/500] | Train Loss: 0.904450 | Val Loss: 1.266799\n",
      "Epoch [400/500] | Train Loss: 0.706613 | Val Loss: 1.306178\n",
      "Epoch [500/500] | Train Loss: 1.014610 | Val Loss: 1.241764\n",
      "Epoch [100/500] | Train Loss: 1.111284 | Val Loss: 1.052331\n",
      "Epoch [200/500] | Train Loss: 0.934730 | Val Loss: 1.084164\n",
      "Epoch [300/500] | Train Loss: 0.930928 | Val Loss: 1.060046\n",
      "Epoch [400/500] | Train Loss: 0.853407 | Val Loss: 1.092053\n",
      "Epoch [500/500] | Train Loss: 0.714313 | Val Loss: 1.094206\n",
      "Epoch [100/500] | Train Loss: 0.988821 | Val Loss: 0.690530\n",
      "Epoch [200/500] | Train Loss: 0.867776 | Val Loss: 0.755379\n",
      "Epoch [300/500] | Train Loss: 0.790556 | Val Loss: 0.766271\n",
      "Epoch [400/500] | Train Loss: 0.758999 | Val Loss: 0.780846\n",
      "Epoch [500/500] | Train Loss: 0.729323 | Val Loss: 0.805445\n",
      "Epoch [100/500] | Train Loss: 1.026636 | Val Loss: 3.431489\n",
      "Epoch [200/500] | Train Loss: 0.868492 | Val Loss: 3.589923\n",
      "Epoch [300/500] | Train Loss: 0.798541 | Val Loss: 4.053056\n",
      "Epoch [400/500] | Train Loss: 0.789207 | Val Loss: 3.930560\n",
      "Epoch [500/500] | Train Loss: 0.774794 | Val Loss: 4.027673\n",
      "Epoch [100/500] | Train Loss: 1.369158 | Val Loss: 2.662105\n",
      "Epoch [200/500] | Train Loss: 1.257906 | Val Loss: 2.574773\n",
      "Epoch [300/500] | Train Loss: 1.156639 | Val Loss: 2.625072\n",
      "Epoch [400/500] | Train Loss: 1.168336 | Val Loss: 2.548809\n",
      "Epoch [500/500] | Train Loss: 1.149982 | Val Loss: 2.600230\n",
      "[Year=1939] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.775692 Test MSE=1.721500\n",
      "Year 1939 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.793203 | Val Loss: 0.892955\n",
      "Epoch [200/500] | Train Loss: 0.691943 | Val Loss: 0.965263\n",
      "Epoch [300/500] | Train Loss: 0.543882 | Val Loss: 1.117560\n",
      "Epoch [400/500] | Train Loss: 0.517218 | Val Loss: 1.132623\n",
      "Epoch [500/500] | Train Loss: 0.437321 | Val Loss: 1.124637\n",
      "Epoch [100/500] | Train Loss: 0.823386 | Val Loss: 0.804932\n",
      "Epoch [200/500] | Train Loss: 0.760898 | Val Loss: 0.827693\n",
      "Epoch [300/500] | Train Loss: 0.657509 | Val Loss: 0.903844\n",
      "Epoch [400/500] | Train Loss: 0.622825 | Val Loss: 0.913996\n",
      "Epoch [500/500] | Train Loss: 0.602917 | Val Loss: 0.939879\n",
      "Epoch [100/500] | Train Loss: 0.796791 | Val Loss: 4.240023\n",
      "Epoch [200/500] | Train Loss: 0.705647 | Val Loss: 4.637153\n",
      "Epoch [300/500] | Train Loss: 0.653160 | Val Loss: 4.881973\n",
      "Epoch [400/500] | Train Loss: 0.619454 | Val Loss: 5.311816\n",
      "Epoch [500/500] | Train Loss: 0.621900 | Val Loss: 5.640768\n",
      "Epoch [100/500] | Train Loss: 1.603151 | Val Loss: 2.013098\n",
      "Epoch [200/500] | Train Loss: 1.552609 | Val Loss: 2.037117\n",
      "Epoch [300/500] | Train Loss: 1.392487 | Val Loss: 2.056394\n",
      "Epoch [400/500] | Train Loss: 1.291954 | Val Loss: 2.096757\n",
      "Epoch [500/500] | Train Loss: 1.139973 | Val Loss: 2.082216\n",
      "Epoch [100/500] | Train Loss: 1.679599 | Val Loss: 1.663906\n",
      "Epoch [200/500] | Train Loss: 1.593195 | Val Loss: 1.700185\n",
      "Epoch [300/500] | Train Loss: 1.487880 | Val Loss: 1.750809\n",
      "Epoch [400/500] | Train Loss: 1.352901 | Val Loss: 1.807959\n",
      "Epoch [500/500] | Train Loss: 1.351596 | Val Loss: 1.810922\n",
      "Epoch [100/500] | Train Loss: 0.667353 | Val Loss: 1.084434\n",
      "Epoch [200/500] | Train Loss: 0.446608 | Val Loss: 1.176036\n",
      "Epoch [300/500] | Train Loss: 0.393632 | Val Loss: 1.229742\n",
      "Epoch [400/500] | Train Loss: 0.467795 | Val Loss: 1.165792\n",
      "Epoch [500/500] | Train Loss: 0.328552 | Val Loss: 1.290778\n",
      "Epoch [100/500] | Train Loss: 0.610097 | Val Loss: 0.902308\n",
      "Epoch [200/500] | Train Loss: 0.489344 | Val Loss: 1.036980\n",
      "Epoch [300/500] | Train Loss: 0.404755 | Val Loss: 1.084036\n",
      "Epoch [400/500] | Train Loss: 0.411730 | Val Loss: 1.109372\n",
      "Epoch [500/500] | Train Loss: 0.420293 | Val Loss: 1.174538\n",
      "Epoch [100/500] | Train Loss: 0.661817 | Val Loss: 4.939461\n",
      "Epoch [200/500] | Train Loss: 0.548607 | Val Loss: 5.248642\n",
      "Epoch [300/500] | Train Loss: 0.516551 | Val Loss: 5.138081\n",
      "Epoch [400/500] | Train Loss: 0.455945 | Val Loss: 5.188240\n",
      "Epoch [500/500] | Train Loss: 0.436512 | Val Loss: 5.118777\n",
      "Epoch [100/500] | Train Loss: 1.362430 | Val Loss: 2.056121\n",
      "Epoch [200/500] | Train Loss: 1.107315 | Val Loss: 2.181483\n",
      "Epoch [300/500] | Train Loss: 1.086472 | Val Loss: 2.297703\n",
      "Epoch [400/500] | Train Loss: 0.984948 | Val Loss: 2.211174\n",
      "Epoch [500/500] | Train Loss: 0.995311 | Val Loss: 2.396201\n",
      "Epoch [100/500] | Train Loss: 1.438933 | Val Loss: 1.813416\n",
      "Epoch [200/500] | Train Loss: 1.157699 | Val Loss: 1.959948\n",
      "Epoch [300/500] | Train Loss: 1.125652 | Val Loss: 1.870177\n",
      "Epoch [400/500] | Train Loss: 1.051207 | Val Loss: 1.956822\n",
      "Epoch [500/500] | Train Loss: 1.013279 | Val Loss: 1.880542\n",
      "Epoch [100/500] | Train Loss: 0.839677 | Val Loss: 0.852071\n",
      "Epoch [200/500] | Train Loss: 0.819986 | Val Loss: 0.870464\n",
      "Epoch [300/500] | Train Loss: 0.766115 | Val Loss: 0.907174\n",
      "Epoch [400/500] | Train Loss: 0.731634 | Val Loss: 0.938272\n",
      "Epoch [500/500] | Train Loss: 0.601200 | Val Loss: 0.943115\n",
      "Epoch [100/500] | Train Loss: 0.830851 | Val Loss: 0.795200\n",
      "Epoch [200/500] | Train Loss: 0.816119 | Val Loss: 0.806567\n",
      "Epoch [300/500] | Train Loss: 0.747029 | Val Loss: 0.834466\n",
      "Epoch [400/500] | Train Loss: 0.724900 | Val Loss: 0.863306\n",
      "Epoch [500/500] | Train Loss: 0.728773 | Val Loss: 0.866528\n",
      "Epoch [100/500] | Train Loss: 0.815959 | Val Loss: 4.228039\n",
      "Epoch [200/500] | Train Loss: 0.790513 | Val Loss: 4.309666\n",
      "Epoch [300/500] | Train Loss: 0.765409 | Val Loss: 4.323399\n",
      "Epoch [400/500] | Train Loss: 0.743724 | Val Loss: 4.371123\n",
      "Epoch [500/500] | Train Loss: 0.760633 | Val Loss: 4.401201\n",
      "Epoch [100/500] | Train Loss: 1.620485 | Val Loss: 2.021895\n",
      "Epoch [200/500] | Train Loss: 1.597695 | Val Loss: 2.044409\n",
      "Epoch [300/500] | Train Loss: 1.419831 | Val Loss: 2.078400\n",
      "Epoch [400/500] | Train Loss: 1.308189 | Val Loss: 2.103098\n",
      "Epoch [500/500] | Train Loss: 1.323646 | Val Loss: 2.122297\n",
      "Epoch [100/500] | Train Loss: 1.702541 | Val Loss: 1.634916\n",
      "Epoch [200/500] | Train Loss: 1.665635 | Val Loss: 1.662748\n",
      "Epoch [300/500] | Train Loss: 1.628023 | Val Loss: 1.686432\n",
      "Epoch [400/500] | Train Loss: 1.550055 | Val Loss: 1.712485\n",
      "Epoch [500/500] | Train Loss: 1.475667 | Val Loss: 1.699636\n",
      "Epoch [100/500] | Train Loss: 0.645024 | Val Loss: 0.946992\n",
      "Epoch [200/500] | Train Loss: 0.617316 | Val Loss: 1.021097\n",
      "Epoch [300/500] | Train Loss: 0.505773 | Val Loss: 1.087833\n",
      "Epoch [400/500] | Train Loss: 0.584898 | Val Loss: 1.051480\n",
      "Epoch [500/500] | Train Loss: 0.526810 | Val Loss: 1.041176\n",
      "Epoch [100/500] | Train Loss: 0.698006 | Val Loss: 0.834859\n",
      "Epoch [200/500] | Train Loss: 0.656931 | Val Loss: 0.883520\n",
      "Epoch [300/500] | Train Loss: 0.587752 | Val Loss: 0.973875\n",
      "Epoch [400/500] | Train Loss: 0.561500 | Val Loss: 0.962534\n",
      "Epoch [500/500] | Train Loss: 0.498616 | Val Loss: 0.977990\n",
      "Epoch [100/500] | Train Loss: 0.730678 | Val Loss: 4.352923\n",
      "Epoch [200/500] | Train Loss: 0.684850 | Val Loss: 4.417889\n",
      "Epoch [300/500] | Train Loss: 0.618481 | Val Loss: 4.508916\n",
      "Epoch [400/500] | Train Loss: 0.602112 | Val Loss: 4.313293\n",
      "Epoch [500/500] | Train Loss: 0.659355 | Val Loss: 4.577353\n",
      "Epoch [100/500] | Train Loss: 1.400072 | Val Loss: 2.035252\n",
      "Epoch [200/500] | Train Loss: 1.195263 | Val Loss: 2.057869\n",
      "Epoch [300/500] | Train Loss: 1.302741 | Val Loss: 2.054135\n",
      "Epoch [400/500] | Train Loss: 1.185282 | Val Loss: 2.136272\n",
      "Epoch [500/500] | Train Loss: 1.114108 | Val Loss: 2.124288\n",
      "Epoch [100/500] | Train Loss: 1.496921 | Val Loss: 1.685858\n",
      "Epoch [200/500] | Train Loss: 1.440698 | Val Loss: 1.729582\n",
      "Epoch [300/500] | Train Loss: 1.330195 | Val Loss: 1.835821\n",
      "Epoch [400/500] | Train Loss: 1.243514 | Val Loss: 1.785548\n",
      "Epoch [500/500] | Train Loss: 1.240012 | Val Loss: 1.681404\n",
      "Epoch [100/500] | Train Loss: 0.747098 | Val Loss: 0.935401\n",
      "Epoch [200/500] | Train Loss: 0.583159 | Val Loss: 0.992543\n",
      "Epoch [300/500] | Train Loss: 0.453523 | Val Loss: 1.078524\n",
      "Epoch [400/500] | Train Loss: 0.444177 | Val Loss: 1.067106\n",
      "Epoch [500/500] | Train Loss: 0.492333 | Val Loss: 1.137884\n",
      "Epoch [100/500] | Train Loss: 0.784838 | Val Loss: 0.812297\n",
      "Epoch [200/500] | Train Loss: 0.696596 | Val Loss: 0.879405\n",
      "Epoch [300/500] | Train Loss: 0.590654 | Val Loss: 0.924915\n",
      "Epoch [400/500] | Train Loss: 0.532104 | Val Loss: 0.968387\n",
      "Epoch [500/500] | Train Loss: 0.481189 | Val Loss: 1.018134\n",
      "Epoch [100/500] | Train Loss: 0.804798 | Val Loss: 4.241106\n",
      "Epoch [200/500] | Train Loss: 0.723283 | Val Loss: 4.694372\n",
      "Epoch [300/500] | Train Loss: 0.641163 | Val Loss: 5.164666\n",
      "Epoch [400/500] | Train Loss: 0.606424 | Val Loss: 5.195539\n",
      "Epoch [500/500] | Train Loss: 0.603959 | Val Loss: 5.207731\n",
      "Epoch [100/500] | Train Loss: 1.529492 | Val Loss: 2.024253\n",
      "Epoch [200/500] | Train Loss: 1.390221 | Val Loss: 2.038972\n",
      "Epoch [300/500] | Train Loss: 1.216981 | Val Loss: 2.110415\n",
      "Epoch [400/500] | Train Loss: 1.093388 | Val Loss: 2.233094\n",
      "Epoch [500/500] | Train Loss: 1.048408 | Val Loss: 2.365279\n",
      "Epoch [100/500] | Train Loss: 1.636298 | Val Loss: 1.632153\n",
      "Epoch [200/500] | Train Loss: 1.504647 | Val Loss: 1.667593\n",
      "Epoch [300/500] | Train Loss: 1.268610 | Val Loss: 1.731657\n",
      "Epoch [400/500] | Train Loss: 1.272430 | Val Loss: 1.865045\n",
      "Epoch [500/500] | Train Loss: 1.177473 | Val Loss: 1.821008\n",
      "Epoch [100/500] | Train Loss: 0.410303 | Val Loss: 1.042380\n",
      "Epoch [200/500] | Train Loss: 0.329156 | Val Loss: 1.172426\n",
      "Epoch [300/500] | Train Loss: 0.212168 | Val Loss: 1.176888\n",
      "Epoch [400/500] | Train Loss: 0.233034 | Val Loss: 1.121286\n",
      "Epoch [500/500] | Train Loss: 0.212294 | Val Loss: 1.140087\n",
      "Epoch [100/500] | Train Loss: 0.702830 | Val Loss: 0.821435\n",
      "Epoch [200/500] | Train Loss: 0.556599 | Val Loss: 1.016225\n",
      "Epoch [300/500] | Train Loss: 0.452072 | Val Loss: 1.023175\n",
      "Epoch [400/500] | Train Loss: 0.385161 | Val Loss: 1.070817\n",
      "Epoch [500/500] | Train Loss: 0.384188 | Val Loss: 1.032418\n",
      "Epoch [100/500] | Train Loss: 0.564268 | Val Loss: 5.363893\n",
      "Epoch [200/500] | Train Loss: 0.435961 | Val Loss: 5.284811\n",
      "Epoch [300/500] | Train Loss: 0.389398 | Val Loss: 5.092100\n",
      "Epoch [400/500] | Train Loss: 0.396250 | Val Loss: 4.819274\n",
      "Epoch [500/500] | Train Loss: 0.377179 | Val Loss: 5.316195\n",
      "Epoch [100/500] | Train Loss: 1.073084 | Val Loss: 2.255880\n",
      "Epoch [200/500] | Train Loss: 0.901405 | Val Loss: 2.230338\n",
      "Epoch [300/500] | Train Loss: 0.819806 | Val Loss: 2.132507\n",
      "Epoch [400/500] | Train Loss: 0.787494 | Val Loss: 2.267278\n",
      "Epoch [500/500] | Train Loss: 0.793325 | Val Loss: 2.208557\n",
      "Epoch [100/500] | Train Loss: 1.272215 | Val Loss: 1.884869\n",
      "Epoch [200/500] | Train Loss: 1.094329 | Val Loss: 1.927342\n",
      "Epoch [300/500] | Train Loss: 1.069272 | Val Loss: 2.005299\n",
      "Epoch [400/500] | Train Loss: 0.944293 | Val Loss: 1.989134\n",
      "Epoch [500/500] | Train Loss: 0.866135 | Val Loss: 1.975469\n",
      "Epoch [100/500] | Train Loss: 0.773222 | Val Loss: 0.873911\n",
      "Epoch [200/500] | Train Loss: 0.657936 | Val Loss: 0.924235\n",
      "Epoch [300/500] | Train Loss: 0.639740 | Val Loss: 0.987639\n",
      "Epoch [400/500] | Train Loss: 0.555149 | Val Loss: 1.040743\n",
      "Epoch [500/500] | Train Loss: 0.511112 | Val Loss: 1.033162\n",
      "Epoch [100/500] | Train Loss: 0.827878 | Val Loss: 0.803989\n",
      "Epoch [200/500] | Train Loss: 0.739048 | Val Loss: 0.828792\n",
      "Epoch [300/500] | Train Loss: 0.710224 | Val Loss: 0.859651\n",
      "Epoch [400/500] | Train Loss: 0.657752 | Val Loss: 0.880594\n",
      "Epoch [500/500] | Train Loss: 0.638330 | Val Loss: 0.903065\n",
      "Epoch [100/500] | Train Loss: 0.848824 | Val Loss: 4.251627\n",
      "Epoch [200/500] | Train Loss: 0.829510 | Val Loss: 4.212416\n",
      "Epoch [300/500] | Train Loss: 0.791742 | Val Loss: 4.346576\n",
      "Epoch [400/500] | Train Loss: 0.748910 | Val Loss: 4.400522\n",
      "Epoch [500/500] | Train Loss: 0.702601 | Val Loss: 4.476485\n",
      "Epoch [100/500] | Train Loss: 1.602169 | Val Loss: 1.998521\n",
      "Epoch [200/500] | Train Loss: 1.521352 | Val Loss: 2.022327\n",
      "Epoch [300/500] | Train Loss: 1.326389 | Val Loss: 2.058971\n",
      "Epoch [400/500] | Train Loss: 1.278970 | Val Loss: 2.112158\n",
      "Epoch [500/500] | Train Loss: 1.124354 | Val Loss: 2.096843\n",
      "Epoch [100/500] | Train Loss: 1.679344 | Val Loss: 1.648043\n",
      "Epoch [200/500] | Train Loss: 1.609110 | Val Loss: 1.650096\n",
      "Epoch [300/500] | Train Loss: 1.543784 | Val Loss: 1.644606\n",
      "Epoch [400/500] | Train Loss: 1.484419 | Val Loss: 1.686584\n",
      "Epoch [500/500] | Train Loss: 1.405308 | Val Loss: 1.715745\n",
      "Epoch [100/500] | Train Loss: 0.701251 | Val Loss: 0.956515\n",
      "Epoch [200/500] | Train Loss: 0.507093 | Val Loss: 1.074246\n",
      "Epoch [300/500] | Train Loss: 0.436991 | Val Loss: 1.133174\n",
      "Epoch [400/500] | Train Loss: 0.355035 | Val Loss: 1.138615\n",
      "Epoch [500/500] | Train Loss: 0.318445 | Val Loss: 1.130073\n",
      "Epoch [100/500] | Train Loss: 0.739068 | Val Loss: 0.826619\n",
      "Epoch [200/500] | Train Loss: 0.565739 | Val Loss: 0.871712\n",
      "Epoch [300/500] | Train Loss: 0.590073 | Val Loss: 0.955026\n",
      "Epoch [400/500] | Train Loss: 0.548380 | Val Loss: 0.924047\n",
      "Epoch [500/500] | Train Loss: 0.517043 | Val Loss: 1.006687\n",
      "Epoch [100/500] | Train Loss: 0.706292 | Val Loss: 4.484170\n",
      "Epoch [200/500] | Train Loss: 0.629985 | Val Loss: 4.573482\n",
      "Epoch [300/500] | Train Loss: 0.618441 | Val Loss: 4.450331\n",
      "Epoch [400/500] | Train Loss: 0.554413 | Val Loss: 4.433597\n",
      "Epoch [500/500] | Train Loss: 0.546952 | Val Loss: 4.618293\n",
      "Epoch [100/500] | Train Loss: 1.264890 | Val Loss: 2.031529\n",
      "Epoch [200/500] | Train Loss: 1.158784 | Val Loss: 2.080654\n",
      "Epoch [300/500] | Train Loss: 1.121214 | Val Loss: 2.042333\n",
      "Epoch [400/500] | Train Loss: 1.088745 | Val Loss: 2.056307\n",
      "Epoch [500/500] | Train Loss: 0.984334 | Val Loss: 2.045831\n",
      "Epoch [100/500] | Train Loss: 1.468732 | Val Loss: 1.735781\n",
      "Epoch [200/500] | Train Loss: 1.253149 | Val Loss: 1.779850\n",
      "Epoch [300/500] | Train Loss: 1.155329 | Val Loss: 1.860530\n",
      "Epoch [400/500] | Train Loss: 1.132055 | Val Loss: 1.859737\n",
      "Epoch [500/500] | Train Loss: 1.090176 | Val Loss: 1.972658\n",
      "[Year=1940] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=2.006555 Test MSE=1.278635\n",
      "Year 1940 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.701561 | Val Loss: 0.871686\n",
      "Epoch [200/500] | Train Loss: 0.548040 | Val Loss: 0.972567\n",
      "Epoch [300/500] | Train Loss: 0.468781 | Val Loss: 1.050405\n",
      "Epoch [400/500] | Train Loss: 0.455292 | Val Loss: 1.056390\n",
      "Epoch [500/500] | Train Loss: 0.375307 | Val Loss: 1.074294\n",
      "Epoch [100/500] | Train Loss: 0.790757 | Val Loss: 4.609218\n",
      "Epoch [200/500] | Train Loss: 0.701185 | Val Loss: 4.736108\n",
      "Epoch [300/500] | Train Loss: 0.648440 | Val Loss: 5.195993\n",
      "Epoch [400/500] | Train Loss: 0.583034 | Val Loss: 5.647971\n",
      "Epoch [500/500] | Train Loss: 0.571892 | Val Loss: 5.802132\n",
      "Epoch [100/500] | Train Loss: 1.977837 | Val Loss: 2.044297\n",
      "Epoch [200/500] | Train Loss: 1.862141 | Val Loss: 2.165913\n",
      "Epoch [300/500] | Train Loss: 1.676497 | Val Loss: 2.206508\n",
      "Epoch [400/500] | Train Loss: 1.504787 | Val Loss: 2.218970\n",
      "Epoch [500/500] | Train Loss: 1.530866 | Val Loss: 2.291563\n",
      "Epoch [100/500] | Train Loss: 1.962473 | Val Loss: 1.162957\n",
      "Epoch [200/500] | Train Loss: 1.777389 | Val Loss: 1.183859\n",
      "Epoch [300/500] | Train Loss: 1.739860 | Val Loss: 1.208815\n",
      "Epoch [400/500] | Train Loss: 1.588141 | Val Loss: 1.214096\n",
      "Epoch [500/500] | Train Loss: 1.527738 | Val Loss: 1.201068\n",
      "Epoch [100/500] | Train Loss: 1.796754 | Val Loss: 1.493515\n",
      "Epoch [200/500] | Train Loss: 1.671256 | Val Loss: 1.588940\n",
      "Epoch [300/500] | Train Loss: 1.642520 | Val Loss: 1.616149\n",
      "Epoch [400/500] | Train Loss: 1.520275 | Val Loss: 1.617051\n",
      "Epoch [500/500] | Train Loss: 1.421403 | Val Loss: 1.630969\n",
      "Epoch [100/500] | Train Loss: 0.478703 | Val Loss: 0.995628\n",
      "Epoch [200/500] | Train Loss: 0.335199 | Val Loss: 1.237801\n",
      "Epoch [300/500] | Train Loss: 0.266476 | Val Loss: 1.157824\n",
      "Epoch [400/500] | Train Loss: 0.223774 | Val Loss: 1.151513\n",
      "Epoch [500/500] | Train Loss: 0.231560 | Val Loss: 1.197849\n",
      "Epoch [100/500] | Train Loss: 0.551621 | Val Loss: 6.339972\n",
      "Epoch [200/500] | Train Loss: 0.428940 | Val Loss: 6.492243\n",
      "Epoch [300/500] | Train Loss: 0.390082 | Val Loss: 6.467810\n",
      "Epoch [400/500] | Train Loss: 0.332626 | Val Loss: 7.144177\n",
      "Epoch [500/500] | Train Loss: 0.342148 | Val Loss: 7.001568\n",
      "Epoch [100/500] | Train Loss: 1.422896 | Val Loss: 2.239748\n",
      "Epoch [200/500] | Train Loss: 1.325235 | Val Loss: 2.339973\n",
      "Epoch [300/500] | Train Loss: 1.124549 | Val Loss: 2.509802\n",
      "Epoch [400/500] | Train Loss: 0.906175 | Val Loss: 2.548838\n",
      "Epoch [500/500] | Train Loss: 1.097798 | Val Loss: 2.502316\n",
      "Epoch [100/500] | Train Loss: 1.554351 | Val Loss: 1.271856\n",
      "Epoch [200/500] | Train Loss: 1.393342 | Val Loss: 1.272587\n",
      "Epoch [300/500] | Train Loss: 1.295607 | Val Loss: 1.396368\n",
      "Epoch [400/500] | Train Loss: 1.243486 | Val Loss: 1.463762\n",
      "Epoch [500/500] | Train Loss: 1.093067 | Val Loss: 1.413450\n",
      "Epoch [100/500] | Train Loss: 1.370319 | Val Loss: 1.641382\n",
      "Epoch [200/500] | Train Loss: 1.268641 | Val Loss: 1.787209\n",
      "Epoch [300/500] | Train Loss: 1.183904 | Val Loss: 1.591443\n",
      "Epoch [400/500] | Train Loss: 1.120786 | Val Loss: 1.693630\n",
      "Epoch [500/500] | Train Loss: 1.058556 | Val Loss: 1.673122\n",
      "Epoch [100/500] | Train Loss: 0.726987 | Val Loss: 0.868327\n",
      "Epoch [200/500] | Train Loss: 0.672356 | Val Loss: 0.919788\n",
      "Epoch [300/500] | Train Loss: 0.594592 | Val Loss: 0.939649\n",
      "Epoch [400/500] | Train Loss: 0.541772 | Val Loss: 0.972044\n",
      "Epoch [500/500] | Train Loss: 0.506631 | Val Loss: 0.970937\n",
      "Epoch [100/500] | Train Loss: 0.790265 | Val Loss: 4.546123\n",
      "Epoch [200/500] | Train Loss: 0.716310 | Val Loss: 4.698756\n",
      "Epoch [300/500] | Train Loss: 0.661499 | Val Loss: 5.017921\n",
      "Epoch [400/500] | Train Loss: 0.656323 | Val Loss: 5.038018\n",
      "Epoch [500/500] | Train Loss: 0.608986 | Val Loss: 4.988941\n",
      "Epoch [100/500] | Train Loss: 1.994025 | Val Loss: 2.060680\n",
      "Epoch [200/500] | Train Loss: 1.897648 | Val Loss: 2.061972\n",
      "Epoch [300/500] | Train Loss: 1.786253 | Val Loss: 2.052593\n",
      "Epoch [400/500] | Train Loss: 1.783651 | Val Loss: 2.121284\n",
      "Epoch [500/500] | Train Loss: 1.654262 | Val Loss: 2.168486\n",
      "Epoch [100/500] | Train Loss: 2.017313 | Val Loss: 1.136214\n",
      "Epoch [200/500] | Train Loss: 1.917997 | Val Loss: 1.140967\n",
      "Epoch [300/500] | Train Loss: 1.764398 | Val Loss: 1.142535\n",
      "Epoch [400/500] | Train Loss: 1.684295 | Val Loss: 1.149252\n",
      "Epoch [500/500] | Train Loss: 1.699321 | Val Loss: 1.159059\n",
      "Epoch [100/500] | Train Loss: 1.818332 | Val Loss: 1.481190\n",
      "Epoch [200/500] | Train Loss: 1.752111 | Val Loss: 1.517303\n",
      "Epoch [300/500] | Train Loss: 1.716037 | Val Loss: 1.500568\n",
      "Epoch [400/500] | Train Loss: 1.623610 | Val Loss: 1.487896\n",
      "Epoch [500/500] | Train Loss: 1.540472 | Val Loss: 1.509161\n",
      "Epoch [100/500] | Train Loss: 0.540002 | Val Loss: 0.985362\n",
      "Epoch [200/500] | Train Loss: 0.425120 | Val Loss: 0.988801\n",
      "Epoch [300/500] | Train Loss: 0.400462 | Val Loss: 1.041078\n",
      "Epoch [400/500] | Train Loss: 0.331082 | Val Loss: 1.046690\n",
      "Epoch [500/500] | Train Loss: 0.329314 | Val Loss: 1.036451\n",
      "Epoch [100/500] | Train Loss: 0.655431 | Val Loss: 5.509605\n",
      "Epoch [200/500] | Train Loss: 0.551885 | Val Loss: 5.338960\n",
      "Epoch [300/500] | Train Loss: 0.521127 | Val Loss: 5.323672\n",
      "Epoch [400/500] | Train Loss: 0.521814 | Val Loss: 5.299883\n",
      "Epoch [500/500] | Train Loss: 0.553187 | Val Loss: 5.291604\n",
      "Epoch [100/500] | Train Loss: 1.652302 | Val Loss: 2.064190\n",
      "Epoch [200/500] | Train Loss: 1.482754 | Val Loss: 2.177333\n",
      "Epoch [300/500] | Train Loss: 1.450509 | Val Loss: 2.194738\n",
      "Epoch [400/500] | Train Loss: 1.320097 | Val Loss: 2.188704\n",
      "Epoch [500/500] | Train Loss: 1.278520 | Val Loss: 2.191717\n",
      "Epoch [100/500] | Train Loss: 1.800555 | Val Loss: 1.192813\n",
      "Epoch [200/500] | Train Loss: 1.652914 | Val Loss: 1.170053\n",
      "Epoch [300/500] | Train Loss: 1.663687 | Val Loss: 1.182921\n",
      "Epoch [400/500] | Train Loss: 1.524576 | Val Loss: 1.186873\n",
      "Epoch [500/500] | Train Loss: 1.429843 | Val Loss: 1.158335\n",
      "Epoch [100/500] | Train Loss: 1.628251 | Val Loss: 1.481201\n",
      "Epoch [200/500] | Train Loss: 1.640039 | Val Loss: 1.485031\n",
      "Epoch [300/500] | Train Loss: 1.440511 | Val Loss: 1.489253\n",
      "Epoch [400/500] | Train Loss: 1.456470 | Val Loss: 1.523426\n",
      "Epoch [500/500] | Train Loss: 1.367771 | Val Loss: 1.634933\n",
      "Epoch [100/500] | Train Loss: 0.749113 | Val Loss: 0.880479\n",
      "Epoch [200/500] | Train Loss: 0.589350 | Val Loss: 0.955506\n",
      "Epoch [300/500] | Train Loss: 0.440036 | Val Loss: 0.988549\n",
      "Epoch [400/500] | Train Loss: 0.417488 | Val Loss: 1.095308\n",
      "Epoch [500/500] | Train Loss: 0.349182 | Val Loss: 1.113083\n",
      "Epoch [100/500] | Train Loss: 0.771542 | Val Loss: 4.654159\n",
      "Epoch [200/500] | Train Loss: 0.688874 | Val Loss: 5.041618\n",
      "Epoch [300/500] | Train Loss: 0.569395 | Val Loss: 5.411580\n",
      "Epoch [400/500] | Train Loss: 0.479325 | Val Loss: 5.755038\n",
      "Epoch [500/500] | Train Loss: 0.480016 | Val Loss: 5.803806\n",
      "Epoch [100/500] | Train Loss: 1.882146 | Val Loss: 2.021745\n",
      "Epoch [200/500] | Train Loss: 1.580176 | Val Loss: 2.179003\n",
      "Epoch [300/500] | Train Loss: 1.379469 | Val Loss: 2.287952\n",
      "Epoch [400/500] | Train Loss: 1.256567 | Val Loss: 2.355273\n",
      "Epoch [500/500] | Train Loss: 1.165604 | Val Loss: 2.346934\n",
      "Epoch [100/500] | Train Loss: 1.894657 | Val Loss: 1.181970\n",
      "Epoch [200/500] | Train Loss: 1.645284 | Val Loss: 1.237003\n",
      "Epoch [300/500] | Train Loss: 1.529247 | Val Loss: 1.314530\n",
      "Epoch [400/500] | Train Loss: 1.484272 | Val Loss: 1.323567\n",
      "Epoch [500/500] | Train Loss: 1.292884 | Val Loss: 1.300441\n",
      "Epoch [100/500] | Train Loss: 1.755784 | Val Loss: 1.508450\n",
      "Epoch [200/500] | Train Loss: 1.581794 | Val Loss: 1.571857\n",
      "Epoch [300/500] | Train Loss: 1.455151 | Val Loss: 1.585887\n",
      "Epoch [400/500] | Train Loss: 1.331715 | Val Loss: 1.573143\n",
      "Epoch [500/500] | Train Loss: 1.321148 | Val Loss: 1.501887\n",
      "Epoch [100/500] | Train Loss: 0.365079 | Val Loss: 1.119839\n",
      "Epoch [200/500] | Train Loss: 0.227055 | Val Loss: 1.129323\n",
      "Epoch [300/500] | Train Loss: 0.211539 | Val Loss: 1.064576\n",
      "Epoch [400/500] | Train Loss: 0.184270 | Val Loss: 1.159162\n",
      "Epoch [500/500] | Train Loss: 0.200840 | Val Loss: 1.080253\n",
      "Epoch [100/500] | Train Loss: 0.526591 | Val Loss: 6.696136\n",
      "Epoch [200/500] | Train Loss: 0.403887 | Val Loss: 6.054118\n",
      "Epoch [300/500] | Train Loss: 0.369527 | Val Loss: 6.348422\n",
      "Epoch [400/500] | Train Loss: 0.345223 | Val Loss: 7.091316\n",
      "Epoch [500/500] | Train Loss: 0.306259 | Val Loss: 5.955127\n",
      "Epoch [100/500] | Train Loss: 1.200171 | Val Loss: 2.148164\n",
      "Epoch [200/500] | Train Loss: 1.022872 | Val Loss: 2.334033\n",
      "Epoch [300/500] | Train Loss: 0.858466 | Val Loss: 2.498837\n",
      "Epoch [400/500] | Train Loss: 0.717400 | Val Loss: 2.677341\n",
      "Epoch [500/500] | Train Loss: 0.743926 | Val Loss: 2.398725\n",
      "Epoch [100/500] | Train Loss: 1.518521 | Val Loss: 1.129288\n",
      "Epoch [200/500] | Train Loss: 1.291074 | Val Loss: 1.255628\n",
      "Epoch [300/500] | Train Loss: 1.175930 | Val Loss: 1.242825\n",
      "Epoch [400/500] | Train Loss: 1.062685 | Val Loss: 1.320496\n",
      "Epoch [500/500] | Train Loss: 1.069786 | Val Loss: 1.418739\n",
      "Epoch [100/500] | Train Loss: 1.392902 | Val Loss: 1.571925\n",
      "Epoch [200/500] | Train Loss: 1.203564 | Val Loss: 1.603842\n",
      "Epoch [300/500] | Train Loss: 1.067127 | Val Loss: 1.552265\n",
      "Epoch [400/500] | Train Loss: 1.008671 | Val Loss: 1.610214\n",
      "Epoch [500/500] | Train Loss: 1.015498 | Val Loss: 1.516372\n",
      "Epoch [100/500] | Train Loss: 0.759157 | Val Loss: 0.876822\n",
      "Epoch [200/500] | Train Loss: 0.628033 | Val Loss: 0.981720\n",
      "Epoch [300/500] | Train Loss: 0.466869 | Val Loss: 1.017448\n",
      "Epoch [400/500] | Train Loss: 0.444445 | Val Loss: 1.050883\n",
      "Epoch [500/500] | Train Loss: 0.446209 | Val Loss: 1.082287\n",
      "Epoch [100/500] | Train Loss: 0.798464 | Val Loss: 4.603274\n",
      "Epoch [200/500] | Train Loss: 0.724920 | Val Loss: 4.896506\n",
      "Epoch [300/500] | Train Loss: 0.638552 | Val Loss: 5.430772\n",
      "Epoch [400/500] | Train Loss: 0.590324 | Val Loss: 5.278847\n",
      "Epoch [500/500] | Train Loss: 0.540813 | Val Loss: 5.226613\n",
      "Epoch [100/500] | Train Loss: 1.981066 | Val Loss: 2.055642\n",
      "Epoch [200/500] | Train Loss: 1.865310 | Val Loss: 2.141087\n",
      "Epoch [300/500] | Train Loss: 1.768343 | Val Loss: 2.170959\n",
      "Epoch [400/500] | Train Loss: 1.613397 | Val Loss: 2.191299\n",
      "Epoch [500/500] | Train Loss: 1.480927 | Val Loss: 2.203582\n",
      "Epoch [100/500] | Train Loss: 1.954465 | Val Loss: 1.143496\n",
      "Epoch [200/500] | Train Loss: 1.861885 | Val Loss: 1.157107\n",
      "Epoch [300/500] | Train Loss: 1.795752 | Val Loss: 1.162892\n",
      "Epoch [400/500] | Train Loss: 1.621251 | Val Loss: 1.162256\n",
      "Epoch [500/500] | Train Loss: 1.643248 | Val Loss: 1.155348\n",
      "Epoch [100/500] | Train Loss: 1.807903 | Val Loss: 1.493362\n",
      "Epoch [200/500] | Train Loss: 1.743776 | Val Loss: 1.494761\n",
      "Epoch [300/500] | Train Loss: 1.619636 | Val Loss: 1.471161\n",
      "Epoch [400/500] | Train Loss: 1.550004 | Val Loss: 1.456174\n",
      "Epoch [500/500] | Train Loss: 1.548208 | Val Loss: 1.435403\n",
      "Epoch [100/500] | Train Loss: 0.489529 | Val Loss: 1.024675\n",
      "Epoch [200/500] | Train Loss: 0.380106 | Val Loss: 1.018798\n",
      "Epoch [300/500] | Train Loss: 0.290665 | Val Loss: 1.071026\n",
      "Epoch [400/500] | Train Loss: 0.273664 | Val Loss: 1.122961\n",
      "Epoch [500/500] | Train Loss: 0.278962 | Val Loss: 1.070945\n",
      "Epoch [100/500] | Train Loss: 0.561913 | Val Loss: 5.248840\n",
      "Epoch [200/500] | Train Loss: 0.508162 | Val Loss: 5.485518\n",
      "Epoch [300/500] | Train Loss: 0.453996 | Val Loss: 5.499743\n",
      "Epoch [400/500] | Train Loss: 0.451028 | Val Loss: 5.591950\n",
      "Epoch [500/500] | Train Loss: 0.411989 | Val Loss: 5.736275\n",
      "Epoch [100/500] | Train Loss: 1.569607 | Val Loss: 2.126872\n",
      "Epoch [200/500] | Train Loss: 1.267684 | Val Loss: 2.200729\n",
      "Epoch [300/500] | Train Loss: 1.225905 | Val Loss: 2.207672\n",
      "Epoch [400/500] | Train Loss: 1.211053 | Val Loss: 2.273714\n",
      "Epoch [500/500] | Train Loss: 1.012187 | Val Loss: 2.270175\n",
      "Epoch [100/500] | Train Loss: 1.623971 | Val Loss: 1.147500\n",
      "Epoch [200/500] | Train Loss: 1.506773 | Val Loss: 1.193914\n",
      "Epoch [300/500] | Train Loss: 1.414700 | Val Loss: 1.166220\n",
      "Epoch [400/500] | Train Loss: 1.394032 | Val Loss: 1.176248\n",
      "Epoch [500/500] | Train Loss: 1.269331 | Val Loss: 1.256050\n",
      "Epoch [100/500] | Train Loss: 1.608713 | Val Loss: 1.472616\n",
      "Epoch [200/500] | Train Loss: 1.463632 | Val Loss: 1.493799\n",
      "Epoch [300/500] | Train Loss: 1.518051 | Val Loss: 1.595829\n",
      "Epoch [400/500] | Train Loss: 1.387652 | Val Loss: 1.573318\n",
      "Epoch [500/500] | Train Loss: 1.343680 | Val Loss: 1.633639\n",
      "[Year=1941] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=2.159317 Test MSE=0.551587\n",
      "Year 1941 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 2.058885 | Val Loss: 3.324461\n",
      "Epoch [200/500] | Train Loss: 1.752548 | Val Loss: 3.706568\n",
      "Epoch [300/500] | Train Loss: 1.371606 | Val Loss: 3.852871\n",
      "Epoch [400/500] | Train Loss: 1.129554 | Val Loss: 3.934447\n",
      "Epoch [500/500] | Train Loss: 0.985677 | Val Loss: 3.889346\n",
      "Epoch [100/500] | Train Loss: 2.635754 | Val Loss: 1.906451\n",
      "Epoch [200/500] | Train Loss: 2.413898 | Val Loss: 1.998315\n",
      "Epoch [300/500] | Train Loss: 2.335053 | Val Loss: 2.054403\n",
      "Epoch [400/500] | Train Loss: 2.178523 | Val Loss: 2.052111\n",
      "Epoch [500/500] | Train Loss: 2.071764 | Val Loss: 2.081694\n",
      "Epoch [100/500] | Train Loss: 2.330452 | Val Loss: 1.054150\n",
      "Epoch [200/500] | Train Loss: 2.064560 | Val Loss: 1.050853\n",
      "Epoch [300/500] | Train Loss: 1.933124 | Val Loss: 1.037841\n",
      "Epoch [400/500] | Train Loss: 1.859535 | Val Loss: 1.058168\n",
      "Epoch [500/500] | Train Loss: 1.645550 | Val Loss: 1.074485\n",
      "Epoch [100/500] | Train Loss: 2.015030 | Val Loss: 1.600244\n",
      "Epoch [200/500] | Train Loss: 1.861081 | Val Loss: 1.670065\n",
      "Epoch [300/500] | Train Loss: 1.744800 | Val Loss: 1.712688\n",
      "Epoch [400/500] | Train Loss: 1.614068 | Val Loss: 1.756524\n",
      "Epoch [500/500] | Train Loss: 1.703394 | Val Loss: 1.802090\n",
      "Epoch [100/500] | Train Loss: 1.929576 | Val Loss: 0.543276\n",
      "Epoch [200/500] | Train Loss: 1.827092 | Val Loss: 0.548366\n",
      "Epoch [300/500] | Train Loss: 1.733873 | Val Loss: 0.566153\n",
      "Epoch [400/500] | Train Loss: 1.666514 | Val Loss: 0.565440\n",
      "Epoch [500/500] | Train Loss: 1.585905 | Val Loss: 0.555992\n",
      "Epoch [100/500] | Train Loss: 0.878668 | Val Loss: 4.591398\n",
      "Epoch [200/500] | Train Loss: 0.717211 | Val Loss: 4.543588\n",
      "Epoch [300/500] | Train Loss: 0.534526 | Val Loss: 4.724078\n",
      "Epoch [400/500] | Train Loss: 0.577515 | Val Loss: 4.347861\n",
      "Epoch [500/500] | Train Loss: 0.579257 | Val Loss: 4.334733\n",
      "Epoch [100/500] | Train Loss: 1.869173 | Val Loss: 2.099969\n",
      "Epoch [200/500] | Train Loss: 1.537270 | Val Loss: 2.180606\n",
      "Epoch [300/500] | Train Loss: 1.207183 | Val Loss: 2.304866\n",
      "Epoch [400/500] | Train Loss: 1.169890 | Val Loss: 2.333896\n",
      "Epoch [500/500] | Train Loss: 1.053896 | Val Loss: 2.140282\n",
      "Epoch [100/500] | Train Loss: 1.948165 | Val Loss: 1.081672\n",
      "Epoch [200/500] | Train Loss: 1.490755 | Val Loss: 1.115508\n",
      "Epoch [300/500] | Train Loss: 1.509587 | Val Loss: 1.083003\n",
      "Epoch [400/500] | Train Loss: 1.403832 | Val Loss: 1.142857\n",
      "Epoch [500/500] | Train Loss: 1.312303 | Val Loss: 1.130470\n",
      "Epoch [100/500] | Train Loss: 1.491259 | Val Loss: 2.011891\n",
      "Epoch [200/500] | Train Loss: 1.385426 | Val Loss: 1.944810\n",
      "Epoch [300/500] | Train Loss: 1.473884 | Val Loss: 2.053148\n",
      "Epoch [400/500] | Train Loss: 1.129737 | Val Loss: 2.011307\n",
      "Epoch [500/500] | Train Loss: 1.142169 | Val Loss: 2.061743\n",
      "Epoch [100/500] | Train Loss: 1.517784 | Val Loss: 0.532546\n",
      "Epoch [200/500] | Train Loss: 1.362325 | Val Loss: 0.606550\n",
      "Epoch [300/500] | Train Loss: 1.284925 | Val Loss: 0.666068\n",
      "Epoch [400/500] | Train Loss: 1.260650 | Val Loss: 0.645632\n",
      "Epoch [500/500] | Train Loss: 1.207780 | Val Loss: 0.663619\n",
      "Epoch [100/500] | Train Loss: 2.268942 | Val Loss: 3.247636\n",
      "Epoch [200/500] | Train Loss: 1.848120 | Val Loss: 3.637458\n",
      "Epoch [300/500] | Train Loss: 1.740723 | Val Loss: 3.835924\n",
      "Epoch [400/500] | Train Loss: 1.793110 | Val Loss: 3.809419\n",
      "Epoch [500/500] | Train Loss: 1.489551 | Val Loss: 3.732186\n",
      "Epoch [100/500] | Train Loss: 2.674155 | Val Loss: 1.826077\n",
      "Epoch [200/500] | Train Loss: 2.536014 | Val Loss: 1.807356\n",
      "Epoch [300/500] | Train Loss: 2.401405 | Val Loss: 1.811651\n",
      "Epoch [400/500] | Train Loss: 2.225145 | Val Loss: 1.853191\n",
      "Epoch [500/500] | Train Loss: 2.055179 | Val Loss: 1.935453\n",
      "Epoch [100/500] | Train Loss: 2.466992 | Val Loss: 1.031942\n",
      "Epoch [200/500] | Train Loss: 2.324155 | Val Loss: 1.038172\n",
      "Epoch [300/500] | Train Loss: 2.251762 | Val Loss: 1.030513\n",
      "Epoch [400/500] | Train Loss: 2.201458 | Val Loss: 1.030738\n",
      "Epoch [500/500] | Train Loss: 2.182475 | Val Loss: 1.030440\n",
      "Epoch [100/500] | Train Loss: 2.072937 | Val Loss: 1.524568\n",
      "Epoch [200/500] | Train Loss: 1.914224 | Val Loss: 1.548106\n",
      "Epoch [300/500] | Train Loss: 1.844077 | Val Loss: 1.576559\n",
      "Epoch [400/500] | Train Loss: 1.808656 | Val Loss: 1.588822\n",
      "Epoch [500/500] | Train Loss: 1.729193 | Val Loss: 1.598032\n",
      "Epoch [100/500] | Train Loss: 1.990599 | Val Loss: 0.528007\n",
      "Epoch [200/500] | Train Loss: 1.851246 | Val Loss: 0.533029\n",
      "Epoch [300/500] | Train Loss: 1.809846 | Val Loss: 0.537878\n",
      "Epoch [400/500] | Train Loss: 1.781727 | Val Loss: 0.536722\n",
      "Epoch [500/500] | Train Loss: 1.751343 | Val Loss: 0.533451\n",
      "Epoch [100/500] | Train Loss: 1.454712 | Val Loss: 3.692788\n",
      "Epoch [200/500] | Train Loss: 1.130815 | Val Loss: 3.987479\n",
      "Epoch [300/500] | Train Loss: 1.011622 | Val Loss: 4.082306\n",
      "Epoch [400/500] | Train Loss: 0.885818 | Val Loss: 4.642895\n",
      "Epoch [500/500] | Train Loss: 0.849477 | Val Loss: 4.203673\n",
      "Epoch [100/500] | Train Loss: 2.271573 | Val Loss: 1.938130\n",
      "Epoch [200/500] | Train Loss: 2.108181 | Val Loss: 1.979785\n",
      "Epoch [300/500] | Train Loss: 1.815757 | Val Loss: 2.217279\n",
      "Epoch [400/500] | Train Loss: 1.803733 | Val Loss: 2.134321\n",
      "Epoch [500/500] | Train Loss: 1.635860 | Val Loss: 2.037202\n",
      "Epoch [100/500] | Train Loss: 2.087717 | Val Loss: 1.043648\n",
      "Epoch [200/500] | Train Loss: 1.848941 | Val Loss: 0.998634\n",
      "Epoch [300/500] | Train Loss: 1.730237 | Val Loss: 1.032354\n",
      "Epoch [400/500] | Train Loss: 1.629642 | Val Loss: 1.046545\n",
      "Epoch [500/500] | Train Loss: 1.640873 | Val Loss: 1.088512\n",
      "Epoch [100/500] | Train Loss: 1.812555 | Val Loss: 1.639541\n",
      "Epoch [200/500] | Train Loss: 1.657151 | Val Loss: 1.744734\n",
      "Epoch [300/500] | Train Loss: 1.573171 | Val Loss: 1.782054\n",
      "Epoch [400/500] | Train Loss: 1.502105 | Val Loss: 1.769431\n",
      "Epoch [500/500] | Train Loss: 1.536225 | Val Loss: 1.763017\n",
      "Epoch [100/500] | Train Loss: 1.726763 | Val Loss: 0.502435\n",
      "Epoch [200/500] | Train Loss: 1.550191 | Val Loss: 0.542682\n",
      "Epoch [300/500] | Train Loss: 1.532590 | Val Loss: 0.570162\n",
      "Epoch [400/500] | Train Loss: 1.507810 | Val Loss: 0.586119\n",
      "Epoch [500/500] | Train Loss: 1.424652 | Val Loss: 0.566521\n",
      "Epoch [100/500] | Train Loss: 1.878524 | Val Loss: 3.488626\n",
      "Epoch [200/500] | Train Loss: 1.358460 | Val Loss: 3.991129\n",
      "Epoch [300/500] | Train Loss: 0.942697 | Val Loss: 4.014869\n",
      "Epoch [400/500] | Train Loss: 0.957984 | Val Loss: 4.408802\n",
      "Epoch [500/500] | Train Loss: 0.751427 | Val Loss: 4.458363\n",
      "Epoch [100/500] | Train Loss: 2.588329 | Val Loss: 1.832945\n",
      "Epoch [200/500] | Train Loss: 2.108553 | Val Loss: 1.931641\n",
      "Epoch [300/500] | Train Loss: 1.934061 | Val Loss: 2.087663\n",
      "Epoch [400/500] | Train Loss: 1.681454 | Val Loss: 2.155321\n",
      "Epoch [500/500] | Train Loss: 1.471342 | Val Loss: 2.173765\n",
      "Epoch [100/500] | Train Loss: 2.345621 | Val Loss: 1.044057\n",
      "Epoch [200/500] | Train Loss: 2.041872 | Val Loss: 1.075876\n",
      "Epoch [300/500] | Train Loss: 1.851181 | Val Loss: 1.096433\n",
      "Epoch [400/500] | Train Loss: 1.675565 | Val Loss: 1.165119\n",
      "Epoch [500/500] | Train Loss: 1.563952 | Val Loss: 1.174221\n",
      "Epoch [100/500] | Train Loss: 1.942001 | Val Loss: 1.561225\n",
      "Epoch [200/500] | Train Loss: 1.742843 | Val Loss: 1.583145\n",
      "Epoch [300/500] | Train Loss: 1.608929 | Val Loss: 1.552921\n",
      "Epoch [400/500] | Train Loss: 1.446669 | Val Loss: 1.615559\n",
      "Epoch [500/500] | Train Loss: 1.323893 | Val Loss: 1.695591\n",
      "Epoch [100/500] | Train Loss: 1.923032 | Val Loss: 0.544841\n",
      "Epoch [200/500] | Train Loss: 1.718588 | Val Loss: 0.572086\n",
      "Epoch [300/500] | Train Loss: 1.513933 | Val Loss: 0.547499\n",
      "Epoch [400/500] | Train Loss: 1.469691 | Val Loss: 0.526117\n",
      "Epoch [500/500] | Train Loss: 1.398154 | Val Loss: 0.517020\n",
      "Epoch [100/500] | Train Loss: 0.910665 | Val Loss: 4.363780\n",
      "Epoch [200/500] | Train Loss: 0.751903 | Val Loss: 4.344379\n",
      "Epoch [300/500] | Train Loss: 0.587101 | Val Loss: 4.209156\n",
      "Epoch [400/500] | Train Loss: 0.484723 | Val Loss: 4.414883\n",
      "Epoch [500/500] | Train Loss: 0.522215 | Val Loss: 4.346869\n",
      "Epoch [100/500] | Train Loss: 1.571941 | Val Loss: 2.291079\n",
      "Epoch [200/500] | Train Loss: 1.206614 | Val Loss: 2.367359\n",
      "Epoch [300/500] | Train Loss: 0.945584 | Val Loss: 2.350371\n",
      "Epoch [400/500] | Train Loss: 0.969546 | Val Loss: 2.690422\n",
      "Epoch [500/500] | Train Loss: 0.838578 | Val Loss: 2.671164\n",
      "Epoch [100/500] | Train Loss: 1.548873 | Val Loss: 1.177784\n",
      "Epoch [200/500] | Train Loss: 1.448116 | Val Loss: 1.267151\n",
      "Epoch [300/500] | Train Loss: 1.115657 | Val Loss: 1.185849\n",
      "Epoch [400/500] | Train Loss: 1.058597 | Val Loss: 1.224766\n",
      "Epoch [500/500] | Train Loss: 0.924674 | Val Loss: 1.273654\n",
      "Epoch [100/500] | Train Loss: 1.535624 | Val Loss: 1.691097\n",
      "Epoch [200/500] | Train Loss: 1.155254 | Val Loss: 1.920471\n",
      "Epoch [300/500] | Train Loss: 1.069215 | Val Loss: 1.846629\n",
      "Epoch [400/500] | Train Loss: 1.045246 | Val Loss: 1.823632\n",
      "Epoch [500/500] | Train Loss: 0.906961 | Val Loss: 1.851634\n",
      "Epoch [100/500] | Train Loss: 1.467211 | Val Loss: 0.539680\n",
      "Epoch [200/500] | Train Loss: 1.148047 | Val Loss: 0.604536\n",
      "Epoch [300/500] | Train Loss: 1.118445 | Val Loss: 0.616884\n",
      "Epoch [400/500] | Train Loss: 1.063629 | Val Loss: 0.638798\n",
      "Epoch [500/500] | Train Loss: 1.107204 | Val Loss: 0.687396\n",
      "Epoch [100/500] | Train Loss: 2.230752 | Val Loss: 3.202445\n",
      "Epoch [200/500] | Train Loss: 1.769555 | Val Loss: 3.589455\n",
      "Epoch [300/500] | Train Loss: 1.684222 | Val Loss: 3.912315\n",
      "Epoch [400/500] | Train Loss: 1.370804 | Val Loss: 4.170853\n",
      "Epoch [500/500] | Train Loss: 1.093124 | Val Loss: 3.937089\n",
      "Epoch [100/500] | Train Loss: 2.623797 | Val Loss: 1.840550\n",
      "Epoch [200/500] | Train Loss: 2.437519 | Val Loss: 1.856612\n",
      "Epoch [300/500] | Train Loss: 2.254588 | Val Loss: 1.898479\n",
      "Epoch [400/500] | Train Loss: 2.056144 | Val Loss: 1.911347\n",
      "Epoch [500/500] | Train Loss: 2.108873 | Val Loss: 1.928938\n",
      "Epoch [100/500] | Train Loss: 2.350318 | Val Loss: 1.061361\n",
      "Epoch [200/500] | Train Loss: 2.237224 | Val Loss: 1.059277\n",
      "Epoch [300/500] | Train Loss: 2.127256 | Val Loss: 1.033005\n",
      "Epoch [400/500] | Train Loss: 2.002107 | Val Loss: 1.043234\n",
      "Epoch [500/500] | Train Loss: 1.991159 | Val Loss: 1.040509\n",
      "Epoch [100/500] | Train Loss: 2.033768 | Val Loss: 1.534065\n",
      "Epoch [200/500] | Train Loss: 1.847060 | Val Loss: 1.566873\n",
      "Epoch [300/500] | Train Loss: 1.861886 | Val Loss: 1.594027\n",
      "Epoch [400/500] | Train Loss: 1.746715 | Val Loss: 1.633462\n",
      "Epoch [500/500] | Train Loss: 1.675071 | Val Loss: 1.633622\n",
      "Epoch [100/500] | Train Loss: 1.937555 | Val Loss: 0.538860\n",
      "Epoch [200/500] | Train Loss: 1.862264 | Val Loss: 0.544470\n",
      "Epoch [300/500] | Train Loss: 1.765909 | Val Loss: 0.521387\n",
      "Epoch [400/500] | Train Loss: 1.647036 | Val Loss: 0.511679\n",
      "Epoch [500/500] | Train Loss: 1.601742 | Val Loss: 0.515467\n",
      "Epoch [100/500] | Train Loss: 1.081913 | Val Loss: 3.895129\n",
      "Epoch [200/500] | Train Loss: 0.946521 | Val Loss: 3.927724\n",
      "Epoch [300/500] | Train Loss: 0.777452 | Val Loss: 4.540855\n",
      "Epoch [400/500] | Train Loss: 0.872234 | Val Loss: 4.344643\n",
      "Epoch [500/500] | Train Loss: 1.237654 | Val Loss: 4.313028\n",
      "Epoch [100/500] | Train Loss: 1.898151 | Val Loss: 1.960715\n",
      "Epoch [200/500] | Train Loss: 1.697083 | Val Loss: 2.089046\n",
      "Epoch [300/500] | Train Loss: 1.464435 | Val Loss: 2.074018\n",
      "Epoch [400/500] | Train Loss: 1.465107 | Val Loss: 2.183024\n",
      "Epoch [500/500] | Train Loss: 1.398854 | Val Loss: 2.180091\n",
      "Epoch [100/500] | Train Loss: 1.806986 | Val Loss: 1.050896\n",
      "Epoch [200/500] | Train Loss: 1.780846 | Val Loss: 1.097781\n",
      "Epoch [300/500] | Train Loss: 1.603529 | Val Loss: 1.101958\n",
      "Epoch [400/500] | Train Loss: 1.587387 | Val Loss: 1.077953\n",
      "Epoch [500/500] | Train Loss: 1.475476 | Val Loss: 1.082682\n",
      "Epoch [100/500] | Train Loss: 1.664414 | Val Loss: 1.643968\n",
      "Epoch [200/500] | Train Loss: 1.547747 | Val Loss: 1.645707\n",
      "Epoch [300/500] | Train Loss: 1.431115 | Val Loss: 1.683597\n",
      "Epoch [400/500] | Train Loss: 1.326746 | Val Loss: 1.721713\n",
      "Epoch [500/500] | Train Loss: 1.294043 | Val Loss: 1.743930\n",
      "Epoch [100/500] | Train Loss: 1.732021 | Val Loss: 0.541381\n",
      "Epoch [200/500] | Train Loss: 1.540012 | Val Loss: 0.537380\n",
      "Epoch [300/500] | Train Loss: 1.450205 | Val Loss: 0.539406\n",
      "Epoch [400/500] | Train Loss: 1.457347 | Val Loss: 0.559882\n",
      "Epoch [500/500] | Train Loss: 1.360446 | Val Loss: 0.569454\n",
      "[Year=1942] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.765912 Test MSE=0.446324\n",
      "Year 1942 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 2.844551 | Val Loss: 1.546610\n",
      "Epoch [200/500] | Train Loss: 2.393375 | Val Loss: 1.650945\n",
      "Epoch [300/500] | Train Loss: 1.927402 | Val Loss: 1.923209\n",
      "Epoch [400/500] | Train Loss: 1.738947 | Val Loss: 2.013138\n",
      "Epoch [500/500] | Train Loss: 1.634657 | Val Loss: 2.114316\n",
      "Epoch [100/500] | Train Loss: 2.105113 | Val Loss: 1.634920\n",
      "Epoch [200/500] | Train Loss: 1.882934 | Val Loss: 1.721714\n",
      "Epoch [300/500] | Train Loss: 1.776102 | Val Loss: 1.725391\n",
      "Epoch [400/500] | Train Loss: 1.685640 | Val Loss: 1.750230\n",
      "Epoch [500/500] | Train Loss: 1.510800 | Val Loss: 1.767569\n",
      "Epoch [100/500] | Train Loss: 1.946948 | Val Loss: 0.659975\n",
      "Epoch [200/500] | Train Loss: 1.834560 | Val Loss: 0.728290\n",
      "Epoch [300/500] | Train Loss: 1.708586 | Val Loss: 0.769611\n",
      "Epoch [400/500] | Train Loss: 1.606600 | Val Loss: 0.768694\n",
      "Epoch [500/500] | Train Loss: 1.610539 | Val Loss: 0.793251\n",
      "Epoch [100/500] | Train Loss: 1.642025 | Val Loss: 0.571575\n",
      "Epoch [200/500] | Train Loss: 1.502261 | Val Loss: 0.583248\n",
      "Epoch [300/500] | Train Loss: 1.378508 | Val Loss: 0.599325\n",
      "Epoch [400/500] | Train Loss: 1.370360 | Val Loss: 0.589014\n",
      "Epoch [500/500] | Train Loss: 1.316918 | Val Loss: 0.588559\n",
      "Epoch [100/500] | Train Loss: 1.464303 | Val Loss: 0.434852\n",
      "Epoch [200/500] | Train Loss: 1.386814 | Val Loss: 0.440948\n",
      "Epoch [300/500] | Train Loss: 1.282305 | Val Loss: 0.449725\n",
      "Epoch [400/500] | Train Loss: 1.222647 | Val Loss: 0.445319\n",
      "Epoch [500/500] | Train Loss: 1.104622 | Val Loss: 0.448762\n",
      "Epoch [100/500] | Train Loss: 1.507570 | Val Loss: 2.213782\n",
      "Epoch [200/500] | Train Loss: 1.438061 | Val Loss: 2.454933\n",
      "Epoch [300/500] | Train Loss: 0.923030 | Val Loss: 2.622078\n",
      "Epoch [400/500] | Train Loss: 1.115847 | Val Loss: 2.469337\n",
      "Epoch [500/500] | Train Loss: 0.957392 | Val Loss: 2.548182\n",
      "Epoch [100/500] | Train Loss: 1.611177 | Val Loss: 1.673818\n",
      "Epoch [200/500] | Train Loss: 1.442834 | Val Loss: 1.734561\n",
      "Epoch [300/500] | Train Loss: 1.177104 | Val Loss: 1.630167\n",
      "Epoch [400/500] | Train Loss: 1.106170 | Val Loss: 1.691149\n",
      "Epoch [500/500] | Train Loss: 1.062743 | Val Loss: 1.760574\n",
      "Epoch [100/500] | Train Loss: 1.451776 | Val Loss: 0.773001\n",
      "Epoch [200/500] | Train Loss: 1.298478 | Val Loss: 0.807331\n",
      "Epoch [300/500] | Train Loss: 1.189225 | Val Loss: 0.795331\n",
      "Epoch [400/500] | Train Loss: 0.971928 | Val Loss: 0.877205\n",
      "Epoch [500/500] | Train Loss: 0.967821 | Val Loss: 0.925855\n",
      "Epoch [100/500] | Train Loss: 1.406173 | Val Loss: 0.589145\n",
      "Epoch [200/500] | Train Loss: 1.098345 | Val Loss: 0.692337\n",
      "Epoch [300/500] | Train Loss: 1.075906 | Val Loss: 0.667569\n",
      "Epoch [400/500] | Train Loss: 1.019775 | Val Loss: 0.714758\n",
      "Epoch [500/500] | Train Loss: 0.959635 | Val Loss: 0.678327\n",
      "Epoch [100/500] | Train Loss: 1.160385 | Val Loss: 0.440145\n",
      "Epoch [200/500] | Train Loss: 1.003993 | Val Loss: 0.445057\n",
      "Epoch [300/500] | Train Loss: 0.966021 | Val Loss: 0.442377\n",
      "Epoch [400/500] | Train Loss: 0.953758 | Val Loss: 0.431872\n",
      "Epoch [500/500] | Train Loss: 0.911188 | Val Loss: 0.456743\n",
      "Epoch [100/500] | Train Loss: 2.873783 | Val Loss: 1.569060\n",
      "Epoch [200/500] | Train Loss: 2.619289 | Val Loss: 1.541560\n",
      "Epoch [300/500] | Train Loss: 2.557778 | Val Loss: 1.629495\n",
      "Epoch [400/500] | Train Loss: 2.267227 | Val Loss: 1.742166\n",
      "Epoch [500/500] | Train Loss: 2.356806 | Val Loss: 1.766793\n",
      "Epoch [100/500] | Train Loss: 2.192559 | Val Loss: 1.669109\n",
      "Epoch [200/500] | Train Loss: 2.120242 | Val Loss: 1.688534\n",
      "Epoch [300/500] | Train Loss: 1.878894 | Val Loss: 1.680162\n",
      "Epoch [400/500] | Train Loss: 1.864160 | Val Loss: 1.717729\n",
      "Epoch [500/500] | Train Loss: 1.819118 | Val Loss: 1.739995\n",
      "Epoch [100/500] | Train Loss: 1.993496 | Val Loss: 0.661086\n",
      "Epoch [200/500] | Train Loss: 1.932017 | Val Loss: 0.676943\n",
      "Epoch [300/500] | Train Loss: 1.881338 | Val Loss: 0.694584\n",
      "Epoch [400/500] | Train Loss: 1.771599 | Val Loss: 0.710338\n",
      "Epoch [500/500] | Train Loss: 1.682084 | Val Loss: 0.724360\n",
      "Epoch [100/500] | Train Loss: 1.668299 | Val Loss: 0.562582\n",
      "Epoch [200/500] | Train Loss: 1.614763 | Val Loss: 0.574939\n",
      "Epoch [300/500] | Train Loss: 1.582750 | Val Loss: 0.578623\n",
      "Epoch [400/500] | Train Loss: 1.501898 | Val Loss: 0.575833\n",
      "Epoch [500/500] | Train Loss: 1.448548 | Val Loss: 0.584507\n",
      "Epoch [100/500] | Train Loss: 1.463533 | Val Loss: 0.419581\n",
      "Epoch [200/500] | Train Loss: 1.408142 | Val Loss: 0.429601\n",
      "Epoch [300/500] | Train Loss: 1.340259 | Val Loss: 0.429740\n",
      "Epoch [400/500] | Train Loss: 1.304731 | Val Loss: 0.416253\n",
      "Epoch [500/500] | Train Loss: 1.249115 | Val Loss: 0.416718\n",
      "Epoch [100/500] | Train Loss: 2.051876 | Val Loss: 1.935835\n",
      "Epoch [200/500] | Train Loss: 1.639726 | Val Loss: 2.214303\n",
      "Epoch [300/500] | Train Loss: 1.701841 | Val Loss: 2.300993\n",
      "Epoch [400/500] | Train Loss: 1.372352 | Val Loss: 2.368511\n",
      "Epoch [500/500] | Train Loss: 1.358366 | Val Loss: 2.480646\n",
      "Epoch [100/500] | Train Loss: 1.994788 | Val Loss: 1.695825\n",
      "Epoch [200/500] | Train Loss: 1.650363 | Val Loss: 1.749032\n",
      "Epoch [300/500] | Train Loss: 1.418534 | Val Loss: 1.824896\n",
      "Epoch [400/500] | Train Loss: 1.371272 | Val Loss: 1.778412\n",
      "Epoch [500/500] | Train Loss: 1.520470 | Val Loss: 1.956523\n",
      "Epoch [100/500] | Train Loss: 1.647296 | Val Loss: 0.786448\n",
      "Epoch [200/500] | Train Loss: 1.594053 | Val Loss: 0.800792\n",
      "Epoch [300/500] | Train Loss: 1.567623 | Val Loss: 0.794118\n",
      "Epoch [400/500] | Train Loss: 1.483652 | Val Loss: 0.782386\n",
      "Epoch [500/500] | Train Loss: 1.496676 | Val Loss: 0.780683\n",
      "Epoch [100/500] | Train Loss: 1.475030 | Val Loss: 0.586991\n",
      "Epoch [200/500] | Train Loss: 1.277030 | Val Loss: 0.584920\n",
      "Epoch [300/500] | Train Loss: 1.263536 | Val Loss: 0.585497\n",
      "Epoch [400/500] | Train Loss: 1.246235 | Val Loss: 0.582280\n",
      "Epoch [500/500] | Train Loss: 1.239524 | Val Loss: 0.578274\n",
      "Epoch [100/500] | Train Loss: 1.283331 | Val Loss: 0.431900\n",
      "Epoch [200/500] | Train Loss: 1.188781 | Val Loss: 0.421807\n",
      "Epoch [300/500] | Train Loss: 1.137188 | Val Loss: 0.432197\n",
      "Epoch [400/500] | Train Loss: 1.093871 | Val Loss: 0.407936\n",
      "Epoch [500/500] | Train Loss: 1.088278 | Val Loss: 0.419047\n",
      "Epoch [100/500] | Train Loss: 2.532840 | Val Loss: 1.671574\n",
      "Epoch [200/500] | Train Loss: 2.020815 | Val Loss: 2.067305\n",
      "Epoch [300/500] | Train Loss: 1.811671 | Val Loss: 2.101513\n",
      "Epoch [400/500] | Train Loss: 1.604724 | Val Loss: 2.084148\n",
      "Epoch [500/500] | Train Loss: 1.421802 | Val Loss: 2.205198\n",
      "Epoch [100/500] | Train Loss: 2.032565 | Val Loss: 1.675813\n",
      "Epoch [200/500] | Train Loss: 1.794660 | Val Loss: 1.657005\n",
      "Epoch [300/500] | Train Loss: 1.562934 | Val Loss: 1.619768\n",
      "Epoch [400/500] | Train Loss: 1.439603 | Val Loss: 1.666365\n",
      "Epoch [500/500] | Train Loss: 1.204181 | Val Loss: 1.708886\n",
      "Epoch [100/500] | Train Loss: 1.957104 | Val Loss: 0.653266\n",
      "Epoch [200/500] | Train Loss: 1.755389 | Val Loss: 0.710127\n",
      "Epoch [300/500] | Train Loss: 1.539922 | Val Loss: 0.777330\n",
      "Epoch [400/500] | Train Loss: 1.381871 | Val Loss: 0.787482\n",
      "Epoch [500/500] | Train Loss: 1.276860 | Val Loss: 0.802012\n",
      "Epoch [100/500] | Train Loss: 1.603403 | Val Loss: 0.583664\n",
      "Epoch [200/500] | Train Loss: 1.444067 | Val Loss: 0.597732\n",
      "Epoch [300/500] | Train Loss: 1.347208 | Val Loss: 0.605138\n",
      "Epoch [400/500] | Train Loss: 1.181003 | Val Loss: 0.586932\n",
      "Epoch [500/500] | Train Loss: 1.123532 | Val Loss: 0.583645\n",
      "Epoch [100/500] | Train Loss: 1.410267 | Val Loss: 0.429024\n",
      "Epoch [200/500] | Train Loss: 1.332836 | Val Loss: 0.438291\n",
      "Epoch [300/500] | Train Loss: 1.149597 | Val Loss: 0.442704\n",
      "Epoch [400/500] | Train Loss: 1.093874 | Val Loss: 0.432749\n",
      "Epoch [500/500] | Train Loss: 1.009046 | Val Loss: 0.432392\n",
      "Epoch [100/500] | Train Loss: 1.582422 | Val Loss: 2.396641\n",
      "Epoch [200/500] | Train Loss: 1.074250 | Val Loss: 2.582242\n",
      "Epoch [300/500] | Train Loss: 0.847181 | Val Loss: 2.965233\n",
      "Epoch [400/500] | Train Loss: 0.789827 | Val Loss: 2.590236\n",
      "Epoch [500/500] | Train Loss: 0.644373 | Val Loss: 2.702455\n",
      "Epoch [100/500] | Train Loss: 1.287099 | Val Loss: 1.970585\n",
      "Epoch [200/500] | Train Loss: 0.918013 | Val Loss: 2.172381\n",
      "Epoch [300/500] | Train Loss: 0.840382 | Val Loss: 2.146799\n",
      "Epoch [400/500] | Train Loss: 0.771712 | Val Loss: 2.239125\n",
      "Epoch [500/500] | Train Loss: 0.731753 | Val Loss: 2.083626\n",
      "Epoch [100/500] | Train Loss: 1.236945 | Val Loss: 0.895737\n",
      "Epoch [200/500] | Train Loss: 0.937615 | Val Loss: 1.028656\n",
      "Epoch [300/500] | Train Loss: 0.981035 | Val Loss: 0.923671\n",
      "Epoch [400/500] | Train Loss: 0.922511 | Val Loss: 0.939741\n",
      "Epoch [500/500] | Train Loss: 0.831224 | Val Loss: 1.105131\n",
      "Epoch [100/500] | Train Loss: 1.209714 | Val Loss: 0.583236\n",
      "Epoch [200/500] | Train Loss: 1.028717 | Val Loss: 0.651095\n",
      "Epoch [300/500] | Train Loss: 0.850325 | Val Loss: 0.725300\n",
      "Epoch [400/500] | Train Loss: 0.831650 | Val Loss: 0.754898\n",
      "Epoch [500/500] | Train Loss: 0.793567 | Val Loss: 0.826298\n",
      "Epoch [100/500] | Train Loss: 1.045561 | Val Loss: 0.433481\n",
      "Epoch [200/500] | Train Loss: 0.906410 | Val Loss: 0.441758\n",
      "Epoch [300/500] | Train Loss: 0.821416 | Val Loss: 0.464750\n",
      "Epoch [400/500] | Train Loss: 0.807633 | Val Loss: 0.468362\n",
      "Epoch [500/500] | Train Loss: 0.824649 | Val Loss: 0.465348\n",
      "Epoch [100/500] | Train Loss: 2.792007 | Val Loss: 1.570840\n",
      "Epoch [200/500] | Train Loss: 2.393257 | Val Loss: 1.666851\n",
      "Epoch [300/500] | Train Loss: 2.244062 | Val Loss: 1.760667\n",
      "Epoch [400/500] | Train Loss: 1.957907 | Val Loss: 1.826136\n",
      "Epoch [500/500] | Train Loss: 1.730461 | Val Loss: 1.900443\n",
      "Epoch [100/500] | Train Loss: 2.172636 | Val Loss: 1.703666\n",
      "Epoch [200/500] | Train Loss: 2.086697 | Val Loss: 1.742264\n",
      "Epoch [300/500] | Train Loss: 1.997828 | Val Loss: 1.755701\n",
      "Epoch [400/500] | Train Loss: 1.691661 | Val Loss: 1.775218\n",
      "Epoch [500/500] | Train Loss: 1.717196 | Val Loss: 1.790867\n",
      "Epoch [100/500] | Train Loss: 2.024103 | Val Loss: 0.652960\n",
      "Epoch [200/500] | Train Loss: 1.895310 | Val Loss: 0.682704\n",
      "Epoch [300/500] | Train Loss: 1.735855 | Val Loss: 0.737784\n",
      "Epoch [400/500] | Train Loss: 1.645720 | Val Loss: 0.753805\n",
      "Epoch [500/500] | Train Loss: 1.577089 | Val Loss: 0.773435\n",
      "Epoch [100/500] | Train Loss: 1.675430 | Val Loss: 0.568925\n",
      "Epoch [200/500] | Train Loss: 1.590358 | Val Loss: 0.579311\n",
      "Epoch [300/500] | Train Loss: 1.493125 | Val Loss: 0.587073\n",
      "Epoch [400/500] | Train Loss: 1.371600 | Val Loss: 0.591309\n",
      "Epoch [500/500] | Train Loss: 1.350648 | Val Loss: 0.598784\n",
      "Epoch [100/500] | Train Loss: 1.458214 | Val Loss: 0.423863\n",
      "Epoch [200/500] | Train Loss: 1.379447 | Val Loss: 0.422136\n",
      "Epoch [300/500] | Train Loss: 1.237036 | Val Loss: 0.420506\n",
      "Epoch [400/500] | Train Loss: 1.161329 | Val Loss: 0.430888\n",
      "Epoch [500/500] | Train Loss: 1.141568 | Val Loss: 0.433354\n",
      "Epoch [100/500] | Train Loss: 2.043868 | Val Loss: 2.046609\n",
      "Epoch [200/500] | Train Loss: 1.479444 | Val Loss: 2.267122\n",
      "Epoch [300/500] | Train Loss: 1.501551 | Val Loss: 2.405978\n",
      "Epoch [400/500] | Train Loss: 1.183836 | Val Loss: 2.445193\n",
      "Epoch [500/500] | Train Loss: 1.343590 | Val Loss: 2.701724\n",
      "Epoch [100/500] | Train Loss: 1.638458 | Val Loss: 1.611176\n",
      "Epoch [200/500] | Train Loss: 1.469895 | Val Loss: 1.796763\n",
      "Epoch [300/500] | Train Loss: 1.376426 | Val Loss: 1.775967\n",
      "Epoch [400/500] | Train Loss: 1.215396 | Val Loss: 1.787234\n",
      "Epoch [500/500] | Train Loss: 1.227681 | Val Loss: 1.848588\n",
      "Epoch [100/500] | Train Loss: 1.539151 | Val Loss: 0.821977\n",
      "Epoch [200/500] | Train Loss: 1.435866 | Val Loss: 0.896529\n",
      "Epoch [300/500] | Train Loss: 1.304869 | Val Loss: 0.920278\n",
      "Epoch [400/500] | Train Loss: 1.338649 | Val Loss: 0.886375\n",
      "Epoch [500/500] | Train Loss: 1.247061 | Val Loss: 0.885828\n",
      "Epoch [100/500] | Train Loss: 1.362452 | Val Loss: 0.594898\n",
      "Epoch [200/500] | Train Loss: 1.273785 | Val Loss: 0.573208\n",
      "Epoch [300/500] | Train Loss: 1.238363 | Val Loss: 0.534853\n",
      "Epoch [400/500] | Train Loss: 1.208314 | Val Loss: 0.572115\n",
      "Epoch [500/500] | Train Loss: 1.043367 | Val Loss: 0.585758\n",
      "Epoch [100/500] | Train Loss: 1.263462 | Val Loss: 0.423360\n",
      "Epoch [200/500] | Train Loss: 1.129546 | Val Loss: 0.435512\n",
      "Epoch [300/500] | Train Loss: 1.003593 | Val Loss: 0.443956\n",
      "Epoch [400/500] | Train Loss: 1.001566 | Val Loss: 0.451683\n",
      "Epoch [500/500] | Train Loss: 0.946663 | Val Loss: 0.452959\n",
      "[Year=1943] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.046474 Test MSE=0.446060\n",
      "Year 1943 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.583578 | Val Loss: 1.361058\n",
      "Epoch [200/500] | Train Loss: 1.329168 | Val Loss: 1.457650\n",
      "Epoch [300/500] | Train Loss: 1.279292 | Val Loss: 1.466924\n",
      "Epoch [400/500] | Train Loss: 1.054266 | Val Loss: 1.426346\n",
      "Epoch [500/500] | Train Loss: 0.922806 | Val Loss: 1.383562\n",
      "Epoch [100/500] | Train Loss: 1.408343 | Val Loss: 0.622782\n",
      "Epoch [200/500] | Train Loss: 1.201473 | Val Loss: 0.738222\n",
      "Epoch [300/500] | Train Loss: 1.024658 | Val Loss: 0.751453\n",
      "Epoch [400/500] | Train Loss: 0.988856 | Val Loss: 0.758986\n",
      "Epoch [500/500] | Train Loss: 0.893014 | Val Loss: 0.801100\n",
      "Epoch [100/500] | Train Loss: 1.182930 | Val Loss: 0.661686\n",
      "Epoch [200/500] | Train Loss: 0.965428 | Val Loss: 0.730098\n",
      "Epoch [300/500] | Train Loss: 0.922096 | Val Loss: 0.769795\n",
      "Epoch [400/500] | Train Loss: 0.891011 | Val Loss: 0.795917\n",
      "Epoch [500/500] | Train Loss: 0.877060 | Val Loss: 0.839386\n",
      "Epoch [100/500] | Train Loss: 1.093158 | Val Loss: 0.311302\n",
      "Epoch [200/500] | Train Loss: 0.994703 | Val Loss: 0.343189\n",
      "Epoch [300/500] | Train Loss: 0.927618 | Val Loss: 0.340676\n",
      "Epoch [400/500] | Train Loss: 0.821404 | Val Loss: 0.332790\n",
      "Epoch [500/500] | Train Loss: 0.824509 | Val Loss: 0.330129\n",
      "Epoch [100/500] | Train Loss: 0.911459 | Val Loss: 0.453699\n",
      "Epoch [200/500] | Train Loss: 0.792332 | Val Loss: 0.464119\n",
      "Epoch [300/500] | Train Loss: 0.724653 | Val Loss: 0.446233\n",
      "Epoch [400/500] | Train Loss: 0.698973 | Val Loss: 0.446991\n",
      "Epoch [500/500] | Train Loss: 0.649430 | Val Loss: 0.441762\n",
      "Epoch [100/500] | Train Loss: 1.237638 | Val Loss: 1.485149\n",
      "Epoch [200/500] | Train Loss: 0.846742 | Val Loss: 1.703139\n",
      "Epoch [300/500] | Train Loss: 0.638150 | Val Loss: 1.629042\n",
      "Epoch [400/500] | Train Loss: 0.638744 | Val Loss: 1.598077\n",
      "Epoch [500/500] | Train Loss: 0.592343 | Val Loss: 1.712300\n",
      "Epoch [100/500] | Train Loss: 0.872605 | Val Loss: 0.814031\n",
      "Epoch [200/500] | Train Loss: 0.694345 | Val Loss: 0.900612\n",
      "Epoch [300/500] | Train Loss: 0.683535 | Val Loss: 0.882422\n",
      "Epoch [400/500] | Train Loss: 0.629477 | Val Loss: 0.870258\n",
      "Epoch [500/500] | Train Loss: 0.614297 | Val Loss: 0.831176\n",
      "Epoch [100/500] | Train Loss: 0.886118 | Val Loss: 0.739575\n",
      "Epoch [200/500] | Train Loss: 0.734903 | Val Loss: 0.703737\n",
      "Epoch [300/500] | Train Loss: 0.662743 | Val Loss: 0.699812\n",
      "Epoch [400/500] | Train Loss: 0.629514 | Val Loss: 0.731455\n",
      "Epoch [500/500] | Train Loss: 0.658688 | Val Loss: 0.750905\n",
      "Epoch [100/500] | Train Loss: 0.766170 | Val Loss: 0.340187\n",
      "Epoch [200/500] | Train Loss: 0.658101 | Val Loss: 0.347112\n",
      "Epoch [300/500] | Train Loss: 0.608720 | Val Loss: 0.344544\n",
      "Epoch [400/500] | Train Loss: 0.591348 | Val Loss: 0.334120\n",
      "Epoch [500/500] | Train Loss: 0.595267 | Val Loss: 0.348149\n",
      "Epoch [100/500] | Train Loss: 0.707947 | Val Loss: 0.449930\n",
      "Epoch [200/500] | Train Loss: 0.595843 | Val Loss: 0.464908\n",
      "Epoch [300/500] | Train Loss: 0.566019 | Val Loss: 0.481324\n",
      "Epoch [400/500] | Train Loss: 0.540146 | Val Loss: 0.497707\n",
      "Epoch [500/500] | Train Loss: 0.559769 | Val Loss: 0.481231\n",
      "Epoch [100/500] | Train Loss: 1.678773 | Val Loss: 1.366742\n",
      "Epoch [200/500] | Train Loss: 1.552828 | Val Loss: 1.505731\n",
      "Epoch [300/500] | Train Loss: 1.487010 | Val Loss: 1.461409\n",
      "Epoch [400/500] | Train Loss: 1.372295 | Val Loss: 1.454468\n",
      "Epoch [500/500] | Train Loss: 1.374357 | Val Loss: 1.441139\n",
      "Epoch [100/500] | Train Loss: 1.504111 | Val Loss: 0.604496\n",
      "Epoch [200/500] | Train Loss: 1.353885 | Val Loss: 0.640077\n",
      "Epoch [300/500] | Train Loss: 1.296816 | Val Loss: 0.640567\n",
      "Epoch [400/500] | Train Loss: 1.137642 | Val Loss: 0.639981\n",
      "Epoch [500/500] | Train Loss: 1.123956 | Val Loss: 0.676822\n",
      "Epoch [100/500] | Train Loss: 1.205843 | Val Loss: 0.653784\n",
      "Epoch [200/500] | Train Loss: 1.109472 | Val Loss: 0.687949\n",
      "Epoch [300/500] | Train Loss: 1.032322 | Val Loss: 0.715576\n",
      "Epoch [400/500] | Train Loss: 1.014145 | Val Loss: 0.732430\n",
      "Epoch [500/500] | Train Loss: 1.017958 | Val Loss: 0.748296\n",
      "Epoch [100/500] | Train Loss: 1.079356 | Val Loss: 0.336013\n",
      "Epoch [200/500] | Train Loss: 0.995420 | Val Loss: 0.334851\n",
      "Epoch [300/500] | Train Loss: 0.945392 | Val Loss: 0.342024\n",
      "Epoch [400/500] | Train Loss: 0.935588 | Val Loss: 0.344992\n",
      "Epoch [500/500] | Train Loss: 0.881163 | Val Loss: 0.340060\n",
      "Epoch [100/500] | Train Loss: 0.933078 | Val Loss: 0.474667\n",
      "Epoch [200/500] | Train Loss: 0.862161 | Val Loss: 0.481330\n",
      "Epoch [300/500] | Train Loss: 0.852395 | Val Loss: 0.476509\n",
      "Epoch [400/500] | Train Loss: 0.819314 | Val Loss: 0.468853\n",
      "Epoch [500/500] | Train Loss: 0.782771 | Val Loss: 0.466017\n",
      "Epoch [100/500] | Train Loss: 1.357162 | Val Loss: 1.326888\n",
      "Epoch [200/500] | Train Loss: 1.013811 | Val Loss: 1.354914\n",
      "Epoch [300/500] | Train Loss: 0.977303 | Val Loss: 1.375106\n",
      "Epoch [400/500] | Train Loss: 1.116068 | Val Loss: 1.481776\n",
      "Epoch [500/500] | Train Loss: 1.053852 | Val Loss: 1.607865\n",
      "Epoch [100/500] | Train Loss: 1.301511 | Val Loss: 0.661159\n",
      "Epoch [200/500] | Train Loss: 1.067252 | Val Loss: 0.674995\n",
      "Epoch [300/500] | Train Loss: 0.937219 | Val Loss: 0.676421\n",
      "Epoch [400/500] | Train Loss: 0.915929 | Val Loss: 0.743338\n",
      "Epoch [500/500] | Train Loss: 0.794330 | Val Loss: 0.767510\n",
      "Epoch [100/500] | Train Loss: 1.003607 | Val Loss: 0.685136\n",
      "Epoch [200/500] | Train Loss: 0.907625 | Val Loss: 0.755561\n",
      "Epoch [300/500] | Train Loss: 0.931149 | Val Loss: 0.741203\n",
      "Epoch [400/500] | Train Loss: 0.823787 | Val Loss: 0.769628\n",
      "Epoch [500/500] | Train Loss: 0.723904 | Val Loss: 0.787460\n",
      "Epoch [100/500] | Train Loss: 0.878772 | Val Loss: 0.323825\n",
      "Epoch [200/500] | Train Loss: 0.784561 | Val Loss: 0.339160\n",
      "Epoch [300/500] | Train Loss: 0.784156 | Val Loss: 0.342972\n",
      "Epoch [400/500] | Train Loss: 0.767200 | Val Loss: 0.328818\n",
      "Epoch [500/500] | Train Loss: 0.793148 | Val Loss: 0.331312\n",
      "Epoch [100/500] | Train Loss: 0.809022 | Val Loss: 0.463258\n",
      "Epoch [200/500] | Train Loss: 0.756930 | Val Loss: 0.446861\n",
      "Epoch [300/500] | Train Loss: 0.710791 | Val Loss: 0.456445\n",
      "Epoch [400/500] | Train Loss: 0.697843 | Val Loss: 0.455983\n",
      "Epoch [500/500] | Train Loss: 0.760846 | Val Loss: 0.452209\n",
      "Epoch [100/500] | Train Loss: 1.597488 | Val Loss: 1.326157\n",
      "Epoch [200/500] | Train Loss: 1.159240 | Val Loss: 1.582823\n",
      "Epoch [300/500] | Train Loss: 1.213647 | Val Loss: 1.604101\n",
      "Epoch [400/500] | Train Loss: 0.933114 | Val Loss: 1.589193\n",
      "Epoch [500/500] | Train Loss: 0.874395 | Val Loss: 1.538755\n",
      "Epoch [100/500] | Train Loss: 1.403642 | Val Loss: 0.634332\n",
      "Epoch [200/500] | Train Loss: 1.166075 | Val Loss: 0.714425\n",
      "Epoch [300/500] | Train Loss: 1.017110 | Val Loss: 0.858886\n",
      "Epoch [400/500] | Train Loss: 0.937099 | Val Loss: 0.897534\n",
      "Epoch [500/500] | Train Loss: 0.803315 | Val Loss: 0.936501\n",
      "Epoch [100/500] | Train Loss: 1.041359 | Val Loss: 0.706601\n",
      "Epoch [200/500] | Train Loss: 0.926278 | Val Loss: 0.763049\n",
      "Epoch [300/500] | Train Loss: 0.845874 | Val Loss: 0.766744\n",
      "Epoch [400/500] | Train Loss: 0.787838 | Val Loss: 0.782116\n",
      "Epoch [500/500] | Train Loss: 0.716977 | Val Loss: 0.774261\n",
      "Epoch [100/500] | Train Loss: 1.063734 | Val Loss: 0.316633\n",
      "Epoch [200/500] | Train Loss: 0.943985 | Val Loss: 0.343531\n",
      "Epoch [300/500] | Train Loss: 0.881207 | Val Loss: 0.344629\n",
      "Epoch [400/500] | Train Loss: 0.749981 | Val Loss: 0.340660\n",
      "Epoch [500/500] | Train Loss: 0.744711 | Val Loss: 0.351932\n",
      "Epoch [100/500] | Train Loss: 0.913856 | Val Loss: 0.464155\n",
      "Epoch [200/500] | Train Loss: 0.833648 | Val Loss: 0.483766\n",
      "Epoch [300/500] | Train Loss: 0.745063 | Val Loss: 0.472569\n",
      "Epoch [400/500] | Train Loss: 0.703177 | Val Loss: 0.482918\n",
      "Epoch [500/500] | Train Loss: 0.644667 | Val Loss: 0.478539\n",
      "Epoch [100/500] | Train Loss: 0.776721 | Val Loss: 1.373563\n",
      "Epoch [200/500] | Train Loss: 0.610936 | Val Loss: 1.536616\n",
      "Epoch [300/500] | Train Loss: 0.527533 | Val Loss: 1.469229\n",
      "Epoch [400/500] | Train Loss: 0.512179 | Val Loss: 1.590687\n",
      "Epoch [500/500] | Train Loss: 0.457901 | Val Loss: 1.652322\n",
      "Epoch [100/500] | Train Loss: 0.852097 | Val Loss: 0.652889\n",
      "Epoch [200/500] | Train Loss: 0.765425 | Val Loss: 0.752704\n",
      "Epoch [300/500] | Train Loss: 0.607633 | Val Loss: 0.756407\n",
      "Epoch [400/500] | Train Loss: 0.551478 | Val Loss: 0.816417\n",
      "Epoch [500/500] | Train Loss: 0.532731 | Val Loss: 0.811315\n",
      "Epoch [100/500] | Train Loss: 0.940782 | Val Loss: 0.922298\n",
      "Epoch [200/500] | Train Loss: 0.724834 | Val Loss: 0.870519\n",
      "Epoch [300/500] | Train Loss: 0.663880 | Val Loss: 0.977763\n",
      "Epoch [400/500] | Train Loss: 0.699667 | Val Loss: 0.732214\n",
      "Epoch [500/500] | Train Loss: 0.618576 | Val Loss: 1.110599\n",
      "Epoch [100/500] | Train Loss: 0.786163 | Val Loss: 0.323486\n",
      "Epoch [200/500] | Train Loss: 0.681709 | Val Loss: 0.353689\n",
      "Epoch [300/500] | Train Loss: 0.588513 | Val Loss: 0.355506\n",
      "Epoch [400/500] | Train Loss: 0.582822 | Val Loss: 0.345492\n",
      "Epoch [500/500] | Train Loss: 0.533444 | Val Loss: 0.363196\n",
      "Epoch [100/500] | Train Loss: 0.764898 | Val Loss: 0.474613\n",
      "Epoch [200/500] | Train Loss: 0.597835 | Val Loss: 0.475037\n",
      "Epoch [300/500] | Train Loss: 0.570534 | Val Loss: 0.495441\n",
      "Epoch [400/500] | Train Loss: 0.519574 | Val Loss: 0.512004\n",
      "Epoch [500/500] | Train Loss: 0.532642 | Val Loss: 0.551838\n",
      "Epoch [100/500] | Train Loss: 1.721455 | Val Loss: 1.270590\n",
      "Epoch [200/500] | Train Loss: 1.449203 | Val Loss: 1.411731\n",
      "Epoch [300/500] | Train Loss: 1.310701 | Val Loss: 1.388829\n",
      "Epoch [400/500] | Train Loss: 1.178174 | Val Loss: 1.314339\n",
      "Epoch [500/500] | Train Loss: 1.240138 | Val Loss: 1.314623\n",
      "Epoch [100/500] | Train Loss: 1.426331 | Val Loss: 0.609277\n",
      "Epoch [200/500] | Train Loss: 1.378205 | Val Loss: 0.599691\n",
      "Epoch [300/500] | Train Loss: 1.198940 | Val Loss: 0.627168\n",
      "Epoch [400/500] | Train Loss: 1.032055 | Val Loss: 0.651769\n",
      "Epoch [500/500] | Train Loss: 1.075959 | Val Loss: 0.666184\n",
      "Epoch [100/500] | Train Loss: 1.193089 | Val Loss: 0.667159\n",
      "Epoch [200/500] | Train Loss: 1.015387 | Val Loss: 0.690724\n",
      "Epoch [300/500] | Train Loss: 1.032112 | Val Loss: 0.700058\n",
      "Epoch [400/500] | Train Loss: 0.888532 | Val Loss: 0.695366\n",
      "Epoch [500/500] | Train Loss: 0.900321 | Val Loss: 0.731569\n",
      "Epoch [100/500] | Train Loss: 1.043602 | Val Loss: 0.338959\n",
      "Epoch [200/500] | Train Loss: 0.999954 | Val Loss: 0.334772\n",
      "Epoch [300/500] | Train Loss: 0.922577 | Val Loss: 0.337088\n",
      "Epoch [400/500] | Train Loss: 0.872928 | Val Loss: 0.338851\n",
      "Epoch [500/500] | Train Loss: 0.816422 | Val Loss: 0.355196\n",
      "Epoch [100/500] | Train Loss: 0.922195 | Val Loss: 0.470115\n",
      "Epoch [200/500] | Train Loss: 0.896396 | Val Loss: 0.480424\n",
      "Epoch [300/500] | Train Loss: 0.822992 | Val Loss: 0.472860\n",
      "Epoch [400/500] | Train Loss: 0.785157 | Val Loss: 0.464044\n",
      "Epoch [500/500] | Train Loss: 0.779828 | Val Loss: 0.457927\n",
      "Epoch [100/500] | Train Loss: 1.257762 | Val Loss: 1.395735\n",
      "Epoch [200/500] | Train Loss: 0.965178 | Val Loss: 1.429783\n",
      "Epoch [300/500] | Train Loss: 0.758121 | Val Loss: 1.451396\n",
      "Epoch [400/500] | Train Loss: 0.720690 | Val Loss: 1.417042\n",
      "Epoch [500/500] | Train Loss: 0.874363 | Val Loss: 1.484741\n",
      "Epoch [100/500] | Train Loss: 1.003677 | Val Loss: 0.640725\n",
      "Epoch [200/500] | Train Loss: 0.915995 | Val Loss: 0.674813\n",
      "Epoch [300/500] | Train Loss: 0.878430 | Val Loss: 0.697277\n",
      "Epoch [400/500] | Train Loss: 0.825684 | Val Loss: 0.746074\n",
      "Epoch [500/500] | Train Loss: 0.621045 | Val Loss: 0.738092\n",
      "Epoch [100/500] | Train Loss: 0.925546 | Val Loss: 0.701270\n",
      "Epoch [200/500] | Train Loss: 0.802084 | Val Loss: 0.720220\n",
      "Epoch [300/500] | Train Loss: 0.765138 | Val Loss: 0.751417\n",
      "Epoch [400/500] | Train Loss: 0.707171 | Val Loss: 0.701859\n",
      "Epoch [500/500] | Train Loss: 0.687808 | Val Loss: 0.774795\n",
      "Epoch [100/500] | Train Loss: 0.856478 | Val Loss: 0.363277\n",
      "Epoch [200/500] | Train Loss: 0.784357 | Val Loss: 0.344413\n",
      "Epoch [300/500] | Train Loss: 0.761566 | Val Loss: 0.355815\n",
      "Epoch [400/500] | Train Loss: 0.797542 | Val Loss: 0.345171\n",
      "Epoch [500/500] | Train Loss: 0.767393 | Val Loss: 0.329518\n",
      "Epoch [100/500] | Train Loss: 0.748980 | Val Loss: 0.458599\n",
      "Epoch [200/500] | Train Loss: 0.749688 | Val Loss: 0.472306\n",
      "Epoch [300/500] | Train Loss: 0.646883 | Val Loss: 0.468514\n",
      "Epoch [400/500] | Train Loss: 0.594512 | Val Loss: 0.453618\n",
      "Epoch [500/500] | Train Loss: 0.611883 | Val Loss: 0.485756\n",
      "[Year=1944] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.705100 Test MSE=0.208271\n",
      "Year 1944 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.121381 | Val Loss: 0.555317\n",
      "Epoch [200/500] | Train Loss: 0.802216 | Val Loss: 0.664228\n",
      "Epoch [300/500] | Train Loss: 0.665911 | Val Loss: 0.663447\n",
      "Epoch [400/500] | Train Loss: 0.609318 | Val Loss: 0.695929\n",
      "Epoch [500/500] | Train Loss: 0.578618 | Val Loss: 0.719604\n",
      "Epoch [100/500] | Train Loss: 0.863262 | Val Loss: 0.687426\n",
      "Epoch [200/500] | Train Loss: 0.681161 | Val Loss: 0.779014\n",
      "Epoch [300/500] | Train Loss: 0.613630 | Val Loss: 0.807412\n",
      "Epoch [400/500] | Train Loss: 0.577326 | Val Loss: 0.834696\n",
      "Epoch [500/500] | Train Loss: 0.648263 | Val Loss: 0.862458\n",
      "Epoch [100/500] | Train Loss: 0.798671 | Val Loss: 0.355292\n",
      "Epoch [200/500] | Train Loss: 0.671607 | Val Loss: 0.350995\n",
      "Epoch [300/500] | Train Loss: 0.646196 | Val Loss: 0.339935\n",
      "Epoch [400/500] | Train Loss: 0.614655 | Val Loss: 0.349417\n",
      "Epoch [500/500] | Train Loss: 0.581803 | Val Loss: 0.344965\n",
      "Epoch [100/500] | Train Loss: 0.689648 | Val Loss: 0.366866\n",
      "Epoch [200/500] | Train Loss: 0.596051 | Val Loss: 0.376021\n",
      "Epoch [300/500] | Train Loss: 0.599442 | Val Loss: 0.393664\n",
      "Epoch [400/500] | Train Loss: 0.508993 | Val Loss: 0.395304\n",
      "Epoch [500/500] | Train Loss: 0.476651 | Val Loss: 0.390869\n",
      "Epoch [100/500] | Train Loss: 0.595267 | Val Loss: 0.213041\n",
      "Epoch [200/500] | Train Loss: 0.536351 | Val Loss: 0.212871\n",
      "Epoch [300/500] | Train Loss: 0.509246 | Val Loss: 0.215316\n",
      "Epoch [400/500] | Train Loss: 0.509908 | Val Loss: 0.218112\n",
      "Epoch [500/500] | Train Loss: 0.484610 | Val Loss: 0.218498\n",
      "Epoch [100/500] | Train Loss: 0.611496 | Val Loss: 0.691637\n",
      "Epoch [200/500] | Train Loss: 0.352968 | Val Loss: 0.640451\n",
      "Epoch [300/500] | Train Loss: 0.315490 | Val Loss: 0.648279\n",
      "Epoch [400/500] | Train Loss: 0.286089 | Val Loss: 0.679757\n",
      "Epoch [500/500] | Train Loss: 0.332278 | Val Loss: 0.730265\n",
      "Epoch [100/500] | Train Loss: 0.570400 | Val Loss: 0.791126\n",
      "Epoch [200/500] | Train Loss: 0.459220 | Val Loss: 0.840346\n",
      "Epoch [300/500] | Train Loss: 0.436832 | Val Loss: 0.867098\n",
      "Epoch [400/500] | Train Loss: 0.527201 | Val Loss: 0.832747\n",
      "Epoch [500/500] | Train Loss: 0.415363 | Val Loss: 0.875259\n",
      "Epoch [100/500] | Train Loss: 0.588766 | Val Loss: 0.348427\n",
      "Epoch [200/500] | Train Loss: 0.517990 | Val Loss: 0.358667\n",
      "Epoch [300/500] | Train Loss: 0.457372 | Val Loss: 0.415151\n",
      "Epoch [400/500] | Train Loss: 0.428650 | Val Loss: 0.387766\n",
      "Epoch [500/500] | Train Loss: 0.421083 | Val Loss: 0.385995\n",
      "Epoch [100/500] | Train Loss: 0.551255 | Val Loss: 0.380276\n",
      "Epoch [200/500] | Train Loss: 0.475594 | Val Loss: 0.394746\n",
      "Epoch [300/500] | Train Loss: 0.456540 | Val Loss: 0.405048\n",
      "Epoch [400/500] | Train Loss: 0.380519 | Val Loss: 0.408485\n",
      "Epoch [500/500] | Train Loss: 0.412349 | Val Loss: 0.410339\n",
      "Epoch [100/500] | Train Loss: 0.464693 | Val Loss: 0.217056\n",
      "Epoch [200/500] | Train Loss: 0.415431 | Val Loss: 0.226757\n",
      "Epoch [300/500] | Train Loss: 0.405494 | Val Loss: 0.223413\n",
      "Epoch [400/500] | Train Loss: 0.369669 | Val Loss: 0.221339\n",
      "Epoch [500/500] | Train Loss: 0.419542 | Val Loss: 0.227795\n",
      "Epoch [100/500] | Train Loss: 1.198923 | Val Loss: 0.527988\n",
      "Epoch [200/500] | Train Loss: 1.066514 | Val Loss: 0.566664\n",
      "Epoch [300/500] | Train Loss: 0.886912 | Val Loss: 0.625001\n",
      "Epoch [400/500] | Train Loss: 0.796005 | Val Loss: 0.635463\n",
      "Epoch [500/500] | Train Loss: 0.801118 | Val Loss: 0.634239\n",
      "Epoch [100/500] | Train Loss: 0.811418 | Val Loss: 0.707169\n",
      "Epoch [200/500] | Train Loss: 0.744159 | Val Loss: 0.757619\n",
      "Epoch [300/500] | Train Loss: 0.746527 | Val Loss: 0.726164\n",
      "Epoch [400/500] | Train Loss: 0.704754 | Val Loss: 0.770630\n",
      "Epoch [500/500] | Train Loss: 0.706635 | Val Loss: 0.778525\n",
      "Epoch [100/500] | Train Loss: 0.819652 | Val Loss: 0.374495\n",
      "Epoch [200/500] | Train Loss: 0.756920 | Val Loss: 0.357688\n",
      "Epoch [300/500] | Train Loss: 0.747026 | Val Loss: 0.367081\n",
      "Epoch [400/500] | Train Loss: 0.701988 | Val Loss: 0.364194\n",
      "Epoch [500/500] | Train Loss: 0.683456 | Val Loss: 0.365969\n",
      "Epoch [100/500] | Train Loss: 0.685420 | Val Loss: 0.379273\n",
      "Epoch [200/500] | Train Loss: 0.640664 | Val Loss: 0.373827\n",
      "Epoch [300/500] | Train Loss: 0.611059 | Val Loss: 0.380185\n",
      "Epoch [400/500] | Train Loss: 0.556732 | Val Loss: 0.370443\n",
      "Epoch [500/500] | Train Loss: 0.562550 | Val Loss: 0.371369\n",
      "Epoch [100/500] | Train Loss: 0.636680 | Val Loss: 0.217556\n",
      "Epoch [200/500] | Train Loss: 0.607058 | Val Loss: 0.215679\n",
      "Epoch [300/500] | Train Loss: 0.559660 | Val Loss: 0.214692\n",
      "Epoch [400/500] | Train Loss: 0.549579 | Val Loss: 0.215566\n",
      "Epoch [500/500] | Train Loss: 0.517823 | Val Loss: 0.218277\n",
      "Epoch [100/500] | Train Loss: 0.730061 | Val Loss: 0.588818\n",
      "Epoch [200/500] | Train Loss: 0.813207 | Val Loss: 0.707649\n",
      "Epoch [300/500] | Train Loss: 0.772375 | Val Loss: 0.628011\n",
      "Epoch [400/500] | Train Loss: 0.810981 | Val Loss: 0.611293\n",
      "Epoch [500/500] | Train Loss: 0.622544 | Val Loss: 0.644567\n",
      "Epoch [100/500] | Train Loss: 0.611433 | Val Loss: 0.808183\n",
      "Epoch [200/500] | Train Loss: 0.607097 | Val Loss: 0.788391\n",
      "Epoch [300/500] | Train Loss: 0.571890 | Val Loss: 0.789674\n",
      "Epoch [400/500] | Train Loss: 0.588371 | Val Loss: 0.741396\n",
      "Epoch [500/500] | Train Loss: 0.599172 | Val Loss: 0.780688\n",
      "Epoch [100/500] | Train Loss: 0.646636 | Val Loss: 0.359661\n",
      "Epoch [200/500] | Train Loss: 0.619739 | Val Loss: 0.362336\n",
      "Epoch [300/500] | Train Loss: 0.583768 | Val Loss: 0.356358\n",
      "Epoch [400/500] | Train Loss: 0.580914 | Val Loss: 0.352536\n",
      "Epoch [500/500] | Train Loss: 0.516423 | Val Loss: 0.358366\n",
      "Epoch [100/500] | Train Loss: 0.579562 | Val Loss: 0.373643\n",
      "Epoch [200/500] | Train Loss: 0.550889 | Val Loss: 0.366019\n",
      "Epoch [300/500] | Train Loss: 0.558242 | Val Loss: 0.368077\n",
      "Epoch [400/500] | Train Loss: 0.489084 | Val Loss: 0.366029\n",
      "Epoch [500/500] | Train Loss: 0.464282 | Val Loss: 0.365532\n",
      "Epoch [100/500] | Train Loss: 0.523939 | Val Loss: 0.211629\n",
      "Epoch [200/500] | Train Loss: 0.483689 | Val Loss: 0.208066\n",
      "Epoch [300/500] | Train Loss: 0.464386 | Val Loss: 0.218179\n",
      "Epoch [400/500] | Train Loss: 0.459659 | Val Loss: 0.222498\n",
      "Epoch [500/500] | Train Loss: 0.440443 | Val Loss: 0.220004\n",
      "Epoch [100/500] | Train Loss: 1.076331 | Val Loss: 0.524702\n",
      "Epoch [200/500] | Train Loss: 0.807093 | Val Loss: 0.531756\n",
      "Epoch [300/500] | Train Loss: 0.784498 | Val Loss: 0.564222\n",
      "Epoch [400/500] | Train Loss: 0.674360 | Val Loss: 0.637277\n",
      "Epoch [500/500] | Train Loss: 0.687736 | Val Loss: 0.658366\n",
      "Epoch [100/500] | Train Loss: 0.734778 | Val Loss: 0.754866\n",
      "Epoch [200/500] | Train Loss: 0.673065 | Val Loss: 0.838114\n",
      "Epoch [300/500] | Train Loss: 0.614879 | Val Loss: 0.881302\n",
      "Epoch [400/500] | Train Loss: 0.549731 | Val Loss: 0.870580\n",
      "Epoch [500/500] | Train Loss: 0.495544 | Val Loss: 0.863015\n",
      "Epoch [100/500] | Train Loss: 0.766501 | Val Loss: 0.366830\n",
      "Epoch [200/500] | Train Loss: 0.681567 | Val Loss: 0.350440\n",
      "Epoch [300/500] | Train Loss: 0.587983 | Val Loss: 0.355783\n",
      "Epoch [400/500] | Train Loss: 0.528674 | Val Loss: 0.359927\n",
      "Epoch [500/500] | Train Loss: 0.505800 | Val Loss: 0.334427\n",
      "Epoch [100/500] | Train Loss: 0.662598 | Val Loss: 0.365118\n",
      "Epoch [200/500] | Train Loss: 0.601458 | Val Loss: 0.386119\n",
      "Epoch [300/500] | Train Loss: 0.530339 | Val Loss: 0.376618\n",
      "Epoch [400/500] | Train Loss: 0.525573 | Val Loss: 0.365502\n",
      "Epoch [500/500] | Train Loss: 0.472588 | Val Loss: 0.365471\n",
      "Epoch [100/500] | Train Loss: 0.586260 | Val Loss: 0.213698\n",
      "Epoch [200/500] | Train Loss: 0.524865 | Val Loss: 0.213929\n",
      "Epoch [300/500] | Train Loss: 0.489438 | Val Loss: 0.210640\n",
      "Epoch [400/500] | Train Loss: 0.485262 | Val Loss: 0.212826\n",
      "Epoch [500/500] | Train Loss: 0.459330 | Val Loss: 0.214351\n",
      "Epoch [100/500] | Train Loss: 0.627785 | Val Loss: 0.832708\n",
      "Epoch [200/500] | Train Loss: 0.418413 | Val Loss: 0.684716\n",
      "Epoch [300/500] | Train Loss: 0.292127 | Val Loss: 0.708171\n",
      "Epoch [400/500] | Train Loss: 0.401184 | Val Loss: 0.704360\n",
      "Epoch [500/500] | Train Loss: 0.271333 | Val Loss: 0.724997\n",
      "Epoch [100/500] | Train Loss: 0.645260 | Val Loss: 0.959344\n",
      "Epoch [200/500] | Train Loss: 0.542962 | Val Loss: 0.905994\n",
      "Epoch [300/500] | Train Loss: 0.464326 | Val Loss: 0.911982\n",
      "Epoch [400/500] | Train Loss: 0.340238 | Val Loss: 0.957024\n",
      "Epoch [500/500] | Train Loss: 0.302694 | Val Loss: 0.918127\n",
      "Epoch [100/500] | Train Loss: 0.607370 | Val Loss: 0.347087\n",
      "Epoch [200/500] | Train Loss: 0.491923 | Val Loss: 0.391410\n",
      "Epoch [300/500] | Train Loss: 0.418329 | Val Loss: 0.404835\n",
      "Epoch [400/500] | Train Loss: 0.395702 | Val Loss: 0.387368\n",
      "Epoch [500/500] | Train Loss: 0.378032 | Val Loss: 0.411277\n",
      "Epoch [100/500] | Train Loss: 0.497742 | Val Loss: 0.363592\n",
      "Epoch [200/500] | Train Loss: 0.467868 | Val Loss: 0.383832\n",
      "Epoch [300/500] | Train Loss: 0.395450 | Val Loss: 0.429821\n",
      "Epoch [400/500] | Train Loss: 0.366090 | Val Loss: 0.383655\n",
      "Epoch [500/500] | Train Loss: 0.367025 | Val Loss: 0.409234\n",
      "Epoch [100/500] | Train Loss: 0.461670 | Val Loss: 0.210804\n",
      "Epoch [200/500] | Train Loss: 0.390239 | Val Loss: 0.221135\n",
      "Epoch [300/500] | Train Loss: 0.355496 | Val Loss: 0.224181\n",
      "Epoch [400/500] | Train Loss: 0.412518 | Val Loss: 0.230619\n",
      "Epoch [500/500] | Train Loss: 0.348737 | Val Loss: 0.245744\n",
      "Epoch [100/500] | Train Loss: 1.031236 | Val Loss: 0.529143\n",
      "Epoch [200/500] | Train Loss: 0.819815 | Val Loss: 0.515904\n",
      "Epoch [300/500] | Train Loss: 0.995655 | Val Loss: 0.562936\n",
      "Epoch [400/500] | Train Loss: 0.753185 | Val Loss: 0.604637\n",
      "Epoch [500/500] | Train Loss: 0.669179 | Val Loss: 0.630930\n",
      "Epoch [100/500] | Train Loss: 0.816874 | Val Loss: 0.715802\n",
      "Epoch [200/500] | Train Loss: 0.670434 | Val Loss: 0.797330\n",
      "Epoch [300/500] | Train Loss: 0.644640 | Val Loss: 0.853215\n",
      "Epoch [400/500] | Train Loss: 0.569563 | Val Loss: 0.807595\n",
      "Epoch [500/500] | Train Loss: 0.543765 | Val Loss: 0.803444\n",
      "Epoch [100/500] | Train Loss: 0.825518 | Val Loss: 0.375904\n",
      "Epoch [200/500] | Train Loss: 0.784274 | Val Loss: 0.366383\n",
      "Epoch [300/500] | Train Loss: 0.710631 | Val Loss: 0.359515\n",
      "Epoch [400/500] | Train Loss: 0.623295 | Val Loss: 0.370469\n",
      "Epoch [500/500] | Train Loss: 0.596471 | Val Loss: 0.368404\n",
      "Epoch [100/500] | Train Loss: 0.682658 | Val Loss: 0.365895\n",
      "Epoch [200/500] | Train Loss: 0.624478 | Val Loss: 0.377106\n",
      "Epoch [300/500] | Train Loss: 0.607616 | Val Loss: 0.374195\n",
      "Epoch [400/500] | Train Loss: 0.601161 | Val Loss: 0.374086\n",
      "Epoch [500/500] | Train Loss: 0.549567 | Val Loss: 0.373404\n",
      "Epoch [100/500] | Train Loss: 0.627673 | Val Loss: 0.214468\n",
      "Epoch [200/500] | Train Loss: 0.615313 | Val Loss: 0.215244\n",
      "Epoch [300/500] | Train Loss: 0.562779 | Val Loss: 0.217477\n",
      "Epoch [400/500] | Train Loss: 0.558366 | Val Loss: 0.218506\n",
      "Epoch [500/500] | Train Loss: 0.496412 | Val Loss: 0.222261\n",
      "Epoch [100/500] | Train Loss: 0.668306 | Val Loss: 0.657932\n",
      "Epoch [200/500] | Train Loss: 0.587601 | Val Loss: 0.731897\n",
      "Epoch [300/500] | Train Loss: 0.531662 | Val Loss: 0.615320\n",
      "Epoch [400/500] | Train Loss: 0.569497 | Val Loss: 0.608975\n",
      "Epoch [500/500] | Train Loss: 0.503964 | Val Loss: 0.624461\n",
      "Epoch [100/500] | Train Loss: 0.591591 | Val Loss: 0.774269\n",
      "Epoch [200/500] | Train Loss: 0.515198 | Val Loss: 0.804935\n",
      "Epoch [300/500] | Train Loss: 0.473730 | Val Loss: 0.846039\n",
      "Epoch [400/500] | Train Loss: 0.403665 | Val Loss: 0.928596\n",
      "Epoch [500/500] | Train Loss: 0.410975 | Val Loss: 0.902901\n",
      "Epoch [100/500] | Train Loss: 0.689064 | Val Loss: 0.362330\n",
      "Epoch [200/500] | Train Loss: 0.617696 | Val Loss: 0.380519\n",
      "Epoch [300/500] | Train Loss: 0.518332 | Val Loss: 0.369546\n",
      "Epoch [400/500] | Train Loss: 0.493506 | Val Loss: 0.380248\n",
      "Epoch [500/500] | Train Loss: 0.495312 | Val Loss: 0.380053\n",
      "Epoch [100/500] | Train Loss: 0.545722 | Val Loss: 0.374884\n",
      "Epoch [200/500] | Train Loss: 0.506814 | Val Loss: 0.376124\n",
      "Epoch [300/500] | Train Loss: 0.510737 | Val Loss: 0.395071\n",
      "Epoch [400/500] | Train Loss: 0.475233 | Val Loss: 0.377872\n",
      "Epoch [500/500] | Train Loss: 0.433715 | Val Loss: 0.380356\n",
      "Epoch [100/500] | Train Loss: 0.579693 | Val Loss: 0.212089\n",
      "Epoch [200/500] | Train Loss: 0.480054 | Val Loss: 0.216397\n",
      "Epoch [300/500] | Train Loss: 0.465428 | Val Loss: 0.222226\n",
      "Epoch [400/500] | Train Loss: 0.407115 | Val Loss: 0.216739\n",
      "Epoch [500/500] | Train Loss: 0.436453 | Val Loss: 0.229264\n",
      "[Year=1945] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.473676 Test MSE=0.411100\n",
      "Year 1945 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.343447 | Val Loss: 0.684035\n",
      "Epoch [200/500] | Train Loss: 0.309180 | Val Loss: 0.731206\n",
      "Epoch [300/500] | Train Loss: 0.293267 | Val Loss: 0.770545\n",
      "Epoch [400/500] | Train Loss: 0.261822 | Val Loss: 0.796001\n",
      "Epoch [500/500] | Train Loss: 0.259672 | Val Loss: 0.802584\n",
      "Epoch [100/500] | Train Loss: 0.496949 | Val Loss: 0.352777\n",
      "Epoch [200/500] | Train Loss: 0.471449 | Val Loss: 0.363362\n",
      "Epoch [300/500] | Train Loss: 0.432543 | Val Loss: 0.379158\n",
      "Epoch [400/500] | Train Loss: 0.396100 | Val Loss: 0.390423\n",
      "Epoch [500/500] | Train Loss: 0.367141 | Val Loss: 0.400111\n",
      "Epoch [100/500] | Train Loss: 0.471012 | Val Loss: 0.356105\n",
      "Epoch [200/500] | Train Loss: 0.431565 | Val Loss: 0.339028\n",
      "Epoch [300/500] | Train Loss: 0.420994 | Val Loss: 0.334439\n",
      "Epoch [400/500] | Train Loss: 0.405848 | Val Loss: 0.340539\n",
      "Epoch [500/500] | Train Loss: 0.384799 | Val Loss: 0.338913\n",
      "Epoch [100/500] | Train Loss: 0.415201 | Val Loss: 0.212556\n",
      "Epoch [200/500] | Train Loss: 0.401479 | Val Loss: 0.210391\n",
      "Epoch [300/500] | Train Loss: 0.384905 | Val Loss: 0.212310\n",
      "Epoch [400/500] | Train Loss: 0.381078 | Val Loss: 0.215977\n",
      "Epoch [500/500] | Train Loss: 0.358860 | Val Loss: 0.220735\n",
      "Epoch [100/500] | Train Loss: 0.387911 | Val Loss: 0.412349\n",
      "Epoch [200/500] | Train Loss: 0.371282 | Val Loss: 0.408267\n",
      "Epoch [300/500] | Train Loss: 0.351989 | Val Loss: 0.418496\n",
      "Epoch [400/500] | Train Loss: 0.339168 | Val Loss: 0.429389\n",
      "Epoch [500/500] | Train Loss: 0.326246 | Val Loss: 0.427085\n",
      "Epoch [100/500] | Train Loss: 0.268726 | Val Loss: 0.776808\n",
      "Epoch [200/500] | Train Loss: 0.180157 | Val Loss: 0.848692\n",
      "Epoch [300/500] | Train Loss: 0.161161 | Val Loss: 0.825036\n",
      "Epoch [400/500] | Train Loss: 0.120913 | Val Loss: 0.800863\n",
      "Epoch [500/500] | Train Loss: 0.128771 | Val Loss: 0.840301\n",
      "Epoch [100/500] | Train Loss: 0.367333 | Val Loss: 0.412584\n",
      "Epoch [200/500] | Train Loss: 0.302043 | Val Loss: 0.416339\n",
      "Epoch [300/500] | Train Loss: 0.255716 | Val Loss: 0.459475\n",
      "Epoch [400/500] | Train Loss: 0.263085 | Val Loss: 0.434964\n",
      "Epoch [500/500] | Train Loss: 0.209016 | Val Loss: 0.495771\n",
      "Epoch [100/500] | Train Loss: 0.374207 | Val Loss: 0.346918\n",
      "Epoch [200/500] | Train Loss: 0.311540 | Val Loss: 0.359082\n",
      "Epoch [300/500] | Train Loss: 0.305441 | Val Loss: 0.374851\n",
      "Epoch [400/500] | Train Loss: 0.279823 | Val Loss: 0.400053\n",
      "Epoch [500/500] | Train Loss: 0.266383 | Val Loss: 0.392942\n",
      "Epoch [100/500] | Train Loss: 0.388514 | Val Loss: 0.209608\n",
      "Epoch [200/500] | Train Loss: 0.340680 | Val Loss: 0.232792\n",
      "Epoch [300/500] | Train Loss: 0.311785 | Val Loss: 0.240855\n",
      "Epoch [400/500] | Train Loss: 0.297256 | Val Loss: 0.240273\n",
      "Epoch [500/500] | Train Loss: 0.266149 | Val Loss: 0.250919\n",
      "Epoch [100/500] | Train Loss: 0.356810 | Val Loss: 0.423186\n",
      "Epoch [200/500] | Train Loss: 0.317657 | Val Loss: 0.439690\n",
      "Epoch [300/500] | Train Loss: 0.297819 | Val Loss: 0.435874\n",
      "Epoch [400/500] | Train Loss: 0.292297 | Val Loss: 0.452125\n",
      "Epoch [500/500] | Train Loss: 0.279167 | Val Loss: 0.446870\n",
      "Epoch [100/500] | Train Loss: 0.385204 | Val Loss: 0.658828\n",
      "Epoch [200/500] | Train Loss: 0.348405 | Val Loss: 0.667055\n",
      "Epoch [300/500] | Train Loss: 0.345897 | Val Loss: 0.702764\n",
      "Epoch [400/500] | Train Loss: 0.331577 | Val Loss: 0.731916\n",
      "Epoch [500/500] | Train Loss: 0.297515 | Val Loss: 0.771215\n",
      "Epoch [100/500] | Train Loss: 0.493318 | Val Loss: 0.372774\n",
      "Epoch [200/500] | Train Loss: 0.501748 | Val Loss: 0.365617\n",
      "Epoch [300/500] | Train Loss: 0.476157 | Val Loss: 0.362771\n",
      "Epoch [400/500] | Train Loss: 0.460202 | Val Loss: 0.355620\n",
      "Epoch [500/500] | Train Loss: 0.427624 | Val Loss: 0.355909\n",
      "Epoch [100/500] | Train Loss: 0.465326 | Val Loss: 0.353397\n",
      "Epoch [200/500] | Train Loss: 0.444233 | Val Loss: 0.341790\n",
      "Epoch [300/500] | Train Loss: 0.439937 | Val Loss: 0.344906\n",
      "Epoch [400/500] | Train Loss: 0.414484 | Val Loss: 0.345126\n",
      "Epoch [500/500] | Train Loss: 0.415040 | Val Loss: 0.345221\n",
      "Epoch [100/500] | Train Loss: 0.431420 | Val Loss: 0.212640\n",
      "Epoch [200/500] | Train Loss: 0.414968 | Val Loss: 0.211544\n",
      "Epoch [300/500] | Train Loss: 0.400219 | Val Loss: 0.214739\n",
      "Epoch [400/500] | Train Loss: 0.388666 | Val Loss: 0.213885\n",
      "Epoch [500/500] | Train Loss: 0.373335 | Val Loss: 0.215721\n",
      "Epoch [100/500] | Train Loss: 0.402139 | Val Loss: 0.458074\n",
      "Epoch [200/500] | Train Loss: 0.380117 | Val Loss: 0.422369\n",
      "Epoch [300/500] | Train Loss: 0.366009 | Val Loss: 0.428197\n",
      "Epoch [400/500] | Train Loss: 0.359541 | Val Loss: 0.431162\n",
      "Epoch [500/500] | Train Loss: 0.361257 | Val Loss: 0.433442\n",
      "Epoch [100/500] | Train Loss: 0.297710 | Val Loss: 0.706463\n",
      "Epoch [200/500] | Train Loss: 0.252769 | Val Loss: 0.782819\n",
      "Epoch [300/500] | Train Loss: 0.290519 | Val Loss: 0.809609\n",
      "Epoch [400/500] | Train Loss: 0.207413 | Val Loss: 0.794872\n",
      "Epoch [500/500] | Train Loss: 0.215902 | Val Loss: 0.781454\n",
      "Epoch [100/500] | Train Loss: 0.451146 | Val Loss: 0.376843\n",
      "Epoch [200/500] | Train Loss: 0.412448 | Val Loss: 0.363913\n",
      "Epoch [300/500] | Train Loss: 0.399076 | Val Loss: 0.366774\n",
      "Epoch [400/500] | Train Loss: 0.382979 | Val Loss: 0.405894\n",
      "Epoch [500/500] | Train Loss: 0.345609 | Val Loss: 0.387027\n",
      "Epoch [100/500] | Train Loss: 0.421317 | Val Loss: 0.332176\n",
      "Epoch [200/500] | Train Loss: 0.378314 | Val Loss: 0.328457\n",
      "Epoch [300/500] | Train Loss: 0.357496 | Val Loss: 0.325732\n",
      "Epoch [400/500] | Train Loss: 0.344268 | Val Loss: 0.349194\n",
      "Epoch [500/500] | Train Loss: 0.352306 | Val Loss: 0.361034\n",
      "Epoch [100/500] | Train Loss: 0.416019 | Val Loss: 0.209751\n",
      "Epoch [200/500] | Train Loss: 0.350340 | Val Loss: 0.212342\n",
      "Epoch [300/500] | Train Loss: 0.342464 | Val Loss: 0.210501\n",
      "Epoch [400/500] | Train Loss: 0.333050 | Val Loss: 0.224158\n",
      "Epoch [500/500] | Train Loss: 0.334150 | Val Loss: 0.230671\n",
      "Epoch [100/500] | Train Loss: 0.348101 | Val Loss: 0.430304\n",
      "Epoch [200/500] | Train Loss: 0.324304 | Val Loss: 0.442879\n",
      "Epoch [300/500] | Train Loss: 0.333294 | Val Loss: 0.443625\n",
      "Epoch [400/500] | Train Loss: 0.310615 | Val Loss: 0.453016\n",
      "Epoch [500/500] | Train Loss: 0.323442 | Val Loss: 0.464464\n",
      "Epoch [100/500] | Train Loss: 0.372009 | Val Loss: 0.660275\n",
      "Epoch [200/500] | Train Loss: 0.333159 | Val Loss: 0.672766\n",
      "Epoch [300/500] | Train Loss: 0.264893 | Val Loss: 0.803626\n",
      "Epoch [400/500] | Train Loss: 0.228694 | Val Loss: 0.884525\n",
      "Epoch [500/500] | Train Loss: 0.186487 | Val Loss: 0.908767\n",
      "Epoch [100/500] | Train Loss: 0.479705 | Val Loss: 0.363938\n",
      "Epoch [200/500] | Train Loss: 0.427869 | Val Loss: 0.381111\n",
      "Epoch [300/500] | Train Loss: 0.383726 | Val Loss: 0.394298\n",
      "Epoch [400/500] | Train Loss: 0.339422 | Val Loss: 0.423846\n",
      "Epoch [500/500] | Train Loss: 0.317965 | Val Loss: 0.424165\n",
      "Epoch [100/500] | Train Loss: 0.439117 | Val Loss: 0.340213\n",
      "Epoch [200/500] | Train Loss: 0.399956 | Val Loss: 0.324079\n",
      "Epoch [300/500] | Train Loss: 0.383619 | Val Loss: 0.315193\n",
      "Epoch [400/500] | Train Loss: 0.358324 | Val Loss: 0.331257\n",
      "Epoch [500/500] | Train Loss: 0.349051 | Val Loss: 0.331146\n",
      "Epoch [100/500] | Train Loss: 0.415088 | Val Loss: 0.211692\n",
      "Epoch [200/500] | Train Loss: 0.384723 | Val Loss: 0.215269\n",
      "Epoch [300/500] | Train Loss: 0.363172 | Val Loss: 0.221213\n",
      "Epoch [400/500] | Train Loss: 0.329178 | Val Loss: 0.218799\n",
      "Epoch [500/500] | Train Loss: 0.329616 | Val Loss: 0.225980\n",
      "Epoch [100/500] | Train Loss: 0.363658 | Val Loss: 0.419174\n",
      "Epoch [200/500] | Train Loss: 0.342573 | Val Loss: 0.436847\n",
      "Epoch [300/500] | Train Loss: 0.322608 | Val Loss: 0.454307\n",
      "Epoch [400/500] | Train Loss: 0.294296 | Val Loss: 0.455324\n",
      "Epoch [500/500] | Train Loss: 0.283450 | Val Loss: 0.451909\n",
      "Epoch [100/500] | Train Loss: 0.225222 | Val Loss: 0.913748\n",
      "Epoch [200/500] | Train Loss: 0.149221 | Val Loss: 1.036143\n",
      "Epoch [300/500] | Train Loss: 0.136674 | Val Loss: 0.973525\n",
      "Epoch [400/500] | Train Loss: 0.108635 | Val Loss: 0.896944\n",
      "Epoch [500/500] | Train Loss: 0.120045 | Val Loss: 0.897344\n",
      "Epoch [100/500] | Train Loss: 0.347566 | Val Loss: 0.448796\n",
      "Epoch [200/500] | Train Loss: 0.267496 | Val Loss: 0.462042\n",
      "Epoch [300/500] | Train Loss: 0.214294 | Val Loss: 0.444635\n",
      "Epoch [400/500] | Train Loss: 0.219492 | Val Loss: 0.480635\n",
      "Epoch [500/500] | Train Loss: 0.176969 | Val Loss: 0.443207\n",
      "Epoch [100/500] | Train Loss: 0.403777 | Val Loss: 0.356701\n",
      "Epoch [200/500] | Train Loss: 0.352491 | Val Loss: 0.391411\n",
      "Epoch [300/500] | Train Loss: 0.325460 | Val Loss: 0.431611\n",
      "Epoch [400/500] | Train Loss: 0.304543 | Val Loss: 0.477424\n",
      "Epoch [500/500] | Train Loss: 0.276566 | Val Loss: 0.487372\n",
      "Epoch [100/500] | Train Loss: 0.355501 | Val Loss: 0.228837\n",
      "Epoch [200/500] | Train Loss: 0.299253 | Val Loss: 0.213519\n",
      "Epoch [300/500] | Train Loss: 0.270730 | Val Loss: 0.224572\n",
      "Epoch [400/500] | Train Loss: 0.241840 | Val Loss: 0.230665\n",
      "Epoch [500/500] | Train Loss: 0.240268 | Val Loss: 0.248798\n",
      "Epoch [100/500] | Train Loss: 0.322726 | Val Loss: 0.448866\n",
      "Epoch [200/500] | Train Loss: 0.273473 | Val Loss: 0.458100\n",
      "Epoch [300/500] | Train Loss: 0.256018 | Val Loss: 0.500100\n",
      "Epoch [400/500] | Train Loss: 0.246079 | Val Loss: 0.489607\n",
      "Epoch [500/500] | Train Loss: 0.232890 | Val Loss: 0.504807\n",
      "Epoch [100/500] | Train Loss: 0.363903 | Val Loss: 0.664230\n",
      "Epoch [200/500] | Train Loss: 0.314779 | Val Loss: 0.686521\n",
      "Epoch [300/500] | Train Loss: 0.287790 | Val Loss: 0.713609\n",
      "Epoch [400/500] | Train Loss: 0.294288 | Val Loss: 0.743587\n",
      "Epoch [500/500] | Train Loss: 0.255462 | Val Loss: 0.764311\n",
      "Epoch [100/500] | Train Loss: 0.488512 | Val Loss: 0.358318\n",
      "Epoch [200/500] | Train Loss: 0.471564 | Val Loss: 0.362023\n",
      "Epoch [300/500] | Train Loss: 0.445563 | Val Loss: 0.356509\n",
      "Epoch [400/500] | Train Loss: 0.415208 | Val Loss: 0.372676\n",
      "Epoch [500/500] | Train Loss: 0.404962 | Val Loss: 0.372923\n",
      "Epoch [100/500] | Train Loss: 0.453102 | Val Loss: 0.342279\n",
      "Epoch [200/500] | Train Loss: 0.418937 | Val Loss: 0.342765\n",
      "Epoch [300/500] | Train Loss: 0.417417 | Val Loss: 0.349998\n",
      "Epoch [400/500] | Train Loss: 0.410157 | Val Loss: 0.348785\n",
      "Epoch [500/500] | Train Loss: 0.380078 | Val Loss: 0.347914\n",
      "Epoch [100/500] | Train Loss: 0.421491 | Val Loss: 0.208665\n",
      "Epoch [200/500] | Train Loss: 0.403903 | Val Loss: 0.209390\n",
      "Epoch [300/500] | Train Loss: 0.390291 | Val Loss: 0.210240\n",
      "Epoch [400/500] | Train Loss: 0.366016 | Val Loss: 0.212533\n",
      "Epoch [500/500] | Train Loss: 0.355749 | Val Loss: 0.217356\n",
      "Epoch [100/500] | Train Loss: 0.379831 | Val Loss: 0.413727\n",
      "Epoch [200/500] | Train Loss: 0.369739 | Val Loss: 0.415245\n",
      "Epoch [300/500] | Train Loss: 0.359821 | Val Loss: 0.423955\n",
      "Epoch [400/500] | Train Loss: 0.350382 | Val Loss: 0.433367\n",
      "Epoch [500/500] | Train Loss: 0.331130 | Val Loss: 0.429853\n",
      "Epoch [100/500] | Train Loss: 0.287649 | Val Loss: 0.752098\n",
      "Epoch [200/500] | Train Loss: 0.263817 | Val Loss: 0.762781\n",
      "Epoch [300/500] | Train Loss: 0.247017 | Val Loss: 0.770641\n",
      "Epoch [400/500] | Train Loss: 0.251618 | Val Loss: 0.797100\n",
      "Epoch [500/500] | Train Loss: 0.224734 | Val Loss: 0.789905\n",
      "Epoch [100/500] | Train Loss: 0.395746 | Val Loss: 0.380957\n",
      "Epoch [200/500] | Train Loss: 0.352559 | Val Loss: 0.390346\n",
      "Epoch [300/500] | Train Loss: 0.325847 | Val Loss: 0.405035\n",
      "Epoch [400/500] | Train Loss: 0.280935 | Val Loss: 0.423716\n",
      "Epoch [500/500] | Train Loss: 0.312269 | Val Loss: 0.445169\n",
      "Epoch [100/500] | Train Loss: 0.396983 | Val Loss: 0.347488\n",
      "Epoch [200/500] | Train Loss: 0.366738 | Val Loss: 0.348005\n",
      "Epoch [300/500] | Train Loss: 0.340075 | Val Loss: 0.353738\n",
      "Epoch [400/500] | Train Loss: 0.331335 | Val Loss: 0.357716\n",
      "Epoch [500/500] | Train Loss: 0.296608 | Val Loss: 0.373178\n",
      "Epoch [100/500] | Train Loss: 0.353027 | Val Loss: 0.225437\n",
      "Epoch [200/500] | Train Loss: 0.338919 | Val Loss: 0.234173\n",
      "Epoch [300/500] | Train Loss: 0.303676 | Val Loss: 0.236713\n",
      "Epoch [400/500] | Train Loss: 0.298629 | Val Loss: 0.238297\n",
      "Epoch [500/500] | Train Loss: 0.292085 | Val Loss: 0.232750\n",
      "Epoch [100/500] | Train Loss: 0.345301 | Val Loss: 0.426882\n",
      "Epoch [200/500] | Train Loss: 0.311577 | Val Loss: 0.424066\n",
      "Epoch [300/500] | Train Loss: 0.299944 | Val Loss: 0.428096\n",
      "Epoch [400/500] | Train Loss: 0.309182 | Val Loss: 0.419180\n",
      "Epoch [500/500] | Train Loss: 0.279169 | Val Loss: 0.443648\n",
      "[Year=1946] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.424302 Test MSE=1.402052\n",
      "Year 1946 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.424563 | Val Loss: 0.419090\n",
      "Epoch [200/500] | Train Loss: 0.352240 | Val Loss: 0.435992\n",
      "Epoch [300/500] | Train Loss: 0.303306 | Val Loss: 0.476219\n",
      "Epoch [400/500] | Train Loss: 0.258817 | Val Loss: 0.494863\n",
      "Epoch [500/500] | Train Loss: 0.257066 | Val Loss: 0.528400\n",
      "Epoch [100/500] | Train Loss: 0.404303 | Val Loss: 0.259434\n",
      "Epoch [200/500] | Train Loss: 0.355799 | Val Loss: 0.274016\n",
      "Epoch [300/500] | Train Loss: 0.349985 | Val Loss: 0.280837\n",
      "Epoch [400/500] | Train Loss: 0.326018 | Val Loss: 0.281563\n",
      "Epoch [500/500] | Train Loss: 0.300334 | Val Loss: 0.291324\n",
      "Epoch [100/500] | Train Loss: 0.348156 | Val Loss: 0.256330\n",
      "Epoch [200/500] | Train Loss: 0.329928 | Val Loss: 0.255826\n",
      "Epoch [300/500] | Train Loss: 0.315343 | Val Loss: 0.263772\n",
      "Epoch [400/500] | Train Loss: 0.290476 | Val Loss: 0.268277\n",
      "Epoch [500/500] | Train Loss: 0.279339 | Val Loss: 0.272510\n",
      "Epoch [100/500] | Train Loss: 0.335492 | Val Loss: 0.443670\n",
      "Epoch [200/500] | Train Loss: 0.318182 | Val Loss: 0.464035\n",
      "Epoch [300/500] | Train Loss: 0.301642 | Val Loss: 0.478697\n",
      "Epoch [400/500] | Train Loss: 0.288703 | Val Loss: 0.487808\n",
      "Epoch [500/500] | Train Loss: 0.283513 | Val Loss: 0.490598\n",
      "Epoch [100/500] | Train Loss: 0.372793 | Val Loss: 1.588748\n",
      "Epoch [200/500] | Train Loss: 0.354680 | Val Loss: 1.484895\n",
      "Epoch [300/500] | Train Loss: 0.349852 | Val Loss: 1.471218\n",
      "Epoch [400/500] | Train Loss: 0.335283 | Val Loss: 1.486296\n",
      "Epoch [500/500] | Train Loss: 0.335646 | Val Loss: 1.501256\n",
      "Epoch [100/500] | Train Loss: 0.284152 | Val Loss: 0.526441\n",
      "Epoch [200/500] | Train Loss: 0.231815 | Val Loss: 0.477937\n",
      "Epoch [300/500] | Train Loss: 0.197098 | Val Loss: 0.568437\n",
      "Epoch [400/500] | Train Loss: 0.146272 | Val Loss: 0.540149\n",
      "Epoch [500/500] | Train Loss: 0.131384 | Val Loss: 0.526720\n",
      "Epoch [100/500] | Train Loss: 0.308461 | Val Loss: 0.305926\n",
      "Epoch [200/500] | Train Loss: 0.256448 | Val Loss: 0.348934\n",
      "Epoch [300/500] | Train Loss: 0.231027 | Val Loss: 0.322154\n",
      "Epoch [400/500] | Train Loss: 0.235610 | Val Loss: 0.339997\n",
      "Epoch [500/500] | Train Loss: 0.208775 | Val Loss: 0.364434\n",
      "Epoch [100/500] | Train Loss: 0.295606 | Val Loss: 0.279257\n",
      "Epoch [200/500] | Train Loss: 0.267905 | Val Loss: 0.286594\n",
      "Epoch [300/500] | Train Loss: 0.229014 | Val Loss: 0.307734\n",
      "Epoch [400/500] | Train Loss: 0.202512 | Val Loss: 0.307326\n",
      "Epoch [500/500] | Train Loss: 0.206123 | Val Loss: 0.292740\n",
      "Epoch [100/500] | Train Loss: 0.269078 | Val Loss: 0.497232\n",
      "Epoch [200/500] | Train Loss: 0.241125 | Val Loss: 0.545428\n",
      "Epoch [300/500] | Train Loss: 0.232135 | Val Loss: 0.602740\n",
      "Epoch [400/500] | Train Loss: 0.208687 | Val Loss: 0.602615\n",
      "Epoch [500/500] | Train Loss: 0.216171 | Val Loss: 0.586654\n",
      "Epoch [100/500] | Train Loss: 0.299272 | Val Loss: 1.518171\n",
      "Epoch [200/500] | Train Loss: 0.292055 | Val Loss: 1.770260\n",
      "Epoch [300/500] | Train Loss: 0.249357 | Val Loss: 1.717795\n",
      "Epoch [400/500] | Train Loss: 0.241319 | Val Loss: 1.661331\n",
      "Epoch [500/500] | Train Loss: 0.231001 | Val Loss: 1.678439\n",
      "Epoch [100/500] | Train Loss: 0.462844 | Val Loss: 0.427807\n",
      "Epoch [200/500] | Train Loss: 0.398238 | Val Loss: 0.413517\n",
      "Epoch [300/500] | Train Loss: 0.375531 | Val Loss: 0.427188\n",
      "Epoch [400/500] | Train Loss: 0.361995 | Val Loss: 0.424323\n",
      "Epoch [500/500] | Train Loss: 0.335455 | Val Loss: 0.425754\n",
      "Epoch [100/500] | Train Loss: 0.448051 | Val Loss: 0.251257\n",
      "Epoch [200/500] | Train Loss: 0.430702 | Val Loss: 0.251743\n",
      "Epoch [300/500] | Train Loss: 0.407819 | Val Loss: 0.254607\n",
      "Epoch [400/500] | Train Loss: 0.397547 | Val Loss: 0.257360\n",
      "Epoch [500/500] | Train Loss: 0.366547 | Val Loss: 0.260057\n",
      "Epoch [100/500] | Train Loss: 0.380553 | Val Loss: 0.261178\n",
      "Epoch [200/500] | Train Loss: 0.359133 | Val Loss: 0.256678\n",
      "Epoch [300/500] | Train Loss: 0.339031 | Val Loss: 0.256841\n",
      "Epoch [400/500] | Train Loss: 0.339899 | Val Loss: 0.257917\n",
      "Epoch [500/500] | Train Loss: 0.329492 | Val Loss: 0.260178\n",
      "Epoch [100/500] | Train Loss: 0.345697 | Val Loss: 0.451712\n",
      "Epoch [200/500] | Train Loss: 0.328803 | Val Loss: 0.460584\n",
      "Epoch [300/500] | Train Loss: 0.329753 | Val Loss: 0.465049\n",
      "Epoch [400/500] | Train Loss: 0.313157 | Val Loss: 0.469197\n",
      "Epoch [500/500] | Train Loss: 0.305563 | Val Loss: 0.466114\n",
      "Epoch [100/500] | Train Loss: 0.361040 | Val Loss: 1.442197\n",
      "Epoch [200/500] | Train Loss: 0.345510 | Val Loss: 1.428030\n",
      "Epoch [300/500] | Train Loss: 0.342148 | Val Loss: 1.447767\n",
      "Epoch [400/500] | Train Loss: 0.337513 | Val Loss: 1.507529\n",
      "Epoch [500/500] | Train Loss: 0.323255 | Val Loss: 1.499792\n",
      "Epoch [100/500] | Train Loss: 0.365558 | Val Loss: 0.465282\n",
      "Epoch [200/500] | Train Loss: 0.279535 | Val Loss: 0.491341\n",
      "Epoch [300/500] | Train Loss: 0.260731 | Val Loss: 0.483432\n",
      "Epoch [400/500] | Train Loss: 0.228420 | Val Loss: 0.531382\n",
      "Epoch [500/500] | Train Loss: 0.206534 | Val Loss: 0.515891\n",
      "Epoch [100/500] | Train Loss: 0.410092 | Val Loss: 0.266665\n",
      "Epoch [200/500] | Train Loss: 0.353234 | Val Loss: 0.267469\n",
      "Epoch [300/500] | Train Loss: 0.319840 | Val Loss: 0.282531\n",
      "Epoch [400/500] | Train Loss: 0.296714 | Val Loss: 0.287757\n",
      "Epoch [500/500] | Train Loss: 0.299852 | Val Loss: 0.294995\n",
      "Epoch [100/500] | Train Loss: 0.322481 | Val Loss: 0.275891\n",
      "Epoch [200/500] | Train Loss: 0.304130 | Val Loss: 0.272358\n",
      "Epoch [300/500] | Train Loss: 0.284581 | Val Loss: 0.274650\n",
      "Epoch [400/500] | Train Loss: 0.276336 | Val Loss: 0.285983\n",
      "Epoch [500/500] | Train Loss: 0.273744 | Val Loss: 0.279228\n",
      "Epoch [100/500] | Train Loss: 0.333035 | Val Loss: 0.455952\n",
      "Epoch [200/500] | Train Loss: 0.303634 | Val Loss: 0.481673\n",
      "Epoch [300/500] | Train Loss: 0.290947 | Val Loss: 0.495818\n",
      "Epoch [400/500] | Train Loss: 0.278102 | Val Loss: 0.490584\n",
      "Epoch [500/500] | Train Loss: 0.289972 | Val Loss: 0.501310\n",
      "Epoch [100/500] | Train Loss: 0.329963 | Val Loss: 1.467562\n",
      "Epoch [200/500] | Train Loss: 0.311736 | Val Loss: 1.510076\n",
      "Epoch [300/500] | Train Loss: 0.296166 | Val Loss: 1.578004\n",
      "Epoch [400/500] | Train Loss: 0.293911 | Val Loss: 1.587297\n",
      "Epoch [500/500] | Train Loss: 0.294819 | Val Loss: 1.586749\n",
      "Epoch [100/500] | Train Loss: 0.417348 | Val Loss: 0.411719\n",
      "Epoch [200/500] | Train Loss: 0.321997 | Val Loss: 0.449817\n",
      "Epoch [300/500] | Train Loss: 0.268629 | Val Loss: 0.491965\n",
      "Epoch [400/500] | Train Loss: 0.228189 | Val Loss: 0.554768\n",
      "Epoch [500/500] | Train Loss: 0.186723 | Val Loss: 0.572305\n",
      "Epoch [100/500] | Train Loss: 0.408970 | Val Loss: 0.257086\n",
      "Epoch [200/500] | Train Loss: 0.342162 | Val Loss: 0.275396\n",
      "Epoch [300/500] | Train Loss: 0.313502 | Val Loss: 0.276551\n",
      "Epoch [400/500] | Train Loss: 0.278495 | Val Loss: 0.286949\n",
      "Epoch [500/500] | Train Loss: 0.279620 | Val Loss: 0.291391\n",
      "Epoch [100/500] | Train Loss: 0.373927 | Val Loss: 0.254508\n",
      "Epoch [200/500] | Train Loss: 0.342872 | Val Loss: 0.257041\n",
      "Epoch [300/500] | Train Loss: 0.313850 | Val Loss: 0.270007\n",
      "Epoch [400/500] | Train Loss: 0.298629 | Val Loss: 0.280197\n",
      "Epoch [500/500] | Train Loss: 0.289423 | Val Loss: 0.290365\n",
      "Epoch [100/500] | Train Loss: 0.341792 | Val Loss: 0.448724\n",
      "Epoch [200/500] | Train Loss: 0.314274 | Val Loss: 0.477334\n",
      "Epoch [300/500] | Train Loss: 0.290373 | Val Loss: 0.495982\n",
      "Epoch [400/500] | Train Loss: 0.276146 | Val Loss: 0.501828\n",
      "Epoch [500/500] | Train Loss: 0.264016 | Val Loss: 0.500197\n",
      "Epoch [100/500] | Train Loss: 0.357219 | Val Loss: 1.460639\n",
      "Epoch [200/500] | Train Loss: 0.335185 | Val Loss: 1.435974\n",
      "Epoch [300/500] | Train Loss: 0.317624 | Val Loss: 1.465068\n",
      "Epoch [400/500] | Train Loss: 0.317745 | Val Loss: 1.520082\n",
      "Epoch [500/500] | Train Loss: 0.290883 | Val Loss: 1.604230\n",
      "Epoch [100/500] | Train Loss: 0.291405 | Val Loss: 0.516703\n",
      "Epoch [200/500] | Train Loss: 0.229759 | Val Loss: 0.551117\n",
      "Epoch [300/500] | Train Loss: 0.195847 | Val Loss: 0.552636\n",
      "Epoch [400/500] | Train Loss: 0.174623 | Val Loss: 0.617457\n",
      "Epoch [500/500] | Train Loss: 0.194905 | Val Loss: 0.585429\n",
      "Epoch [100/500] | Train Loss: 0.309058 | Val Loss: 0.286739\n",
      "Epoch [200/500] | Train Loss: 0.268718 | Val Loss: 0.310884\n",
      "Epoch [300/500] | Train Loss: 0.197523 | Val Loss: 0.330498\n",
      "Epoch [400/500] | Train Loss: 0.208094 | Val Loss: 0.356543\n",
      "Epoch [500/500] | Train Loss: 0.198098 | Val Loss: 0.393906\n",
      "Epoch [100/500] | Train Loss: 0.289573 | Val Loss: 0.270705\n",
      "Epoch [200/500] | Train Loss: 0.271068 | Val Loss: 0.302925\n",
      "Epoch [300/500] | Train Loss: 0.238744 | Val Loss: 0.317020\n",
      "Epoch [400/500] | Train Loss: 0.200789 | Val Loss: 0.330773\n",
      "Epoch [500/500] | Train Loss: 0.195041 | Val Loss: 0.330702\n",
      "Epoch [100/500] | Train Loss: 0.280670 | Val Loss: 0.501473\n",
      "Epoch [200/500] | Train Loss: 0.243579 | Val Loss: 0.521555\n",
      "Epoch [300/500] | Train Loss: 0.216669 | Val Loss: 0.553389\n",
      "Epoch [400/500] | Train Loss: 0.203126 | Val Loss: 0.542646\n",
      "Epoch [500/500] | Train Loss: 0.181614 | Val Loss: 0.551934\n",
      "Epoch [100/500] | Train Loss: 0.302641 | Val Loss: 1.664933\n",
      "Epoch [200/500] | Train Loss: 0.253541 | Val Loss: 1.604592\n",
      "Epoch [300/500] | Train Loss: 0.232573 | Val Loss: 1.667368\n",
      "Epoch [400/500] | Train Loss: 0.224679 | Val Loss: 1.670068\n",
      "Epoch [500/500] | Train Loss: 0.201547 | Val Loss: 1.571318\n",
      "Epoch [100/500] | Train Loss: 0.425420 | Val Loss: 0.406194\n",
      "Epoch [200/500] | Train Loss: 0.374870 | Val Loss: 0.410692\n",
      "Epoch [300/500] | Train Loss: 0.341203 | Val Loss: 0.431556\n",
      "Epoch [400/500] | Train Loss: 0.317513 | Val Loss: 0.459345\n",
      "Epoch [500/500] | Train Loss: 0.291706 | Val Loss: 0.468720\n",
      "Epoch [100/500] | Train Loss: 0.418923 | Val Loss: 0.258072\n",
      "Epoch [200/500] | Train Loss: 0.380454 | Val Loss: 0.259638\n",
      "Epoch [300/500] | Train Loss: 0.350332 | Val Loss: 0.265854\n",
      "Epoch [400/500] | Train Loss: 0.325812 | Val Loss: 0.269389\n",
      "Epoch [500/500] | Train Loss: 0.334683 | Val Loss: 0.280560\n",
      "Epoch [100/500] | Train Loss: 0.379857 | Val Loss: 0.261367\n",
      "Epoch [200/500] | Train Loss: 0.358814 | Val Loss: 0.260728\n",
      "Epoch [300/500] | Train Loss: 0.320316 | Val Loss: 0.262015\n",
      "Epoch [400/500] | Train Loss: 0.319953 | Val Loss: 0.259251\n",
      "Epoch [500/500] | Train Loss: 0.313504 | Val Loss: 0.270544\n",
      "Epoch [100/500] | Train Loss: 0.338665 | Val Loss: 0.453183\n",
      "Epoch [200/500] | Train Loss: 0.325228 | Val Loss: 0.459862\n",
      "Epoch [300/500] | Train Loss: 0.297337 | Val Loss: 0.476643\n",
      "Epoch [400/500] | Train Loss: 0.291971 | Val Loss: 0.483192\n",
      "Epoch [500/500] | Train Loss: 0.287444 | Val Loss: 0.487677\n",
      "Epoch [100/500] | Train Loss: 0.366535 | Val Loss: 1.452400\n",
      "Epoch [200/500] | Train Loss: 0.347694 | Val Loss: 1.451298\n",
      "Epoch [300/500] | Train Loss: 0.332168 | Val Loss: 1.491101\n",
      "Epoch [400/500] | Train Loss: 0.331144 | Val Loss: 1.537305\n",
      "Epoch [500/500] | Train Loss: 0.318167 | Val Loss: 1.571237\n",
      "Epoch [100/500] | Train Loss: 0.300101 | Val Loss: 0.482106\n",
      "Epoch [200/500] | Train Loss: 0.229552 | Val Loss: 0.527183\n",
      "Epoch [300/500] | Train Loss: 0.203540 | Val Loss: 0.525987\n",
      "Epoch [400/500] | Train Loss: 0.197328 | Val Loss: 0.532210\n",
      "Epoch [500/500] | Train Loss: 0.193211 | Val Loss: 0.534135\n",
      "Epoch [100/500] | Train Loss: 0.317418 | Val Loss: 0.285565\n",
      "Epoch [200/500] | Train Loss: 0.278811 | Val Loss: 0.292970\n",
      "Epoch [300/500] | Train Loss: 0.271326 | Val Loss: 0.301011\n",
      "Epoch [400/500] | Train Loss: 0.250907 | Val Loss: 0.314455\n",
      "Epoch [500/500] | Train Loss: 0.249179 | Val Loss: 0.326921\n",
      "Epoch [100/500] | Train Loss: 0.341084 | Val Loss: 0.259307\n",
      "Epoch [200/500] | Train Loss: 0.302702 | Val Loss: 0.274427\n",
      "Epoch [300/500] | Train Loss: 0.275755 | Val Loss: 0.285530\n",
      "Epoch [400/500] | Train Loss: 0.272945 | Val Loss: 0.309556\n",
      "Epoch [500/500] | Train Loss: 0.249531 | Val Loss: 0.314876\n",
      "Epoch [100/500] | Train Loss: 0.287803 | Val Loss: 0.510572\n",
      "Epoch [200/500] | Train Loss: 0.262242 | Val Loss: 0.526327\n",
      "Epoch [300/500] | Train Loss: 0.240931 | Val Loss: 0.505336\n",
      "Epoch [400/500] | Train Loss: 0.240932 | Val Loss: 0.523398\n",
      "Epoch [500/500] | Train Loss: 0.235217 | Val Loss: 0.512369\n",
      "Epoch [100/500] | Train Loss: 0.341334 | Val Loss: 1.423658\n",
      "Epoch [200/500] | Train Loss: 0.321640 | Val Loss: 1.479814\n",
      "Epoch [300/500] | Train Loss: 0.297839 | Val Loss: 1.485548\n",
      "Epoch [400/500] | Train Loss: 0.262075 | Val Loss: 1.477376\n",
      "Epoch [500/500] | Train Loss: 0.269491 | Val Loss: 1.484628\n",
      "[Year=1947] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.582379 Test MSE=0.537995\n",
      "Year 1947 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.374435 | Val Loss: 0.270556\n",
      "Epoch [200/500] | Train Loss: 0.297726 | Val Loss: 0.291935\n",
      "Epoch [300/500] | Train Loss: 0.259325 | Val Loss: 0.317149\n",
      "Epoch [400/500] | Train Loss: 0.221127 | Val Loss: 0.332981\n",
      "Epoch [500/500] | Train Loss: 0.198688 | Val Loss: 0.355199\n",
      "Epoch [100/500] | Train Loss: 0.320100 | Val Loss: 0.252704\n",
      "Epoch [200/500] | Train Loss: 0.286661 | Val Loss: 0.262457\n",
      "Epoch [300/500] | Train Loss: 0.266272 | Val Loss: 0.275299\n",
      "Epoch [400/500] | Train Loss: 0.246664 | Val Loss: 0.290708\n",
      "Epoch [500/500] | Train Loss: 0.254478 | Val Loss: 0.304408\n",
      "Epoch [100/500] | Train Loss: 0.303726 | Val Loss: 0.674928\n",
      "Epoch [200/500] | Train Loss: 0.279085 | Val Loss: 0.648698\n",
      "Epoch [300/500] | Train Loss: 0.262839 | Val Loss: 0.647656\n",
      "Epoch [400/500] | Train Loss: 0.247037 | Val Loss: 0.670803\n",
      "Epoch [500/500] | Train Loss: 0.249484 | Val Loss: 0.709924\n",
      "Epoch [100/500] | Train Loss: 0.383366 | Val Loss: 1.290803\n",
      "Epoch [200/500] | Train Loss: 0.351571 | Val Loss: 1.260666\n",
      "Epoch [300/500] | Train Loss: 0.336164 | Val Loss: 1.299353\n",
      "Epoch [400/500] | Train Loss: 0.314355 | Val Loss: 1.368109\n",
      "Epoch [500/500] | Train Loss: 0.303767 | Val Loss: 1.462710\n",
      "Epoch [100/500] | Train Loss: 0.559468 | Val Loss: 0.537001\n",
      "Epoch [200/500] | Train Loss: 0.490698 | Val Loss: 0.557176\n",
      "Epoch [300/500] | Train Loss: 0.474955 | Val Loss: 0.558499\n",
      "Epoch [400/500] | Train Loss: 0.436252 | Val Loss: 0.577464\n",
      "Epoch [500/500] | Train Loss: 0.394977 | Val Loss: 0.585400\n",
      "Epoch [100/500] | Train Loss: 0.243880 | Val Loss: 0.303391\n",
      "Epoch [200/500] | Train Loss: 0.199451 | Val Loss: 0.328863\n",
      "Epoch [300/500] | Train Loss: 0.162872 | Val Loss: 0.400010\n",
      "Epoch [400/500] | Train Loss: 0.141281 | Val Loss: 0.353231\n",
      "Epoch [500/500] | Train Loss: 0.112560 | Val Loss: 0.395905\n",
      "Epoch [100/500] | Train Loss: 0.232595 | Val Loss: 0.305001\n",
      "Epoch [200/500] | Train Loss: 0.176913 | Val Loss: 0.304341\n",
      "Epoch [300/500] | Train Loss: 0.157943 | Val Loss: 0.301569\n",
      "Epoch [400/500] | Train Loss: 0.152207 | Val Loss: 0.294444\n",
      "Epoch [500/500] | Train Loss: 0.145763 | Val Loss: 0.292897\n",
      "Epoch [100/500] | Train Loss: 0.227961 | Val Loss: 0.784072\n",
      "Epoch [200/500] | Train Loss: 0.208359 | Val Loss: 0.919495\n",
      "Epoch [300/500] | Train Loss: 0.205249 | Val Loss: 1.002990\n",
      "Epoch [400/500] | Train Loss: 0.180191 | Val Loss: 0.894658\n",
      "Epoch [500/500] | Train Loss: 0.173451 | Val Loss: 0.822598\n",
      "Epoch [100/500] | Train Loss: 0.301378 | Val Loss: 1.419908\n",
      "Epoch [200/500] | Train Loss: 0.278601 | Val Loss: 1.595441\n",
      "Epoch [300/500] | Train Loss: 0.270666 | Val Loss: 1.646204\n",
      "Epoch [400/500] | Train Loss: 0.248343 | Val Loss: 1.645632\n",
      "Epoch [500/500] | Train Loss: 0.253571 | Val Loss: 1.483724\n",
      "Epoch [100/500] | Train Loss: 0.444876 | Val Loss: 0.588208\n",
      "Epoch [200/500] | Train Loss: 0.424247 | Val Loss: 0.685012\n",
      "Epoch [300/500] | Train Loss: 0.385896 | Val Loss: 0.683638\n",
      "Epoch [400/500] | Train Loss: 0.360708 | Val Loss: 0.554557\n",
      "Epoch [500/500] | Train Loss: 0.348459 | Val Loss: 0.616165\n",
      "Epoch [100/500] | Train Loss: 0.382173 | Val Loss: 0.262774\n",
      "Epoch [200/500] | Train Loss: 0.360902 | Val Loss: 0.265250\n",
      "Epoch [300/500] | Train Loss: 0.342984 | Val Loss: 0.272837\n",
      "Epoch [400/500] | Train Loss: 0.316891 | Val Loss: 0.279936\n",
      "Epoch [500/500] | Train Loss: 0.291589 | Val Loss: 0.287015\n",
      "Epoch [100/500] | Train Loss: 0.334632 | Val Loss: 0.265998\n",
      "Epoch [200/500] | Train Loss: 0.313136 | Val Loss: 0.255806\n",
      "Epoch [300/500] | Train Loss: 0.290790 | Val Loss: 0.257687\n",
      "Epoch [400/500] | Train Loss: 0.271037 | Val Loss: 0.265027\n",
      "Epoch [500/500] | Train Loss: 0.271429 | Val Loss: 0.270142\n",
      "Epoch [100/500] | Train Loss: 0.328948 | Val Loss: 0.685084\n",
      "Epoch [200/500] | Train Loss: 0.306743 | Val Loss: 0.668371\n",
      "Epoch [300/500] | Train Loss: 0.302964 | Val Loss: 0.660749\n",
      "Epoch [400/500] | Train Loss: 0.283481 | Val Loss: 0.662686\n",
      "Epoch [500/500] | Train Loss: 0.284694 | Val Loss: 0.664178\n",
      "Epoch [100/500] | Train Loss: 0.395099 | Val Loss: 1.291294\n",
      "Epoch [200/500] | Train Loss: 0.375594 | Val Loss: 1.266671\n",
      "Epoch [300/500] | Train Loss: 0.345622 | Val Loss: 1.403510\n",
      "Epoch [400/500] | Train Loss: 0.339958 | Val Loss: 1.505676\n",
      "Epoch [500/500] | Train Loss: 0.334616 | Val Loss: 1.523168\n",
      "Epoch [100/500] | Train Loss: 0.559514 | Val Loss: 0.524584\n",
      "Epoch [200/500] | Train Loss: 0.522009 | Val Loss: 0.526763\n",
      "Epoch [300/500] | Train Loss: 0.531615 | Val Loss: 0.533053\n",
      "Epoch [400/500] | Train Loss: 0.518164 | Val Loss: 0.541163\n",
      "Epoch [500/500] | Train Loss: 0.505798 | Val Loss: 0.541058\n",
      "Epoch [100/500] | Train Loss: 0.312953 | Val Loss: 0.271973\n",
      "Epoch [200/500] | Train Loss: 0.229745 | Val Loss: 0.275919\n",
      "Epoch [300/500] | Train Loss: 0.225217 | Val Loss: 0.303071\n",
      "Epoch [400/500] | Train Loss: 0.189555 | Val Loss: 0.313082\n",
      "Epoch [500/500] | Train Loss: 0.224740 | Val Loss: 0.302956\n",
      "Epoch [100/500] | Train Loss: 0.266600 | Val Loss: 0.278551\n",
      "Epoch [200/500] | Train Loss: 0.221043 | Val Loss: 0.283977\n",
      "Epoch [300/500] | Train Loss: 0.193261 | Val Loss: 0.298441\n",
      "Epoch [400/500] | Train Loss: 0.197628 | Val Loss: 0.286807\n",
      "Epoch [500/500] | Train Loss: 0.176367 | Val Loss: 0.275015\n",
      "Epoch [100/500] | Train Loss: 0.278323 | Val Loss: 0.666598\n",
      "Epoch [200/500] | Train Loss: 0.251640 | Val Loss: 0.697323\n",
      "Epoch [300/500] | Train Loss: 0.227378 | Val Loss: 0.732222\n",
      "Epoch [400/500] | Train Loss: 0.239289 | Val Loss: 0.730542\n",
      "Epoch [500/500] | Train Loss: 0.200557 | Val Loss: 0.757923\n",
      "Epoch [100/500] | Train Loss: 0.337522 | Val Loss: 1.340171\n",
      "Epoch [200/500] | Train Loss: 0.307152 | Val Loss: 1.407003\n",
      "Epoch [300/500] | Train Loss: 0.294766 | Val Loss: 1.360132\n",
      "Epoch [400/500] | Train Loss: 0.302894 | Val Loss: 1.382164\n",
      "Epoch [500/500] | Train Loss: 0.273913 | Val Loss: 1.393458\n",
      "Epoch [100/500] | Train Loss: 0.499042 | Val Loss: 0.538508\n",
      "Epoch [200/500] | Train Loss: 0.431048 | Val Loss: 0.535056\n",
      "Epoch [300/500] | Train Loss: 0.412888 | Val Loss: 0.533138\n",
      "Epoch [400/500] | Train Loss: 0.433772 | Val Loss: 0.535820\n",
      "Epoch [500/500] | Train Loss: 0.408262 | Val Loss: 0.530584\n",
      "Epoch [100/500] | Train Loss: 0.423634 | Val Loss: 0.258565\n",
      "Epoch [200/500] | Train Loss: 0.325061 | Val Loss: 0.265346\n",
      "Epoch [300/500] | Train Loss: 0.267290 | Val Loss: 0.285437\n",
      "Epoch [400/500] | Train Loss: 0.244411 | Val Loss: 0.318323\n",
      "Epoch [500/500] | Train Loss: 0.194415 | Val Loss: 0.318148\n",
      "Epoch [100/500] | Train Loss: 0.296048 | Val Loss: 0.252350\n",
      "Epoch [200/500] | Train Loss: 0.257847 | Val Loss: 0.269296\n",
      "Epoch [300/500] | Train Loss: 0.216574 | Val Loss: 0.281309\n",
      "Epoch [400/500] | Train Loss: 0.228250 | Val Loss: 0.292994\n",
      "Epoch [500/500] | Train Loss: 0.195815 | Val Loss: 0.302260\n",
      "Epoch [100/500] | Train Loss: 0.289855 | Val Loss: 0.648357\n",
      "Epoch [200/500] | Train Loss: 0.269162 | Val Loss: 0.654447\n",
      "Epoch [300/500] | Train Loss: 0.237624 | Val Loss: 0.653739\n",
      "Epoch [400/500] | Train Loss: 0.221988 | Val Loss: 0.696688\n",
      "Epoch [500/500] | Train Loss: 0.207672 | Val Loss: 0.758989\n",
      "Epoch [100/500] | Train Loss: 0.372178 | Val Loss: 1.261181\n",
      "Epoch [200/500] | Train Loss: 0.334828 | Val Loss: 1.290818\n",
      "Epoch [300/500] | Train Loss: 0.310063 | Val Loss: 1.414100\n",
      "Epoch [400/500] | Train Loss: 0.291259 | Val Loss: 1.508669\n",
      "Epoch [500/500] | Train Loss: 0.284453 | Val Loss: 1.509272\n",
      "Epoch [100/500] | Train Loss: 0.560581 | Val Loss: 0.518585\n",
      "Epoch [200/500] | Train Loss: 0.535883 | Val Loss: 0.518652\n",
      "Epoch [300/500] | Train Loss: 0.467564 | Val Loss: 0.531671\n",
      "Epoch [400/500] | Train Loss: 0.454873 | Val Loss: 0.565209\n",
      "Epoch [500/500] | Train Loss: 0.395462 | Val Loss: 0.572207\n",
      "Epoch [100/500] | Train Loss: 0.265300 | Val Loss: 0.283531\n",
      "Epoch [200/500] | Train Loss: 0.153425 | Val Loss: 0.323261\n",
      "Epoch [300/500] | Train Loss: 0.141028 | Val Loss: 0.330102\n",
      "Epoch [400/500] | Train Loss: 0.165229 | Val Loss: 0.337604\n",
      "Epoch [500/500] | Train Loss: 0.113162 | Val Loss: 0.355315\n",
      "Epoch [100/500] | Train Loss: 0.247086 | Val Loss: 0.317123\n",
      "Epoch [200/500] | Train Loss: 0.159175 | Val Loss: 0.293992\n",
      "Epoch [300/500] | Train Loss: 0.160116 | Val Loss: 0.297639\n",
      "Epoch [400/500] | Train Loss: 0.137024 | Val Loss: 0.310211\n",
      "Epoch [500/500] | Train Loss: 0.128638 | Val Loss: 0.305927\n",
      "Epoch [100/500] | Train Loss: 0.232414 | Val Loss: 0.756074\n",
      "Epoch [200/500] | Train Loss: 0.186405 | Val Loss: 0.804757\n",
      "Epoch [300/500] | Train Loss: 0.173043 | Val Loss: 0.799042\n",
      "Epoch [400/500] | Train Loss: 0.143653 | Val Loss: 0.800203\n",
      "Epoch [500/500] | Train Loss: 0.155087 | Val Loss: 0.809169\n",
      "Epoch [100/500] | Train Loss: 0.315882 | Val Loss: 1.332729\n",
      "Epoch [200/500] | Train Loss: 0.274987 | Val Loss: 1.507388\n",
      "Epoch [300/500] | Train Loss: 0.235807 | Val Loss: 1.681322\n",
      "Epoch [400/500] | Train Loss: 0.218534 | Val Loss: 1.658109\n",
      "Epoch [500/500] | Train Loss: 0.226102 | Val Loss: 1.698514\n",
      "Epoch [100/500] | Train Loss: 0.436911 | Val Loss: 0.642813\n",
      "Epoch [200/500] | Train Loss: 0.382129 | Val Loss: 0.589024\n",
      "Epoch [300/500] | Train Loss: 0.360759 | Val Loss: 0.606319\n",
      "Epoch [400/500] | Train Loss: 0.325540 | Val Loss: 0.625087\n",
      "Epoch [500/500] | Train Loss: 0.326389 | Val Loss: 0.606515\n",
      "Epoch [100/500] | Train Loss: 0.376579 | Val Loss: 0.262271\n",
      "Epoch [200/500] | Train Loss: 0.341251 | Val Loss: 0.265784\n",
      "Epoch [300/500] | Train Loss: 0.311003 | Val Loss: 0.276862\n",
      "Epoch [400/500] | Train Loss: 0.277437 | Val Loss: 0.283230\n",
      "Epoch [500/500] | Train Loss: 0.257472 | Val Loss: 0.286526\n",
      "Epoch [100/500] | Train Loss: 0.322354 | Val Loss: 0.254801\n",
      "Epoch [200/500] | Train Loss: 0.291668 | Val Loss: 0.255724\n",
      "Epoch [300/500] | Train Loss: 0.282583 | Val Loss: 0.260164\n",
      "Epoch [400/500] | Train Loss: 0.275400 | Val Loss: 0.269084\n",
      "Epoch [500/500] | Train Loss: 0.260251 | Val Loss: 0.273131\n",
      "Epoch [100/500] | Train Loss: 0.308034 | Val Loss: 0.675380\n",
      "Epoch [200/500] | Train Loss: 0.281443 | Val Loss: 0.667266\n",
      "Epoch [300/500] | Train Loss: 0.272969 | Val Loss: 0.683532\n",
      "Epoch [400/500] | Train Loss: 0.240165 | Val Loss: 0.701738\n",
      "Epoch [500/500] | Train Loss: 0.255169 | Val Loss: 0.750922\n",
      "Epoch [100/500] | Train Loss: 0.389368 | Val Loss: 1.320032\n",
      "Epoch [200/500] | Train Loss: 0.366902 | Val Loss: 1.298515\n",
      "Epoch [300/500] | Train Loss: 0.342946 | Val Loss: 1.281520\n",
      "Epoch [400/500] | Train Loss: 0.320625 | Val Loss: 1.309257\n",
      "Epoch [500/500] | Train Loss: 0.322231 | Val Loss: 1.321014\n",
      "Epoch [100/500] | Train Loss: 0.551662 | Val Loss: 0.522629\n",
      "Epoch [200/500] | Train Loss: 0.520228 | Val Loss: 0.539278\n",
      "Epoch [300/500] | Train Loss: 0.492337 | Val Loss: 0.551551\n",
      "Epoch [400/500] | Train Loss: 0.473786 | Val Loss: 0.570860\n",
      "Epoch [500/500] | Train Loss: 0.424856 | Val Loss: 0.596789\n",
      "Epoch [100/500] | Train Loss: 0.261744 | Val Loss: 0.302821\n",
      "Epoch [200/500] | Train Loss: 0.215581 | Val Loss: 0.284707\n",
      "Epoch [300/500] | Train Loss: 0.213598 | Val Loss: 0.318620\n",
      "Epoch [400/500] | Train Loss: 0.181183 | Val Loss: 0.348431\n",
      "Epoch [500/500] | Train Loss: 0.158784 | Val Loss: 0.311329\n",
      "Epoch [100/500] | Train Loss: 0.278522 | Val Loss: 0.268373\n",
      "Epoch [200/500] | Train Loss: 0.226065 | Val Loss: 0.285281\n",
      "Epoch [300/500] | Train Loss: 0.227263 | Val Loss: 0.276647\n",
      "Epoch [400/500] | Train Loss: 0.202554 | Val Loss: 0.286405\n",
      "Epoch [500/500] | Train Loss: 0.158352 | Val Loss: 0.286758\n",
      "Epoch [100/500] | Train Loss: 0.295840 | Val Loss: 0.698650\n",
      "Epoch [200/500] | Train Loss: 0.267609 | Val Loss: 0.698365\n",
      "Epoch [300/500] | Train Loss: 0.260230 | Val Loss: 0.725128\n",
      "Epoch [400/500] | Train Loss: 0.244163 | Val Loss: 0.717973\n",
      "Epoch [500/500] | Train Loss: 0.227608 | Val Loss: 0.735829\n",
      "Epoch [100/500] | Train Loss: 0.365183 | Val Loss: 1.246437\n",
      "Epoch [200/500] | Train Loss: 0.307764 | Val Loss: 1.424339\n",
      "Epoch [300/500] | Train Loss: 0.302729 | Val Loss: 1.439791\n",
      "Epoch [400/500] | Train Loss: 0.281409 | Val Loss: 1.410060\n",
      "Epoch [500/500] | Train Loss: 0.278540 | Val Loss: 1.355410\n",
      "Epoch [100/500] | Train Loss: 0.518262 | Val Loss: 0.525988\n",
      "Epoch [200/500] | Train Loss: 0.438574 | Val Loss: 0.525671\n",
      "Epoch [300/500] | Train Loss: 0.404618 | Val Loss: 0.544212\n",
      "Epoch [400/500] | Train Loss: 0.389935 | Val Loss: 0.524975\n",
      "Epoch [500/500] | Train Loss: 0.417354 | Val Loss: 0.536476\n",
      "[Year=1948] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.01} CV-MSE=0.645161 Test MSE=0.708549\n",
      "Year 1948 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.197886 | Val Loss: 0.309593\n",
      "Epoch [200/500] | Train Loss: 0.176974 | Val Loss: 0.312895\n",
      "Epoch [300/500] | Train Loss: 0.160205 | Val Loss: 0.321431\n",
      "Epoch [400/500] | Train Loss: 0.141635 | Val Loss: 0.346261\n",
      "Epoch [500/500] | Train Loss: 0.130243 | Val Loss: 0.356587\n",
      "Epoch [100/500] | Train Loss: 0.243982 | Val Loss: 0.626577\n",
      "Epoch [200/500] | Train Loss: 0.221576 | Val Loss: 0.670533\n",
      "Epoch [300/500] | Train Loss: 0.214910 | Val Loss: 0.674648\n",
      "Epoch [400/500] | Train Loss: 0.200815 | Val Loss: 0.687822\n",
      "Epoch [500/500] | Train Loss: 0.204627 | Val Loss: 0.688965\n",
      "Epoch [100/500] | Train Loss: 0.363186 | Val Loss: 1.389288\n",
      "Epoch [200/500] | Train Loss: 0.326959 | Val Loss: 1.405397\n",
      "Epoch [300/500] | Train Loss: 0.296674 | Val Loss: 1.492550\n",
      "Epoch [400/500] | Train Loss: 0.281909 | Val Loss: 1.532756\n",
      "Epoch [500/500] | Train Loss: 0.271705 | Val Loss: 1.643078\n",
      "Epoch [100/500] | Train Loss: 0.685849 | Val Loss: 0.477006\n",
      "Epoch [200/500] | Train Loss: 0.603085 | Val Loss: 0.493780\n",
      "Epoch [300/500] | Train Loss: 0.558581 | Val Loss: 0.500648\n",
      "Epoch [400/500] | Train Loss: 0.540419 | Val Loss: 0.514916\n",
      "Epoch [500/500] | Train Loss: 0.505667 | Val Loss: 0.491174\n",
      "Epoch [100/500] | Train Loss: 0.589162 | Val Loss: 0.706081\n",
      "Epoch [200/500] | Train Loss: 0.544901 | Val Loss: 0.740672\n",
      "Epoch [300/500] | Train Loss: 0.513358 | Val Loss: 0.764074\n",
      "Epoch [400/500] | Train Loss: 0.486450 | Val Loss: 0.764357\n",
      "Epoch [500/500] | Train Loss: 0.454177 | Val Loss: 0.771099\n",
      "Epoch [100/500] | Train Loss: 0.178691 | Val Loss: 0.326585\n",
      "Epoch [200/500] | Train Loss: 0.158432 | Val Loss: 0.348314\n",
      "Epoch [300/500] | Train Loss: 0.148833 | Val Loss: 0.351822\n",
      "Epoch [400/500] | Train Loss: 0.136470 | Val Loss: 0.352867\n",
      "Epoch [500/500] | Train Loss: 0.098288 | Val Loss: 0.363071\n",
      "Epoch [100/500] | Train Loss: 0.237464 | Val Loss: 0.644409\n",
      "Epoch [200/500] | Train Loss: 0.201485 | Val Loss: 0.681783\n",
      "Epoch [300/500] | Train Loss: 0.177953 | Val Loss: 0.673060\n",
      "Epoch [400/500] | Train Loss: 0.154582 | Val Loss: 0.729239\n",
      "Epoch [500/500] | Train Loss: 0.135264 | Val Loss: 0.695418\n",
      "Epoch [100/500] | Train Loss: 0.281610 | Val Loss: 1.765211\n",
      "Epoch [200/500] | Train Loss: 0.260642 | Val Loss: 1.771676\n",
      "Epoch [300/500] | Train Loss: 0.250439 | Val Loss: 1.804657\n",
      "Epoch [400/500] | Train Loss: 0.222857 | Val Loss: 1.756937\n",
      "Epoch [500/500] | Train Loss: 0.212897 | Val Loss: 1.788030\n",
      "Epoch [100/500] | Train Loss: 0.463622 | Val Loss: 0.493895\n",
      "Epoch [200/500] | Train Loss: 0.377056 | Val Loss: 0.529257\n",
      "Epoch [300/500] | Train Loss: 0.395561 | Val Loss: 0.524842\n",
      "Epoch [400/500] | Train Loss: 0.372025 | Val Loss: 0.536048\n",
      "Epoch [500/500] | Train Loss: 0.348393 | Val Loss: 0.539742\n",
      "Epoch [100/500] | Train Loss: 0.460260 | Val Loss: 0.779974\n",
      "Epoch [200/500] | Train Loss: 0.394733 | Val Loss: 0.790901\n",
      "Epoch [300/500] | Train Loss: 0.382134 | Val Loss: 0.812964\n",
      "Epoch [400/500] | Train Loss: 0.383208 | Val Loss: 0.778441\n",
      "Epoch [500/500] | Train Loss: 0.374692 | Val Loss: 0.760390\n",
      "Epoch [100/500] | Train Loss: 0.188046 | Val Loss: 0.310919\n",
      "Epoch [200/500] | Train Loss: 0.180254 | Val Loss: 0.312600\n",
      "Epoch [300/500] | Train Loss: 0.181056 | Val Loss: 0.330232\n",
      "Epoch [400/500] | Train Loss: 0.160611 | Val Loss: 0.343268\n",
      "Epoch [500/500] | Train Loss: 0.134935 | Val Loss: 0.348206\n",
      "Epoch [100/500] | Train Loss: 0.272061 | Val Loss: 0.643895\n",
      "Epoch [200/500] | Train Loss: 0.245254 | Val Loss: 0.619653\n",
      "Epoch [300/500] | Train Loss: 0.257373 | Val Loss: 0.635906\n",
      "Epoch [400/500] | Train Loss: 0.225922 | Val Loss: 0.653159\n",
      "Epoch [500/500] | Train Loss: 0.216001 | Val Loss: 0.669457\n",
      "Epoch [100/500] | Train Loss: 0.364268 | Val Loss: 1.385353\n",
      "Epoch [200/500] | Train Loss: 0.352981 | Val Loss: 1.373256\n",
      "Epoch [300/500] | Train Loss: 0.335842 | Val Loss: 1.392812\n",
      "Epoch [400/500] | Train Loss: 0.330501 | Val Loss: 1.523095\n",
      "Epoch [500/500] | Train Loss: 0.302230 | Val Loss: 1.628047\n",
      "Epoch [100/500] | Train Loss: 0.638277 | Val Loss: 0.475943\n",
      "Epoch [200/500] | Train Loss: 0.621884 | Val Loss: 0.484472\n",
      "Epoch [300/500] | Train Loss: 0.588627 | Val Loss: 0.489384\n",
      "Epoch [400/500] | Train Loss: 0.548059 | Val Loss: 0.490068\n",
      "Epoch [500/500] | Train Loss: 0.537617 | Val Loss: 0.499844\n",
      "Epoch [100/500] | Train Loss: 0.613801 | Val Loss: 0.702584\n",
      "Epoch [200/500] | Train Loss: 0.599215 | Val Loss: 0.728972\n",
      "Epoch [300/500] | Train Loss: 0.562496 | Val Loss: 0.746447\n",
      "Epoch [400/500] | Train Loss: 0.556430 | Val Loss: 0.774155\n",
      "Epoch [500/500] | Train Loss: 0.533727 | Val Loss: 0.771880\n",
      "Epoch [100/500] | Train Loss: 0.174551 | Val Loss: 0.318817\n",
      "Epoch [200/500] | Train Loss: 0.146579 | Val Loss: 0.329374\n",
      "Epoch [300/500] | Train Loss: 0.113970 | Val Loss: 0.363055\n",
      "Epoch [400/500] | Train Loss: 0.115977 | Val Loss: 0.360604\n",
      "Epoch [500/500] | Train Loss: 0.115022 | Val Loss: 0.353070\n",
      "Epoch [100/500] | Train Loss: 0.237358 | Val Loss: 0.646355\n",
      "Epoch [200/500] | Train Loss: 0.208973 | Val Loss: 0.692903\n",
      "Epoch [300/500] | Train Loss: 0.197858 | Val Loss: 0.698905\n",
      "Epoch [400/500] | Train Loss: 0.175821 | Val Loss: 0.715350\n",
      "Epoch [500/500] | Train Loss: 0.171578 | Val Loss: 0.712505\n",
      "Epoch [100/500] | Train Loss: 0.313099 | Val Loss: 1.474777\n",
      "Epoch [200/500] | Train Loss: 0.311773 | Val Loss: 1.524439\n",
      "Epoch [300/500] | Train Loss: 0.290192 | Val Loss: 1.494939\n",
      "Epoch [400/500] | Train Loss: 0.271832 | Val Loss: 1.555093\n",
      "Epoch [500/500] | Train Loss: 0.281431 | Val Loss: 1.807565\n",
      "Epoch [100/500] | Train Loss: 0.546471 | Val Loss: 0.466163\n",
      "Epoch [200/500] | Train Loss: 0.477824 | Val Loss: 0.466106\n",
      "Epoch [300/500] | Train Loss: 0.463023 | Val Loss: 0.472948\n",
      "Epoch [400/500] | Train Loss: 0.470530 | Val Loss: 0.497940\n",
      "Epoch [500/500] | Train Loss: 0.475958 | Val Loss: 0.467032\n",
      "Epoch [100/500] | Train Loss: 0.522842 | Val Loss: 0.722117\n",
      "Epoch [200/500] | Train Loss: 0.491754 | Val Loss: 0.692595\n",
      "Epoch [300/500] | Train Loss: 0.463272 | Val Loss: 0.685908\n",
      "Epoch [400/500] | Train Loss: 0.505106 | Val Loss: 0.723663\n",
      "Epoch [500/500] | Train Loss: 0.412175 | Val Loss: 0.721358\n",
      "Epoch [100/500] | Train Loss: 0.192445 | Val Loss: 0.307614\n",
      "Epoch [200/500] | Train Loss: 0.168511 | Val Loss: 0.314493\n",
      "Epoch [300/500] | Train Loss: 0.144183 | Val Loss: 0.341732\n",
      "Epoch [400/500] | Train Loss: 0.122913 | Val Loss: 0.359564\n",
      "Epoch [500/500] | Train Loss: 0.107362 | Val Loss: 0.360861\n",
      "Epoch [100/500] | Train Loss: 0.252160 | Val Loss: 0.626049\n",
      "Epoch [200/500] | Train Loss: 0.224042 | Val Loss: 0.666685\n",
      "Epoch [300/500] | Train Loss: 0.208650 | Val Loss: 0.689754\n",
      "Epoch [400/500] | Train Loss: 0.197221 | Val Loss: 0.700046\n",
      "Epoch [500/500] | Train Loss: 0.189291 | Val Loss: 0.722830\n",
      "Epoch [100/500] | Train Loss: 0.346852 | Val Loss: 1.391554\n",
      "Epoch [200/500] | Train Loss: 0.314537 | Val Loss: 1.496642\n",
      "Epoch [300/500] | Train Loss: 0.276046 | Val Loss: 1.637366\n",
      "Epoch [400/500] | Train Loss: 0.272510 | Val Loss: 1.707055\n",
      "Epoch [500/500] | Train Loss: 0.271082 | Val Loss: 1.613171\n",
      "Epoch [100/500] | Train Loss: 0.618879 | Val Loss: 0.482013\n",
      "Epoch [200/500] | Train Loss: 0.545599 | Val Loss: 0.496191\n",
      "Epoch [300/500] | Train Loss: 0.507860 | Val Loss: 0.510056\n",
      "Epoch [400/500] | Train Loss: 0.455025 | Val Loss: 0.506349\n",
      "Epoch [500/500] | Train Loss: 0.439911 | Val Loss: 0.513257\n",
      "Epoch [100/500] | Train Loss: 0.583319 | Val Loss: 0.731355\n",
      "Epoch [200/500] | Train Loss: 0.524182 | Val Loss: 0.751353\n",
      "Epoch [300/500] | Train Loss: 0.475378 | Val Loss: 0.747080\n",
      "Epoch [400/500] | Train Loss: 0.464882 | Val Loss: 0.758403\n",
      "Epoch [500/500] | Train Loss: 0.422187 | Val Loss: 0.730826\n",
      "Epoch [100/500] | Train Loss: 0.125063 | Val Loss: 0.367406\n",
      "Epoch [200/500] | Train Loss: 0.077197 | Val Loss: 0.406552\n",
      "Epoch [300/500] | Train Loss: 0.066399 | Val Loss: 0.405670\n",
      "Epoch [400/500] | Train Loss: 0.057334 | Val Loss: 0.403066\n",
      "Epoch [500/500] | Train Loss: 0.049387 | Val Loss: 0.383754\n",
      "Epoch [100/500] | Train Loss: 0.181682 | Val Loss: 0.685623\n",
      "Epoch [200/500] | Train Loss: 0.131040 | Val Loss: 0.735078\n",
      "Epoch [300/500] | Train Loss: 0.106037 | Val Loss: 0.763689\n",
      "Epoch [400/500] | Train Loss: 0.097304 | Val Loss: 0.730990\n",
      "Epoch [500/500] | Train Loss: 0.102703 | Val Loss: 0.739632\n",
      "Epoch [100/500] | Train Loss: 0.323460 | Val Loss: 1.830300\n",
      "Epoch [200/500] | Train Loss: 0.263392 | Val Loss: 1.692485\n",
      "Epoch [300/500] | Train Loss: 0.238489 | Val Loss: 2.011783\n",
      "Epoch [400/500] | Train Loss: 0.222729 | Val Loss: 2.015367\n",
      "Epoch [500/500] | Train Loss: 0.197439 | Val Loss: 2.039816\n",
      "Epoch [100/500] | Train Loss: 0.422625 | Val Loss: 0.538186\n",
      "Epoch [200/500] | Train Loss: 0.381248 | Val Loss: 0.532268\n",
      "Epoch [300/500] | Train Loss: 0.358145 | Val Loss: 0.554306\n",
      "Epoch [400/500] | Train Loss: 0.322424 | Val Loss: 0.593103\n",
      "Epoch [500/500] | Train Loss: 0.292982 | Val Loss: 0.562933\n",
      "Epoch [100/500] | Train Loss: 0.479220 | Val Loss: 0.788156\n",
      "Epoch [200/500] | Train Loss: 0.408066 | Val Loss: 0.788811\n",
      "Epoch [300/500] | Train Loss: 0.377267 | Val Loss: 0.799606\n",
      "Epoch [400/500] | Train Loss: 0.332187 | Val Loss: 0.832017\n",
      "Epoch [500/500] | Train Loss: 0.317425 | Val Loss: 0.810325\n",
      "Epoch [100/500] | Train Loss: 0.188631 | Val Loss: 0.306772\n",
      "Epoch [200/500] | Train Loss: 0.168359 | Val Loss: 0.318059\n",
      "Epoch [300/500] | Train Loss: 0.154734 | Val Loss: 0.323355\n",
      "Epoch [400/500] | Train Loss: 0.141571 | Val Loss: 0.335112\n",
      "Epoch [500/500] | Train Loss: 0.149003 | Val Loss: 0.347301\n",
      "Epoch [100/500] | Train Loss: 0.244717 | Val Loss: 0.624613\n",
      "Epoch [200/500] | Train Loss: 0.222117 | Val Loss: 0.652268\n",
      "Epoch [300/500] | Train Loss: 0.220155 | Val Loss: 0.664824\n",
      "Epoch [400/500] | Train Loss: 0.196416 | Val Loss: 0.678178\n",
      "Epoch [500/500] | Train Loss: 0.199031 | Val Loss: 0.696713\n",
      "Epoch [100/500] | Train Loss: 0.375723 | Val Loss: 1.415905\n",
      "Epoch [200/500] | Train Loss: 0.364655 | Val Loss: 1.388177\n",
      "Epoch [300/500] | Train Loss: 0.339128 | Val Loss: 1.382771\n",
      "Epoch [400/500] | Train Loss: 0.299624 | Val Loss: 1.456498\n",
      "Epoch [500/500] | Train Loss: 0.329484 | Val Loss: 1.551153\n",
      "Epoch [100/500] | Train Loss: 0.623000 | Val Loss: 0.478004\n",
      "Epoch [200/500] | Train Loss: 0.575650 | Val Loss: 0.494368\n",
      "Epoch [300/500] | Train Loss: 0.549785 | Val Loss: 0.501892\n",
      "Epoch [400/500] | Train Loss: 0.490982 | Val Loss: 0.479127\n",
      "Epoch [500/500] | Train Loss: 0.534573 | Val Loss: 0.476303\n",
      "Epoch [100/500] | Train Loss: 0.592566 | Val Loss: 0.721492\n",
      "Epoch [200/500] | Train Loss: 0.549831 | Val Loss: 0.746983\n",
      "Epoch [300/500] | Train Loss: 0.545205 | Val Loss: 0.762058\n",
      "Epoch [400/500] | Train Loss: 0.516265 | Val Loss: 0.770541\n",
      "Epoch [500/500] | Train Loss: 0.489601 | Val Loss: 0.776507\n",
      "Epoch [100/500] | Train Loss: 0.131830 | Val Loss: 0.345561\n",
      "Epoch [200/500] | Train Loss: 0.115573 | Val Loss: 0.351909\n",
      "Epoch [300/500] | Train Loss: 0.108602 | Val Loss: 0.364814\n",
      "Epoch [400/500] | Train Loss: 0.106201 | Val Loss: 0.357685\n",
      "Epoch [500/500] | Train Loss: 0.083412 | Val Loss: 0.371586\n",
      "Epoch [100/500] | Train Loss: 0.221768 | Val Loss: 0.677411\n",
      "Epoch [200/500] | Train Loss: 0.168876 | Val Loss: 0.653196\n",
      "Epoch [300/500] | Train Loss: 0.169920 | Val Loss: 0.629251\n",
      "Epoch [400/500] | Train Loss: 0.146205 | Val Loss: 0.662768\n",
      "Epoch [500/500] | Train Loss: 0.167599 | Val Loss: 0.650563\n",
      "Epoch [100/500] | Train Loss: 0.320853 | Val Loss: 1.610933\n",
      "Epoch [200/500] | Train Loss: 0.278089 | Val Loss: 1.557664\n",
      "Epoch [300/500] | Train Loss: 0.262975 | Val Loss: 1.601592\n",
      "Epoch [400/500] | Train Loss: 0.255971 | Val Loss: 1.488965\n",
      "Epoch [500/500] | Train Loss: 0.256466 | Val Loss: 1.443685\n",
      "Epoch [100/500] | Train Loss: 0.494080 | Val Loss: 0.485559\n",
      "Epoch [200/500] | Train Loss: 0.436106 | Val Loss: 0.454879\n",
      "Epoch [300/500] | Train Loss: 0.438597 | Val Loss: 0.475516\n",
      "Epoch [400/500] | Train Loss: 0.452035 | Val Loss: 0.460850\n",
      "Epoch [500/500] | Train Loss: 0.400630 | Val Loss: 0.462496\n",
      "Epoch [100/500] | Train Loss: 0.527887 | Val Loss: 0.719010\n",
      "Epoch [200/500] | Train Loss: 0.459717 | Val Loss: 0.749280\n",
      "Epoch [300/500] | Train Loss: 0.421628 | Val Loss: 0.723142\n",
      "Epoch [400/500] | Train Loss: 0.418357 | Val Loss: 0.739997\n",
      "Epoch [500/500] | Train Loss: 0.377276 | Val Loss: 0.735435\n",
      "[Year=1949] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.01} CV-MSE=0.732753 Test MSE=0.311433\n",
      "Year 1949 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.359707 | Val Loss: 0.975466\n",
      "Epoch [200/500] | Train Loss: 0.293812 | Val Loss: 0.995395\n",
      "Epoch [300/500] | Train Loss: 0.278552 | Val Loss: 1.014581\n",
      "Epoch [400/500] | Train Loss: 0.262041 | Val Loss: 1.036320\n",
      "Epoch [500/500] | Train Loss: 0.246032 | Val Loss: 1.060189\n",
      "Epoch [100/500] | Train Loss: 0.558777 | Val Loss: 1.194302\n",
      "Epoch [200/500] | Train Loss: 0.484311 | Val Loss: 1.327397\n",
      "Epoch [300/500] | Train Loss: 0.378072 | Val Loss: 1.598310\n",
      "Epoch [400/500] | Train Loss: 0.365088 | Val Loss: 1.645566\n",
      "Epoch [500/500] | Train Loss: 0.374767 | Val Loss: 1.740999\n",
      "Epoch [100/500] | Train Loss: 0.809722 | Val Loss: 0.408553\n",
      "Epoch [200/500] | Train Loss: 0.748005 | Val Loss: 0.421820\n",
      "Epoch [300/500] | Train Loss: 0.686323 | Val Loss: 0.438280\n",
      "Epoch [400/500] | Train Loss: 0.615661 | Val Loss: 0.437294\n",
      "Epoch [500/500] | Train Loss: 0.593102 | Val Loss: 0.436953\n",
      "Epoch [100/500] | Train Loss: 0.690226 | Val Loss: 0.752352\n",
      "Epoch [200/500] | Train Loss: 0.619872 | Val Loss: 0.772015\n",
      "Epoch [300/500] | Train Loss: 0.597840 | Val Loss: 0.795805\n",
      "Epoch [400/500] | Train Loss: 0.566450 | Val Loss: 0.804772\n",
      "Epoch [500/500] | Train Loss: 0.529203 | Val Loss: 0.780725\n",
      "Epoch [100/500] | Train Loss: 0.689274 | Val Loss: 0.281679\n",
      "Epoch [200/500] | Train Loss: 0.647765 | Val Loss: 0.281015\n",
      "Epoch [300/500] | Train Loss: 0.572877 | Val Loss: 0.285896\n",
      "Epoch [400/500] | Train Loss: 0.534166 | Val Loss: 0.284947\n",
      "Epoch [500/500] | Train Loss: 0.544966 | Val Loss: 0.291250\n",
      "Epoch [100/500] | Train Loss: 0.223183 | Val Loss: 1.049997\n",
      "Epoch [200/500] | Train Loss: 0.173186 | Val Loss: 1.043013\n",
      "Epoch [300/500] | Train Loss: 0.144204 | Val Loss: 1.052740\n",
      "Epoch [400/500] | Train Loss: 0.134511 | Val Loss: 1.061990\n",
      "Epoch [500/500] | Train Loss: 0.133690 | Val Loss: 1.013821\n",
      "Epoch [100/500] | Train Loss: 0.369431 | Val Loss: 1.446303\n",
      "Epoch [200/500] | Train Loss: 0.331496 | Val Loss: 1.873694\n",
      "Epoch [300/500] | Train Loss: 0.343166 | Val Loss: 1.730189\n",
      "Epoch [400/500] | Train Loss: 0.288290 | Val Loss: 1.637937\n",
      "Epoch [500/500] | Train Loss: 0.278987 | Val Loss: 1.547993\n",
      "Epoch [100/500] | Train Loss: 0.624914 | Val Loss: 0.428559\n",
      "Epoch [200/500] | Train Loss: 0.484932 | Val Loss: 0.444592\n",
      "Epoch [300/500] | Train Loss: 0.500551 | Val Loss: 0.452848\n",
      "Epoch [400/500] | Train Loss: 0.432034 | Val Loss: 0.458188\n",
      "Epoch [500/500] | Train Loss: 0.428967 | Val Loss: 0.467124\n",
      "Epoch [100/500] | Train Loss: 0.598592 | Val Loss: 0.820044\n",
      "Epoch [200/500] | Train Loss: 0.499322 | Val Loss: 0.923632\n",
      "Epoch [300/500] | Train Loss: 0.469655 | Val Loss: 0.942031\n",
      "Epoch [400/500] | Train Loss: 0.417754 | Val Loss: 0.967640\n",
      "Epoch [500/500] | Train Loss: 0.418196 | Val Loss: 0.847478\n",
      "Epoch [100/500] | Train Loss: 0.605870 | Val Loss: 0.278902\n",
      "Epoch [200/500] | Train Loss: 0.539161 | Val Loss: 0.291889\n",
      "Epoch [300/500] | Train Loss: 0.504968 | Val Loss: 0.296504\n",
      "Epoch [400/500] | Train Loss: 0.496668 | Val Loss: 0.304759\n",
      "Epoch [500/500] | Train Loss: 0.467613 | Val Loss: 0.299527\n",
      "Epoch [100/500] | Train Loss: 0.351289 | Val Loss: 0.908134\n",
      "Epoch [200/500] | Train Loss: 0.313326 | Val Loss: 0.917428\n",
      "Epoch [300/500] | Train Loss: 0.287340 | Val Loss: 0.929008\n",
      "Epoch [400/500] | Train Loss: 0.295172 | Val Loss: 0.931673\n",
      "Epoch [500/500] | Train Loss: 0.268008 | Val Loss: 0.948929\n",
      "Epoch [100/500] | Train Loss: 0.632024 | Val Loss: 1.215427\n",
      "Epoch [200/500] | Train Loss: 0.594234 | Val Loss: 1.179319\n",
      "Epoch [300/500] | Train Loss: 0.583544 | Val Loss: 1.178730\n",
      "Epoch [400/500] | Train Loss: 0.497007 | Val Loss: 1.258693\n",
      "Epoch [500/500] | Train Loss: 0.484090 | Val Loss: 1.288901\n",
      "Epoch [100/500] | Train Loss: 0.858110 | Val Loss: 0.402464\n",
      "Epoch [200/500] | Train Loss: 0.826354 | Val Loss: 0.409315\n",
      "Epoch [300/500] | Train Loss: 0.771752 | Val Loss: 0.419078\n",
      "Epoch [400/500] | Train Loss: 0.749990 | Val Loss: 0.426556\n",
      "Epoch [500/500] | Train Loss: 0.735323 | Val Loss: 0.420073\n",
      "Epoch [100/500] | Train Loss: 0.724142 | Val Loss: 0.729163\n",
      "Epoch [200/500] | Train Loss: 0.679229 | Val Loss: 0.742507\n",
      "Epoch [300/500] | Train Loss: 0.673748 | Val Loss: 0.748655\n",
      "Epoch [400/500] | Train Loss: 0.633034 | Val Loss: 0.737032\n",
      "Epoch [500/500] | Train Loss: 0.599312 | Val Loss: 0.733010\n",
      "Epoch [100/500] | Train Loss: 0.718653 | Val Loss: 0.281471\n",
      "Epoch [200/500] | Train Loss: 0.698147 | Val Loss: 0.281978\n",
      "Epoch [300/500] | Train Loss: 0.657317 | Val Loss: 0.280315\n",
      "Epoch [400/500] | Train Loss: 0.648306 | Val Loss: 0.277345\n",
      "Epoch [500/500] | Train Loss: 0.656370 | Val Loss: 0.279261\n",
      "Epoch [100/500] | Train Loss: 0.270831 | Val Loss: 1.022930\n",
      "Epoch [200/500] | Train Loss: 0.202080 | Val Loss: 1.014732\n",
      "Epoch [300/500] | Train Loss: 0.183744 | Val Loss: 1.021419\n",
      "Epoch [400/500] | Train Loss: 0.175508 | Val Loss: 1.004532\n",
      "Epoch [500/500] | Train Loss: 0.185943 | Val Loss: 1.031534\n",
      "Epoch [100/500] | Train Loss: 0.461835 | Val Loss: 1.540676\n",
      "Epoch [200/500] | Train Loss: 0.438828 | Val Loss: 1.687508\n",
      "Epoch [300/500] | Train Loss: 0.502997 | Val Loss: 1.576317\n",
      "Epoch [400/500] | Train Loss: 0.373635 | Val Loss: 1.758775\n",
      "Epoch [500/500] | Train Loss: 0.306430 | Val Loss: 1.870020\n",
      "Epoch [100/500] | Train Loss: 0.732073 | Val Loss: 0.402231\n",
      "Epoch [200/500] | Train Loss: 0.584149 | Val Loss: 0.419081\n",
      "Epoch [300/500] | Train Loss: 0.569902 | Val Loss: 0.424599\n",
      "Epoch [400/500] | Train Loss: 0.578409 | Val Loss: 0.444899\n",
      "Epoch [500/500] | Train Loss: 0.596652 | Val Loss: 0.429781\n",
      "Epoch [100/500] | Train Loss: 0.624247 | Val Loss: 0.788904\n",
      "Epoch [200/500] | Train Loss: 0.595462 | Val Loss: 0.744278\n",
      "Epoch [300/500] | Train Loss: 0.513885 | Val Loss: 0.837906\n",
      "Epoch [400/500] | Train Loss: 0.496613 | Val Loss: 0.818399\n",
      "Epoch [500/500] | Train Loss: 0.516056 | Val Loss: 0.853256\n",
      "Epoch [100/500] | Train Loss: 0.688883 | Val Loss: 0.281641\n",
      "Epoch [200/500] | Train Loss: 0.604414 | Val Loss: 0.290500\n",
      "Epoch [300/500] | Train Loss: 0.574194 | Val Loss: 0.295128\n",
      "Epoch [400/500] | Train Loss: 0.560786 | Val Loss: 0.308332\n",
      "Epoch [500/500] | Train Loss: 0.531615 | Val Loss: 0.306040\n",
      "Epoch [100/500] | Train Loss: 0.318435 | Val Loss: 0.949671\n",
      "Epoch [200/500] | Train Loss: 0.270023 | Val Loss: 0.974104\n",
      "Epoch [300/500] | Train Loss: 0.233692 | Val Loss: 0.992694\n",
      "Epoch [400/500] | Train Loss: 0.236058 | Val Loss: 1.000416\n",
      "Epoch [500/500] | Train Loss: 0.203015 | Val Loss: 1.002136\n",
      "Epoch [100/500] | Train Loss: 0.576914 | Val Loss: 1.186146\n",
      "Epoch [200/500] | Train Loss: 0.462320 | Val Loss: 1.409698\n",
      "Epoch [300/500] | Train Loss: 0.366995 | Val Loss: 1.541736\n",
      "Epoch [400/500] | Train Loss: 0.374722 | Val Loss: 1.719356\n",
      "Epoch [500/500] | Train Loss: 0.331185 | Val Loss: 1.722284\n",
      "Epoch [100/500] | Train Loss: 0.775139 | Val Loss: 0.406655\n",
      "Epoch [200/500] | Train Loss: 0.651470 | Val Loss: 0.432072\n",
      "Epoch [300/500] | Train Loss: 0.589279 | Val Loss: 0.416184\n",
      "Epoch [400/500] | Train Loss: 0.559633 | Val Loss: 0.423735\n",
      "Epoch [500/500] | Train Loss: 0.499747 | Val Loss: 0.435362\n",
      "Epoch [100/500] | Train Loss: 0.673835 | Val Loss: 0.767699\n",
      "Epoch [200/500] | Train Loss: 0.614212 | Val Loss: 0.792628\n",
      "Epoch [300/500] | Train Loss: 0.550357 | Val Loss: 0.796803\n",
      "Epoch [400/500] | Train Loss: 0.551533 | Val Loss: 0.804941\n",
      "Epoch [500/500] | Train Loss: 0.488673 | Val Loss: 0.798418\n",
      "Epoch [100/500] | Train Loss: 0.704806 | Val Loss: 0.279858\n",
      "Epoch [200/500] | Train Loss: 0.637484 | Val Loss: 0.280949\n",
      "Epoch [300/500] | Train Loss: 0.581047 | Val Loss: 0.282305\n",
      "Epoch [400/500] | Train Loss: 0.530351 | Val Loss: 0.279918\n",
      "Epoch [500/500] | Train Loss: 0.538854 | Val Loss: 0.275640\n",
      "Epoch [100/500] | Train Loss: 0.252147 | Val Loss: 1.005784\n",
      "Epoch [200/500] | Train Loss: 0.200717 | Val Loss: 1.089564\n",
      "Epoch [300/500] | Train Loss: 0.160463 | Val Loss: 1.066057\n",
      "Epoch [400/500] | Train Loss: 0.159133 | Val Loss: 1.068345\n",
      "Epoch [500/500] | Train Loss: 0.105871 | Val Loss: 1.074223\n",
      "Epoch [100/500] | Train Loss: 0.340354 | Val Loss: 1.678677\n",
      "Epoch [200/500] | Train Loss: 0.253543 | Val Loss: 1.923060\n",
      "Epoch [300/500] | Train Loss: 0.258188 | Val Loss: 1.747783\n",
      "Epoch [400/500] | Train Loss: 0.208229 | Val Loss: 1.681275\n",
      "Epoch [500/500] | Train Loss: 0.195441 | Val Loss: 1.784491\n",
      "Epoch [100/500] | Train Loss: 0.497133 | Val Loss: 0.429081\n",
      "Epoch [200/500] | Train Loss: 0.466875 | Val Loss: 0.449577\n",
      "Epoch [300/500] | Train Loss: 0.422393 | Val Loss: 0.456194\n",
      "Epoch [400/500] | Train Loss: 0.396565 | Val Loss: 0.459845\n",
      "Epoch [500/500] | Train Loss: 0.365971 | Val Loss: 0.484553\n",
      "Epoch [100/500] | Train Loss: 0.531244 | Val Loss: 0.856603\n",
      "Epoch [200/500] | Train Loss: 0.413205 | Val Loss: 0.901826\n",
      "Epoch [300/500] | Train Loss: 0.403606 | Val Loss: 0.900023\n",
      "Epoch [400/500] | Train Loss: 0.364317 | Val Loss: 0.882641\n",
      "Epoch [500/500] | Train Loss: 0.344560 | Val Loss: 0.927170\n",
      "Epoch [100/500] | Train Loss: 0.521628 | Val Loss: 0.300920\n",
      "Epoch [200/500] | Train Loss: 0.460668 | Val Loss: 0.312927\n",
      "Epoch [300/500] | Train Loss: 0.405184 | Val Loss: 0.318217\n",
      "Epoch [400/500] | Train Loss: 0.391576 | Val Loss: 0.338252\n",
      "Epoch [500/500] | Train Loss: 0.375729 | Val Loss: 0.350380\n",
      "Epoch [100/500] | Train Loss: 0.328532 | Val Loss: 0.923357\n",
      "Epoch [200/500] | Train Loss: 0.323876 | Val Loss: 0.945902\n",
      "Epoch [300/500] | Train Loss: 0.287391 | Val Loss: 0.945209\n",
      "Epoch [400/500] | Train Loss: 0.265624 | Val Loss: 0.964947\n",
      "Epoch [500/500] | Train Loss: 0.261478 | Val Loss: 0.989809\n",
      "Epoch [100/500] | Train Loss: 0.624002 | Val Loss: 1.202253\n",
      "Epoch [200/500] | Train Loss: 0.553446 | Val Loss: 1.274857\n",
      "Epoch [300/500] | Train Loss: 0.446111 | Val Loss: 1.355631\n",
      "Epoch [400/500] | Train Loss: 0.389842 | Val Loss: 1.383659\n",
      "Epoch [500/500] | Train Loss: 0.442700 | Val Loss: 1.450657\n",
      "Epoch [100/500] | Train Loss: 0.779914 | Val Loss: 0.404545\n",
      "Epoch [200/500] | Train Loss: 0.689498 | Val Loss: 0.416969\n",
      "Epoch [300/500] | Train Loss: 0.664400 | Val Loss: 0.412037\n",
      "Epoch [400/500] | Train Loss: 0.609276 | Val Loss: 0.410809\n",
      "Epoch [500/500] | Train Loss: 0.581451 | Val Loss: 0.407999\n",
      "Epoch [100/500] | Train Loss: 0.687828 | Val Loss: 0.745098\n",
      "Epoch [200/500] | Train Loss: 0.668028 | Val Loss: 0.751156\n",
      "Epoch [300/500] | Train Loss: 0.607207 | Val Loss: 0.767292\n",
      "Epoch [400/500] | Train Loss: 0.558070 | Val Loss: 0.766655\n",
      "Epoch [500/500] | Train Loss: 0.569272 | Val Loss: 0.777891\n",
      "Epoch [100/500] | Train Loss: 0.697199 | Val Loss: 0.278278\n",
      "Epoch [200/500] | Train Loss: 0.701721 | Val Loss: 0.279546\n",
      "Epoch [300/500] | Train Loss: 0.613431 | Val Loss: 0.285431\n",
      "Epoch [400/500] | Train Loss: 0.556962 | Val Loss: 0.289381\n",
      "Epoch [500/500] | Train Loss: 0.559042 | Val Loss: 0.282876\n",
      "Epoch [100/500] | Train Loss: 0.243760 | Val Loss: 0.970002\n",
      "Epoch [200/500] | Train Loss: 0.193055 | Val Loss: 0.970267\n",
      "Epoch [300/500] | Train Loss: 0.185690 | Val Loss: 0.980778\n",
      "Epoch [400/500] | Train Loss: 0.169636 | Val Loss: 0.960170\n",
      "Epoch [500/500] | Train Loss: 0.161588 | Val Loss: 1.007035\n",
      "Epoch [100/500] | Train Loss: 0.437587 | Val Loss: 1.695803\n",
      "Epoch [200/500] | Train Loss: 0.398519 | Val Loss: 1.610245\n",
      "Epoch [300/500] | Train Loss: 0.377468 | Val Loss: 1.621132\n",
      "Epoch [400/500] | Train Loss: 0.343289 | Val Loss: 1.693540\n",
      "Epoch [500/500] | Train Loss: 0.307266 | Val Loss: 1.689161\n",
      "Epoch [100/500] | Train Loss: 0.602971 | Val Loss: 0.403868\n",
      "Epoch [200/500] | Train Loss: 0.520641 | Val Loss: 0.419497\n",
      "Epoch [300/500] | Train Loss: 0.510528 | Val Loss: 0.415964\n",
      "Epoch [400/500] | Train Loss: 0.492393 | Val Loss: 0.423295\n",
      "Epoch [500/500] | Train Loss: 0.455707 | Val Loss: 0.468369\n",
      "Epoch [100/500] | Train Loss: 0.525646 | Val Loss: 0.769377\n",
      "Epoch [200/500] | Train Loss: 0.511719 | Val Loss: 0.771340\n",
      "Epoch [300/500] | Train Loss: 0.487742 | Val Loss: 0.737816\n",
      "Epoch [400/500] | Train Loss: 0.466466 | Val Loss: 0.775610\n",
      "Epoch [500/500] | Train Loss: 0.447003 | Val Loss: 0.754918\n",
      "Epoch [100/500] | Train Loss: 0.617939 | Val Loss: 0.284500\n",
      "Epoch [200/500] | Train Loss: 0.530159 | Val Loss: 0.289191\n",
      "Epoch [300/500] | Train Loss: 0.521095 | Val Loss: 0.295756\n",
      "Epoch [400/500] | Train Loss: 0.496812 | Val Loss: 0.300527\n",
      "Epoch [500/500] | Train Loss: 0.471539 | Val Loss: 0.301621\n",
      "[Year=1950] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.734035 Test MSE=0.653477\n",
      "Year 1950 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.169443 | Val Loss: 0.756893\n",
      "Epoch [200/500] | Train Loss: 0.967869 | Val Loss: 0.891409\n",
      "Epoch [300/500] | Train Loss: 0.658439 | Val Loss: 0.967081\n",
      "Epoch [400/500] | Train Loss: 0.776231 | Val Loss: 1.013020\n",
      "Epoch [500/500] | Train Loss: 0.609622 | Val Loss: 1.028324\n",
      "Epoch [100/500] | Train Loss: 0.966638 | Val Loss: 0.380899\n",
      "Epoch [200/500] | Train Loss: 0.921603 | Val Loss: 0.383637\n",
      "Epoch [300/500] | Train Loss: 0.755777 | Val Loss: 0.402930\n",
      "Epoch [400/500] | Train Loss: 0.786689 | Val Loss: 0.395717\n",
      "Epoch [500/500] | Train Loss: 0.660860 | Val Loss: 0.397291\n",
      "Epoch [100/500] | Train Loss: 0.808461 | Val Loss: 0.693759\n",
      "Epoch [200/500] | Train Loss: 0.716097 | Val Loss: 0.745974\n",
      "Epoch [300/500] | Train Loss: 0.616341 | Val Loss: 0.811702\n",
      "Epoch [400/500] | Train Loss: 0.589404 | Val Loss: 0.832148\n",
      "Epoch [500/500] | Train Loss: 0.556948 | Val Loss: 0.807176\n",
      "Epoch [100/500] | Train Loss: 0.755617 | Val Loss: 0.290185\n",
      "Epoch [200/500] | Train Loss: 0.673764 | Val Loss: 0.290106\n",
      "Epoch [300/500] | Train Loss: 0.607214 | Val Loss: 0.288575\n",
      "Epoch [400/500] | Train Loss: 0.570474 | Val Loss: 0.292408\n",
      "Epoch [500/500] | Train Loss: 0.593426 | Val Loss: 0.298497\n",
      "Epoch [100/500] | Train Loss: 0.681673 | Val Loss: 0.706488\n",
      "Epoch [200/500] | Train Loss: 0.643104 | Val Loss: 0.706351\n",
      "Epoch [300/500] | Train Loss: 0.581119 | Val Loss: 0.749202\n",
      "Epoch [400/500] | Train Loss: 0.544852 | Val Loss: 0.782803\n",
      "Epoch [500/500] | Train Loss: 0.486363 | Val Loss: 0.822216\n",
      "Epoch [100/500] | Train Loss: 0.753841 | Val Loss: 0.928909\n",
      "Epoch [200/500] | Train Loss: 0.455533 | Val Loss: 1.117014\n",
      "Epoch [300/500] | Train Loss: 0.420226 | Val Loss: 1.166517\n",
      "Epoch [400/500] | Train Loss: 0.375435 | Val Loss: 1.347817\n",
      "Epoch [500/500] | Train Loss: 0.388071 | Val Loss: 1.240703\n",
      "Epoch [100/500] | Train Loss: 0.614710 | Val Loss: 0.373838\n",
      "Epoch [200/500] | Train Loss: 0.547814 | Val Loss: 0.377659\n",
      "Epoch [300/500] | Train Loss: 0.468886 | Val Loss: 0.384189\n",
      "Epoch [400/500] | Train Loss: 0.437058 | Val Loss: 0.420322\n",
      "Epoch [500/500] | Train Loss: 0.344643 | Val Loss: 0.451142\n",
      "Epoch [100/500] | Train Loss: 0.567408 | Val Loss: 0.784369\n",
      "Epoch [200/500] | Train Loss: 0.461475 | Val Loss: 0.798697\n",
      "Epoch [300/500] | Train Loss: 0.467306 | Val Loss: 0.803390\n",
      "Epoch [400/500] | Train Loss: 0.443173 | Val Loss: 0.894300\n",
      "Epoch [500/500] | Train Loss: 0.428120 | Val Loss: 0.863272\n",
      "Epoch [100/500] | Train Loss: 0.602945 | Val Loss: 0.291203\n",
      "Epoch [200/500] | Train Loss: 0.502285 | Val Loss: 0.286369\n",
      "Epoch [300/500] | Train Loss: 0.488866 | Val Loss: 0.304915\n",
      "Epoch [400/500] | Train Loss: 0.456591 | Val Loss: 0.342945\n",
      "Epoch [500/500] | Train Loss: 0.432462 | Val Loss: 0.344261\n",
      "Epoch [100/500] | Train Loss: 0.519760 | Val Loss: 0.793265\n",
      "Epoch [200/500] | Train Loss: 0.504064 | Val Loss: 0.730169\n",
      "Epoch [300/500] | Train Loss: 0.499144 | Val Loss: 0.769614\n",
      "Epoch [400/500] | Train Loss: 0.484983 | Val Loss: 0.795422\n",
      "Epoch [500/500] | Train Loss: 0.439668 | Val Loss: 0.753056\n",
      "Epoch [100/500] | Train Loss: 1.330148 | Val Loss: 0.734299\n",
      "Epoch [200/500] | Train Loss: 1.212712 | Val Loss: 0.764720\n",
      "Epoch [300/500] | Train Loss: 1.098675 | Val Loss: 0.821872\n",
      "Epoch [400/500] | Train Loss: 0.943185 | Val Loss: 0.834309\n",
      "Epoch [500/500] | Train Loss: 0.896180 | Val Loss: 0.876818\n",
      "Epoch [100/500] | Train Loss: 1.009182 | Val Loss: 0.370934\n",
      "Epoch [200/500] | Train Loss: 0.986658 | Val Loss: 0.383794\n",
      "Epoch [300/500] | Train Loss: 0.936061 | Val Loss: 0.389458\n",
      "Epoch [400/500] | Train Loss: 0.861833 | Val Loss: 0.397644\n",
      "Epoch [500/500] | Train Loss: 0.829203 | Val Loss: 0.391394\n",
      "Epoch [100/500] | Train Loss: 0.821460 | Val Loss: 0.691645\n",
      "Epoch [200/500] | Train Loss: 0.762288 | Val Loss: 0.718784\n",
      "Epoch [300/500] | Train Loss: 0.736157 | Val Loss: 0.755182\n",
      "Epoch [400/500] | Train Loss: 0.699784 | Val Loss: 0.765026\n",
      "Epoch [500/500] | Train Loss: 0.652428 | Val Loss: 0.756144\n",
      "Epoch [100/500] | Train Loss: 0.786221 | Val Loss: 0.293379\n",
      "Epoch [200/500] | Train Loss: 0.745710 | Val Loss: 0.289954\n",
      "Epoch [300/500] | Train Loss: 0.687855 | Val Loss: 0.286607\n",
      "Epoch [400/500] | Train Loss: 0.711107 | Val Loss: 0.290544\n",
      "Epoch [500/500] | Train Loss: 0.634816 | Val Loss: 0.291304\n",
      "Epoch [100/500] | Train Loss: 0.690668 | Val Loss: 0.684618\n",
      "Epoch [200/500] | Train Loss: 0.663691 | Val Loss: 0.683590\n",
      "Epoch [300/500] | Train Loss: 0.631940 | Val Loss: 0.677524\n",
      "Epoch [400/500] | Train Loss: 0.616275 | Val Loss: 0.685389\n",
      "Epoch [500/500] | Train Loss: 0.590217 | Val Loss: 0.708270\n",
      "Epoch [100/500] | Train Loss: 0.966803 | Val Loss: 0.843349\n",
      "Epoch [200/500] | Train Loss: 0.747078 | Val Loss: 0.895012\n",
      "Epoch [300/500] | Train Loss: 0.717242 | Val Loss: 0.828841\n",
      "Epoch [400/500] | Train Loss: 0.773613 | Val Loss: 0.884348\n",
      "Epoch [500/500] | Train Loss: 0.520458 | Val Loss: 1.014744\n",
      "Epoch [100/500] | Train Loss: 0.806298 | Val Loss: 0.382078\n",
      "Epoch [200/500] | Train Loss: 0.647081 | Val Loss: 0.394909\n",
      "Epoch [300/500] | Train Loss: 0.669889 | Val Loss: 0.388445\n",
      "Epoch [400/500] | Train Loss: 0.603524 | Val Loss: 0.410640\n",
      "Epoch [500/500] | Train Loss: 0.707126 | Val Loss: 0.437814\n",
      "Epoch [100/500] | Train Loss: 0.652823 | Val Loss: 0.737477\n",
      "Epoch [200/500] | Train Loss: 0.695371 | Val Loss: 0.750774\n",
      "Epoch [300/500] | Train Loss: 0.607711 | Val Loss: 0.765514\n",
      "Epoch [400/500] | Train Loss: 0.545867 | Val Loss: 0.788196\n",
      "Epoch [500/500] | Train Loss: 0.545194 | Val Loss: 0.781159\n",
      "Epoch [100/500] | Train Loss: 0.702731 | Val Loss: 0.305427\n",
      "Epoch [200/500] | Train Loss: 0.680925 | Val Loss: 0.291662\n",
      "Epoch [300/500] | Train Loss: 0.588793 | Val Loss: 0.310166\n",
      "Epoch [400/500] | Train Loss: 0.579417 | Val Loss: 0.298001\n",
      "Epoch [500/500] | Train Loss: 0.596906 | Val Loss: 0.295656\n",
      "Epoch [100/500] | Train Loss: 0.570639 | Val Loss: 0.703693\n",
      "Epoch [200/500] | Train Loss: 0.561505 | Val Loss: 0.755786\n",
      "Epoch [300/500] | Train Loss: 0.519340 | Val Loss: 0.779384\n",
      "Epoch [400/500] | Train Loss: 0.500175 | Val Loss: 0.839529\n",
      "Epoch [500/500] | Train Loss: 0.544777 | Val Loss: 0.785711\n",
      "Epoch [100/500] | Train Loss: 1.163773 | Val Loss: 0.812226\n",
      "Epoch [200/500] | Train Loss: 0.907202 | Val Loss: 0.919558\n",
      "Epoch [300/500] | Train Loss: 0.745982 | Val Loss: 1.020619\n",
      "Epoch [400/500] | Train Loss: 0.659554 | Val Loss: 1.015500\n",
      "Epoch [500/500] | Train Loss: 0.630216 | Val Loss: 1.048220\n",
      "Epoch [100/500] | Train Loss: 0.931161 | Val Loss: 0.383532\n",
      "Epoch [200/500] | Train Loss: 0.744566 | Val Loss: 0.403651\n",
      "Epoch [300/500] | Train Loss: 0.605760 | Val Loss: 0.421798\n",
      "Epoch [400/500] | Train Loss: 0.570641 | Val Loss: 0.418133\n",
      "Epoch [500/500] | Train Loss: 0.517660 | Val Loss: 0.420637\n",
      "Epoch [100/500] | Train Loss: 0.771338 | Val Loss: 0.717872\n",
      "Epoch [200/500] | Train Loss: 0.683065 | Val Loss: 0.778115\n",
      "Epoch [300/500] | Train Loss: 0.570368 | Val Loss: 0.805936\n",
      "Epoch [400/500] | Train Loss: 0.531878 | Val Loss: 0.791150\n",
      "Epoch [500/500] | Train Loss: 0.498870 | Val Loss: 0.835102\n",
      "Epoch [100/500] | Train Loss: 0.752838 | Val Loss: 0.295670\n",
      "Epoch [200/500] | Train Loss: 0.655508 | Val Loss: 0.286460\n",
      "Epoch [300/500] | Train Loss: 0.621656 | Val Loss: 0.287971\n",
      "Epoch [400/500] | Train Loss: 0.577399 | Val Loss: 0.284207\n",
      "Epoch [500/500] | Train Loss: 0.540011 | Val Loss: 0.287020\n",
      "Epoch [100/500] | Train Loss: 0.666076 | Val Loss: 0.702569\n",
      "Epoch [200/500] | Train Loss: 0.586618 | Val Loss: 0.768978\n",
      "Epoch [300/500] | Train Loss: 0.523446 | Val Loss: 0.836646\n",
      "Epoch [400/500] | Train Loss: 0.493397 | Val Loss: 0.847138\n",
      "Epoch [500/500] | Train Loss: 0.467405 | Val Loss: 0.830446\n",
      "Epoch [100/500] | Train Loss: 0.572093 | Val Loss: 1.143666\n",
      "Epoch [200/500] | Train Loss: 0.418819 | Val Loss: 1.146824\n",
      "Epoch [300/500] | Train Loss: 0.343232 | Val Loss: 1.204331\n",
      "Epoch [400/500] | Train Loss: 0.321136 | Val Loss: 1.171834\n",
      "Epoch [500/500] | Train Loss: 0.347358 | Val Loss: 1.220441\n",
      "Epoch [100/500] | Train Loss: 0.702368 | Val Loss: 0.387357\n",
      "Epoch [200/500] | Train Loss: 0.528033 | Val Loss: 0.436266\n",
      "Epoch [300/500] | Train Loss: 0.459567 | Val Loss: 0.435408\n",
      "Epoch [400/500] | Train Loss: 0.416032 | Val Loss: 0.424871\n",
      "Epoch [500/500] | Train Loss: 0.356894 | Val Loss: 0.418519\n",
      "Epoch [100/500] | Train Loss: 0.531784 | Val Loss: 0.796204\n",
      "Epoch [200/500] | Train Loss: 0.459507 | Val Loss: 0.801635\n",
      "Epoch [300/500] | Train Loss: 0.450022 | Val Loss: 0.841886\n",
      "Epoch [400/500] | Train Loss: 0.390266 | Val Loss: 0.848532\n",
      "Epoch [500/500] | Train Loss: 0.396427 | Val Loss: 0.906032\n",
      "Epoch [100/500] | Train Loss: 0.544250 | Val Loss: 0.299106\n",
      "Epoch [200/500] | Train Loss: 0.458817 | Val Loss: 0.344806\n",
      "Epoch [300/500] | Train Loss: 0.445509 | Val Loss: 0.357771\n",
      "Epoch [400/500] | Train Loss: 0.413033 | Val Loss: 0.356962\n",
      "Epoch [500/500] | Train Loss: 0.386233 | Val Loss: 0.360134\n",
      "Epoch [100/500] | Train Loss: 0.565941 | Val Loss: 0.753245\n",
      "Epoch [200/500] | Train Loss: 0.509998 | Val Loss: 0.767882\n",
      "Epoch [300/500] | Train Loss: 0.474004 | Val Loss: 0.706523\n",
      "Epoch [400/500] | Train Loss: 0.423340 | Val Loss: 0.698545\n",
      "Epoch [500/500] | Train Loss: 0.400097 | Val Loss: 0.728589\n",
      "Epoch [100/500] | Train Loss: 1.302196 | Val Loss: 0.711097\n",
      "Epoch [200/500] | Train Loss: 0.968483 | Val Loss: 0.779535\n",
      "Epoch [300/500] | Train Loss: 0.905002 | Val Loss: 0.847574\n",
      "Epoch [400/500] | Train Loss: 0.926794 | Val Loss: 0.899310\n",
      "Epoch [500/500] | Train Loss: 0.714022 | Val Loss: 0.904823\n",
      "Epoch [100/500] | Train Loss: 0.988839 | Val Loss: 0.380526\n",
      "Epoch [200/500] | Train Loss: 0.889047 | Val Loss: 0.391080\n",
      "Epoch [300/500] | Train Loss: 0.892072 | Val Loss: 0.400387\n",
      "Epoch [400/500] | Train Loss: 0.795554 | Val Loss: 0.398664\n",
      "Epoch [500/500] | Train Loss: 0.682785 | Val Loss: 0.404923\n",
      "Epoch [100/500] | Train Loss: 0.793802 | Val Loss: 0.710480\n",
      "Epoch [200/500] | Train Loss: 0.754742 | Val Loss: 0.725352\n",
      "Epoch [300/500] | Train Loss: 0.668755 | Val Loss: 0.748421\n",
      "Epoch [400/500] | Train Loss: 0.675862 | Val Loss: 0.748413\n",
      "Epoch [500/500] | Train Loss: 0.580833 | Val Loss: 0.730978\n",
      "Epoch [100/500] | Train Loss: 0.806107 | Val Loss: 0.285598\n",
      "Epoch [200/500] | Train Loss: 0.718550 | Val Loss: 0.286368\n",
      "Epoch [300/500] | Train Loss: 0.675226 | Val Loss: 0.286059\n",
      "Epoch [400/500] | Train Loss: 0.621285 | Val Loss: 0.286877\n",
      "Epoch [500/500] | Train Loss: 0.617826 | Val Loss: 0.289266\n",
      "Epoch [100/500] | Train Loss: 0.684051 | Val Loss: 0.716142\n",
      "Epoch [200/500] | Train Loss: 0.617929 | Val Loss: 0.721512\n",
      "Epoch [300/500] | Train Loss: 0.600489 | Val Loss: 0.717673\n",
      "Epoch [400/500] | Train Loss: 0.579854 | Val Loss: 0.712708\n",
      "Epoch [500/500] | Train Loss: 0.543743 | Val Loss: 0.707377\n",
      "Epoch [100/500] | Train Loss: 0.772310 | Val Loss: 0.901495\n",
      "Epoch [200/500] | Train Loss: 0.546900 | Val Loss: 0.984603\n",
      "Epoch [300/500] | Train Loss: 0.516225 | Val Loss: 0.995560\n",
      "Epoch [400/500] | Train Loss: 0.567711 | Val Loss: 1.112361\n",
      "Epoch [500/500] | Train Loss: 0.437515 | Val Loss: 1.085073\n",
      "Epoch [100/500] | Train Loss: 0.729244 | Val Loss: 0.399718\n",
      "Epoch [200/500] | Train Loss: 0.598475 | Val Loss: 0.398800\n",
      "Epoch [300/500] | Train Loss: 0.549288 | Val Loss: 0.383203\n",
      "Epoch [400/500] | Train Loss: 0.493381 | Val Loss: 0.399584\n",
      "Epoch [500/500] | Train Loss: 0.497145 | Val Loss: 0.413556\n",
      "Epoch [100/500] | Train Loss: 0.713970 | Val Loss: 0.810897\n",
      "Epoch [200/500] | Train Loss: 0.535467 | Val Loss: 0.744208\n",
      "Epoch [300/500] | Train Loss: 0.497472 | Val Loss: 0.800112\n",
      "Epoch [400/500] | Train Loss: 0.528356 | Val Loss: 0.762940\n",
      "Epoch [500/500] | Train Loss: 0.456587 | Val Loss: 0.815791\n",
      "Epoch [100/500] | Train Loss: 0.633629 | Val Loss: 0.297733\n",
      "Epoch [200/500] | Train Loss: 0.526556 | Val Loss: 0.289842\n",
      "Epoch [300/500] | Train Loss: 0.540361 | Val Loss: 0.313942\n",
      "Epoch [400/500] | Train Loss: 0.588337 | Val Loss: 0.303371\n",
      "Epoch [500/500] | Train Loss: 0.535609 | Val Loss: 0.297233\n",
      "Epoch [100/500] | Train Loss: 0.608444 | Val Loss: 0.769878\n",
      "Epoch [200/500] | Train Loss: 0.527148 | Val Loss: 0.809713\n",
      "Epoch [300/500] | Train Loss: 0.565321 | Val Loss: 0.797170\n",
      "Epoch [400/500] | Train Loss: 0.463415 | Val Loss: 0.772856\n",
      "Epoch [500/500] | Train Loss: 0.433832 | Val Loss: 0.740948\n",
      "[Year=1951] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.604786 Test MSE=0.318321\n",
      "Year 1951 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.654606 | Val Loss: 0.506962\n",
      "Epoch [200/500] | Train Loss: 0.627730 | Val Loss: 0.477121\n",
      "Epoch [300/500] | Train Loss: 0.584143 | Val Loss: 0.470780\n",
      "Epoch [400/500] | Train Loss: 0.486550 | Val Loss: 0.494148\n",
      "Epoch [500/500] | Train Loss: 0.389283 | Val Loss: 0.501880\n",
      "Epoch [100/500] | Train Loss: 0.491247 | Val Loss: 0.594527\n",
      "Epoch [200/500] | Train Loss: 0.455169 | Val Loss: 0.636855\n",
      "Epoch [300/500] | Train Loss: 0.430088 | Val Loss: 0.689644\n",
      "Epoch [400/500] | Train Loss: 0.391788 | Val Loss: 0.703127\n",
      "Epoch [500/500] | Train Loss: 0.372465 | Val Loss: 0.716668\n",
      "Epoch [100/500] | Train Loss: 0.504751 | Val Loss: 0.254690\n",
      "Epoch [200/500] | Train Loss: 0.450248 | Val Loss: 0.265759\n",
      "Epoch [300/500] | Train Loss: 0.427312 | Val Loss: 0.269285\n",
      "Epoch [400/500] | Train Loss: 0.420877 | Val Loss: 0.270386\n",
      "Epoch [500/500] | Train Loss: 0.393090 | Val Loss: 0.273842\n",
      "Epoch [100/500] | Train Loss: 0.451528 | Val Loss: 0.726472\n",
      "Epoch [200/500] | Train Loss: 0.430732 | Val Loss: 0.746367\n",
      "Epoch [300/500] | Train Loss: 0.410318 | Val Loss: 0.773613\n",
      "Epoch [400/500] | Train Loss: 0.389681 | Val Loss: 0.794067\n",
      "Epoch [500/500] | Train Loss: 0.393382 | Val Loss: 0.801624\n",
      "Epoch [100/500] | Train Loss: 0.513352 | Val Loss: 0.311246\n",
      "Epoch [200/500] | Train Loss: 0.487760 | Val Loss: 0.307236\n",
      "Epoch [300/500] | Train Loss: 0.467255 | Val Loss: 0.309202\n",
      "Epoch [400/500] | Train Loss: 0.447570 | Val Loss: 0.309155\n",
      "Epoch [500/500] | Train Loss: 0.436974 | Val Loss: 0.311829\n",
      "Epoch [100/500] | Train Loss: 0.314478 | Val Loss: 0.614086\n",
      "Epoch [200/500] | Train Loss: 0.214696 | Val Loss: 0.668472\n",
      "Epoch [300/500] | Train Loss: 0.221801 | Val Loss: 0.705417\n",
      "Epoch [400/500] | Train Loss: 0.165184 | Val Loss: 0.715782\n",
      "Epoch [500/500] | Train Loss: 0.169141 | Val Loss: 0.684057\n",
      "Epoch [100/500] | Train Loss: 0.358853 | Val Loss: 0.693301\n",
      "Epoch [200/500] | Train Loss: 0.326521 | Val Loss: 0.717949\n",
      "Epoch [300/500] | Train Loss: 0.288710 | Val Loss: 0.732988\n",
      "Epoch [400/500] | Train Loss: 0.275176 | Val Loss: 0.705589\n",
      "Epoch [500/500] | Train Loss: 0.243554 | Val Loss: 0.729595\n",
      "Epoch [100/500] | Train Loss: 0.446853 | Val Loss: 0.272319\n",
      "Epoch [200/500] | Train Loss: 0.414271 | Val Loss: 0.282480\n",
      "Epoch [300/500] | Train Loss: 0.364587 | Val Loss: 0.287893\n",
      "Epoch [400/500] | Train Loss: 0.348261 | Val Loss: 0.308028\n",
      "Epoch [500/500] | Train Loss: 0.325533 | Val Loss: 0.299260\n",
      "Epoch [100/500] | Train Loss: 0.406835 | Val Loss: 0.744162\n",
      "Epoch [200/500] | Train Loss: 0.354121 | Val Loss: 0.790041\n",
      "Epoch [300/500] | Train Loss: 0.332262 | Val Loss: 0.916461\n",
      "Epoch [400/500] | Train Loss: 0.285859 | Val Loss: 0.870492\n",
      "Epoch [500/500] | Train Loss: 0.292406 | Val Loss: 0.832562\n",
      "Epoch [100/500] | Train Loss: 0.415217 | Val Loss: 0.322231\n",
      "Epoch [200/500] | Train Loss: 0.376927 | Val Loss: 0.341677\n",
      "Epoch [300/500] | Train Loss: 0.363514 | Val Loss: 0.372819\n",
      "Epoch [400/500] | Train Loss: 0.361615 | Val Loss: 0.369041\n",
      "Epoch [500/500] | Train Loss: 0.332957 | Val Loss: 0.353642\n",
      "Epoch [100/500] | Train Loss: 0.529021 | Val Loss: 0.443451\n",
      "Epoch [200/500] | Train Loss: 0.490253 | Val Loss: 0.479635\n",
      "Epoch [300/500] | Train Loss: 0.470479 | Val Loss: 0.500836\n",
      "Epoch [400/500] | Train Loss: 0.420749 | Val Loss: 0.511956\n",
      "Epoch [500/500] | Train Loss: 0.424823 | Val Loss: 0.517332\n",
      "Epoch [100/500] | Train Loss: 0.496444 | Val Loss: 0.578660\n",
      "Epoch [200/500] | Train Loss: 0.479169 | Val Loss: 0.602856\n",
      "Epoch [300/500] | Train Loss: 0.453797 | Val Loss: 0.633923\n",
      "Epoch [400/500] | Train Loss: 0.449337 | Val Loss: 0.646588\n",
      "Epoch [500/500] | Train Loss: 0.401107 | Val Loss: 0.667860\n",
      "Epoch [100/500] | Train Loss: 0.529674 | Val Loss: 0.268130\n",
      "Epoch [200/500] | Train Loss: 0.509746 | Val Loss: 0.262373\n",
      "Epoch [300/500] | Train Loss: 0.512688 | Val Loss: 0.265656\n",
      "Epoch [400/500] | Train Loss: 0.508949 | Val Loss: 0.270658\n",
      "Epoch [500/500] | Train Loss: 0.468236 | Val Loss: 0.275951\n",
      "Epoch [100/500] | Train Loss: 0.457331 | Val Loss: 0.734369\n",
      "Epoch [200/500] | Train Loss: 0.448445 | Val Loss: 0.747556\n",
      "Epoch [300/500] | Train Loss: 0.432833 | Val Loss: 0.762141\n",
      "Epoch [400/500] | Train Loss: 0.418484 | Val Loss: 0.764111\n",
      "Epoch [500/500] | Train Loss: 0.402933 | Val Loss: 0.771338\n",
      "Epoch [100/500] | Train Loss: 0.511255 | Val Loss: 0.306399\n",
      "Epoch [200/500] | Train Loss: 0.496526 | Val Loss: 0.304528\n",
      "Epoch [300/500] | Train Loss: 0.479163 | Val Loss: 0.304079\n",
      "Epoch [400/500] | Train Loss: 0.478848 | Val Loss: 0.303783\n",
      "Epoch [500/500] | Train Loss: 0.457580 | Val Loss: 0.302904\n",
      "Epoch [100/500] | Train Loss: 0.445593 | Val Loss: 0.518917\n",
      "Epoch [200/500] | Train Loss: 0.391136 | Val Loss: 0.560412\n",
      "Epoch [300/500] | Train Loss: 0.370205 | Val Loss: 0.559152\n",
      "Epoch [400/500] | Train Loss: 0.296602 | Val Loss: 0.605333\n",
      "Epoch [500/500] | Train Loss: 0.276509 | Val Loss: 0.588052\n",
      "Epoch [100/500] | Train Loss: 0.430857 | Val Loss: 0.710427\n",
      "Epoch [200/500] | Train Loss: 0.421903 | Val Loss: 0.764304\n",
      "Epoch [300/500] | Train Loss: 0.342144 | Val Loss: 0.759570\n",
      "Epoch [400/500] | Train Loss: 0.340245 | Val Loss: 0.736327\n",
      "Epoch [500/500] | Train Loss: 0.320501 | Val Loss: 0.784586\n",
      "Epoch [100/500] | Train Loss: 0.445045 | Val Loss: 0.270441\n",
      "Epoch [200/500] | Train Loss: 0.428830 | Val Loss: 0.266506\n",
      "Epoch [300/500] | Train Loss: 0.414240 | Val Loss: 0.279315\n",
      "Epoch [400/500] | Train Loss: 0.392852 | Val Loss: 0.277679\n",
      "Epoch [500/500] | Train Loss: 0.386621 | Val Loss: 0.300781\n",
      "Epoch [100/500] | Train Loss: 0.421912 | Val Loss: 0.746375\n",
      "Epoch [200/500] | Train Loss: 0.387064 | Val Loss: 0.764927\n",
      "Epoch [300/500] | Train Loss: 0.371947 | Val Loss: 0.755218\n",
      "Epoch [400/500] | Train Loss: 0.355752 | Val Loss: 0.777715\n",
      "Epoch [500/500] | Train Loss: 0.343737 | Val Loss: 0.745281\n",
      "Epoch [100/500] | Train Loss: 0.495143 | Val Loss: 0.309367\n",
      "Epoch [200/500] | Train Loss: 0.445581 | Val Loss: 0.298299\n",
      "Epoch [300/500] | Train Loss: 0.438048 | Val Loss: 0.310354\n",
      "Epoch [400/500] | Train Loss: 0.427406 | Val Loss: 0.306024\n",
      "Epoch [500/500] | Train Loss: 0.427397 | Val Loss: 0.325418\n",
      "Epoch [100/500] | Train Loss: 0.499581 | Val Loss: 0.458892\n",
      "Epoch [200/500] | Train Loss: 0.411836 | Val Loss: 0.501691\n",
      "Epoch [300/500] | Train Loss: 0.355381 | Val Loss: 0.551037\n",
      "Epoch [400/500] | Train Loss: 0.324001 | Val Loss: 0.584634\n",
      "Epoch [500/500] | Train Loss: 0.278940 | Val Loss: 0.628631\n",
      "Epoch [100/500] | Train Loss: 0.496887 | Val Loss: 0.592075\n",
      "Epoch [200/500] | Train Loss: 0.456282 | Val Loss: 0.615165\n",
      "Epoch [300/500] | Train Loss: 0.392918 | Val Loss: 0.683717\n",
      "Epoch [400/500] | Train Loss: 0.340410 | Val Loss: 0.738180\n",
      "Epoch [500/500] | Train Loss: 0.315610 | Val Loss: 0.754827\n",
      "Epoch [100/500] | Train Loss: 0.528910 | Val Loss: 0.272321\n",
      "Epoch [200/500] | Train Loss: 0.477751 | Val Loss: 0.268424\n",
      "Epoch [300/500] | Train Loss: 0.459186 | Val Loss: 0.267543\n",
      "Epoch [400/500] | Train Loss: 0.440072 | Val Loss: 0.271118\n",
      "Epoch [500/500] | Train Loss: 0.420817 | Val Loss: 0.269742\n",
      "Epoch [100/500] | Train Loss: 0.454706 | Val Loss: 0.738394\n",
      "Epoch [200/500] | Train Loss: 0.421454 | Val Loss: 0.774516\n",
      "Epoch [300/500] | Train Loss: 0.400460 | Val Loss: 0.813798\n",
      "Epoch [400/500] | Train Loss: 0.385248 | Val Loss: 0.798439\n",
      "Epoch [500/500] | Train Loss: 0.357200 | Val Loss: 0.814719\n",
      "Epoch [100/500] | Train Loss: 0.516042 | Val Loss: 0.313689\n",
      "Epoch [200/500] | Train Loss: 0.477128 | Val Loss: 0.303471\n",
      "Epoch [300/500] | Train Loss: 0.437715 | Val Loss: 0.304886\n",
      "Epoch [400/500] | Train Loss: 0.420785 | Val Loss: 0.310243\n",
      "Epoch [500/500] | Train Loss: 0.404098 | Val Loss: 0.319836\n",
      "Epoch [100/500] | Train Loss: 0.317942 | Val Loss: 0.650015\n",
      "Epoch [200/500] | Train Loss: 0.202046 | Val Loss: 0.690897\n",
      "Epoch [300/500] | Train Loss: 0.195938 | Val Loss: 0.668565\n",
      "Epoch [400/500] | Train Loss: 0.150867 | Val Loss: 0.713749\n",
      "Epoch [500/500] | Train Loss: 0.139852 | Val Loss: 0.669900\n",
      "Epoch [100/500] | Train Loss: 0.312420 | Val Loss: 0.746372\n",
      "Epoch [200/500] | Train Loss: 0.265852 | Val Loss: 0.748370\n",
      "Epoch [300/500] | Train Loss: 0.226354 | Val Loss: 0.782642\n",
      "Epoch [400/500] | Train Loss: 0.188920 | Val Loss: 0.799553\n",
      "Epoch [500/500] | Train Loss: 0.171740 | Val Loss: 0.828540\n",
      "Epoch [100/500] | Train Loss: 0.392102 | Val Loss: 0.286031\n",
      "Epoch [200/500] | Train Loss: 0.297692 | Val Loss: 0.339597\n",
      "Epoch [300/500] | Train Loss: 0.274548 | Val Loss: 0.398526\n",
      "Epoch [400/500] | Train Loss: 0.269540 | Val Loss: 0.405773\n",
      "Epoch [500/500] | Train Loss: 0.244781 | Val Loss: 0.386527\n",
      "Epoch [100/500] | Train Loss: 0.360244 | Val Loss: 0.793374\n",
      "Epoch [200/500] | Train Loss: 0.309174 | Val Loss: 0.805010\n",
      "Epoch [300/500] | Train Loss: 0.278587 | Val Loss: 0.817131\n",
      "Epoch [400/500] | Train Loss: 0.253099 | Val Loss: 0.845284\n",
      "Epoch [500/500] | Train Loss: 0.268120 | Val Loss: 0.835423\n",
      "Epoch [100/500] | Train Loss: 0.428378 | Val Loss: 0.297419\n",
      "Epoch [200/500] | Train Loss: 0.376833 | Val Loss: 0.309842\n",
      "Epoch [300/500] | Train Loss: 0.330528 | Val Loss: 0.328719\n",
      "Epoch [400/500] | Train Loss: 0.297594 | Val Loss: 0.353036\n",
      "Epoch [500/500] | Train Loss: 0.320128 | Val Loss: 0.330594\n",
      "Epoch [100/500] | Train Loss: 0.547129 | Val Loss: 0.438284\n",
      "Epoch [200/500] | Train Loss: 0.474777 | Val Loss: 0.474394\n",
      "Epoch [300/500] | Train Loss: 0.401625 | Val Loss: 0.484967\n",
      "Epoch [400/500] | Train Loss: 0.408495 | Val Loss: 0.509879\n",
      "Epoch [500/500] | Train Loss: 0.346016 | Val Loss: 0.541474\n",
      "Epoch [100/500] | Train Loss: 0.474477 | Val Loss: 0.598766\n",
      "Epoch [200/500] | Train Loss: 0.439326 | Val Loss: 0.637335\n",
      "Epoch [300/500] | Train Loss: 0.413507 | Val Loss: 0.677473\n",
      "Epoch [400/500] | Train Loss: 0.406511 | Val Loss: 0.686998\n",
      "Epoch [500/500] | Train Loss: 0.359089 | Val Loss: 0.719399\n",
      "Epoch [100/500] | Train Loss: 0.534066 | Val Loss: 0.256810\n",
      "Epoch [200/500] | Train Loss: 0.509824 | Val Loss: 0.255271\n",
      "Epoch [300/500] | Train Loss: 0.497710 | Val Loss: 0.261462\n",
      "Epoch [400/500] | Train Loss: 0.463570 | Val Loss: 0.264830\n",
      "Epoch [500/500] | Train Loss: 0.439506 | Val Loss: 0.265935\n",
      "Epoch [100/500] | Train Loss: 0.469774 | Val Loss: 0.746868\n",
      "Epoch [200/500] | Train Loss: 0.430398 | Val Loss: 0.769590\n",
      "Epoch [300/500] | Train Loss: 0.425074 | Val Loss: 0.751037\n",
      "Epoch [400/500] | Train Loss: 0.406850 | Val Loss: 0.747955\n",
      "Epoch [500/500] | Train Loss: 0.405236 | Val Loss: 0.756247\n",
      "Epoch [100/500] | Train Loss: 0.505084 | Val Loss: 0.309337\n",
      "Epoch [200/500] | Train Loss: 0.475459 | Val Loss: 0.304473\n",
      "Epoch [300/500] | Train Loss: 0.459233 | Val Loss: 0.305637\n",
      "Epoch [400/500] | Train Loss: 0.438940 | Val Loss: 0.307039\n",
      "Epoch [500/500] | Train Loss: 0.437621 | Val Loss: 0.311289\n",
      "Epoch [100/500] | Train Loss: 0.420499 | Val Loss: 0.504936\n",
      "Epoch [200/500] | Train Loss: 0.346966 | Val Loss: 0.556995\n",
      "Epoch [300/500] | Train Loss: 0.298331 | Val Loss: 0.599047\n",
      "Epoch [400/500] | Train Loss: 0.264335 | Val Loss: 0.560796\n",
      "Epoch [500/500] | Train Loss: 0.228900 | Val Loss: 0.592215\n",
      "Epoch [100/500] | Train Loss: 0.402653 | Val Loss: 0.690824\n",
      "Epoch [200/500] | Train Loss: 0.316903 | Val Loss: 0.764993\n",
      "Epoch [300/500] | Train Loss: 0.305640 | Val Loss: 0.788567\n",
      "Epoch [400/500] | Train Loss: 0.284590 | Val Loss: 0.761987\n",
      "Epoch [500/500] | Train Loss: 0.275893 | Val Loss: 0.710017\n",
      "Epoch [100/500] | Train Loss: 0.444273 | Val Loss: 0.261743\n",
      "Epoch [200/500] | Train Loss: 0.403476 | Val Loss: 0.284083\n",
      "Epoch [300/500] | Train Loss: 0.377149 | Val Loss: 0.283618\n",
      "Epoch [400/500] | Train Loss: 0.348165 | Val Loss: 0.270994\n",
      "Epoch [500/500] | Train Loss: 0.348583 | Val Loss: 0.285899\n",
      "Epoch [100/500] | Train Loss: 0.395403 | Val Loss: 0.774764\n",
      "Epoch [200/500] | Train Loss: 0.382825 | Val Loss: 0.839432\n",
      "Epoch [300/500] | Train Loss: 0.334826 | Val Loss: 0.839987\n",
      "Epoch [400/500] | Train Loss: 0.327550 | Val Loss: 0.847377\n",
      "Epoch [500/500] | Train Loss: 0.316161 | Val Loss: 0.814482\n",
      "Epoch [100/500] | Train Loss: 0.461042 | Val Loss: 0.318232\n",
      "Epoch [200/500] | Train Loss: 0.423977 | Val Loss: 0.325657\n",
      "Epoch [300/500] | Train Loss: 0.407913 | Val Loss: 0.333192\n",
      "Epoch [400/500] | Train Loss: 0.414606 | Val Loss: 0.356285\n",
      "Epoch [500/500] | Train Loss: 0.380287 | Val Loss: 0.354502\n",
      "[Year=1952] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.507077 Test MSE=0.170852\n",
      "Year 1952 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.462568 | Val Loss: 0.554841\n",
      "Epoch [200/500] | Train Loss: 0.433132 | Val Loss: 0.581657\n",
      "Epoch [300/500] | Train Loss: 0.392551 | Val Loss: 0.613611\n",
      "Epoch [400/500] | Train Loss: 0.330480 | Val Loss: 0.715791\n",
      "Epoch [500/500] | Train Loss: 0.311989 | Val Loss: 0.825073\n",
      "Epoch [100/500] | Train Loss: 0.479007 | Val Loss: 0.246189\n",
      "Epoch [200/500] | Train Loss: 0.411886 | Val Loss: 0.261429\n",
      "Epoch [300/500] | Train Loss: 0.376233 | Val Loss: 0.273248\n",
      "Epoch [400/500] | Train Loss: 0.367787 | Val Loss: 0.284383\n",
      "Epoch [500/500] | Train Loss: 0.328351 | Val Loss: 0.298103\n",
      "Epoch [100/500] | Train Loss: 0.396260 | Val Loss: 0.773586\n",
      "Epoch [200/500] | Train Loss: 0.360112 | Val Loss: 0.799368\n",
      "Epoch [300/500] | Train Loss: 0.345978 | Val Loss: 0.786433\n",
      "Epoch [400/500] | Train Loss: 0.324462 | Val Loss: 0.780597\n",
      "Epoch [500/500] | Train Loss: 0.307287 | Val Loss: 0.763692\n",
      "Epoch [100/500] | Train Loss: 0.508582 | Val Loss: 0.282398\n",
      "Epoch [200/500] | Train Loss: 0.460838 | Val Loss: 0.276144\n",
      "Epoch [300/500] | Train Loss: 0.410354 | Val Loss: 0.293543\n",
      "Epoch [400/500] | Train Loss: 0.412001 | Val Loss: 0.302791\n",
      "Epoch [500/500] | Train Loss: 0.394862 | Val Loss: 0.309512\n",
      "Epoch [100/500] | Train Loss: 0.455493 | Val Loss: 0.172452\n",
      "Epoch [200/500] | Train Loss: 0.425219 | Val Loss: 0.170188\n",
      "Epoch [300/500] | Train Loss: 0.394269 | Val Loss: 0.177594\n",
      "Epoch [400/500] | Train Loss: 0.391460 | Val Loss: 0.181218\n",
      "Epoch [500/500] | Train Loss: 0.372602 | Val Loss: 0.183839\n",
      "Epoch [100/500] | Train Loss: 0.353282 | Val Loss: 0.703770\n",
      "Epoch [200/500] | Train Loss: 0.282537 | Val Loss: 0.822200\n",
      "Epoch [300/500] | Train Loss: 0.219082 | Val Loss: 0.938880\n",
      "Epoch [400/500] | Train Loss: 0.199399 | Val Loss: 0.943149\n",
      "Epoch [500/500] | Train Loss: 0.204843 | Val Loss: 0.937743\n",
      "Epoch [100/500] | Train Loss: 0.384789 | Val Loss: 0.288784\n",
      "Epoch [200/500] | Train Loss: 0.279463 | Val Loss: 0.318438\n",
      "Epoch [300/500] | Train Loss: 0.240350 | Val Loss: 0.311842\n",
      "Epoch [400/500] | Train Loss: 0.289233 | Val Loss: 0.355161\n",
      "Epoch [500/500] | Train Loss: 0.261549 | Val Loss: 0.371572\n",
      "Epoch [100/500] | Train Loss: 0.347434 | Val Loss: 0.805748\n",
      "Epoch [200/500] | Train Loss: 0.277891 | Val Loss: 0.817473\n",
      "Epoch [300/500] | Train Loss: 0.270990 | Val Loss: 0.826563\n",
      "Epoch [400/500] | Train Loss: 0.249419 | Val Loss: 0.842532\n",
      "Epoch [500/500] | Train Loss: 0.234867 | Val Loss: 0.816546\n",
      "Epoch [100/500] | Train Loss: 0.398023 | Val Loss: 0.315142\n",
      "Epoch [200/500] | Train Loss: 0.361648 | Val Loss: 0.356186\n",
      "Epoch [300/500] | Train Loss: 0.312671 | Val Loss: 0.356891\n",
      "Epoch [400/500] | Train Loss: 0.322961 | Val Loss: 0.328806\n",
      "Epoch [500/500] | Train Loss: 0.288661 | Val Loss: 0.360664\n",
      "Epoch [100/500] | Train Loss: 0.389874 | Val Loss: 0.178076\n",
      "Epoch [200/500] | Train Loss: 0.355970 | Val Loss: 0.206317\n",
      "Epoch [300/500] | Train Loss: 0.344578 | Val Loss: 0.198569\n",
      "Epoch [400/500] | Train Loss: 0.335798 | Val Loss: 0.196978\n",
      "Epoch [500/500] | Train Loss: 0.322816 | Val Loss: 0.213539\n",
      "Epoch [100/500] | Train Loss: 0.487608 | Val Loss: 0.532531\n",
      "Epoch [200/500] | Train Loss: 0.459911 | Val Loss: 0.538704\n",
      "Epoch [300/500] | Train Loss: 0.436080 | Val Loss: 0.536377\n",
      "Epoch [400/500] | Train Loss: 0.395170 | Val Loss: 0.550641\n",
      "Epoch [500/500] | Train Loss: 0.389700 | Val Loss: 0.566182\n",
      "Epoch [100/500] | Train Loss: 0.486906 | Val Loss: 0.246234\n",
      "Epoch [200/500] | Train Loss: 0.467823 | Val Loss: 0.253664\n",
      "Epoch [300/500] | Train Loss: 0.416555 | Val Loss: 0.257579\n",
      "Epoch [400/500] | Train Loss: 0.402142 | Val Loss: 0.258529\n",
      "Epoch [500/500] | Train Loss: 0.398080 | Val Loss: 0.264132\n",
      "Epoch [100/500] | Train Loss: 0.420286 | Val Loss: 0.769140\n",
      "Epoch [200/500] | Train Loss: 0.406951 | Val Loss: 0.765034\n",
      "Epoch [300/500] | Train Loss: 0.382248 | Val Loss: 0.769468\n",
      "Epoch [400/500] | Train Loss: 0.376868 | Val Loss: 0.769306\n",
      "Epoch [500/500] | Train Loss: 0.375656 | Val Loss: 0.768762\n",
      "Epoch [100/500] | Train Loss: 0.489908 | Val Loss: 0.278543\n",
      "Epoch [200/500] | Train Loss: 0.471627 | Val Loss: 0.280333\n",
      "Epoch [300/500] | Train Loss: 0.476464 | Val Loss: 0.284922\n",
      "Epoch [400/500] | Train Loss: 0.444387 | Val Loss: 0.287778\n",
      "Epoch [500/500] | Train Loss: 0.415794 | Val Loss: 0.285966\n",
      "Epoch [100/500] | Train Loss: 0.464526 | Val Loss: 0.178881\n",
      "Epoch [200/500] | Train Loss: 0.448510 | Val Loss: 0.169830\n",
      "Epoch [300/500] | Train Loss: 0.422046 | Val Loss: 0.170707\n",
      "Epoch [400/500] | Train Loss: 0.410874 | Val Loss: 0.173803\n",
      "Epoch [500/500] | Train Loss: 0.402659 | Val Loss: 0.175774\n",
      "Epoch [100/500] | Train Loss: 0.402546 | Val Loss: 0.630485\n",
      "Epoch [200/500] | Train Loss: 0.311399 | Val Loss: 0.852897\n",
      "Epoch [300/500] | Train Loss: 0.264996 | Val Loss: 0.983905\n",
      "Epoch [400/500] | Train Loss: 0.250902 | Val Loss: 0.946990\n",
      "Epoch [500/500] | Train Loss: 0.271817 | Val Loss: 0.815529\n",
      "Epoch [100/500] | Train Loss: 0.446881 | Val Loss: 0.279885\n",
      "Epoch [200/500] | Train Loss: 0.321394 | Val Loss: 0.303687\n",
      "Epoch [300/500] | Train Loss: 0.363509 | Val Loss: 0.340397\n",
      "Epoch [400/500] | Train Loss: 0.300108 | Val Loss: 0.318481\n",
      "Epoch [500/500] | Train Loss: 0.313721 | Val Loss: 0.356844\n",
      "Epoch [100/500] | Train Loss: 0.357897 | Val Loss: 0.768841\n",
      "Epoch [200/500] | Train Loss: 0.327579 | Val Loss: 0.759471\n",
      "Epoch [300/500] | Train Loss: 0.315159 | Val Loss: 0.718345\n",
      "Epoch [400/500] | Train Loss: 0.308143 | Val Loss: 0.730433\n",
      "Epoch [500/500] | Train Loss: 0.298301 | Val Loss: 0.743391\n",
      "Epoch [100/500] | Train Loss: 0.434365 | Val Loss: 0.278906\n",
      "Epoch [200/500] | Train Loss: 0.411371 | Val Loss: 0.293005\n",
      "Epoch [300/500] | Train Loss: 0.396719 | Val Loss: 0.308011\n",
      "Epoch [400/500] | Train Loss: 0.363271 | Val Loss: 0.327944\n",
      "Epoch [500/500] | Train Loss: 0.358490 | Val Loss: 0.319634\n",
      "Epoch [100/500] | Train Loss: 0.427383 | Val Loss: 0.171366\n",
      "Epoch [200/500] | Train Loss: 0.383606 | Val Loss: 0.173082\n",
      "Epoch [300/500] | Train Loss: 0.373971 | Val Loss: 0.186603\n",
      "Epoch [400/500] | Train Loss: 0.375073 | Val Loss: 0.188743\n",
      "Epoch [500/500] | Train Loss: 0.350980 | Val Loss: 0.192301\n",
      "Epoch [100/500] | Train Loss: 0.462076 | Val Loss: 0.548829\n",
      "Epoch [200/500] | Train Loss: 0.344017 | Val Loss: 0.719852\n",
      "Epoch [300/500] | Train Loss: 0.318583 | Val Loss: 1.039794\n",
      "Epoch [400/500] | Train Loss: 0.263236 | Val Loss: 1.055149\n",
      "Epoch [500/500] | Train Loss: 0.264513 | Val Loss: 0.984132\n",
      "Epoch [100/500] | Train Loss: 0.496585 | Val Loss: 0.248608\n",
      "Epoch [200/500] | Train Loss: 0.433665 | Val Loss: 0.261969\n",
      "Epoch [300/500] | Train Loss: 0.391224 | Val Loss: 0.275709\n",
      "Epoch [400/500] | Train Loss: 0.355006 | Val Loss: 0.304730\n",
      "Epoch [500/500] | Train Loss: 0.311900 | Val Loss: 0.336883\n",
      "Epoch [100/500] | Train Loss: 0.388038 | Val Loss: 0.802681\n",
      "Epoch [200/500] | Train Loss: 0.351481 | Val Loss: 0.825084\n",
      "Epoch [300/500] | Train Loss: 0.327605 | Val Loss: 0.782921\n",
      "Epoch [400/500] | Train Loss: 0.313316 | Val Loss: 0.771144\n",
      "Epoch [500/500] | Train Loss: 0.303417 | Val Loss: 0.806130\n",
      "Epoch [100/500] | Train Loss: 0.470571 | Val Loss: 0.276524\n",
      "Epoch [200/500] | Train Loss: 0.439450 | Val Loss: 0.291145\n",
      "Epoch [300/500] | Train Loss: 0.387409 | Val Loss: 0.300010\n",
      "Epoch [400/500] | Train Loss: 0.363170 | Val Loss: 0.305017\n",
      "Epoch [500/500] | Train Loss: 0.352176 | Val Loss: 0.304243\n",
      "Epoch [100/500] | Train Loss: 0.439178 | Val Loss: 0.169163\n",
      "Epoch [200/500] | Train Loss: 0.393279 | Val Loss: 0.182991\n",
      "Epoch [300/500] | Train Loss: 0.384482 | Val Loss: 0.191835\n",
      "Epoch [400/500] | Train Loss: 0.351893 | Val Loss: 0.194790\n",
      "Epoch [500/500] | Train Loss: 0.349797 | Val Loss: 0.197408\n",
      "Epoch [100/500] | Train Loss: 0.293067 | Val Loss: 0.938385\n",
      "Epoch [200/500] | Train Loss: 0.217333 | Val Loss: 1.035647\n",
      "Epoch [300/500] | Train Loss: 0.157110 | Val Loss: 0.993676\n",
      "Epoch [400/500] | Train Loss: 0.153252 | Val Loss: 0.874513\n",
      "Epoch [500/500] | Train Loss: 0.143549 | Val Loss: 0.949718\n",
      "Epoch [100/500] | Train Loss: 0.364512 | Val Loss: 0.269953\n",
      "Epoch [200/500] | Train Loss: 0.300498 | Val Loss: 0.329029\n",
      "Epoch [300/500] | Train Loss: 0.211653 | Val Loss: 0.361435\n",
      "Epoch [400/500] | Train Loss: 0.197481 | Val Loss: 0.331345\n",
      "Epoch [500/500] | Train Loss: 0.195141 | Val Loss: 0.429079\n",
      "Epoch [100/500] | Train Loss: 0.353510 | Val Loss: 0.864024\n",
      "Epoch [200/500] | Train Loss: 0.287112 | Val Loss: 0.813046\n",
      "Epoch [300/500] | Train Loss: 0.278580 | Val Loss: 0.892437\n",
      "Epoch [400/500] | Train Loss: 0.262866 | Val Loss: 0.863181\n",
      "Epoch [500/500] | Train Loss: 0.242760 | Val Loss: 0.868366\n",
      "Epoch [100/500] | Train Loss: 0.398633 | Val Loss: 0.305625\n",
      "Epoch [200/500] | Train Loss: 0.353640 | Val Loss: 0.324335\n",
      "Epoch [300/500] | Train Loss: 0.301739 | Val Loss: 0.347773\n",
      "Epoch [400/500] | Train Loss: 0.297819 | Val Loss: 0.330596\n",
      "Epoch [500/500] | Train Loss: 0.260914 | Val Loss: 0.345138\n",
      "Epoch [100/500] | Train Loss: 0.345945 | Val Loss: 0.195056\n",
      "Epoch [200/500] | Train Loss: 0.296725 | Val Loss: 0.211280\n",
      "Epoch [300/500] | Train Loss: 0.269095 | Val Loss: 0.220707\n",
      "Epoch [400/500] | Train Loss: 0.249160 | Val Loss: 0.218385\n",
      "Epoch [500/500] | Train Loss: 0.238955 | Val Loss: 0.205644\n",
      "Epoch [100/500] | Train Loss: 0.472727 | Val Loss: 0.553502\n",
      "Epoch [200/500] | Train Loss: 0.413317 | Val Loss: 0.562964\n",
      "Epoch [300/500] | Train Loss: 0.370213 | Val Loss: 0.622886\n",
      "Epoch [400/500] | Train Loss: 0.327895 | Val Loss: 0.693344\n",
      "Epoch [500/500] | Train Loss: 0.295375 | Val Loss: 0.747251\n",
      "Epoch [100/500] | Train Loss: 0.498082 | Val Loss: 0.251018\n",
      "Epoch [200/500] | Train Loss: 0.466493 | Val Loss: 0.255597\n",
      "Epoch [300/500] | Train Loss: 0.386701 | Val Loss: 0.267793\n",
      "Epoch [400/500] | Train Loss: 0.378230 | Val Loss: 0.271370\n",
      "Epoch [500/500] | Train Loss: 0.369895 | Val Loss: 0.297980\n",
      "Epoch [100/500] | Train Loss: 0.403108 | Val Loss: 0.782695\n",
      "Epoch [200/500] | Train Loss: 0.358835 | Val Loss: 0.803332\n",
      "Epoch [300/500] | Train Loss: 0.344773 | Val Loss: 0.785861\n",
      "Epoch [400/500] | Train Loss: 0.343084 | Val Loss: 0.756745\n",
      "Epoch [500/500] | Train Loss: 0.323578 | Val Loss: 0.759456\n",
      "Epoch [100/500] | Train Loss: 0.518876 | Val Loss: 0.284948\n",
      "Epoch [200/500] | Train Loss: 0.465389 | Val Loss: 0.281816\n",
      "Epoch [300/500] | Train Loss: 0.449244 | Val Loss: 0.290084\n",
      "Epoch [400/500] | Train Loss: 0.427370 | Val Loss: 0.292140\n",
      "Epoch [500/500] | Train Loss: 0.404644 | Val Loss: 0.296879\n",
      "Epoch [100/500] | Train Loss: 0.449651 | Val Loss: 0.171141\n",
      "Epoch [200/500] | Train Loss: 0.414597 | Val Loss: 0.169875\n",
      "Epoch [300/500] | Train Loss: 0.410616 | Val Loss: 0.173577\n",
      "Epoch [400/500] | Train Loss: 0.375728 | Val Loss: 0.180137\n",
      "Epoch [500/500] | Train Loss: 0.363196 | Val Loss: 0.182326\n",
      "Epoch [100/500] | Train Loss: 0.311406 | Val Loss: 0.612231\n",
      "Epoch [200/500] | Train Loss: 0.268801 | Val Loss: 0.657758\n",
      "Epoch [300/500] | Train Loss: 0.291469 | Val Loss: 0.704921\n",
      "Epoch [400/500] | Train Loss: 0.256202 | Val Loss: 0.739679\n",
      "Epoch [500/500] | Train Loss: 0.239790 | Val Loss: 0.730754\n",
      "Epoch [100/500] | Train Loss: 0.396585 | Val Loss: 0.259244\n",
      "Epoch [200/500] | Train Loss: 0.344439 | Val Loss: 0.285998\n",
      "Epoch [300/500] | Train Loss: 0.306148 | Val Loss: 0.289969\n",
      "Epoch [400/500] | Train Loss: 0.308839 | Val Loss: 0.309086\n",
      "Epoch [500/500] | Train Loss: 0.300564 | Val Loss: 0.300095\n",
      "Epoch [100/500] | Train Loss: 0.396549 | Val Loss: 0.852865\n",
      "Epoch [200/500] | Train Loss: 0.312868 | Val Loss: 0.796095\n",
      "Epoch [300/500] | Train Loss: 0.284260 | Val Loss: 0.807824\n",
      "Epoch [400/500] | Train Loss: 0.268650 | Val Loss: 0.802659\n",
      "Epoch [500/500] | Train Loss: 0.263944 | Val Loss: 0.794853\n",
      "Epoch [100/500] | Train Loss: 0.414900 | Val Loss: 0.292182\n",
      "Epoch [200/500] | Train Loss: 0.381227 | Val Loss: 0.306544\n",
      "Epoch [300/500] | Train Loss: 0.369096 | Val Loss: 0.318195\n",
      "Epoch [400/500] | Train Loss: 0.334733 | Val Loss: 0.332497\n",
      "Epoch [500/500] | Train Loss: 0.322526 | Val Loss: 0.325054\n",
      "Epoch [100/500] | Train Loss: 0.379870 | Val Loss: 0.183702\n",
      "Epoch [200/500] | Train Loss: 0.355778 | Val Loss: 0.192173\n",
      "Epoch [300/500] | Train Loss: 0.337112 | Val Loss: 0.186974\n",
      "Epoch [400/500] | Train Loss: 0.328921 | Val Loss: 0.198434\n",
      "Epoch [500/500] | Train Loss: 0.327205 | Val Loss: 0.209562\n",
      "[Year=1953] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.412163 Test MSE=0.254947\n",
      "Year 1953 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.318012 | Val Loss: 0.542262\n",
      "Epoch [200/500] | Train Loss: 0.283694 | Val Loss: 0.569477\n",
      "Epoch [300/500] | Train Loss: 0.247325 | Val Loss: 0.599913\n",
      "Epoch [400/500] | Train Loss: 0.221847 | Val Loss: 0.674831\n",
      "Epoch [500/500] | Train Loss: 0.210909 | Val Loss: 0.673905\n",
      "Epoch [100/500] | Train Loss: 0.421669 | Val Loss: 0.490368\n",
      "Epoch [200/500] | Train Loss: 0.360334 | Val Loss: 0.515557\n",
      "Epoch [300/500] | Train Loss: 0.344539 | Val Loss: 0.509291\n",
      "Epoch [400/500] | Train Loss: 0.314640 | Val Loss: 0.497567\n",
      "Epoch [500/500] | Train Loss: 0.307391 | Val Loss: 0.490297\n",
      "Epoch [100/500] | Train Loss: 0.429116 | Val Loss: 0.260142\n",
      "Epoch [200/500] | Train Loss: 0.394031 | Val Loss: 0.257900\n",
      "Epoch [300/500] | Train Loss: 0.387065 | Val Loss: 0.256944\n",
      "Epoch [400/500] | Train Loss: 0.368681 | Val Loss: 0.259207\n",
      "Epoch [500/500] | Train Loss: 0.363510 | Val Loss: 0.259411\n",
      "Epoch [100/500] | Train Loss: 0.384301 | Val Loss: 0.157917\n",
      "Epoch [200/500] | Train Loss: 0.344711 | Val Loss: 0.164112\n",
      "Epoch [300/500] | Train Loss: 0.334544 | Val Loss: 0.171993\n",
      "Epoch [400/500] | Train Loss: 0.330536 | Val Loss: 0.179373\n",
      "Epoch [500/500] | Train Loss: 0.309915 | Val Loss: 0.185195\n",
      "Epoch [100/500] | Train Loss: 0.354331 | Val Loss: 0.262951\n",
      "Epoch [200/500] | Train Loss: 0.333391 | Val Loss: 0.263486\n",
      "Epoch [300/500] | Train Loss: 0.311330 | Val Loss: 0.266145\n",
      "Epoch [400/500] | Train Loss: 0.302974 | Val Loss: 0.271289\n",
      "Epoch [500/500] | Train Loss: 0.296960 | Val Loss: 0.278795\n",
      "Epoch [100/500] | Train Loss: 0.221898 | Val Loss: 0.562384\n",
      "Epoch [200/500] | Train Loss: 0.191287 | Val Loss: 0.582808\n",
      "Epoch [300/500] | Train Loss: 0.156493 | Val Loss: 0.586960\n",
      "Epoch [400/500] | Train Loss: 0.161873 | Val Loss: 0.616584\n",
      "Epoch [500/500] | Train Loss: 0.145902 | Val Loss: 0.603740\n",
      "Epoch [100/500] | Train Loss: 0.297779 | Val Loss: 0.485675\n",
      "Epoch [200/500] | Train Loss: 0.262147 | Val Loss: 0.524363\n",
      "Epoch [300/500] | Train Loss: 0.234202 | Val Loss: 0.520562\n",
      "Epoch [400/500] | Train Loss: 0.205485 | Val Loss: 0.526187\n",
      "Epoch [500/500] | Train Loss: 0.201846 | Val Loss: 0.500912\n",
      "Epoch [100/500] | Train Loss: 0.325854 | Val Loss: 0.290866\n",
      "Epoch [200/500] | Train Loss: 0.282386 | Val Loss: 0.345840\n",
      "Epoch [300/500] | Train Loss: 0.246423 | Val Loss: 0.349326\n",
      "Epoch [400/500] | Train Loss: 0.232094 | Val Loss: 0.411837\n",
      "Epoch [500/500] | Train Loss: 0.220804 | Val Loss: 0.364560\n",
      "Epoch [100/500] | Train Loss: 0.318181 | Val Loss: 0.174430\n",
      "Epoch [200/500] | Train Loss: 0.304559 | Val Loss: 0.186397\n",
      "Epoch [300/500] | Train Loss: 0.256966 | Val Loss: 0.202170\n",
      "Epoch [400/500] | Train Loss: 0.274283 | Val Loss: 0.204620\n",
      "Epoch [500/500] | Train Loss: 0.263146 | Val Loss: 0.234889\n",
      "Epoch [100/500] | Train Loss: 0.264452 | Val Loss: 0.282304\n",
      "Epoch [200/500] | Train Loss: 0.232942 | Val Loss: 0.307626\n",
      "Epoch [300/500] | Train Loss: 0.240125 | Val Loss: 0.308939\n",
      "Epoch [400/500] | Train Loss: 0.202206 | Val Loss: 0.317408\n",
      "Epoch [500/500] | Train Loss: 0.208173 | Val Loss: 0.334893\n",
      "Epoch [100/500] | Train Loss: 0.331015 | Val Loss: 0.537704\n",
      "Epoch [200/500] | Train Loss: 0.310992 | Val Loss: 0.523655\n",
      "Epoch [300/500] | Train Loss: 0.281329 | Val Loss: 0.518879\n",
      "Epoch [400/500] | Train Loss: 0.255365 | Val Loss: 0.517246\n",
      "Epoch [500/500] | Train Loss: 0.206429 | Val Loss: 0.518295\n",
      "Epoch [100/500] | Train Loss: 0.428701 | Val Loss: 0.502984\n",
      "Epoch [200/500] | Train Loss: 0.354416 | Val Loss: 0.500897\n",
      "Epoch [300/500] | Train Loss: 0.340433 | Val Loss: 0.503387\n",
      "Epoch [400/500] | Train Loss: 0.348634 | Val Loss: 0.497216\n",
      "Epoch [500/500] | Train Loss: 0.318402 | Val Loss: 0.500278\n",
      "Epoch [100/500] | Train Loss: 0.439214 | Val Loss: 0.258275\n",
      "Epoch [200/500] | Train Loss: 0.414038 | Val Loss: 0.260502\n",
      "Epoch [300/500] | Train Loss: 0.375163 | Val Loss: 0.272474\n",
      "Epoch [400/500] | Train Loss: 0.372462 | Val Loss: 0.279402\n",
      "Epoch [500/500] | Train Loss: 0.367729 | Val Loss: 0.289909\n",
      "Epoch [100/500] | Train Loss: 0.398512 | Val Loss: 0.158910\n",
      "Epoch [200/500] | Train Loss: 0.377036 | Val Loss: 0.156240\n",
      "Epoch [300/500] | Train Loss: 0.377363 | Val Loss: 0.157373\n",
      "Epoch [400/500] | Train Loss: 0.373460 | Val Loss: 0.157309\n",
      "Epoch [500/500] | Train Loss: 0.351739 | Val Loss: 0.159532\n",
      "Epoch [100/500] | Train Loss: 0.351481 | Val Loss: 0.270617\n",
      "Epoch [200/500] | Train Loss: 0.336460 | Val Loss: 0.262431\n",
      "Epoch [300/500] | Train Loss: 0.339303 | Val Loss: 0.263343\n",
      "Epoch [400/500] | Train Loss: 0.317075 | Val Loss: 0.263398\n",
      "Epoch [500/500] | Train Loss: 0.313709 | Val Loss: 0.264739\n",
      "Epoch [100/500] | Train Loss: 0.295371 | Val Loss: 0.536636\n",
      "Epoch [200/500] | Train Loss: 0.261588 | Val Loss: 0.552806\n",
      "Epoch [300/500] | Train Loss: 0.198409 | Val Loss: 0.589036\n",
      "Epoch [400/500] | Train Loss: 0.189652 | Val Loss: 0.591409\n",
      "Epoch [500/500] | Train Loss: 0.200621 | Val Loss: 0.590831\n",
      "Epoch [100/500] | Train Loss: 0.343701 | Val Loss: 0.493366\n",
      "Epoch [200/500] | Train Loss: 0.299520 | Val Loss: 0.516404\n",
      "Epoch [300/500] | Train Loss: 0.285874 | Val Loss: 0.537267\n",
      "Epoch [400/500] | Train Loss: 0.243144 | Val Loss: 0.587052\n",
      "Epoch [500/500] | Train Loss: 0.288039 | Val Loss: 0.538629\n",
      "Epoch [100/500] | Train Loss: 0.371201 | Val Loss: 0.270160\n",
      "Epoch [200/500] | Train Loss: 0.361390 | Val Loss: 0.280088\n",
      "Epoch [300/500] | Train Loss: 0.334525 | Val Loss: 0.305431\n",
      "Epoch [400/500] | Train Loss: 0.320123 | Val Loss: 0.289663\n",
      "Epoch [500/500] | Train Loss: 0.334171 | Val Loss: 0.286709\n",
      "Epoch [100/500] | Train Loss: 0.377607 | Val Loss: 0.158132\n",
      "Epoch [200/500] | Train Loss: 0.350502 | Val Loss: 0.168023\n",
      "Epoch [300/500] | Train Loss: 0.355018 | Val Loss: 0.169761\n",
      "Epoch [400/500] | Train Loss: 0.335771 | Val Loss: 0.178903\n",
      "Epoch [500/500] | Train Loss: 0.318854 | Val Loss: 0.178968\n",
      "Epoch [100/500] | Train Loss: 0.323967 | Val Loss: 0.266165\n",
      "Epoch [200/500] | Train Loss: 0.305872 | Val Loss: 0.275371\n",
      "Epoch [300/500] | Train Loss: 0.303582 | Val Loss: 0.279154\n",
      "Epoch [400/500] | Train Loss: 0.289732 | Val Loss: 0.278534\n",
      "Epoch [500/500] | Train Loss: 0.279674 | Val Loss: 0.286899\n",
      "Epoch [100/500] | Train Loss: 0.300130 | Val Loss: 0.551049\n",
      "Epoch [200/500] | Train Loss: 0.261619 | Val Loss: 0.557425\n",
      "Epoch [300/500] | Train Loss: 0.216508 | Val Loss: 0.586583\n",
      "Epoch [400/500] | Train Loss: 0.192431 | Val Loss: 0.576701\n",
      "Epoch [500/500] | Train Loss: 0.176799 | Val Loss: 0.594473\n",
      "Epoch [100/500] | Train Loss: 0.378821 | Val Loss: 0.502374\n",
      "Epoch [200/500] | Train Loss: 0.303256 | Val Loss: 0.519872\n",
      "Epoch [300/500] | Train Loss: 0.281972 | Val Loss: 0.506239\n",
      "Epoch [400/500] | Train Loss: 0.262083 | Val Loss: 0.513346\n",
      "Epoch [500/500] | Train Loss: 0.241341 | Val Loss: 0.518614\n",
      "Epoch [100/500] | Train Loss: 0.420067 | Val Loss: 0.252353\n",
      "Epoch [200/500] | Train Loss: 0.367538 | Val Loss: 0.262157\n",
      "Epoch [300/500] | Train Loss: 0.339335 | Val Loss: 0.276358\n",
      "Epoch [400/500] | Train Loss: 0.327404 | Val Loss: 0.281256\n",
      "Epoch [500/500] | Train Loss: 0.314094 | Val Loss: 0.288691\n",
      "Epoch [100/500] | Train Loss: 0.398323 | Val Loss: 0.158508\n",
      "Epoch [200/500] | Train Loss: 0.373854 | Val Loss: 0.163409\n",
      "Epoch [300/500] | Train Loss: 0.341069 | Val Loss: 0.169182\n",
      "Epoch [400/500] | Train Loss: 0.309556 | Val Loss: 0.176625\n",
      "Epoch [500/500] | Train Loss: 0.300552 | Val Loss: 0.177617\n",
      "Epoch [100/500] | Train Loss: 0.342970 | Val Loss: 0.265820\n",
      "Epoch [200/500] | Train Loss: 0.298890 | Val Loss: 0.258644\n",
      "Epoch [300/500] | Train Loss: 0.287073 | Val Loss: 0.274867\n",
      "Epoch [400/500] | Train Loss: 0.277264 | Val Loss: 0.283559\n",
      "Epoch [500/500] | Train Loss: 0.266913 | Val Loss: 0.293866\n",
      "Epoch [100/500] | Train Loss: 0.199540 | Val Loss: 0.550990\n",
      "Epoch [200/500] | Train Loss: 0.148676 | Val Loss: 0.520286\n",
      "Epoch [300/500] | Train Loss: 0.103623 | Val Loss: 0.536545\n",
      "Epoch [400/500] | Train Loss: 0.101144 | Val Loss: 0.593172\n",
      "Epoch [500/500] | Train Loss: 0.109340 | Val Loss: 0.614597\n",
      "Epoch [100/500] | Train Loss: 0.284009 | Val Loss: 0.490171\n",
      "Epoch [200/500] | Train Loss: 0.201372 | Val Loss: 0.558271\n",
      "Epoch [300/500] | Train Loss: 0.173642 | Val Loss: 0.637308\n",
      "Epoch [400/500] | Train Loss: 0.179514 | Val Loss: 0.624356\n",
      "Epoch [500/500] | Train Loss: 0.165741 | Val Loss: 0.530618\n",
      "Epoch [100/500] | Train Loss: 0.277006 | Val Loss: 0.359006\n",
      "Epoch [200/500] | Train Loss: 0.231053 | Val Loss: 0.331140\n",
      "Epoch [300/500] | Train Loss: 0.206525 | Val Loss: 0.345097\n",
      "Epoch [400/500] | Train Loss: 0.187890 | Val Loss: 0.335169\n",
      "Epoch [500/500] | Train Loss: 0.210550 | Val Loss: 0.323038\n",
      "Epoch [100/500] | Train Loss: 0.295983 | Val Loss: 0.180249\n",
      "Epoch [200/500] | Train Loss: 0.244130 | Val Loss: 0.192349\n",
      "Epoch [300/500] | Train Loss: 0.226597 | Val Loss: 0.222188\n",
      "Epoch [400/500] | Train Loss: 0.206224 | Val Loss: 0.229652\n",
      "Epoch [500/500] | Train Loss: 0.200669 | Val Loss: 0.216830\n",
      "Epoch [100/500] | Train Loss: 0.273139 | Val Loss: 0.289858\n",
      "Epoch [200/500] | Train Loss: 0.249519 | Val Loss: 0.291468\n",
      "Epoch [300/500] | Train Loss: 0.199472 | Val Loss: 0.288716\n",
      "Epoch [400/500] | Train Loss: 0.198977 | Val Loss: 0.327525\n",
      "Epoch [500/500] | Train Loss: 0.184416 | Val Loss: 0.305952\n",
      "Epoch [100/500] | Train Loss: 0.323846 | Val Loss: 0.539620\n",
      "Epoch [200/500] | Train Loss: 0.289335 | Val Loss: 0.526712\n",
      "Epoch [300/500] | Train Loss: 0.262545 | Val Loss: 0.539069\n",
      "Epoch [400/500] | Train Loss: 0.257417 | Val Loss: 0.528982\n",
      "Epoch [500/500] | Train Loss: 0.224406 | Val Loss: 0.525546\n",
      "Epoch [100/500] | Train Loss: 0.407399 | Val Loss: 0.504403\n",
      "Epoch [200/500] | Train Loss: 0.369444 | Val Loss: 0.512211\n",
      "Epoch [300/500] | Train Loss: 0.317338 | Val Loss: 0.519769\n",
      "Epoch [400/500] | Train Loss: 0.324339 | Val Loss: 0.521010\n",
      "Epoch [500/500] | Train Loss: 0.306627 | Val Loss: 0.521521\n",
      "Epoch [100/500] | Train Loss: 0.460048 | Val Loss: 0.276278\n",
      "Epoch [200/500] | Train Loss: 0.436348 | Val Loss: 0.264449\n",
      "Epoch [300/500] | Train Loss: 0.408089 | Val Loss: 0.268570\n",
      "Epoch [400/500] | Train Loss: 0.375446 | Val Loss: 0.291298\n",
      "Epoch [500/500] | Train Loss: 0.344214 | Val Loss: 0.304446\n",
      "Epoch [100/500] | Train Loss: 0.396244 | Val Loss: 0.162706\n",
      "Epoch [200/500] | Train Loss: 0.354510 | Val Loss: 0.166327\n",
      "Epoch [300/500] | Train Loss: 0.345885 | Val Loss: 0.176512\n",
      "Epoch [400/500] | Train Loss: 0.321084 | Val Loss: 0.182452\n",
      "Epoch [500/500] | Train Loss: 0.314516 | Val Loss: 0.184239\n",
      "Epoch [100/500] | Train Loss: 0.357707 | Val Loss: 0.262871\n",
      "Epoch [200/500] | Train Loss: 0.346468 | Val Loss: 0.262392\n",
      "Epoch [300/500] | Train Loss: 0.332013 | Val Loss: 0.262309\n",
      "Epoch [400/500] | Train Loss: 0.306692 | Val Loss: 0.266887\n",
      "Epoch [500/500] | Train Loss: 0.294468 | Val Loss: 0.270796\n",
      "Epoch [100/500] | Train Loss: 0.244356 | Val Loss: 0.535657\n",
      "Epoch [200/500] | Train Loss: 0.214817 | Val Loss: 0.542218\n",
      "Epoch [300/500] | Train Loss: 0.201900 | Val Loss: 0.538626\n",
      "Epoch [400/500] | Train Loss: 0.194869 | Val Loss: 0.559981\n",
      "Epoch [500/500] | Train Loss: 0.169415 | Val Loss: 0.558072\n",
      "Epoch [100/500] | Train Loss: 0.306136 | Val Loss: 0.478768\n",
      "Epoch [200/500] | Train Loss: 0.255291 | Val Loss: 0.476703\n",
      "Epoch [300/500] | Train Loss: 0.216305 | Val Loss: 0.478434\n",
      "Epoch [400/500] | Train Loss: 0.245684 | Val Loss: 0.498780\n",
      "Epoch [500/500] | Train Loss: 0.182559 | Val Loss: 0.549864\n",
      "Epoch [100/500] | Train Loss: 0.344871 | Val Loss: 0.269533\n",
      "Epoch [200/500] | Train Loss: 0.305859 | Val Loss: 0.286989\n",
      "Epoch [300/500] | Train Loss: 0.295370 | Val Loss: 0.291290\n",
      "Epoch [400/500] | Train Loss: 0.292220 | Val Loss: 0.277210\n",
      "Epoch [500/500] | Train Loss: 0.290894 | Val Loss: 0.293966\n",
      "Epoch [100/500] | Train Loss: 0.385619 | Val Loss: 0.161977\n",
      "Epoch [200/500] | Train Loss: 0.337286 | Val Loss: 0.163014\n",
      "Epoch [300/500] | Train Loss: 0.315226 | Val Loss: 0.177387\n",
      "Epoch [400/500] | Train Loss: 0.309269 | Val Loss: 0.183019\n",
      "Epoch [500/500] | Train Loss: 0.264876 | Val Loss: 0.182223\n",
      "Epoch [100/500] | Train Loss: 0.291770 | Val Loss: 0.276818\n",
      "Epoch [200/500] | Train Loss: 0.274220 | Val Loss: 0.284156\n",
      "Epoch [300/500] | Train Loss: 0.253993 | Val Loss: 0.299535\n",
      "Epoch [400/500] | Train Loss: 0.251680 | Val Loss: 0.305564\n",
      "Epoch [500/500] | Train Loss: 0.227206 | Val Loss: 0.293338\n",
      "[Year=1954] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.346551 Test MSE=0.226907\n",
      "Year 1954 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.510034 | Val Loss: 0.512311\n",
      "Epoch [200/500] | Train Loss: 0.422520 | Val Loss: 0.544175\n",
      "Epoch [300/500] | Train Loss: 0.399243 | Val Loss: 0.567304\n",
      "Epoch [400/500] | Train Loss: 0.348815 | Val Loss: 0.582763\n",
      "Epoch [500/500] | Train Loss: 0.337907 | Val Loss: 0.591704\n",
      "Epoch [100/500] | Train Loss: 0.502462 | Val Loss: 0.253827\n",
      "Epoch [200/500] | Train Loss: 0.426970 | Val Loss: 0.288624\n",
      "Epoch [300/500] | Train Loss: 0.375457 | Val Loss: 0.309934\n",
      "Epoch [400/500] | Train Loss: 0.343847 | Val Loss: 0.320749\n",
      "Epoch [500/500] | Train Loss: 0.307433 | Val Loss: 0.328576\n",
      "Epoch [100/500] | Train Loss: 0.416198 | Val Loss: 0.135695\n",
      "Epoch [200/500] | Train Loss: 0.387508 | Val Loss: 0.140690\n",
      "Epoch [300/500] | Train Loss: 0.354111 | Val Loss: 0.144609\n",
      "Epoch [400/500] | Train Loss: 0.320587 | Val Loss: 0.151750\n",
      "Epoch [500/500] | Train Loss: 0.332045 | Val Loss: 0.151338\n",
      "Epoch [100/500] | Train Loss: 0.343750 | Val Loss: 0.263996\n",
      "Epoch [200/500] | Train Loss: 0.315276 | Val Loss: 0.256833\n",
      "Epoch [300/500] | Train Loss: 0.284880 | Val Loss: 0.274898\n",
      "Epoch [400/500] | Train Loss: 0.288490 | Val Loss: 0.287922\n",
      "Epoch [500/500] | Train Loss: 0.277022 | Val Loss: 0.291327\n",
      "Epoch [100/500] | Train Loss: 0.342186 | Val Loss: 0.227531\n",
      "Epoch [200/500] | Train Loss: 0.325027 | Val Loss: 0.219468\n",
      "Epoch [300/500] | Train Loss: 0.306660 | Val Loss: 0.225313\n",
      "Epoch [400/500] | Train Loss: 0.284293 | Val Loss: 0.237306\n",
      "Epoch [500/500] | Train Loss: 0.272139 | Val Loss: 0.237957\n",
      "Epoch [100/500] | Train Loss: 0.313122 | Val Loss: 0.606201\n",
      "Epoch [200/500] | Train Loss: 0.285952 | Val Loss: 0.627148\n",
      "Epoch [300/500] | Train Loss: 0.191957 | Val Loss: 0.807409\n",
      "Epoch [400/500] | Train Loss: 0.168418 | Val Loss: 0.684569\n",
      "Epoch [500/500] | Train Loss: 0.153881 | Val Loss: 0.765725\n",
      "Epoch [100/500] | Train Loss: 0.364553 | Val Loss: 0.320918\n",
      "Epoch [200/500] | Train Loss: 0.280854 | Val Loss: 0.321776\n",
      "Epoch [300/500] | Train Loss: 0.285263 | Val Loss: 0.309944\n",
      "Epoch [400/500] | Train Loss: 0.282101 | Val Loss: 0.307896\n",
      "Epoch [500/500] | Train Loss: 0.252108 | Val Loss: 0.320616\n",
      "Epoch [100/500] | Train Loss: 0.335763 | Val Loss: 0.143099\n",
      "Epoch [200/500] | Train Loss: 0.276753 | Val Loss: 0.174014\n",
      "Epoch [300/500] | Train Loss: 0.242747 | Val Loss: 0.159092\n",
      "Epoch [400/500] | Train Loss: 0.196538 | Val Loss: 0.213247\n",
      "Epoch [500/500] | Train Loss: 0.203136 | Val Loss: 0.173557\n",
      "Epoch [100/500] | Train Loss: 0.294716 | Val Loss: 0.276061\n",
      "Epoch [200/500] | Train Loss: 0.274965 | Val Loss: 0.282258\n",
      "Epoch [300/500] | Train Loss: 0.258417 | Val Loss: 0.299409\n",
      "Epoch [400/500] | Train Loss: 0.208474 | Val Loss: 0.302331\n",
      "Epoch [500/500] | Train Loss: 0.206358 | Val Loss: 0.300838\n",
      "Epoch [100/500] | Train Loss: 0.290198 | Val Loss: 0.235717\n",
      "Epoch [200/500] | Train Loss: 0.258551 | Val Loss: 0.248182\n",
      "Epoch [300/500] | Train Loss: 0.235613 | Val Loss: 0.242139\n",
      "Epoch [400/500] | Train Loss: 0.216795 | Val Loss: 0.263099\n",
      "Epoch [500/500] | Train Loss: 0.215095 | Val Loss: 0.255304\n",
      "Epoch [100/500] | Train Loss: 0.534488 | Val Loss: 0.533280\n",
      "Epoch [200/500] | Train Loss: 0.422038 | Val Loss: 0.548899\n",
      "Epoch [300/500] | Train Loss: 0.426800 | Val Loss: 0.553019\n",
      "Epoch [400/500] | Train Loss: 0.397887 | Val Loss: 0.553798\n",
      "Epoch [500/500] | Train Loss: 0.392728 | Val Loss: 0.549268\n",
      "Epoch [100/500] | Train Loss: 0.498490 | Val Loss: 0.252995\n",
      "Epoch [200/500] | Train Loss: 0.488430 | Val Loss: 0.260367\n",
      "Epoch [300/500] | Train Loss: 0.418638 | Val Loss: 0.277359\n",
      "Epoch [400/500] | Train Loss: 0.389504 | Val Loss: 0.293433\n",
      "Epoch [500/500] | Train Loss: 0.397087 | Val Loss: 0.302291\n",
      "Epoch [100/500] | Train Loss: 0.469633 | Val Loss: 0.152674\n",
      "Epoch [200/500] | Train Loss: 0.440359 | Val Loss: 0.138197\n",
      "Epoch [300/500] | Train Loss: 0.417396 | Val Loss: 0.138526\n",
      "Epoch [400/500] | Train Loss: 0.397818 | Val Loss: 0.136890\n",
      "Epoch [500/500] | Train Loss: 0.370187 | Val Loss: 0.138005\n",
      "Epoch [100/500] | Train Loss: 0.358259 | Val Loss: 0.277638\n",
      "Epoch [200/500] | Train Loss: 0.342034 | Val Loss: 0.270087\n",
      "Epoch [300/500] | Train Loss: 0.317866 | Val Loss: 0.270990\n",
      "Epoch [400/500] | Train Loss: 0.308672 | Val Loss: 0.267009\n",
      "Epoch [500/500] | Train Loss: 0.297804 | Val Loss: 0.263803\n",
      "Epoch [100/500] | Train Loss: 0.343473 | Val Loss: 0.233386\n",
      "Epoch [200/500] | Train Loss: 0.327941 | Val Loss: 0.225455\n",
      "Epoch [300/500] | Train Loss: 0.327792 | Val Loss: 0.231580\n",
      "Epoch [400/500] | Train Loss: 0.299531 | Val Loss: 0.233754\n",
      "Epoch [500/500] | Train Loss: 0.300000 | Val Loss: 0.236905\n",
      "Epoch [100/500] | Train Loss: 0.351949 | Val Loss: 0.558200\n",
      "Epoch [200/500] | Train Loss: 0.282356 | Val Loss: 0.582445\n",
      "Epoch [300/500] | Train Loss: 0.219360 | Val Loss: 0.585496\n",
      "Epoch [400/500] | Train Loss: 0.346125 | Val Loss: 0.625524\n",
      "Epoch [500/500] | Train Loss: 0.268014 | Val Loss: 0.590196\n",
      "Epoch [100/500] | Train Loss: 0.432200 | Val Loss: 0.285716\n",
      "Epoch [200/500] | Train Loss: 0.341405 | Val Loss: 0.289990\n",
      "Epoch [300/500] | Train Loss: 0.369217 | Val Loss: 0.337215\n",
      "Epoch [400/500] | Train Loss: 0.326971 | Val Loss: 0.313675\n",
      "Epoch [500/500] | Train Loss: 0.273509 | Val Loss: 0.324776\n",
      "Epoch [100/500] | Train Loss: 0.397880 | Val Loss: 0.135212\n",
      "Epoch [200/500] | Train Loss: 0.372387 | Val Loss: 0.147605\n",
      "Epoch [300/500] | Train Loss: 0.336037 | Val Loss: 0.162602\n",
      "Epoch [400/500] | Train Loss: 0.306120 | Val Loss: 0.182198\n",
      "Epoch [500/500] | Train Loss: 0.289157 | Val Loss: 0.170439\n",
      "Epoch [100/500] | Train Loss: 0.308934 | Val Loss: 0.274794\n",
      "Epoch [200/500] | Train Loss: 0.287980 | Val Loss: 0.283394\n",
      "Epoch [300/500] | Train Loss: 0.276339 | Val Loss: 0.288463\n",
      "Epoch [400/500] | Train Loss: 0.252643 | Val Loss: 0.287588\n",
      "Epoch [500/500] | Train Loss: 0.258185 | Val Loss: 0.288495\n",
      "Epoch [100/500] | Train Loss: 0.307743 | Val Loss: 0.229160\n",
      "Epoch [200/500] | Train Loss: 0.289569 | Val Loss: 0.236811\n",
      "Epoch [300/500] | Train Loss: 0.258262 | Val Loss: 0.244537\n",
      "Epoch [400/500] | Train Loss: 0.274514 | Val Loss: 0.232974\n",
      "Epoch [500/500] | Train Loss: 0.265865 | Val Loss: 0.246292\n",
      "Epoch [100/500] | Train Loss: 0.463266 | Val Loss: 0.533494\n",
      "Epoch [200/500] | Train Loss: 0.358470 | Val Loss: 0.567153\n",
      "Epoch [300/500] | Train Loss: 0.307761 | Val Loss: 0.584179\n",
      "Epoch [400/500] | Train Loss: 0.280521 | Val Loss: 0.601847\n",
      "Epoch [500/500] | Train Loss: 0.200315 | Val Loss: 0.639185\n",
      "Epoch [100/500] | Train Loss: 0.481044 | Val Loss: 0.246788\n",
      "Epoch [200/500] | Train Loss: 0.433671 | Val Loss: 0.273038\n",
      "Epoch [300/500] | Train Loss: 0.355436 | Val Loss: 0.305004\n",
      "Epoch [400/500] | Train Loss: 0.326051 | Val Loss: 0.336438\n",
      "Epoch [500/500] | Train Loss: 0.309492 | Val Loss: 0.330623\n",
      "Epoch [100/500] | Train Loss: 0.414739 | Val Loss: 0.132754\n",
      "Epoch [200/500] | Train Loss: 0.364461 | Val Loss: 0.140658\n",
      "Epoch [300/500] | Train Loss: 0.325554 | Val Loss: 0.150366\n",
      "Epoch [400/500] | Train Loss: 0.308723 | Val Loss: 0.158115\n",
      "Epoch [500/500] | Train Loss: 0.272433 | Val Loss: 0.165646\n",
      "Epoch [100/500] | Train Loss: 0.365422 | Val Loss: 0.276934\n",
      "Epoch [200/500] | Train Loss: 0.331002 | Val Loss: 0.274570\n",
      "Epoch [300/500] | Train Loss: 0.310359 | Val Loss: 0.279524\n",
      "Epoch [400/500] | Train Loss: 0.284747 | Val Loss: 0.298701\n",
      "Epoch [500/500] | Train Loss: 0.268310 | Val Loss: 0.308780\n",
      "Epoch [100/500] | Train Loss: 0.329199 | Val Loss: 0.222887\n",
      "Epoch [200/500] | Train Loss: 0.293942 | Val Loss: 0.247775\n",
      "Epoch [300/500] | Train Loss: 0.277113 | Val Loss: 0.249889\n",
      "Epoch [400/500] | Train Loss: 0.261790 | Val Loss: 0.256764\n",
      "Epoch [500/500] | Train Loss: 0.255175 | Val Loss: 0.252316\n",
      "Epoch [100/500] | Train Loss: 0.255921 | Val Loss: 0.684402\n",
      "Epoch [200/500] | Train Loss: 0.170743 | Val Loss: 0.673528\n",
      "Epoch [300/500] | Train Loss: 0.206435 | Val Loss: 0.754304\n",
      "Epoch [400/500] | Train Loss: 0.160670 | Val Loss: 0.727927\n",
      "Epoch [500/500] | Train Loss: 0.098631 | Val Loss: 0.850913\n",
      "Epoch [100/500] | Train Loss: 0.318618 | Val Loss: 0.337159\n",
      "Epoch [200/500] | Train Loss: 0.268997 | Val Loss: 0.379307\n",
      "Epoch [300/500] | Train Loss: 0.243959 | Val Loss: 0.402146\n",
      "Epoch [400/500] | Train Loss: 0.206750 | Val Loss: 0.408393\n",
      "Epoch [500/500] | Train Loss: 0.198437 | Val Loss: 0.410656\n",
      "Epoch [100/500] | Train Loss: 0.361114 | Val Loss: 0.139624\n",
      "Epoch [200/500] | Train Loss: 0.292158 | Val Loss: 0.158267\n",
      "Epoch [300/500] | Train Loss: 0.238521 | Val Loss: 0.158778\n",
      "Epoch [400/500] | Train Loss: 0.234486 | Val Loss: 0.183565\n",
      "Epoch [500/500] | Train Loss: 0.182256 | Val Loss: 0.194304\n",
      "Epoch [100/500] | Train Loss: 0.258978 | Val Loss: 0.291265\n",
      "Epoch [200/500] | Train Loss: 0.223057 | Val Loss: 0.319367\n",
      "Epoch [300/500] | Train Loss: 0.167662 | Val Loss: 0.346620\n",
      "Epoch [400/500] | Train Loss: 0.158134 | Val Loss: 0.356902\n",
      "Epoch [500/500] | Train Loss: 0.173981 | Val Loss: 0.361924\n",
      "Epoch [100/500] | Train Loss: 0.266863 | Val Loss: 0.234616\n",
      "Epoch [200/500] | Train Loss: 0.243553 | Val Loss: 0.284469\n",
      "Epoch [300/500] | Train Loss: 0.192583 | Val Loss: 0.268015\n",
      "Epoch [400/500] | Train Loss: 0.206278 | Val Loss: 0.273664\n",
      "Epoch [500/500] | Train Loss: 0.181926 | Val Loss: 0.257764\n",
      "Epoch [100/500] | Train Loss: 0.479507 | Val Loss: 0.532014\n",
      "Epoch [200/500] | Train Loss: 0.405648 | Val Loss: 0.564100\n",
      "Epoch [300/500] | Train Loss: 0.415126 | Val Loss: 0.546165\n",
      "Epoch [400/500] | Train Loss: 0.384179 | Val Loss: 0.547414\n",
      "Epoch [500/500] | Train Loss: 0.343376 | Val Loss: 0.538630\n",
      "Epoch [100/500] | Train Loss: 0.524518 | Val Loss: 0.248726\n",
      "Epoch [200/500] | Train Loss: 0.462753 | Val Loss: 0.278124\n",
      "Epoch [300/500] | Train Loss: 0.426860 | Val Loss: 0.287686\n",
      "Epoch [400/500] | Train Loss: 0.393944 | Val Loss: 0.301734\n",
      "Epoch [500/500] | Train Loss: 0.386044 | Val Loss: 0.301160\n",
      "Epoch [100/500] | Train Loss: 0.437001 | Val Loss: 0.137739\n",
      "Epoch [200/500] | Train Loss: 0.395942 | Val Loss: 0.135338\n",
      "Epoch [300/500] | Train Loss: 0.350617 | Val Loss: 0.139781\n",
      "Epoch [400/500] | Train Loss: 0.356359 | Val Loss: 0.146953\n",
      "Epoch [500/500] | Train Loss: 0.328933 | Val Loss: 0.147176\n",
      "Epoch [100/500] | Train Loss: 0.340724 | Val Loss: 0.273635\n",
      "Epoch [200/500] | Train Loss: 0.315994 | Val Loss: 0.274668\n",
      "Epoch [300/500] | Train Loss: 0.307628 | Val Loss: 0.277332\n",
      "Epoch [400/500] | Train Loss: 0.297572 | Val Loss: 0.278590\n",
      "Epoch [500/500] | Train Loss: 0.280332 | Val Loss: 0.282141\n",
      "Epoch [100/500] | Train Loss: 0.352024 | Val Loss: 0.231335\n",
      "Epoch [200/500] | Train Loss: 0.324546 | Val Loss: 0.223110\n",
      "Epoch [300/500] | Train Loss: 0.322193 | Val Loss: 0.229362\n",
      "Epoch [400/500] | Train Loss: 0.313315 | Val Loss: 0.231782\n",
      "Epoch [500/500] | Train Loss: 0.293295 | Val Loss: 0.230684\n",
      "Epoch [100/500] | Train Loss: 0.375141 | Val Loss: 0.529511\n",
      "Epoch [200/500] | Train Loss: 0.264198 | Val Loss: 0.641401\n",
      "Epoch [300/500] | Train Loss: 0.241822 | Val Loss: 0.614347\n",
      "Epoch [400/500] | Train Loss: 0.235373 | Val Loss: 0.650804\n",
      "Epoch [500/500] | Train Loss: 0.236073 | Val Loss: 0.655086\n",
      "Epoch [100/500] | Train Loss: 0.445836 | Val Loss: 0.251808\n",
      "Epoch [200/500] | Train Loss: 0.421447 | Val Loss: 0.262102\n",
      "Epoch [300/500] | Train Loss: 0.435326 | Val Loss: 0.283503\n",
      "Epoch [400/500] | Train Loss: 0.375907 | Val Loss: 0.284042\n",
      "Epoch [500/500] | Train Loss: 0.353245 | Val Loss: 0.296746\n",
      "Epoch [100/500] | Train Loss: 0.356275 | Val Loss: 0.137780\n",
      "Epoch [200/500] | Train Loss: 0.320492 | Val Loss: 0.160751\n",
      "Epoch [300/500] | Train Loss: 0.290451 | Val Loss: 0.160962\n",
      "Epoch [400/500] | Train Loss: 0.294569 | Val Loss: 0.158026\n",
      "Epoch [500/500] | Train Loss: 0.252754 | Val Loss: 0.165452\n",
      "Epoch [100/500] | Train Loss: 0.328856 | Val Loss: 0.267640\n",
      "Epoch [200/500] | Train Loss: 0.275423 | Val Loss: 0.291305\n",
      "Epoch [300/500] | Train Loss: 0.250357 | Val Loss: 0.303100\n",
      "Epoch [400/500] | Train Loss: 0.232552 | Val Loss: 0.305505\n",
      "Epoch [500/500] | Train Loss: 0.228905 | Val Loss: 0.311019\n",
      "Epoch [100/500] | Train Loss: 0.303726 | Val Loss: 0.224784\n",
      "Epoch [200/500] | Train Loss: 0.259014 | Val Loss: 0.236626\n",
      "Epoch [300/500] | Train Loss: 0.259183 | Val Loss: 0.225101\n",
      "Epoch [400/500] | Train Loss: 0.238941 | Val Loss: 0.241252\n",
      "Epoch [500/500] | Train Loss: 0.229877 | Val Loss: 0.314742\n",
      "[Year=1955] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.298055 Test MSE=0.578103\n",
      "Year 1955 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.290764 | Val Loss: 0.236111\n",
      "Epoch [200/500] | Train Loss: 0.220867 | Val Loss: 0.293861\n",
      "Epoch [300/500] | Train Loss: 0.205331 | Val Loss: 0.325327\n",
      "Epoch [400/500] | Train Loss: 0.172922 | Val Loss: 0.350138\n",
      "Epoch [500/500] | Train Loss: 0.163547 | Val Loss: 0.368106\n",
      "Epoch [100/500] | Train Loss: 0.267247 | Val Loss: 0.199959\n",
      "Epoch [200/500] | Train Loss: 0.251944 | Val Loss: 0.205468\n",
      "Epoch [300/500] | Train Loss: 0.224623 | Val Loss: 0.230810\n",
      "Epoch [400/500] | Train Loss: 0.189885 | Val Loss: 0.250589\n",
      "Epoch [500/500] | Train Loss: 0.193118 | Val Loss: 0.271723\n",
      "Epoch [100/500] | Train Loss: 0.237778 | Val Loss: 0.223395\n",
      "Epoch [200/500] | Train Loss: 0.218711 | Val Loss: 0.220932\n",
      "Epoch [300/500] | Train Loss: 0.197089 | Val Loss: 0.223098\n",
      "Epoch [400/500] | Train Loss: 0.188213 | Val Loss: 0.220813\n",
      "Epoch [500/500] | Train Loss: 0.182407 | Val Loss: 0.219763\n",
      "Epoch [100/500] | Train Loss: 0.231355 | Val Loss: 0.282536\n",
      "Epoch [200/500] | Train Loss: 0.218190 | Val Loss: 0.289516\n",
      "Epoch [300/500] | Train Loss: 0.207463 | Val Loss: 0.299699\n",
      "Epoch [400/500] | Train Loss: 0.203272 | Val Loss: 0.302435\n",
      "Epoch [500/500] | Train Loss: 0.191333 | Val Loss: 0.311018\n",
      "Epoch [100/500] | Train Loss: 0.246486 | Val Loss: 0.591065\n",
      "Epoch [200/500] | Train Loss: 0.242162 | Val Loss: 0.585264\n",
      "Epoch [300/500] | Train Loss: 0.229152 | Val Loss: 0.580463\n",
      "Epoch [400/500] | Train Loss: 0.230510 | Val Loss: 0.572108\n",
      "Epoch [500/500] | Train Loss: 0.215131 | Val Loss: 0.592406\n",
      "Epoch [100/500] | Train Loss: 0.159788 | Val Loss: 0.390472\n",
      "Epoch [200/500] | Train Loss: 0.120221 | Val Loss: 0.405536\n",
      "Epoch [300/500] | Train Loss: 0.136883 | Val Loss: 0.434306\n",
      "Epoch [400/500] | Train Loss: 0.094120 | Val Loss: 0.418019\n",
      "Epoch [500/500] | Train Loss: 0.077877 | Val Loss: 0.439189\n",
      "Epoch [100/500] | Train Loss: 0.180445 | Val Loss: 0.255524\n",
      "Epoch [200/500] | Train Loss: 0.146535 | Val Loss: 0.279520\n",
      "Epoch [300/500] | Train Loss: 0.121280 | Val Loss: 0.305621\n",
      "Epoch [400/500] | Train Loss: 0.130459 | Val Loss: 0.281816\n",
      "Epoch [500/500] | Train Loss: 0.099906 | Val Loss: 0.297568\n",
      "Epoch [100/500] | Train Loss: 0.199938 | Val Loss: 0.217173\n",
      "Epoch [200/500] | Train Loss: 0.167033 | Val Loss: 0.217819\n",
      "Epoch [300/500] | Train Loss: 0.150541 | Val Loss: 0.235982\n",
      "Epoch [400/500] | Train Loss: 0.124123 | Val Loss: 0.243325\n",
      "Epoch [500/500] | Train Loss: 0.136928 | Val Loss: 0.251291\n",
      "Epoch [100/500] | Train Loss: 0.221012 | Val Loss: 0.298169\n",
      "Epoch [200/500] | Train Loss: 0.203957 | Val Loss: 0.315100\n",
      "Epoch [300/500] | Train Loss: 0.184504 | Val Loss: 0.331241\n",
      "Epoch [400/500] | Train Loss: 0.180995 | Val Loss: 0.320775\n",
      "Epoch [500/500] | Train Loss: 0.167578 | Val Loss: 0.339666\n",
      "Epoch [100/500] | Train Loss: 0.219454 | Val Loss: 0.607107\n",
      "Epoch [200/500] | Train Loss: 0.193555 | Val Loss: 0.621724\n",
      "Epoch [300/500] | Train Loss: 0.167585 | Val Loss: 0.669738\n",
      "Epoch [400/500] | Train Loss: 0.172997 | Val Loss: 0.710907\n",
      "Epoch [500/500] | Train Loss: 0.160101 | Val Loss: 0.687851\n",
      "Epoch [100/500] | Train Loss: 0.311123 | Val Loss: 0.233830\n",
      "Epoch [200/500] | Train Loss: 0.275697 | Val Loss: 0.264880\n",
      "Epoch [300/500] | Train Loss: 0.254880 | Val Loss: 0.295573\n",
      "Epoch [400/500] | Train Loss: 0.208072 | Val Loss: 0.305674\n",
      "Epoch [500/500] | Train Loss: 0.191311 | Val Loss: 0.328251\n",
      "Epoch [100/500] | Train Loss: 0.265739 | Val Loss: 0.193464\n",
      "Epoch [200/500] | Train Loss: 0.248985 | Val Loss: 0.196200\n",
      "Epoch [300/500] | Train Loss: 0.235479 | Val Loss: 0.207223\n",
      "Epoch [400/500] | Train Loss: 0.227776 | Val Loss: 0.216595\n",
      "Epoch [500/500] | Train Loss: 0.222937 | Val Loss: 0.222966\n",
      "Epoch [100/500] | Train Loss: 0.262572 | Val Loss: 0.246473\n",
      "Epoch [200/500] | Train Loss: 0.240550 | Val Loss: 0.229381\n",
      "Epoch [300/500] | Train Loss: 0.237256 | Val Loss: 0.226178\n",
      "Epoch [400/500] | Train Loss: 0.234567 | Val Loss: 0.224246\n",
      "Epoch [500/500] | Train Loss: 0.224151 | Val Loss: 0.222182\n",
      "Epoch [100/500] | Train Loss: 0.241449 | Val Loss: 0.290420\n",
      "Epoch [200/500] | Train Loss: 0.232385 | Val Loss: 0.283845\n",
      "Epoch [300/500] | Train Loss: 0.224947 | Val Loss: 0.286231\n",
      "Epoch [400/500] | Train Loss: 0.223650 | Val Loss: 0.291085\n",
      "Epoch [500/500] | Train Loss: 0.217198 | Val Loss: 0.291672\n",
      "Epoch [100/500] | Train Loss: 0.262154 | Val Loss: 0.594391\n",
      "Epoch [200/500] | Train Loss: 0.247368 | Val Loss: 0.587101\n",
      "Epoch [300/500] | Train Loss: 0.238314 | Val Loss: 0.587241\n",
      "Epoch [400/500] | Train Loss: 0.233289 | Val Loss: 0.595639\n",
      "Epoch [500/500] | Train Loss: 0.228739 | Val Loss: 0.602122\n",
      "Epoch [100/500] | Train Loss: 0.229358 | Val Loss: 0.301489\n",
      "Epoch [200/500] | Train Loss: 0.167212 | Val Loss: 0.329422\n",
      "Epoch [300/500] | Train Loss: 0.185512 | Val Loss: 0.324237\n",
      "Epoch [400/500] | Train Loss: 0.155338 | Val Loss: 0.332860\n",
      "Epoch [500/500] | Train Loss: 0.118886 | Val Loss: 0.300694\n",
      "Epoch [100/500] | Train Loss: 0.227392 | Val Loss: 0.214101\n",
      "Epoch [200/500] | Train Loss: 0.209953 | Val Loss: 0.240948\n",
      "Epoch [300/500] | Train Loss: 0.185915 | Val Loss: 0.255002\n",
      "Epoch [400/500] | Train Loss: 0.176662 | Val Loss: 0.272755\n",
      "Epoch [500/500] | Train Loss: 0.155785 | Val Loss: 0.255828\n",
      "Epoch [100/500] | Train Loss: 0.214000 | Val Loss: 0.227587\n",
      "Epoch [200/500] | Train Loss: 0.201228 | Val Loss: 0.232524\n",
      "Epoch [300/500] | Train Loss: 0.206779 | Val Loss: 0.225718\n",
      "Epoch [400/500] | Train Loss: 0.196037 | Val Loss: 0.228726\n",
      "Epoch [500/500] | Train Loss: 0.187302 | Val Loss: 0.237908\n",
      "Epoch [100/500] | Train Loss: 0.223381 | Val Loss: 0.295772\n",
      "Epoch [200/500] | Train Loss: 0.217293 | Val Loss: 0.312403\n",
      "Epoch [300/500] | Train Loss: 0.205119 | Val Loss: 0.315462\n",
      "Epoch [400/500] | Train Loss: 0.201398 | Val Loss: 0.313334\n",
      "Epoch [500/500] | Train Loss: 0.191902 | Val Loss: 0.321687\n",
      "Epoch [100/500] | Train Loss: 0.232705 | Val Loss: 0.584401\n",
      "Epoch [200/500] | Train Loss: 0.224985 | Val Loss: 0.589774\n",
      "Epoch [300/500] | Train Loss: 0.221542 | Val Loss: 0.576175\n",
      "Epoch [400/500] | Train Loss: 0.213882 | Val Loss: 0.579643\n",
      "Epoch [500/500] | Train Loss: 0.202766 | Val Loss: 0.574471\n",
      "Epoch [100/500] | Train Loss: 0.288680 | Val Loss: 0.233335\n",
      "Epoch [200/500] | Train Loss: 0.194760 | Val Loss: 0.285586\n",
      "Epoch [300/500] | Train Loss: 0.162119 | Val Loss: 0.346468\n",
      "Epoch [400/500] | Train Loss: 0.129313 | Val Loss: 0.369296\n",
      "Epoch [500/500] | Train Loss: 0.103800 | Val Loss: 0.377432\n",
      "Epoch [100/500] | Train Loss: 0.257686 | Val Loss: 0.194536\n",
      "Epoch [200/500] | Train Loss: 0.225495 | Val Loss: 0.227661\n",
      "Epoch [300/500] | Train Loss: 0.190961 | Val Loss: 0.252679\n",
      "Epoch [400/500] | Train Loss: 0.174980 | Val Loss: 0.268392\n",
      "Epoch [500/500] | Train Loss: 0.159794 | Val Loss: 0.278117\n",
      "Epoch [100/500] | Train Loss: 0.233564 | Val Loss: 0.220934\n",
      "Epoch [200/500] | Train Loss: 0.204720 | Val Loss: 0.218236\n",
      "Epoch [300/500] | Train Loss: 0.189694 | Val Loss: 0.216757\n",
      "Epoch [400/500] | Train Loss: 0.186924 | Val Loss: 0.218197\n",
      "Epoch [500/500] | Train Loss: 0.167467 | Val Loss: 0.219220\n",
      "Epoch [100/500] | Train Loss: 0.229076 | Val Loss: 0.283892\n",
      "Epoch [200/500] | Train Loss: 0.210775 | Val Loss: 0.287899\n",
      "Epoch [300/500] | Train Loss: 0.197883 | Val Loss: 0.304825\n",
      "Epoch [400/500] | Train Loss: 0.185448 | Val Loss: 0.316131\n",
      "Epoch [500/500] | Train Loss: 0.174712 | Val Loss: 0.314241\n",
      "Epoch [100/500] | Train Loss: 0.251332 | Val Loss: 0.594263\n",
      "Epoch [200/500] | Train Loss: 0.229233 | Val Loss: 0.592242\n",
      "Epoch [300/500] | Train Loss: 0.215550 | Val Loss: 0.609618\n",
      "Epoch [400/500] | Train Loss: 0.204724 | Val Loss: 0.615762\n",
      "Epoch [500/500] | Train Loss: 0.194215 | Val Loss: 0.627344\n",
      "Epoch [100/500] | Train Loss: 0.149720 | Val Loss: 0.353992\n",
      "Epoch [200/500] | Train Loss: 0.097392 | Val Loss: 0.373269\n",
      "Epoch [300/500] | Train Loss: 0.072146 | Val Loss: 0.409776\n",
      "Epoch [400/500] | Train Loss: 0.069998 | Val Loss: 0.394615\n",
      "Epoch [500/500] | Train Loss: 0.061101 | Val Loss: 0.368875\n",
      "Epoch [100/500] | Train Loss: 0.163772 | Val Loss: 0.291612\n",
      "Epoch [200/500] | Train Loss: 0.102885 | Val Loss: 0.329548\n",
      "Epoch [300/500] | Train Loss: 0.115880 | Val Loss: 0.335301\n",
      "Epoch [400/500] | Train Loss: 0.088155 | Val Loss: 0.335154\n",
      "Epoch [500/500] | Train Loss: 0.096592 | Val Loss: 0.336068\n",
      "Epoch [100/500] | Train Loss: 0.189383 | Val Loss: 0.246237\n",
      "Epoch [200/500] | Train Loss: 0.152339 | Val Loss: 0.252784\n",
      "Epoch [300/500] | Train Loss: 0.126183 | Val Loss: 0.253563\n",
      "Epoch [400/500] | Train Loss: 0.113835 | Val Loss: 0.270566\n",
      "Epoch [500/500] | Train Loss: 0.109272 | Val Loss: 0.267407\n",
      "Epoch [100/500] | Train Loss: 0.203630 | Val Loss: 0.303516\n",
      "Epoch [200/500] | Train Loss: 0.167603 | Val Loss: 0.328542\n",
      "Epoch [300/500] | Train Loss: 0.153327 | Val Loss: 0.355412\n",
      "Epoch [400/500] | Train Loss: 0.131522 | Val Loss: 0.341817\n",
      "Epoch [500/500] | Train Loss: 0.124467 | Val Loss: 0.336830\n",
      "Epoch [100/500] | Train Loss: 0.208167 | Val Loss: 0.563583\n",
      "Epoch [200/500] | Train Loss: 0.184261 | Val Loss: 0.590860\n",
      "Epoch [300/500] | Train Loss: 0.170960 | Val Loss: 0.728329\n",
      "Epoch [400/500] | Train Loss: 0.152694 | Val Loss: 0.669989\n",
      "Epoch [500/500] | Train Loss: 0.144440 | Val Loss: 0.698987\n",
      "Epoch [100/500] | Train Loss: 0.289525 | Val Loss: 0.236380\n",
      "Epoch [200/500] | Train Loss: 0.253278 | Val Loss: 0.283634\n",
      "Epoch [300/500] | Train Loss: 0.199615 | Val Loss: 0.302050\n",
      "Epoch [400/500] | Train Loss: 0.207903 | Val Loss: 0.322319\n",
      "Epoch [500/500] | Train Loss: 0.162402 | Val Loss: 0.342002\n",
      "Epoch [100/500] | Train Loss: 0.262205 | Val Loss: 0.198103\n",
      "Epoch [200/500] | Train Loss: 0.250360 | Val Loss: 0.205855\n",
      "Epoch [300/500] | Train Loss: 0.222955 | Val Loss: 0.224920\n",
      "Epoch [400/500] | Train Loss: 0.201645 | Val Loss: 0.243430\n",
      "Epoch [500/500] | Train Loss: 0.195694 | Val Loss: 0.249338\n",
      "Epoch [100/500] | Train Loss: 0.258146 | Val Loss: 0.235814\n",
      "Epoch [200/500] | Train Loss: 0.241338 | Val Loss: 0.224923\n",
      "Epoch [300/500] | Train Loss: 0.223550 | Val Loss: 0.219058\n",
      "Epoch [400/500] | Train Loss: 0.208637 | Val Loss: 0.215732\n",
      "Epoch [500/500] | Train Loss: 0.201302 | Val Loss: 0.220218\n",
      "Epoch [100/500] | Train Loss: 0.238381 | Val Loss: 0.286019\n",
      "Epoch [200/500] | Train Loss: 0.233736 | Val Loss: 0.282357\n",
      "Epoch [300/500] | Train Loss: 0.224640 | Val Loss: 0.289754\n",
      "Epoch [400/500] | Train Loss: 0.211338 | Val Loss: 0.295538\n",
      "Epoch [500/500] | Train Loss: 0.215255 | Val Loss: 0.296243\n",
      "Epoch [100/500] | Train Loss: 0.252951 | Val Loss: 0.590809\n",
      "Epoch [200/500] | Train Loss: 0.239563 | Val Loss: 0.586238\n",
      "Epoch [300/500] | Train Loss: 0.230763 | Val Loss: 0.583196\n",
      "Epoch [400/500] | Train Loss: 0.229732 | Val Loss: 0.587640\n",
      "Epoch [500/500] | Train Loss: 0.216962 | Val Loss: 0.593847\n",
      "Epoch [100/500] | Train Loss: 0.179773 | Val Loss: 0.336958\n",
      "Epoch [200/500] | Train Loss: 0.151810 | Val Loss: 0.307595\n",
      "Epoch [300/500] | Train Loss: 0.139994 | Val Loss: 0.329144\n",
      "Epoch [400/500] | Train Loss: 0.102950 | Val Loss: 0.330476\n",
      "Epoch [500/500] | Train Loss: 0.113564 | Val Loss: 0.325777\n",
      "Epoch [100/500] | Train Loss: 0.220050 | Val Loss: 0.248797\n",
      "Epoch [200/500] | Train Loss: 0.178858 | Val Loss: 0.266790\n",
      "Epoch [300/500] | Train Loss: 0.153420 | Val Loss: 0.274790\n",
      "Epoch [400/500] | Train Loss: 0.161772 | Val Loss: 0.325591\n",
      "Epoch [500/500] | Train Loss: 0.154492 | Val Loss: 0.303358\n",
      "Epoch [100/500] | Train Loss: 0.222187 | Val Loss: 0.227352\n",
      "Epoch [200/500] | Train Loss: 0.196010 | Val Loss: 0.234113\n",
      "Epoch [300/500] | Train Loss: 0.177207 | Val Loss: 0.240827\n",
      "Epoch [400/500] | Train Loss: 0.170539 | Val Loss: 0.243606\n",
      "Epoch [500/500] | Train Loss: 0.158839 | Val Loss: 0.247454\n",
      "Epoch [100/500] | Train Loss: 0.227308 | Val Loss: 0.305454\n",
      "Epoch [200/500] | Train Loss: 0.200777 | Val Loss: 0.305791\n",
      "Epoch [300/500] | Train Loss: 0.199753 | Val Loss: 0.309964\n",
      "Epoch [400/500] | Train Loss: 0.184006 | Val Loss: 0.307214\n",
      "Epoch [500/500] | Train Loss: 0.180600 | Val Loss: 0.313519\n",
      "Epoch [100/500] | Train Loss: 0.218466 | Val Loss: 0.579959\n",
      "Epoch [200/500] | Train Loss: 0.199181 | Val Loss: 0.592011\n",
      "Epoch [300/500] | Train Loss: 0.192530 | Val Loss: 0.587066\n",
      "Epoch [400/500] | Train Loss: 0.185157 | Val Loss: 0.607478\n",
      "Epoch [500/500] | Train Loss: 0.185431 | Val Loss: 0.630161\n",
      "[Year=1956] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.333439 Test MSE=0.438247\n",
      "Year 1956 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.149313 | Val Loss: 0.238738\n",
      "Epoch [200/500] | Train Loss: 0.127991 | Val Loss: 0.240369\n",
      "Epoch [300/500] | Train Loss: 0.109798 | Val Loss: 0.246773\n",
      "Epoch [400/500] | Train Loss: 0.090926 | Val Loss: 0.252147\n",
      "Epoch [500/500] | Train Loss: 0.092195 | Val Loss: 0.261856\n",
      "Epoch [100/500] | Train Loss: 0.200308 | Val Loss: 0.217665\n",
      "Epoch [200/500] | Train Loss: 0.179410 | Val Loss: 0.222993\n",
      "Epoch [300/500] | Train Loss: 0.168936 | Val Loss: 0.226772\n",
      "Epoch [400/500] | Train Loss: 0.158690 | Val Loss: 0.231785\n",
      "Epoch [500/500] | Train Loss: 0.146650 | Val Loss: 0.238513\n",
      "Epoch [100/500] | Train Loss: 0.202620 | Val Loss: 0.350057\n",
      "Epoch [200/500] | Train Loss: 0.181627 | Val Loss: 0.351931\n",
      "Epoch [300/500] | Train Loss: 0.183396 | Val Loss: 0.356385\n",
      "Epoch [400/500] | Train Loss: 0.171607 | Val Loss: 0.371777\n",
      "Epoch [500/500] | Train Loss: 0.147765 | Val Loss: 0.380285\n",
      "Epoch [100/500] | Train Loss: 0.236785 | Val Loss: 0.581807\n",
      "Epoch [200/500] | Train Loss: 0.223133 | Val Loss: 0.595998\n",
      "Epoch [300/500] | Train Loss: 0.205780 | Val Loss: 0.624739\n",
      "Epoch [400/500] | Train Loss: 0.188680 | Val Loss: 0.641331\n",
      "Epoch [500/500] | Train Loss: 0.185911 | Val Loss: 0.656075\n",
      "Epoch [100/500] | Train Loss: 0.310892 | Val Loss: 0.421083\n",
      "Epoch [200/500] | Train Loss: 0.287065 | Val Loss: 0.427154\n",
      "Epoch [300/500] | Train Loss: 0.261732 | Val Loss: 0.451628\n",
      "Epoch [400/500] | Train Loss: 0.259316 | Val Loss: 0.476680\n",
      "Epoch [500/500] | Train Loss: 0.244800 | Val Loss: 0.502348\n",
      "Epoch [100/500] | Train Loss: 0.104133 | Val Loss: 0.273756\n",
      "Epoch [200/500] | Train Loss: 0.069024 | Val Loss: 0.291278\n",
      "Epoch [300/500] | Train Loss: 0.051050 | Val Loss: 0.317861\n",
      "Epoch [400/500] | Train Loss: 0.056695 | Val Loss: 0.288053\n",
      "Epoch [500/500] | Train Loss: 0.046708 | Val Loss: 0.312437\n",
      "Epoch [100/500] | Train Loss: 0.154124 | Val Loss: 0.246273\n",
      "Epoch [200/500] | Train Loss: 0.124029 | Val Loss: 0.249826\n",
      "Epoch [300/500] | Train Loss: 0.111101 | Val Loss: 0.266026\n",
      "Epoch [400/500] | Train Loss: 0.088563 | Val Loss: 0.281497\n",
      "Epoch [500/500] | Train Loss: 0.081989 | Val Loss: 0.279351\n",
      "Epoch [100/500] | Train Loss: 0.179216 | Val Loss: 0.367674\n",
      "Epoch [200/500] | Train Loss: 0.162635 | Val Loss: 0.362506\n",
      "Epoch [300/500] | Train Loss: 0.135022 | Val Loss: 0.388922\n",
      "Epoch [400/500] | Train Loss: 0.117584 | Val Loss: 0.395547\n",
      "Epoch [500/500] | Train Loss: 0.110337 | Val Loss: 0.402324\n",
      "Epoch [100/500] | Train Loss: 0.196456 | Val Loss: 0.642910\n",
      "Epoch [200/500] | Train Loss: 0.163027 | Val Loss: 0.709195\n",
      "Epoch [300/500] | Train Loss: 0.152139 | Val Loss: 0.673315\n",
      "Epoch [400/500] | Train Loss: 0.146620 | Val Loss: 0.666809\n",
      "Epoch [500/500] | Train Loss: 0.141762 | Val Loss: 0.680141\n",
      "Epoch [100/500] | Train Loss: 0.249678 | Val Loss: 0.468142\n",
      "Epoch [200/500] | Train Loss: 0.241128 | Val Loss: 0.480238\n",
      "Epoch [300/500] | Train Loss: 0.224209 | Val Loss: 0.486760\n",
      "Epoch [400/500] | Train Loss: 0.215835 | Val Loss: 0.499042\n",
      "Epoch [500/500] | Train Loss: 0.212176 | Val Loss: 0.517483\n",
      "Epoch [100/500] | Train Loss: 0.147626 | Val Loss: 0.241375\n",
      "Epoch [200/500] | Train Loss: 0.137476 | Val Loss: 0.245038\n",
      "Epoch [300/500] | Train Loss: 0.123998 | Val Loss: 0.248471\n",
      "Epoch [400/500] | Train Loss: 0.127418 | Val Loss: 0.250137\n",
      "Epoch [500/500] | Train Loss: 0.112987 | Val Loss: 0.254249\n",
      "Epoch [100/500] | Train Loss: 0.207029 | Val Loss: 0.232272\n",
      "Epoch [200/500] | Train Loss: 0.196778 | Val Loss: 0.228372\n",
      "Epoch [300/500] | Train Loss: 0.188782 | Val Loss: 0.229954\n",
      "Epoch [400/500] | Train Loss: 0.170033 | Val Loss: 0.228813\n",
      "Epoch [500/500] | Train Loss: 0.172535 | Val Loss: 0.229176\n",
      "Epoch [100/500] | Train Loss: 0.216978 | Val Loss: 0.373737\n",
      "Epoch [200/500] | Train Loss: 0.196937 | Val Loss: 0.343260\n",
      "Epoch [300/500] | Train Loss: 0.187687 | Val Loss: 0.330160\n",
      "Epoch [400/500] | Train Loss: 0.191462 | Val Loss: 0.325513\n",
      "Epoch [500/500] | Train Loss: 0.175559 | Val Loss: 0.330013\n",
      "Epoch [100/500] | Train Loss: 0.247674 | Val Loss: 0.606828\n",
      "Epoch [200/500] | Train Loss: 0.229518 | Val Loss: 0.628903\n",
      "Epoch [300/500] | Train Loss: 0.213454 | Val Loss: 0.639845\n",
      "Epoch [400/500] | Train Loss: 0.208519 | Val Loss: 0.641429\n",
      "Epoch [500/500] | Train Loss: 0.202574 | Val Loss: 0.645355\n",
      "Epoch [100/500] | Train Loss: 0.330262 | Val Loss: 0.405158\n",
      "Epoch [200/500] | Train Loss: 0.297660 | Val Loss: 0.416985\n",
      "Epoch [300/500] | Train Loss: 0.296692 | Val Loss: 0.426073\n",
      "Epoch [400/500] | Train Loss: 0.285901 | Val Loss: 0.435142\n",
      "Epoch [500/500] | Train Loss: 0.286119 | Val Loss: 0.437165\n",
      "Epoch [100/500] | Train Loss: 0.123425 | Val Loss: 0.253561\n",
      "Epoch [200/500] | Train Loss: 0.106810 | Val Loss: 0.256227\n",
      "Epoch [300/500] | Train Loss: 0.111814 | Val Loss: 0.256736\n",
      "Epoch [400/500] | Train Loss: 0.100354 | Val Loss: 0.262702\n",
      "Epoch [500/500] | Train Loss: 0.094967 | Val Loss: 0.275877\n",
      "Epoch [100/500] | Train Loss: 0.169226 | Val Loss: 0.244079\n",
      "Epoch [200/500] | Train Loss: 0.151466 | Val Loss: 0.230460\n",
      "Epoch [300/500] | Train Loss: 0.129249 | Val Loss: 0.236247\n",
      "Epoch [400/500] | Train Loss: 0.120704 | Val Loss: 0.238307\n",
      "Epoch [500/500] | Train Loss: 0.122348 | Val Loss: 0.240487\n",
      "Epoch [100/500] | Train Loss: 0.193390 | Val Loss: 0.340028\n",
      "Epoch [200/500] | Train Loss: 0.168851 | Val Loss: 0.351497\n",
      "Epoch [300/500] | Train Loss: 0.141291 | Val Loss: 0.351237\n",
      "Epoch [400/500] | Train Loss: 0.145151 | Val Loss: 0.350868\n",
      "Epoch [500/500] | Train Loss: 0.155356 | Val Loss: 0.356024\n",
      "Epoch [100/500] | Train Loss: 0.226140 | Val Loss: 0.594816\n",
      "Epoch [200/500] | Train Loss: 0.212251 | Val Loss: 0.583451\n",
      "Epoch [300/500] | Train Loss: 0.201210 | Val Loss: 0.594577\n",
      "Epoch [400/500] | Train Loss: 0.189669 | Val Loss: 0.620051\n",
      "Epoch [500/500] | Train Loss: 0.174802 | Val Loss: 0.608650\n",
      "Epoch [100/500] | Train Loss: 0.273944 | Val Loss: 0.443721\n",
      "Epoch [200/500] | Train Loss: 0.262509 | Val Loss: 0.514496\n",
      "Epoch [300/500] | Train Loss: 0.253630 | Val Loss: 0.494043\n",
      "Epoch [400/500] | Train Loss: 0.242383 | Val Loss: 0.531798\n",
      "Epoch [500/500] | Train Loss: 0.231321 | Val Loss: 0.522612\n",
      "Epoch [100/500] | Train Loss: 0.145505 | Val Loss: 0.242973\n",
      "Epoch [200/500] | Train Loss: 0.114378 | Val Loss: 0.248722\n",
      "Epoch [300/500] | Train Loss: 0.093441 | Val Loss: 0.271544\n",
      "Epoch [400/500] | Train Loss: 0.078583 | Val Loss: 0.292764\n",
      "Epoch [500/500] | Train Loss: 0.069240 | Val Loss: 0.298301\n",
      "Epoch [100/500] | Train Loss: 0.185385 | Val Loss: 0.224187\n",
      "Epoch [200/500] | Train Loss: 0.160835 | Val Loss: 0.237973\n",
      "Epoch [300/500] | Train Loss: 0.144604 | Val Loss: 0.246634\n",
      "Epoch [400/500] | Train Loss: 0.131184 | Val Loss: 0.253030\n",
      "Epoch [500/500] | Train Loss: 0.125144 | Val Loss: 0.261764\n",
      "Epoch [100/500] | Train Loss: 0.217912 | Val Loss: 0.381932\n",
      "Epoch [200/500] | Train Loss: 0.197023 | Val Loss: 0.338304\n",
      "Epoch [300/500] | Train Loss: 0.185967 | Val Loss: 0.339308\n",
      "Epoch [400/500] | Train Loss: 0.164588 | Val Loss: 0.353001\n",
      "Epoch [500/500] | Train Loss: 0.164044 | Val Loss: 0.357756\n",
      "Epoch [100/500] | Train Loss: 0.233718 | Val Loss: 0.614082\n",
      "Epoch [200/500] | Train Loss: 0.211530 | Val Loss: 0.622207\n",
      "Epoch [300/500] | Train Loss: 0.196108 | Val Loss: 0.657466\n",
      "Epoch [400/500] | Train Loss: 0.183898 | Val Loss: 0.685361\n",
      "Epoch [500/500] | Train Loss: 0.172336 | Val Loss: 0.688093\n",
      "Epoch [100/500] | Train Loss: 0.295554 | Val Loss: 0.419051\n",
      "Epoch [200/500] | Train Loss: 0.279200 | Val Loss: 0.451742\n",
      "Epoch [300/500] | Train Loss: 0.250571 | Val Loss: 0.495138\n",
      "Epoch [400/500] | Train Loss: 0.242190 | Val Loss: 0.523071\n",
      "Epoch [500/500] | Train Loss: 0.233028 | Val Loss: 0.537838\n",
      "Epoch [100/500] | Train Loss: 0.109288 | Val Loss: 0.245177\n",
      "Epoch [200/500] | Train Loss: 0.071815 | Val Loss: 0.267617\n",
      "Epoch [300/500] | Train Loss: 0.058320 | Val Loss: 0.299143\n",
      "Epoch [400/500] | Train Loss: 0.061726 | Val Loss: 0.304203\n",
      "Epoch [500/500] | Train Loss: 0.036358 | Val Loss: 0.316035\n",
      "Epoch [100/500] | Train Loss: 0.141548 | Val Loss: 0.247971\n",
      "Epoch [200/500] | Train Loss: 0.121616 | Val Loss: 0.263667\n",
      "Epoch [300/500] | Train Loss: 0.098845 | Val Loss: 0.266308\n",
      "Epoch [400/500] | Train Loss: 0.081626 | Val Loss: 0.275627\n",
      "Epoch [500/500] | Train Loss: 0.086538 | Val Loss: 0.274772\n",
      "Epoch [100/500] | Train Loss: 0.141314 | Val Loss: 0.357574\n",
      "Epoch [200/500] | Train Loss: 0.118175 | Val Loss: 0.352444\n",
      "Epoch [300/500] | Train Loss: 0.098972 | Val Loss: 0.371685\n",
      "Epoch [400/500] | Train Loss: 0.094361 | Val Loss: 0.345933\n",
      "Epoch [500/500] | Train Loss: 0.093240 | Val Loss: 0.354413\n",
      "Epoch [100/500] | Train Loss: 0.186574 | Val Loss: 0.681096\n",
      "Epoch [200/500] | Train Loss: 0.163130 | Val Loss: 1.085351\n",
      "Epoch [300/500] | Train Loss: 0.142001 | Val Loss: 0.893187\n",
      "Epoch [400/500] | Train Loss: 0.143730 | Val Loss: 0.994958\n",
      "Epoch [500/500] | Train Loss: 0.133239 | Val Loss: 0.813453\n",
      "Epoch [100/500] | Train Loss: 0.237795 | Val Loss: 0.563657\n",
      "Epoch [200/500] | Train Loss: 0.213420 | Val Loss: 0.577111\n",
      "Epoch [300/500] | Train Loss: 0.197824 | Val Loss: 0.614543\n",
      "Epoch [400/500] | Train Loss: 0.194026 | Val Loss: 0.600350\n",
      "Epoch [500/500] | Train Loss: 0.179931 | Val Loss: 0.624523\n",
      "Epoch [100/500] | Train Loss: 0.165526 | Val Loss: 0.241151\n",
      "Epoch [200/500] | Train Loss: 0.143874 | Val Loss: 0.244266\n",
      "Epoch [300/500] | Train Loss: 0.126644 | Val Loss: 0.250175\n",
      "Epoch [400/500] | Train Loss: 0.117800 | Val Loss: 0.259677\n",
      "Epoch [500/500] | Train Loss: 0.103400 | Val Loss: 0.262348\n",
      "Epoch [100/500] | Train Loss: 0.190606 | Val Loss: 0.220890\n",
      "Epoch [200/500] | Train Loss: 0.178880 | Val Loss: 0.226150\n",
      "Epoch [300/500] | Train Loss: 0.161275 | Val Loss: 0.239399\n",
      "Epoch [400/500] | Train Loss: 0.150788 | Val Loss: 0.247324\n",
      "Epoch [500/500] | Train Loss: 0.144622 | Val Loss: 0.254132\n",
      "Epoch [100/500] | Train Loss: 0.207581 | Val Loss: 0.368352\n",
      "Epoch [200/500] | Train Loss: 0.195031 | Val Loss: 0.342656\n",
      "Epoch [300/500] | Train Loss: 0.180775 | Val Loss: 0.333161\n",
      "Epoch [400/500] | Train Loss: 0.172614 | Val Loss: 0.346714\n",
      "Epoch [500/500] | Train Loss: 0.159809 | Val Loss: 0.348769\n",
      "Epoch [100/500] | Train Loss: 0.249208 | Val Loss: 0.595970\n",
      "Epoch [200/500] | Train Loss: 0.232813 | Val Loss: 0.593116\n",
      "Epoch [300/500] | Train Loss: 0.221670 | Val Loss: 0.598496\n",
      "Epoch [400/500] | Train Loss: 0.217176 | Val Loss: 0.605383\n",
      "Epoch [500/500] | Train Loss: 0.213519 | Val Loss: 0.623324\n",
      "Epoch [100/500] | Train Loss: 0.299833 | Val Loss: 0.420857\n",
      "Epoch [200/500] | Train Loss: 0.280396 | Val Loss: 0.433137\n",
      "Epoch [300/500] | Train Loss: 0.268199 | Val Loss: 0.449430\n",
      "Epoch [400/500] | Train Loss: 0.262729 | Val Loss: 0.459090\n",
      "Epoch [500/500] | Train Loss: 0.256812 | Val Loss: 0.466184\n",
      "Epoch [100/500] | Train Loss: 0.117652 | Val Loss: 0.254640\n",
      "Epoch [200/500] | Train Loss: 0.096492 | Val Loss: 0.259335\n",
      "Epoch [300/500] | Train Loss: 0.099825 | Val Loss: 0.271257\n",
      "Epoch [400/500] | Train Loss: 0.085412 | Val Loss: 0.267699\n",
      "Epoch [500/500] | Train Loss: 0.071831 | Val Loss: 0.269313\n",
      "Epoch [100/500] | Train Loss: 0.150604 | Val Loss: 0.232064\n",
      "Epoch [200/500] | Train Loss: 0.130756 | Val Loss: 0.247048\n",
      "Epoch [300/500] | Train Loss: 0.119880 | Val Loss: 0.256634\n",
      "Epoch [400/500] | Train Loss: 0.108835 | Val Loss: 0.257286\n",
      "Epoch [500/500] | Train Loss: 0.108882 | Val Loss: 0.276085\n",
      "Epoch [100/500] | Train Loss: 0.172459 | Val Loss: 0.355466\n",
      "Epoch [200/500] | Train Loss: 0.138811 | Val Loss: 0.347049\n",
      "Epoch [300/500] | Train Loss: 0.144069 | Val Loss: 0.344010\n",
      "Epoch [400/500] | Train Loss: 0.131866 | Val Loss: 0.347798\n",
      "Epoch [500/500] | Train Loss: 0.134342 | Val Loss: 0.362589\n",
      "Epoch [100/500] | Train Loss: 0.202715 | Val Loss: 0.625189\n",
      "Epoch [200/500] | Train Loss: 0.193154 | Val Loss: 0.621588\n",
      "Epoch [300/500] | Train Loss: 0.173693 | Val Loss: 0.646981\n",
      "Epoch [400/500] | Train Loss: 0.168371 | Val Loss: 0.669191\n",
      "Epoch [500/500] | Train Loss: 0.159339 | Val Loss: 0.648022\n",
      "Epoch [100/500] | Train Loss: 0.263345 | Val Loss: 0.490155\n",
      "Epoch [200/500] | Train Loss: 0.239429 | Val Loss: 0.517104\n",
      "Epoch [300/500] | Train Loss: 0.232395 | Val Loss: 0.502163\n",
      "Epoch [400/500] | Train Loss: 0.217462 | Val Loss: 0.511889\n",
      "Epoch [500/500] | Train Loss: 0.225764 | Val Loss: 0.511561\n",
      "[Year=1957] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.379192 Test MSE=0.651318\n",
      "Year 1957 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.247573 | Val Loss: 0.204403\n",
      "Epoch [200/500] | Train Loss: 0.228976 | Val Loss: 0.214554\n",
      "Epoch [300/500] | Train Loss: 0.206787 | Val Loss: 0.222854\n",
      "Epoch [400/500] | Train Loss: 0.184554 | Val Loss: 0.230710\n",
      "Epoch [500/500] | Train Loss: 0.164502 | Val Loss: 0.240892\n",
      "Epoch [100/500] | Train Loss: 0.224249 | Val Loss: 0.341216\n",
      "Epoch [200/500] | Train Loss: 0.204783 | Val Loss: 0.332505\n",
      "Epoch [300/500] | Train Loss: 0.191088 | Val Loss: 0.330965\n",
      "Epoch [400/500] | Train Loss: 0.177623 | Val Loss: 0.324175\n",
      "Epoch [500/500] | Train Loss: 0.161622 | Val Loss: 0.327310\n",
      "Epoch [100/500] | Train Loss: 0.280010 | Val Loss: 0.648667\n",
      "Epoch [200/500] | Train Loss: 0.261418 | Val Loss: 0.644645\n",
      "Epoch [300/500] | Train Loss: 0.242711 | Val Loss: 0.662579\n",
      "Epoch [400/500] | Train Loss: 0.224933 | Val Loss: 0.680990\n",
      "Epoch [500/500] | Train Loss: 0.209744 | Val Loss: 0.708735\n",
      "Epoch [100/500] | Train Loss: 0.363631 | Val Loss: 0.446014\n",
      "Epoch [200/500] | Train Loss: 0.332136 | Val Loss: 0.448771\n",
      "Epoch [300/500] | Train Loss: 0.332154 | Val Loss: 0.470630\n",
      "Epoch [400/500] | Train Loss: 0.308893 | Val Loss: 0.499574\n",
      "Epoch [500/500] | Train Loss: 0.298769 | Val Loss: 0.508917\n",
      "Epoch [100/500] | Train Loss: 0.357758 | Val Loss: 0.702256\n",
      "Epoch [200/500] | Train Loss: 0.341658 | Val Loss: 0.709637\n",
      "Epoch [300/500] | Train Loss: 0.314987 | Val Loss: 0.705850\n",
      "Epoch [400/500] | Train Loss: 0.310418 | Val Loss: 0.700273\n",
      "Epoch [500/500] | Train Loss: 0.310269 | Val Loss: 0.693603\n",
      "Epoch [100/500] | Train Loss: 0.195103 | Val Loss: 0.228446\n",
      "Epoch [200/500] | Train Loss: 0.134254 | Val Loss: 0.224685\n",
      "Epoch [300/500] | Train Loss: 0.127204 | Val Loss: 0.247442\n",
      "Epoch [400/500] | Train Loss: 0.112972 | Val Loss: 0.233422\n",
      "Epoch [500/500] | Train Loss: 0.110910 | Val Loss: 0.254133\n",
      "Epoch [100/500] | Train Loss: 0.206694 | Val Loss: 0.337433\n",
      "Epoch [200/500] | Train Loss: 0.153146 | Val Loss: 0.354121\n",
      "Epoch [300/500] | Train Loss: 0.131758 | Val Loss: 0.367985\n",
      "Epoch [400/500] | Train Loss: 0.123508 | Val Loss: 0.387303\n",
      "Epoch [500/500] | Train Loss: 0.110704 | Val Loss: 0.376855\n",
      "Epoch [100/500] | Train Loss: 0.209967 | Val Loss: 0.743331\n",
      "Epoch [200/500] | Train Loss: 0.165392 | Val Loss: 0.760959\n",
      "Epoch [300/500] | Train Loss: 0.154949 | Val Loss: 0.730526\n",
      "Epoch [400/500] | Train Loss: 0.142050 | Val Loss: 0.714452\n",
      "Epoch [500/500] | Train Loss: 0.129317 | Val Loss: 0.660604\n",
      "Epoch [100/500] | Train Loss: 0.288809 | Val Loss: 0.528416\n",
      "Epoch [200/500] | Train Loss: 0.246199 | Val Loss: 0.584968\n",
      "Epoch [300/500] | Train Loss: 0.228805 | Val Loss: 0.613925\n",
      "Epoch [400/500] | Train Loss: 0.227288 | Val Loss: 0.590243\n",
      "Epoch [500/500] | Train Loss: 0.239076 | Val Loss: 0.583934\n",
      "Epoch [100/500] | Train Loss: 0.321108 | Val Loss: 0.755472\n",
      "Epoch [200/500] | Train Loss: 0.272053 | Val Loss: 0.734676\n",
      "Epoch [300/500] | Train Loss: 0.246198 | Val Loss: 0.660550\n",
      "Epoch [400/500] | Train Loss: 0.229687 | Val Loss: 0.677208\n",
      "Epoch [500/500] | Train Loss: 0.231628 | Val Loss: 0.685719\n",
      "Epoch [100/500] | Train Loss: 0.278307 | Val Loss: 0.203996\n",
      "Epoch [200/500] | Train Loss: 0.267043 | Val Loss: 0.198929\n",
      "Epoch [300/500] | Train Loss: 0.260182 | Val Loss: 0.198295\n",
      "Epoch [400/500] | Train Loss: 0.237152 | Val Loss: 0.203901\n",
      "Epoch [500/500] | Train Loss: 0.237511 | Val Loss: 0.207700\n",
      "Epoch [100/500] | Train Loss: 0.239236 | Val Loss: 0.360997\n",
      "Epoch [200/500] | Train Loss: 0.225762 | Val Loss: 0.341838\n",
      "Epoch [300/500] | Train Loss: 0.209014 | Val Loss: 0.335543\n",
      "Epoch [400/500] | Train Loss: 0.200837 | Val Loss: 0.332322\n",
      "Epoch [500/500] | Train Loss: 0.192350 | Val Loss: 0.336786\n",
      "Epoch [100/500] | Train Loss: 0.293229 | Val Loss: 0.642834\n",
      "Epoch [200/500] | Train Loss: 0.261736 | Val Loss: 0.634008\n",
      "Epoch [300/500] | Train Loss: 0.240844 | Val Loss: 0.641887\n",
      "Epoch [400/500] | Train Loss: 0.228178 | Val Loss: 0.634223\n",
      "Epoch [500/500] | Train Loss: 0.221850 | Val Loss: 0.629103\n",
      "Epoch [100/500] | Train Loss: 0.359046 | Val Loss: 0.433480\n",
      "Epoch [200/500] | Train Loss: 0.332058 | Val Loss: 0.440578\n",
      "Epoch [300/500] | Train Loss: 0.328572 | Val Loss: 0.448514\n",
      "Epoch [400/500] | Train Loss: 0.324982 | Val Loss: 0.460544\n",
      "Epoch [500/500] | Train Loss: 0.325408 | Val Loss: 0.471709\n",
      "Epoch [100/500] | Train Loss: 0.369110 | Val Loss: 0.695158\n",
      "Epoch [200/500] | Train Loss: 0.367011 | Val Loss: 0.694905\n",
      "Epoch [300/500] | Train Loss: 0.356527 | Val Loss: 0.702478\n",
      "Epoch [400/500] | Train Loss: 0.343281 | Val Loss: 0.698594\n",
      "Epoch [500/500] | Train Loss: 0.328986 | Val Loss: 0.699476\n",
      "Epoch [100/500] | Train Loss: 0.196592 | Val Loss: 0.226176\n",
      "Epoch [200/500] | Train Loss: 0.169334 | Val Loss: 0.213331\n",
      "Epoch [300/500] | Train Loss: 0.146373 | Val Loss: 0.231268\n",
      "Epoch [400/500] | Train Loss: 0.136277 | Val Loss: 0.206793\n",
      "Epoch [500/500] | Train Loss: 0.141383 | Val Loss: 0.225696\n",
      "Epoch [100/500] | Train Loss: 0.190040 | Val Loss: 0.325120\n",
      "Epoch [200/500] | Train Loss: 0.178531 | Val Loss: 0.343668\n",
      "Epoch [300/500] | Train Loss: 0.175338 | Val Loss: 0.359141\n",
      "Epoch [400/500] | Train Loss: 0.149494 | Val Loss: 0.361095\n",
      "Epoch [500/500] | Train Loss: 0.146327 | Val Loss: 0.375148\n",
      "Epoch [100/500] | Train Loss: 0.226132 | Val Loss: 0.662681\n",
      "Epoch [200/500] | Train Loss: 0.196901 | Val Loss: 0.671234\n",
      "Epoch [300/500] | Train Loss: 0.179867 | Val Loss: 0.917515\n",
      "Epoch [400/500] | Train Loss: 0.178073 | Val Loss: 0.808229\n",
      "Epoch [500/500] | Train Loss: 0.165651 | Val Loss: 0.735560\n",
      "Epoch [100/500] | Train Loss: 0.324658 | Val Loss: 0.467465\n",
      "Epoch [200/500] | Train Loss: 0.286820 | Val Loss: 0.516066\n",
      "Epoch [300/500] | Train Loss: 0.269555 | Val Loss: 0.511459\n",
      "Epoch [400/500] | Train Loss: 0.267133 | Val Loss: 0.557967\n",
      "Epoch [500/500] | Train Loss: 0.271369 | Val Loss: 0.528899\n",
      "Epoch [100/500] | Train Loss: 0.348954 | Val Loss: 0.688480\n",
      "Epoch [200/500] | Train Loss: 0.332607 | Val Loss: 0.697189\n",
      "Epoch [300/500] | Train Loss: 0.309844 | Val Loss: 0.674321\n",
      "Epoch [400/500] | Train Loss: 0.288867 | Val Loss: 0.666616\n",
      "Epoch [500/500] | Train Loss: 0.305600 | Val Loss: 0.626429\n",
      "Epoch [100/500] | Train Loss: 0.239797 | Val Loss: 0.203696\n",
      "Epoch [200/500] | Train Loss: 0.202808 | Val Loss: 0.220597\n",
      "Epoch [300/500] | Train Loss: 0.155541 | Val Loss: 0.238891\n",
      "Epoch [400/500] | Train Loss: 0.128110 | Val Loss: 0.241438\n",
      "Epoch [500/500] | Train Loss: 0.112103 | Val Loss: 0.260179\n",
      "Epoch [100/500] | Train Loss: 0.225441 | Val Loss: 0.354806\n",
      "Epoch [200/500] | Train Loss: 0.195372 | Val Loss: 0.337760\n",
      "Epoch [300/500] | Train Loss: 0.185678 | Val Loss: 0.331041\n",
      "Epoch [400/500] | Train Loss: 0.154140 | Val Loss: 0.335544\n",
      "Epoch [500/500] | Train Loss: 0.151006 | Val Loss: 0.344544\n",
      "Epoch [100/500] | Train Loss: 0.262224 | Val Loss: 0.656706\n",
      "Epoch [200/500] | Train Loss: 0.224729 | Val Loss: 0.656343\n",
      "Epoch [300/500] | Train Loss: 0.199001 | Val Loss: 0.670392\n",
      "Epoch [400/500] | Train Loss: 0.184128 | Val Loss: 0.703703\n",
      "Epoch [500/500] | Train Loss: 0.157898 | Val Loss: 0.746787\n",
      "Epoch [100/500] | Train Loss: 0.319210 | Val Loss: 0.475375\n",
      "Epoch [200/500] | Train Loss: 0.301629 | Val Loss: 0.528762\n",
      "Epoch [300/500] | Train Loss: 0.276347 | Val Loss: 0.577444\n",
      "Epoch [400/500] | Train Loss: 0.262620 | Val Loss: 0.608547\n",
      "Epoch [500/500] | Train Loss: 0.253305 | Val Loss: 0.631081\n",
      "Epoch [100/500] | Train Loss: 0.346199 | Val Loss: 0.703503\n",
      "Epoch [200/500] | Train Loss: 0.325859 | Val Loss: 0.711254\n",
      "Epoch [300/500] | Train Loss: 0.316472 | Val Loss: 0.703209\n",
      "Epoch [400/500] | Train Loss: 0.286577 | Val Loss: 0.704127\n",
      "Epoch [500/500] | Train Loss: 0.296252 | Val Loss: 0.705962\n",
      "Epoch [100/500] | Train Loss: 0.143822 | Val Loss: 0.234326\n",
      "Epoch [200/500] | Train Loss: 0.081355 | Val Loss: 0.244906\n",
      "Epoch [300/500] | Train Loss: 0.088858 | Val Loss: 0.274189\n",
      "Epoch [400/500] | Train Loss: 0.066959 | Val Loss: 0.284248\n",
      "Epoch [500/500] | Train Loss: 0.062652 | Val Loss: 0.284486\n",
      "Epoch [100/500] | Train Loss: 0.195542 | Val Loss: 0.363741\n",
      "Epoch [200/500] | Train Loss: 0.151733 | Val Loss: 0.400654\n",
      "Epoch [300/500] | Train Loss: 0.135102 | Val Loss: 0.398889\n",
      "Epoch [400/500] | Train Loss: 0.123676 | Val Loss: 0.406746\n",
      "Epoch [500/500] | Train Loss: 0.108597 | Val Loss: 0.419224\n",
      "Epoch [100/500] | Train Loss: 0.185428 | Val Loss: 0.709204\n",
      "Epoch [200/500] | Train Loss: 0.152631 | Val Loss: 0.773043\n",
      "Epoch [300/500] | Train Loss: 0.131590 | Val Loss: 0.801187\n",
      "Epoch [400/500] | Train Loss: 0.127874 | Val Loss: 0.726682\n",
      "Epoch [500/500] | Train Loss: 0.110743 | Val Loss: 0.789595\n",
      "Epoch [100/500] | Train Loss: 0.274970 | Val Loss: 0.569922\n",
      "Epoch [200/500] | Train Loss: 0.229705 | Val Loss: 0.626114\n",
      "Epoch [300/500] | Train Loss: 0.215676 | Val Loss: 0.571549\n",
      "Epoch [400/500] | Train Loss: 0.203040 | Val Loss: 0.623610\n",
      "Epoch [500/500] | Train Loss: 0.203509 | Val Loss: 0.592742\n",
      "Epoch [100/500] | Train Loss: 0.279711 | Val Loss: 0.692713\n",
      "Epoch [200/500] | Train Loss: 0.234599 | Val Loss: 0.733158\n",
      "Epoch [300/500] | Train Loss: 0.222399 | Val Loss: 0.772088\n",
      "Epoch [400/500] | Train Loss: 0.194880 | Val Loss: 0.752283\n",
      "Epoch [500/500] | Train Loss: 0.187599 | Val Loss: 0.778382\n",
      "Epoch [100/500] | Train Loss: 0.262407 | Val Loss: 0.203236\n",
      "Epoch [200/500] | Train Loss: 0.211648 | Val Loss: 0.210004\n",
      "Epoch [300/500] | Train Loss: 0.200066 | Val Loss: 0.222652\n",
      "Epoch [400/500] | Train Loss: 0.190218 | Val Loss: 0.214653\n",
      "Epoch [500/500] | Train Loss: 0.145889 | Val Loss: 0.219286\n",
      "Epoch [100/500] | Train Loss: 0.238544 | Val Loss: 0.358595\n",
      "Epoch [200/500] | Train Loss: 0.222472 | Val Loss: 0.367347\n",
      "Epoch [300/500] | Train Loss: 0.197270 | Val Loss: 0.369357\n",
      "Epoch [400/500] | Train Loss: 0.180866 | Val Loss: 0.364172\n",
      "Epoch [500/500] | Train Loss: 0.186968 | Val Loss: 0.362101\n",
      "Epoch [100/500] | Train Loss: 0.263021 | Val Loss: 0.630174\n",
      "Epoch [200/500] | Train Loss: 0.249750 | Val Loss: 0.650882\n",
      "Epoch [300/500] | Train Loss: 0.221530 | Val Loss: 0.720480\n",
      "Epoch [400/500] | Train Loss: 0.217364 | Val Loss: 0.774485\n",
      "Epoch [500/500] | Train Loss: 0.199306 | Val Loss: 0.769106\n",
      "Epoch [100/500] | Train Loss: 0.362702 | Val Loss: 0.458687\n",
      "Epoch [200/500] | Train Loss: 0.330819 | Val Loss: 0.460944\n",
      "Epoch [300/500] | Train Loss: 0.318497 | Val Loss: 0.480479\n",
      "Epoch [400/500] | Train Loss: 0.309161 | Val Loss: 0.495658\n",
      "Epoch [500/500] | Train Loss: 0.289865 | Val Loss: 0.520516\n",
      "Epoch [100/500] | Train Loss: 0.367203 | Val Loss: 0.693672\n",
      "Epoch [200/500] | Train Loss: 0.354666 | Val Loss: 0.705928\n",
      "Epoch [300/500] | Train Loss: 0.339957 | Val Loss: 0.708462\n",
      "Epoch [400/500] | Train Loss: 0.333767 | Val Loss: 0.711043\n",
      "Epoch [500/500] | Train Loss: 0.311054 | Val Loss: 0.707182\n",
      "Epoch [100/500] | Train Loss: 0.173787 | Val Loss: 0.212410\n",
      "Epoch [200/500] | Train Loss: 0.110227 | Val Loss: 0.226429\n",
      "Epoch [300/500] | Train Loss: 0.140477 | Val Loss: 0.221208\n",
      "Epoch [400/500] | Train Loss: 0.120658 | Val Loss: 0.231800\n",
      "Epoch [500/500] | Train Loss: 0.094484 | Val Loss: 0.231910\n",
      "Epoch [100/500] | Train Loss: 0.199270 | Val Loss: 0.360774\n",
      "Epoch [200/500] | Train Loss: 0.146392 | Val Loss: 0.368260\n",
      "Epoch [300/500] | Train Loss: 0.147485 | Val Loss: 0.366920\n",
      "Epoch [400/500] | Train Loss: 0.135305 | Val Loss: 0.373992\n",
      "Epoch [500/500] | Train Loss: 0.133219 | Val Loss: 0.378534\n",
      "Epoch [100/500] | Train Loss: 0.210723 | Val Loss: 0.711094\n",
      "Epoch [200/500] | Train Loss: 0.187033 | Val Loss: 0.717648\n",
      "Epoch [300/500] | Train Loss: 0.173605 | Val Loss: 0.693072\n",
      "Epoch [400/500] | Train Loss: 0.163471 | Val Loss: 0.675011\n",
      "Epoch [500/500] | Train Loss: 0.169244 | Val Loss: 0.727613\n",
      "Epoch [100/500] | Train Loss: 0.297371 | Val Loss: 0.538390\n",
      "Epoch [200/500] | Train Loss: 0.280375 | Val Loss: 0.602599\n",
      "Epoch [300/500] | Train Loss: 0.245843 | Val Loss: 0.603452\n",
      "Epoch [400/500] | Train Loss: 0.236439 | Val Loss: 0.585978\n",
      "Epoch [500/500] | Train Loss: 0.216278 | Val Loss: 0.610542\n",
      "Epoch [100/500] | Train Loss: 0.325573 | Val Loss: 0.715203\n",
      "Epoch [200/500] | Train Loss: 0.300921 | Val Loss: 0.690984\n",
      "Epoch [300/500] | Train Loss: 0.284784 | Val Loss: 0.702378\n",
      "Epoch [400/500] | Train Loss: 0.276291 | Val Loss: 0.662183\n",
      "Epoch [500/500] | Train Loss: 0.283180 | Val Loss: 0.677333\n",
      "[Year=1958] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.468955 Test MSE=0.273232\n",
      "Year 1958 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.171173 | Val Loss: 0.388224\n",
      "Epoch [200/500] | Train Loss: 0.156875 | Val Loss: 0.415408\n",
      "Epoch [300/500] | Train Loss: 0.146913 | Val Loss: 0.420746\n",
      "Epoch [400/500] | Train Loss: 0.130534 | Val Loss: 0.421239\n",
      "Epoch [500/500] | Train Loss: 0.099822 | Val Loss: 0.438448\n",
      "Epoch [100/500] | Train Loss: 0.264139 | Val Loss: 0.754782\n",
      "Epoch [200/500] | Train Loss: 0.236189 | Val Loss: 0.777295\n",
      "Epoch [300/500] | Train Loss: 0.212902 | Val Loss: 0.858777\n",
      "Epoch [400/500] | Train Loss: 0.182096 | Val Loss: 0.895639\n",
      "Epoch [500/500] | Train Loss: 0.184862 | Val Loss: 0.936162\n",
      "Epoch [100/500] | Train Loss: 0.400913 | Val Loss: 0.331399\n",
      "Epoch [200/500] | Train Loss: 0.375211 | Val Loss: 0.325152\n",
      "Epoch [300/500] | Train Loss: 0.353686 | Val Loss: 0.325741\n",
      "Epoch [400/500] | Train Loss: 0.359643 | Val Loss: 0.323851\n",
      "Epoch [500/500] | Train Loss: 0.327299 | Val Loss: 0.330970\n",
      "Epoch [100/500] | Train Loss: 0.384413 | Val Loss: 0.745697\n",
      "Epoch [200/500] | Train Loss: 0.369237 | Val Loss: 0.758097\n",
      "Epoch [300/500] | Train Loss: 0.339995 | Val Loss: 0.768595\n",
      "Epoch [400/500] | Train Loss: 0.337281 | Val Loss: 0.768258\n",
      "Epoch [500/500] | Train Loss: 0.313829 | Val Loss: 0.775195\n",
      "Epoch [100/500] | Train Loss: 0.466520 | Val Loss: 0.273668\n",
      "Epoch [200/500] | Train Loss: 0.448121 | Val Loss: 0.274932\n",
      "Epoch [300/500] | Train Loss: 0.403807 | Val Loss: 0.276675\n",
      "Epoch [400/500] | Train Loss: 0.387467 | Val Loss: 0.272740\n",
      "Epoch [500/500] | Train Loss: 0.397137 | Val Loss: 0.275412\n",
      "Epoch [100/500] | Train Loss: 0.136991 | Val Loss: 0.398125\n",
      "Epoch [200/500] | Train Loss: 0.101750 | Val Loss: 0.445232\n",
      "Epoch [300/500] | Train Loss: 0.090926 | Val Loss: 0.467476\n",
      "Epoch [400/500] | Train Loss: 0.079112 | Val Loss: 0.464978\n",
      "Epoch [500/500] | Train Loss: 0.065890 | Val Loss: 0.464994\n",
      "Epoch [100/500] | Train Loss: 0.217112 | Val Loss: 0.910182\n",
      "Epoch [200/500] | Train Loss: 0.137538 | Val Loss: 0.981620\n",
      "Epoch [300/500] | Train Loss: 0.151735 | Val Loss: 0.990074\n",
      "Epoch [400/500] | Train Loss: 0.123849 | Val Loss: 0.871187\n",
      "Epoch [500/500] | Train Loss: 0.126819 | Val Loss: 0.823669\n",
      "Epoch [100/500] | Train Loss: 0.344347 | Val Loss: 0.336435\n",
      "Epoch [200/500] | Train Loss: 0.263792 | Val Loss: 0.392368\n",
      "Epoch [300/500] | Train Loss: 0.205810 | Val Loss: 0.379786\n",
      "Epoch [400/500] | Train Loss: 0.206715 | Val Loss: 0.418052\n",
      "Epoch [500/500] | Train Loss: 0.190533 | Val Loss: 0.398204\n",
      "Epoch [100/500] | Train Loss: 0.344782 | Val Loss: 0.733562\n",
      "Epoch [200/500] | Train Loss: 0.302896 | Val Loss: 0.811516\n",
      "Epoch [300/500] | Train Loss: 0.268582 | Val Loss: 0.893281\n",
      "Epoch [400/500] | Train Loss: 0.258095 | Val Loss: 0.881233\n",
      "Epoch [500/500] | Train Loss: 0.276769 | Val Loss: 0.952213\n",
      "Epoch [100/500] | Train Loss: 0.381453 | Val Loss: 0.276568\n",
      "Epoch [200/500] | Train Loss: 0.335811 | Val Loss: 0.303244\n",
      "Epoch [300/500] | Train Loss: 0.320696 | Val Loss: 0.302772\n",
      "Epoch [400/500] | Train Loss: 0.301312 | Val Loss: 0.309927\n",
      "Epoch [500/500] | Train Loss: 0.281358 | Val Loss: 0.325536\n",
      "Epoch [100/500] | Train Loss: 0.197285 | Val Loss: 0.378389\n",
      "Epoch [200/500] | Train Loss: 0.177822 | Val Loss: 0.381611\n",
      "Epoch [300/500] | Train Loss: 0.152259 | Val Loss: 0.393067\n",
      "Epoch [400/500] | Train Loss: 0.158867 | Val Loss: 0.384046\n",
      "Epoch [500/500] | Train Loss: 0.151241 | Val Loss: 0.401210\n",
      "Epoch [100/500] | Train Loss: 0.275552 | Val Loss: 0.743188\n",
      "Epoch [200/500] | Train Loss: 0.268289 | Val Loss: 0.775703\n",
      "Epoch [300/500] | Train Loss: 0.242380 | Val Loss: 0.796849\n",
      "Epoch [400/500] | Train Loss: 0.241909 | Val Loss: 0.817933\n",
      "Epoch [500/500] | Train Loss: 0.237362 | Val Loss: 0.849692\n",
      "Epoch [100/500] | Train Loss: 0.517638 | Val Loss: 0.398473\n",
      "Epoch [200/500] | Train Loss: 0.425453 | Val Loss: 0.356569\n",
      "Epoch [300/500] | Train Loss: 0.399174 | Val Loss: 0.328054\n",
      "Epoch [400/500] | Train Loss: 0.372816 | Val Loss: 0.321984\n",
      "Epoch [500/500] | Train Loss: 0.366472 | Val Loss: 0.325514\n",
      "Epoch [100/500] | Train Loss: 0.400692 | Val Loss: 0.745929\n",
      "Epoch [200/500] | Train Loss: 0.385173 | Val Loss: 0.745638\n",
      "Epoch [300/500] | Train Loss: 0.363045 | Val Loss: 0.749384\n",
      "Epoch [400/500] | Train Loss: 0.346465 | Val Loss: 0.754713\n",
      "Epoch [500/500] | Train Loss: 0.358441 | Val Loss: 0.760772\n",
      "Epoch [100/500] | Train Loss: 0.469126 | Val Loss: 0.274567\n",
      "Epoch [200/500] | Train Loss: 0.434477 | Val Loss: 0.279137\n",
      "Epoch [300/500] | Train Loss: 0.424489 | Val Loss: 0.279180\n",
      "Epoch [400/500] | Train Loss: 0.414565 | Val Loss: 0.279653\n",
      "Epoch [500/500] | Train Loss: 0.405869 | Val Loss: 0.277872\n",
      "Epoch [100/500] | Train Loss: 0.137881 | Val Loss: 0.406103\n",
      "Epoch [200/500] | Train Loss: 0.115179 | Val Loss: 0.429834\n",
      "Epoch [300/500] | Train Loss: 0.101527 | Val Loss: 0.415749\n",
      "Epoch [400/500] | Train Loss: 0.114684 | Val Loss: 0.437050\n",
      "Epoch [500/500] | Train Loss: 0.078035 | Val Loss: 0.449919\n",
      "Epoch [100/500] | Train Loss: 0.255280 | Val Loss: 0.739859\n",
      "Epoch [200/500] | Train Loss: 0.231977 | Val Loss: 0.735490\n",
      "Epoch [300/500] | Train Loss: 0.211874 | Val Loss: 0.806426\n",
      "Epoch [400/500] | Train Loss: 0.194881 | Val Loss: 0.764470\n",
      "Epoch [500/500] | Train Loss: 0.180408 | Val Loss: 0.763862\n",
      "Epoch [100/500] | Train Loss: 0.360582 | Val Loss: 0.349072\n",
      "Epoch [200/500] | Train Loss: 0.346743 | Val Loss: 0.349593\n",
      "Epoch [300/500] | Train Loss: 0.316944 | Val Loss: 0.361518\n",
      "Epoch [400/500] | Train Loss: 0.323813 | Val Loss: 0.370638\n",
      "Epoch [500/500] | Train Loss: 0.297553 | Val Loss: 0.385206\n",
      "Epoch [100/500] | Train Loss: 0.371814 | Val Loss: 0.722823\n",
      "Epoch [200/500] | Train Loss: 0.350004 | Val Loss: 0.718334\n",
      "Epoch [300/500] | Train Loss: 0.318812 | Val Loss: 0.733090\n",
      "Epoch [400/500] | Train Loss: 0.314910 | Val Loss: 0.743598\n",
      "Epoch [500/500] | Train Loss: 0.300393 | Val Loss: 0.753858\n",
      "Epoch [100/500] | Train Loss: 0.396457 | Val Loss: 0.270088\n",
      "Epoch [200/500] | Train Loss: 0.387036 | Val Loss: 0.276240\n",
      "Epoch [300/500] | Train Loss: 0.381314 | Val Loss: 0.284356\n",
      "Epoch [400/500] | Train Loss: 0.357683 | Val Loss: 0.279256\n",
      "Epoch [500/500] | Train Loss: 0.352029 | Val Loss: 0.279733\n",
      "Epoch [100/500] | Train Loss: 0.181716 | Val Loss: 0.382492\n",
      "Epoch [200/500] | Train Loss: 0.127536 | Val Loss: 0.427133\n",
      "Epoch [300/500] | Train Loss: 0.118392 | Val Loss: 0.456545\n",
      "Epoch [400/500] | Train Loss: 0.108148 | Val Loss: 0.470467\n",
      "Epoch [500/500] | Train Loss: 0.098825 | Val Loss: 0.473849\n",
      "Epoch [100/500] | Train Loss: 0.276231 | Val Loss: 0.722983\n",
      "Epoch [200/500] | Train Loss: 0.235298 | Val Loss: 0.735000\n",
      "Epoch [300/500] | Train Loss: 0.223406 | Val Loss: 0.777172\n",
      "Epoch [400/500] | Train Loss: 0.180623 | Val Loss: 0.821865\n",
      "Epoch [500/500] | Train Loss: 0.163122 | Val Loss: 0.878179\n",
      "Epoch [100/500] | Train Loss: 0.408538 | Val Loss: 0.328951\n",
      "Epoch [200/500] | Train Loss: 0.370400 | Val Loss: 0.319353\n",
      "Epoch [300/500] | Train Loss: 0.344647 | Val Loss: 0.323692\n",
      "Epoch [400/500] | Train Loss: 0.310882 | Val Loss: 0.338804\n",
      "Epoch [500/500] | Train Loss: 0.295303 | Val Loss: 0.346746\n",
      "Epoch [100/500] | Train Loss: 0.399769 | Val Loss: 0.735534\n",
      "Epoch [200/500] | Train Loss: 0.362760 | Val Loss: 0.748006\n",
      "Epoch [300/500] | Train Loss: 0.352972 | Val Loss: 0.763868\n",
      "Epoch [400/500] | Train Loss: 0.324448 | Val Loss: 0.789703\n",
      "Epoch [500/500] | Train Loss: 0.324881 | Val Loss: 0.794172\n",
      "Epoch [100/500] | Train Loss: 0.455660 | Val Loss: 0.273417\n",
      "Epoch [200/500] | Train Loss: 0.411826 | Val Loss: 0.281287\n",
      "Epoch [300/500] | Train Loss: 0.383911 | Val Loss: 0.283196\n",
      "Epoch [400/500] | Train Loss: 0.353229 | Val Loss: 0.287456\n",
      "Epoch [500/500] | Train Loss: 0.349561 | Val Loss: 0.290859\n",
      "Epoch [100/500] | Train Loss: 0.225906 | Val Loss: 0.400534\n",
      "Epoch [200/500] | Train Loss: 0.225894 | Val Loss: 0.400504\n",
      "Epoch [300/500] | Train Loss: 0.225894 | Val Loss: 0.400504\n",
      "Epoch [400/500] | Train Loss: 0.225894 | Val Loss: 0.400504\n",
      "Epoch [500/500] | Train Loss: 0.225894 | Val Loss: 0.400504\n",
      "Epoch [100/500] | Train Loss: 0.200156 | Val Loss: 0.909783\n",
      "Epoch [200/500] | Train Loss: 0.151692 | Val Loss: 1.099324\n",
      "Epoch [300/500] | Train Loss: 0.143039 | Val Loss: 1.176629\n",
      "Epoch [400/500] | Train Loss: 0.117556 | Val Loss: 1.119159\n",
      "Epoch [500/500] | Train Loss: 0.111861 | Val Loss: 1.063942\n",
      "Epoch [100/500] | Train Loss: 0.333506 | Val Loss: 0.342884\n",
      "Epoch [200/500] | Train Loss: 0.261046 | Val Loss: 0.398770\n",
      "Epoch [300/500] | Train Loss: 0.210660 | Val Loss: 0.378145\n",
      "Epoch [400/500] | Train Loss: 0.188987 | Val Loss: 0.396274\n",
      "Epoch [500/500] | Train Loss: 0.179259 | Val Loss: 0.404649\n",
      "Epoch [100/500] | Train Loss: 0.282805 | Val Loss: 0.817742\n",
      "Epoch [200/500] | Train Loss: 0.242134 | Val Loss: 0.854543\n",
      "Epoch [300/500] | Train Loss: 0.224307 | Val Loss: 0.931572\n",
      "Epoch [400/500] | Train Loss: 0.182643 | Val Loss: 0.912058\n",
      "Epoch [500/500] | Train Loss: 0.179116 | Val Loss: 0.893479\n",
      "Epoch [100/500] | Train Loss: 0.353948 | Val Loss: 0.276514\n",
      "Epoch [200/500] | Train Loss: 0.314296 | Val Loss: 0.284886\n",
      "Epoch [300/500] | Train Loss: 0.272406 | Val Loss: 0.284309\n",
      "Epoch [400/500] | Train Loss: 0.238177 | Val Loss: 0.303142\n",
      "Epoch [500/500] | Train Loss: 0.254341 | Val Loss: 0.308805\n",
      "Epoch [100/500] | Train Loss: 0.189240 | Val Loss: 0.401112\n",
      "Epoch [200/500] | Train Loss: 0.172037 | Val Loss: 0.417242\n",
      "Epoch [300/500] | Train Loss: 0.169980 | Val Loss: 0.419830\n",
      "Epoch [400/500] | Train Loss: 0.125755 | Val Loss: 0.429427\n",
      "Epoch [500/500] | Train Loss: 0.124592 | Val Loss: 0.447409\n",
      "Epoch [100/500] | Train Loss: 0.266067 | Val Loss: 0.725457\n",
      "Epoch [200/500] | Train Loss: 0.247133 | Val Loss: 0.756765\n",
      "Epoch [300/500] | Train Loss: 0.237886 | Val Loss: 0.792003\n",
      "Epoch [400/500] | Train Loss: 0.222103 | Val Loss: 0.853578\n",
      "Epoch [500/500] | Train Loss: 0.206562 | Val Loss: 0.853339\n",
      "Epoch [100/500] | Train Loss: 0.414450 | Val Loss: 0.327349\n",
      "Epoch [200/500] | Train Loss: 0.393832 | Val Loss: 0.320863\n",
      "Epoch [300/500] | Train Loss: 0.378867 | Val Loss: 0.323464\n",
      "Epoch [400/500] | Train Loss: 0.371344 | Val Loss: 0.328933\n",
      "Epoch [500/500] | Train Loss: 0.367637 | Val Loss: 0.332776\n",
      "Epoch [100/500] | Train Loss: 0.399446 | Val Loss: 0.754151\n",
      "Epoch [200/500] | Train Loss: 0.373222 | Val Loss: 0.757296\n",
      "Epoch [300/500] | Train Loss: 0.351919 | Val Loss: 0.758157\n",
      "Epoch [400/500] | Train Loss: 0.335072 | Val Loss: 0.756464\n",
      "Epoch [500/500] | Train Loss: 0.332854 | Val Loss: 0.751115\n",
      "Epoch [100/500] | Train Loss: 0.457011 | Val Loss: 0.274899\n",
      "Epoch [200/500] | Train Loss: 0.434229 | Val Loss: 0.278997\n",
      "Epoch [300/500] | Train Loss: 0.414290 | Val Loss: 0.274275\n",
      "Epoch [400/500] | Train Loss: 0.399921 | Val Loss: 0.272482\n",
      "Epoch [500/500] | Train Loss: 0.387462 | Val Loss: 0.276836\n",
      "Epoch [100/500] | Train Loss: 0.147299 | Val Loss: 0.417074\n",
      "Epoch [200/500] | Train Loss: 0.097522 | Val Loss: 0.431482\n",
      "Epoch [300/500] | Train Loss: 0.090684 | Val Loss: 0.432253\n",
      "Epoch [400/500] | Train Loss: 0.075847 | Val Loss: 0.434043\n",
      "Epoch [500/500] | Train Loss: 0.086846 | Val Loss: 0.448776\n",
      "Epoch [100/500] | Train Loss: 0.210882 | Val Loss: 0.816912\n",
      "Epoch [200/500] | Train Loss: 0.188093 | Val Loss: 0.802071\n",
      "Epoch [300/500] | Train Loss: 0.152539 | Val Loss: 0.762068\n",
      "Epoch [400/500] | Train Loss: 0.165263 | Val Loss: 0.782718\n",
      "Epoch [500/500] | Train Loss: 0.137860 | Val Loss: 0.757708\n",
      "Epoch [100/500] | Train Loss: 0.391033 | Val Loss: 0.326436\n",
      "Epoch [200/500] | Train Loss: 0.363848 | Val Loss: 0.355868\n",
      "Epoch [300/500] | Train Loss: 0.327450 | Val Loss: 0.392597\n",
      "Epoch [400/500] | Train Loss: 0.293429 | Val Loss: 0.403176\n",
      "Epoch [500/500] | Train Loss: 0.338624 | Val Loss: 0.416738\n",
      "Epoch [100/500] | Train Loss: 0.360492 | Val Loss: 0.712321\n",
      "Epoch [200/500] | Train Loss: 0.326264 | Val Loss: 0.765693\n",
      "Epoch [300/500] | Train Loss: 0.308778 | Val Loss: 0.750952\n",
      "Epoch [400/500] | Train Loss: 0.314651 | Val Loss: 0.745549\n",
      "Epoch [500/500] | Train Loss: 0.287132 | Val Loss: 0.799396\n",
      "Epoch [100/500] | Train Loss: 0.394889 | Val Loss: 0.274399\n",
      "Epoch [200/500] | Train Loss: 0.365834 | Val Loss: 0.270545\n",
      "Epoch [300/500] | Train Loss: 0.356887 | Val Loss: 0.262146\n",
      "Epoch [400/500] | Train Loss: 0.332222 | Val Loss: 0.274040\n",
      "Epoch [500/500] | Train Loss: 0.317552 | Val Loss: 0.275178\n",
      "[Year=1959] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.523012 Test MSE=0.302234\n",
      "Year 1959 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.589701 | Val Loss: 0.398115\n",
      "Epoch [200/500] | Train Loss: 0.496546 | Val Loss: 0.452384\n",
      "Epoch [300/500] | Train Loss: 0.490600 | Val Loss: 0.493283\n",
      "Epoch [400/500] | Train Loss: 0.412842 | Val Loss: 0.533036\n",
      "Epoch [500/500] | Train Loss: 0.331831 | Val Loss: 0.560126\n",
      "Epoch [100/500] | Train Loss: 0.509041 | Val Loss: 0.330114\n",
      "Epoch [200/500] | Train Loss: 0.476768 | Val Loss: 0.320816\n",
      "Epoch [300/500] | Train Loss: 0.460119 | Val Loss: 0.318818\n",
      "Epoch [400/500] | Train Loss: 0.424289 | Val Loss: 0.323786\n",
      "Epoch [500/500] | Train Loss: 0.369544 | Val Loss: 0.341609\n",
      "Epoch [100/500] | Train Loss: 0.438948 | Val Loss: 0.728555\n",
      "Epoch [200/500] | Train Loss: 0.403086 | Val Loss: 0.717863\n",
      "Epoch [300/500] | Train Loss: 0.376128 | Val Loss: 0.717804\n",
      "Epoch [400/500] | Train Loss: 0.362924 | Val Loss: 0.711361\n",
      "Epoch [500/500] | Train Loss: 0.351519 | Val Loss: 0.702628\n",
      "Epoch [100/500] | Train Loss: 0.506394 | Val Loss: 0.290723\n",
      "Epoch [200/500] | Train Loss: 0.451067 | Val Loss: 0.295181\n",
      "Epoch [300/500] | Train Loss: 0.452797 | Val Loss: 0.297083\n",
      "Epoch [400/500] | Train Loss: 0.411445 | Val Loss: 0.294348\n",
      "Epoch [500/500] | Train Loss: 0.412132 | Val Loss: 0.300776\n",
      "Epoch [100/500] | Train Loss: 0.484545 | Val Loss: 0.312325\n",
      "Epoch [200/500] | Train Loss: 0.450282 | Val Loss: 0.302372\n",
      "Epoch [300/500] | Train Loss: 0.430981 | Val Loss: 0.304898\n",
      "Epoch [400/500] | Train Loss: 0.415692 | Val Loss: 0.307010\n",
      "Epoch [500/500] | Train Loss: 0.398925 | Val Loss: 0.306746\n",
      "Epoch [100/500] | Train Loss: 0.450925 | Val Loss: 0.503502\n",
      "Epoch [200/500] | Train Loss: 0.346332 | Val Loss: 0.587226\n",
      "Epoch [300/500] | Train Loss: 0.156542 | Val Loss: 0.533096\n",
      "Epoch [400/500] | Train Loss: 0.142763 | Val Loss: 0.539954\n",
      "Epoch [500/500] | Train Loss: 0.163535 | Val Loss: 0.653990\n",
      "Epoch [100/500] | Train Loss: 0.398818 | Val Loss: 0.338791\n",
      "Epoch [200/500] | Train Loss: 0.318866 | Val Loss: 0.397036\n",
      "Epoch [300/500] | Train Loss: 0.315760 | Val Loss: 0.454858\n",
      "Epoch [400/500] | Train Loss: 0.241716 | Val Loss: 0.494183\n",
      "Epoch [500/500] | Train Loss: 0.221576 | Val Loss: 0.586191\n",
      "Epoch [100/500] | Train Loss: 0.341564 | Val Loss: 0.767172\n",
      "Epoch [200/500] | Train Loss: 0.266683 | Val Loss: 0.747146\n",
      "Epoch [300/500] | Train Loss: 0.232479 | Val Loss: 0.720399\n",
      "Epoch [400/500] | Train Loss: 0.223350 | Val Loss: 0.764610\n",
      "Epoch [500/500] | Train Loss: 0.223928 | Val Loss: 0.743659\n",
      "Epoch [100/500] | Train Loss: 0.431075 | Val Loss: 0.298871\n",
      "Epoch [200/500] | Train Loss: 0.373900 | Val Loss: 0.286986\n",
      "Epoch [300/500] | Train Loss: 0.326867 | Val Loss: 0.321138\n",
      "Epoch [400/500] | Train Loss: 0.330866 | Val Loss: 0.328604\n",
      "Epoch [500/500] | Train Loss: 0.305650 | Val Loss: 0.331016\n",
      "Epoch [100/500] | Train Loss: 0.390570 | Val Loss: 0.334431\n",
      "Epoch [200/500] | Train Loss: 0.359611 | Val Loss: 0.335080\n",
      "Epoch [300/500] | Train Loss: 0.339935 | Val Loss: 0.339397\n",
      "Epoch [400/500] | Train Loss: 0.345221 | Val Loss: 0.327760\n",
      "Epoch [500/500] | Train Loss: 0.322932 | Val Loss: 0.350294\n",
      "Epoch [100/500] | Train Loss: 0.703872 | Val Loss: 0.382681\n",
      "Epoch [200/500] | Train Loss: 0.624956 | Val Loss: 0.396893\n",
      "Epoch [300/500] | Train Loss: 0.605969 | Val Loss: 0.408804\n",
      "Epoch [400/500] | Train Loss: 0.565937 | Val Loss: 0.425131\n",
      "Epoch [500/500] | Train Loss: 0.534356 | Val Loss: 0.442190\n",
      "Epoch [100/500] | Train Loss: 0.525899 | Val Loss: 0.350257\n",
      "Epoch [200/500] | Train Loss: 0.492896 | Val Loss: 0.332855\n",
      "Epoch [300/500] | Train Loss: 0.474817 | Val Loss: 0.332509\n",
      "Epoch [400/500] | Train Loss: 0.450179 | Val Loss: 0.331277\n",
      "Epoch [500/500] | Train Loss: 0.455544 | Val Loss: 0.326115\n",
      "Epoch [100/500] | Train Loss: 0.456989 | Val Loss: 0.736611\n",
      "Epoch [200/500] | Train Loss: 0.437952 | Val Loss: 0.735167\n",
      "Epoch [300/500] | Train Loss: 0.419198 | Val Loss: 0.730915\n",
      "Epoch [400/500] | Train Loss: 0.409227 | Val Loss: 0.729387\n",
      "Epoch [500/500] | Train Loss: 0.413036 | Val Loss: 0.737113\n",
      "Epoch [100/500] | Train Loss: 0.524843 | Val Loss: 0.293953\n",
      "Epoch [200/500] | Train Loss: 0.494577 | Val Loss: 0.287862\n",
      "Epoch [300/500] | Train Loss: 0.477501 | Val Loss: 0.293089\n",
      "Epoch [400/500] | Train Loss: 0.468486 | Val Loss: 0.293908\n",
      "Epoch [500/500] | Train Loss: 0.471667 | Val Loss: 0.291250\n",
      "Epoch [100/500] | Train Loss: 0.482565 | Val Loss: 0.310247\n",
      "Epoch [200/500] | Train Loss: 0.453573 | Val Loss: 0.305974\n",
      "Epoch [300/500] | Train Loss: 0.438525 | Val Loss: 0.304012\n",
      "Epoch [400/500] | Train Loss: 0.425297 | Val Loss: 0.314442\n",
      "Epoch [500/500] | Train Loss: 0.413877 | Val Loss: 0.315037\n",
      "Epoch [100/500] | Train Loss: 0.557820 | Val Loss: 0.443226\n",
      "Epoch [200/500] | Train Loss: 0.474742 | Val Loss: 0.476462\n",
      "Epoch [300/500] | Train Loss: 0.344802 | Val Loss: 0.507812\n",
      "Epoch [400/500] | Train Loss: 0.461929 | Val Loss: 0.480920\n",
      "Epoch [500/500] | Train Loss: 0.212337 | Val Loss: 0.512065\n",
      "Epoch [100/500] | Train Loss: 0.457500 | Val Loss: 0.321410\n",
      "Epoch [200/500] | Train Loss: 0.411102 | Val Loss: 0.356821\n",
      "Epoch [300/500] | Train Loss: 0.380870 | Val Loss: 0.397140\n",
      "Epoch [400/500] | Train Loss: 0.366552 | Val Loss: 0.379039\n",
      "Epoch [500/500] | Train Loss: 0.379189 | Val Loss: 0.377317\n",
      "Epoch [100/500] | Train Loss: 0.413443 | Val Loss: 0.698506\n",
      "Epoch [200/500] | Train Loss: 0.394212 | Val Loss: 0.714121\n",
      "Epoch [300/500] | Train Loss: 0.383218 | Val Loss: 0.736321\n",
      "Epoch [400/500] | Train Loss: 0.348897 | Val Loss: 0.753052\n",
      "Epoch [500/500] | Train Loss: 0.332497 | Val Loss: 0.782163\n",
      "Epoch [100/500] | Train Loss: 0.471855 | Val Loss: 0.287797\n",
      "Epoch [200/500] | Train Loss: 0.421398 | Val Loss: 0.300303\n",
      "Epoch [300/500] | Train Loss: 0.411707 | Val Loss: 0.295827\n",
      "Epoch [400/500] | Train Loss: 0.407513 | Val Loss: 0.299169\n",
      "Epoch [500/500] | Train Loss: 0.391368 | Val Loss: 0.301939\n",
      "Epoch [100/500] | Train Loss: 0.415262 | Val Loss: 0.305283\n",
      "Epoch [200/500] | Train Loss: 0.373040 | Val Loss: 0.326666\n",
      "Epoch [300/500] | Train Loss: 0.389936 | Val Loss: 0.329562\n",
      "Epoch [400/500] | Train Loss: 0.369283 | Val Loss: 0.330661\n",
      "Epoch [500/500] | Train Loss: 0.338268 | Val Loss: 0.337030\n",
      "Epoch [100/500] | Train Loss: 0.579880 | Val Loss: 0.401398\n",
      "Epoch [200/500] | Train Loss: 0.509798 | Val Loss: 0.461512\n",
      "Epoch [300/500] | Train Loss: 0.392645 | Val Loss: 0.499683\n",
      "Epoch [400/500] | Train Loss: 0.344609 | Val Loss: 0.508814\n",
      "Epoch [500/500] | Train Loss: 0.235416 | Val Loss: 0.551130\n",
      "Epoch [100/500] | Train Loss: 0.477858 | Val Loss: 0.319209\n",
      "Epoch [200/500] | Train Loss: 0.450200 | Val Loss: 0.311115\n",
      "Epoch [300/500] | Train Loss: 0.371873 | Val Loss: 0.324232\n",
      "Epoch [400/500] | Train Loss: 0.353329 | Val Loss: 0.350892\n",
      "Epoch [500/500] | Train Loss: 0.319028 | Val Loss: 0.381217\n",
      "Epoch [100/500] | Train Loss: 0.445047 | Val Loss: 0.728005\n",
      "Epoch [200/500] | Train Loss: 0.409507 | Val Loss: 0.715738\n",
      "Epoch [300/500] | Train Loss: 0.363526 | Val Loss: 0.708215\n",
      "Epoch [400/500] | Train Loss: 0.352514 | Val Loss: 0.709067\n",
      "Epoch [500/500] | Train Loss: 0.349505 | Val Loss: 0.736023\n",
      "Epoch [100/500] | Train Loss: 0.480347 | Val Loss: 0.297619\n",
      "Epoch [200/500] | Train Loss: 0.422858 | Val Loss: 0.295361\n",
      "Epoch [300/500] | Train Loss: 0.394331 | Val Loss: 0.292983\n",
      "Epoch [400/500] | Train Loss: 0.382667 | Val Loss: 0.299063\n",
      "Epoch [500/500] | Train Loss: 0.369674 | Val Loss: 0.302403\n",
      "Epoch [100/500] | Train Loss: 0.440509 | Val Loss: 0.304484\n",
      "Epoch [200/500] | Train Loss: 0.398497 | Val Loss: 0.317336\n",
      "Epoch [300/500] | Train Loss: 0.377715 | Val Loss: 0.314583\n",
      "Epoch [400/500] | Train Loss: 0.358870 | Val Loss: 0.317319\n",
      "Epoch [500/500] | Train Loss: 0.351373 | Val Loss: 0.321589\n",
      "Epoch [100/500] | Train Loss: 0.469467 | Val Loss: 0.528147\n",
      "Epoch [200/500] | Train Loss: 0.185712 | Val Loss: 0.741740\n",
      "Epoch [300/500] | Train Loss: 0.306784 | Val Loss: 0.611640\n",
      "Epoch [400/500] | Train Loss: 0.126350 | Val Loss: 0.558975\n",
      "Epoch [500/500] | Train Loss: 0.121887 | Val Loss: 0.698412\n",
      "Epoch [100/500] | Train Loss: 0.411765 | Val Loss: 0.380055\n",
      "Epoch [200/500] | Train Loss: 0.287575 | Val Loss: 0.418934\n",
      "Epoch [300/500] | Train Loss: 0.190105 | Val Loss: 0.574401\n",
      "Epoch [400/500] | Train Loss: 0.184285 | Val Loss: 0.478829\n",
      "Epoch [500/500] | Train Loss: 0.171001 | Val Loss: 0.557038\n",
      "Epoch [100/500] | Train Loss: 0.363423 | Val Loss: 0.748179\n",
      "Epoch [200/500] | Train Loss: 0.276273 | Val Loss: 0.790849\n",
      "Epoch [300/500] | Train Loss: 0.282579 | Val Loss: 0.830360\n",
      "Epoch [400/500] | Train Loss: 0.220304 | Val Loss: 0.848019\n",
      "Epoch [500/500] | Train Loss: 0.222185 | Val Loss: 0.788951\n",
      "Epoch [100/500] | Train Loss: 0.350671 | Val Loss: 0.309816\n",
      "Epoch [200/500] | Train Loss: 0.330290 | Val Loss: 0.318780\n",
      "Epoch [300/500] | Train Loss: 0.302918 | Val Loss: 0.338708\n",
      "Epoch [400/500] | Train Loss: 0.282617 | Val Loss: 0.355838\n",
      "Epoch [500/500] | Train Loss: 0.218037 | Val Loss: 0.331406\n",
      "Epoch [100/500] | Train Loss: 0.352625 | Val Loss: 0.332684\n",
      "Epoch [200/500] | Train Loss: 0.297388 | Val Loss: 0.355737\n",
      "Epoch [300/500] | Train Loss: 0.294190 | Val Loss: 0.369141\n",
      "Epoch [400/500] | Train Loss: 0.263562 | Val Loss: 0.392075\n",
      "Epoch [500/500] | Train Loss: 0.255741 | Val Loss: 0.387852\n",
      "Epoch [100/500] | Train Loss: 0.596580 | Val Loss: 0.379751\n",
      "Epoch [200/500] | Train Loss: 0.558298 | Val Loss: 0.408316\n",
      "Epoch [300/500] | Train Loss: 0.515127 | Val Loss: 0.441364\n",
      "Epoch [400/500] | Train Loss: 0.474632 | Val Loss: 0.458736\n",
      "Epoch [500/500] | Train Loss: 0.479898 | Val Loss: 0.483084\n",
      "Epoch [100/500] | Train Loss: 0.513059 | Val Loss: 0.334242\n",
      "Epoch [200/500] | Train Loss: 0.465615 | Val Loss: 0.326206\n",
      "Epoch [300/500] | Train Loss: 0.501815 | Val Loss: 0.331286\n",
      "Epoch [400/500] | Train Loss: 0.440964 | Val Loss: 0.340628\n",
      "Epoch [500/500] | Train Loss: 0.465935 | Val Loss: 0.354185\n",
      "Epoch [100/500] | Train Loss: 0.445459 | Val Loss: 0.725052\n",
      "Epoch [200/500] | Train Loss: 0.415307 | Val Loss: 0.710815\n",
      "Epoch [300/500] | Train Loss: 0.408189 | Val Loss: 0.709220\n",
      "Epoch [400/500] | Train Loss: 0.383496 | Val Loss: 0.694975\n",
      "Epoch [500/500] | Train Loss: 0.368430 | Val Loss: 0.702281\n",
      "Epoch [100/500] | Train Loss: 0.512428 | Val Loss: 0.295360\n",
      "Epoch [200/500] | Train Loss: 0.494274 | Val Loss: 0.305494\n",
      "Epoch [300/500] | Train Loss: 0.466018 | Val Loss: 0.302738\n",
      "Epoch [400/500] | Train Loss: 0.456818 | Val Loss: 0.296640\n",
      "Epoch [500/500] | Train Loss: 0.413731 | Val Loss: 0.300176\n",
      "Epoch [100/500] | Train Loss: 0.490022 | Val Loss: 0.314382\n",
      "Epoch [200/500] | Train Loss: 0.459066 | Val Loss: 0.308132\n",
      "Epoch [300/500] | Train Loss: 0.427781 | Val Loss: 0.308512\n",
      "Epoch [400/500] | Train Loss: 0.439068 | Val Loss: 0.309164\n",
      "Epoch [500/500] | Train Loss: 0.397774 | Val Loss: 0.308266\n",
      "Epoch [100/500] | Train Loss: 0.504231 | Val Loss: 0.445639\n",
      "Epoch [200/500] | Train Loss: 0.314600 | Val Loss: 0.446623\n",
      "Epoch [300/500] | Train Loss: 0.212667 | Val Loss: 0.518368\n",
      "Epoch [400/500] | Train Loss: 0.197283 | Val Loss: 0.587365\n",
      "Epoch [500/500] | Train Loss: 0.188683 | Val Loss: 0.554329\n",
      "Epoch [100/500] | Train Loss: 0.411564 | Val Loss: 0.320135\n",
      "Epoch [200/500] | Train Loss: 0.375286 | Val Loss: 0.350795\n",
      "Epoch [300/500] | Train Loss: 0.332638 | Val Loss: 0.428250\n",
      "Epoch [400/500] | Train Loss: 0.288379 | Val Loss: 0.430058\n",
      "Epoch [500/500] | Train Loss: 0.301584 | Val Loss: 0.436755\n",
      "Epoch [100/500] | Train Loss: 0.424218 | Val Loss: 0.718747\n",
      "Epoch [200/500] | Train Loss: 0.381125 | Val Loss: 0.698449\n",
      "Epoch [300/500] | Train Loss: 0.356503 | Val Loss: 0.747447\n",
      "Epoch [400/500] | Train Loss: 0.350506 | Val Loss: 0.737970\n",
      "Epoch [500/500] | Train Loss: 0.337874 | Val Loss: 0.720547\n",
      "Epoch [100/500] | Train Loss: 0.467374 | Val Loss: 0.284455\n",
      "Epoch [200/500] | Train Loss: 0.408593 | Val Loss: 0.288116\n",
      "Epoch [300/500] | Train Loss: 0.384822 | Val Loss: 0.286531\n",
      "Epoch [400/500] | Train Loss: 0.390971 | Val Loss: 0.300612\n",
      "Epoch [500/500] | Train Loss: 0.376368 | Val Loss: 0.298319\n",
      "Epoch [100/500] | Train Loss: 0.417762 | Val Loss: 0.311871\n",
      "Epoch [200/500] | Train Loss: 0.362694 | Val Loss: 0.326623\n",
      "Epoch [300/500] | Train Loss: 0.346212 | Val Loss: 0.306474\n",
      "Epoch [400/500] | Train Loss: 0.353534 | Val Loss: 0.318996\n",
      "Epoch [500/500] | Train Loss: 0.325563 | Val Loss: 0.316358\n",
      "[Year=1960] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.422341 Test MSE=0.369772\n",
      "Year 1960 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.418141 | Val Loss: 0.365481\n",
      "Epoch [200/500] | Train Loss: 0.343184 | Val Loss: 0.375508\n",
      "Epoch [300/500] | Train Loss: 0.295428 | Val Loss: 0.410459\n",
      "Epoch [400/500] | Train Loss: 0.267286 | Val Loss: 0.435891\n",
      "Epoch [500/500] | Train Loss: 0.241492 | Val Loss: 0.450993\n",
      "Epoch [100/500] | Train Loss: 0.367985 | Val Loss: 0.681320\n",
      "Epoch [200/500] | Train Loss: 0.331396 | Val Loss: 0.752702\n",
      "Epoch [300/500] | Train Loss: 0.281384 | Val Loss: 0.802281\n",
      "Epoch [400/500] | Train Loss: 0.270419 | Val Loss: 0.840667\n",
      "Epoch [500/500] | Train Loss: 0.268452 | Val Loss: 0.851750\n",
      "Epoch [100/500] | Train Loss: 0.468137 | Val Loss: 0.296181\n",
      "Epoch [200/500] | Train Loss: 0.435313 | Val Loss: 0.307876\n",
      "Epoch [300/500] | Train Loss: 0.405349 | Val Loss: 0.312658\n",
      "Epoch [400/500] | Train Loss: 0.390110 | Val Loss: 0.312887\n",
      "Epoch [500/500] | Train Loss: 0.344917 | Val Loss: 0.318448\n",
      "Epoch [100/500] | Train Loss: 0.416142 | Val Loss: 0.364782\n",
      "Epoch [200/500] | Train Loss: 0.391483 | Val Loss: 0.358029\n",
      "Epoch [300/500] | Train Loss: 0.357679 | Val Loss: 0.358930\n",
      "Epoch [400/500] | Train Loss: 0.333691 | Val Loss: 0.372518\n",
      "Epoch [500/500] | Train Loss: 0.316259 | Val Loss: 0.384879\n",
      "Epoch [100/500] | Train Loss: 0.404581 | Val Loss: 0.356471\n",
      "Epoch [200/500] | Train Loss: 0.361899 | Val Loss: 0.368744\n",
      "Epoch [300/500] | Train Loss: 0.331859 | Val Loss: 0.376855\n",
      "Epoch [400/500] | Train Loss: 0.332968 | Val Loss: 0.380633\n",
      "Epoch [500/500] | Train Loss: 0.307796 | Val Loss: 0.382307\n",
      "Epoch [100/500] | Train Loss: 0.218976 | Val Loss: 0.419977\n",
      "Epoch [200/500] | Train Loss: 0.170739 | Val Loss: 0.456917\n",
      "Epoch [300/500] | Train Loss: 0.159156 | Val Loss: 0.468498\n",
      "Epoch [400/500] | Train Loss: 0.115591 | Val Loss: 0.485593\n",
      "Epoch [500/500] | Train Loss: 0.112836 | Val Loss: 0.502044\n",
      "Epoch [100/500] | Train Loss: 0.285745 | Val Loss: 0.717404\n",
      "Epoch [200/500] | Train Loss: 0.246792 | Val Loss: 0.736471\n",
      "Epoch [300/500] | Train Loss: 0.186861 | Val Loss: 0.836154\n",
      "Epoch [400/500] | Train Loss: 0.184683 | Val Loss: 0.793022\n",
      "Epoch [500/500] | Train Loss: 0.166955 | Val Loss: 0.818718\n",
      "Epoch [100/500] | Train Loss: 0.360886 | Val Loss: 0.304882\n",
      "Epoch [200/500] | Train Loss: 0.287706 | Val Loss: 0.332137\n",
      "Epoch [300/500] | Train Loss: 0.285978 | Val Loss: 0.333986\n",
      "Epoch [400/500] | Train Loss: 0.255916 | Val Loss: 0.336493\n",
      "Epoch [500/500] | Train Loss: 0.228945 | Val Loss: 0.368770\n",
      "Epoch [100/500] | Train Loss: 0.330105 | Val Loss: 0.357470\n",
      "Epoch [200/500] | Train Loss: 0.300124 | Val Loss: 0.361084\n",
      "Epoch [300/500] | Train Loss: 0.264256 | Val Loss: 0.356885\n",
      "Epoch [400/500] | Train Loss: 0.234420 | Val Loss: 0.356183\n",
      "Epoch [500/500] | Train Loss: 0.243037 | Val Loss: 0.362823\n",
      "Epoch [100/500] | Train Loss: 0.340349 | Val Loss: 0.384924\n",
      "Epoch [200/500] | Train Loss: 0.273519 | Val Loss: 0.386962\n",
      "Epoch [300/500] | Train Loss: 0.254456 | Val Loss: 0.380926\n",
      "Epoch [400/500] | Train Loss: 0.261309 | Val Loss: 0.386576\n",
      "Epoch [500/500] | Train Loss: 0.229578 | Val Loss: 0.384546\n",
      "Epoch [100/500] | Train Loss: 0.388178 | Val Loss: 0.366269\n",
      "Epoch [200/500] | Train Loss: 0.329311 | Val Loss: 0.387296\n",
      "Epoch [300/500] | Train Loss: 0.290834 | Val Loss: 0.412256\n",
      "Epoch [400/500] | Train Loss: 0.262168 | Val Loss: 0.425796\n",
      "Epoch [500/500] | Train Loss: 0.250907 | Val Loss: 0.439386\n",
      "Epoch [100/500] | Train Loss: 0.386445 | Val Loss: 0.667916\n",
      "Epoch [200/500] | Train Loss: 0.356395 | Val Loss: 0.690969\n",
      "Epoch [300/500] | Train Loss: 0.343629 | Val Loss: 0.723257\n",
      "Epoch [400/500] | Train Loss: 0.358679 | Val Loss: 0.735795\n",
      "Epoch [500/500] | Train Loss: 0.332052 | Val Loss: 0.740186\n",
      "Epoch [100/500] | Train Loss: 0.474976 | Val Loss: 0.299574\n",
      "Epoch [200/500] | Train Loss: 0.456768 | Val Loss: 0.295546\n",
      "Epoch [300/500] | Train Loss: 0.411146 | Val Loss: 0.301692\n",
      "Epoch [400/500] | Train Loss: 0.402847 | Val Loss: 0.301732\n",
      "Epoch [500/500] | Train Loss: 0.384563 | Val Loss: 0.302553\n",
      "Epoch [100/500] | Train Loss: 0.426312 | Val Loss: 0.369146\n",
      "Epoch [200/500] | Train Loss: 0.410631 | Val Loss: 0.362459\n",
      "Epoch [300/500] | Train Loss: 0.392236 | Val Loss: 0.359857\n",
      "Epoch [400/500] | Train Loss: 0.382640 | Val Loss: 0.359852\n",
      "Epoch [500/500] | Train Loss: 0.365067 | Val Loss: 0.359933\n",
      "Epoch [100/500] | Train Loss: 0.431048 | Val Loss: 0.359050\n",
      "Epoch [200/500] | Train Loss: 0.413666 | Val Loss: 0.355017\n",
      "Epoch [300/500] | Train Loss: 0.399239 | Val Loss: 0.352657\n",
      "Epoch [400/500] | Train Loss: 0.381725 | Val Loss: 0.355686\n",
      "Epoch [500/500] | Train Loss: 0.363353 | Val Loss: 0.358138\n",
      "Epoch [100/500] | Train Loss: 0.311491 | Val Loss: 0.409239\n",
      "Epoch [200/500] | Train Loss: 0.267488 | Val Loss: 0.409863\n",
      "Epoch [300/500] | Train Loss: 0.206264 | Val Loss: 0.458437\n",
      "Epoch [400/500] | Train Loss: 0.202296 | Val Loss: 0.484855\n",
      "Epoch [500/500] | Train Loss: 0.197284 | Val Loss: 0.457403\n",
      "Epoch [100/500] | Train Loss: 0.347567 | Val Loss: 0.715668\n",
      "Epoch [200/500] | Train Loss: 0.298536 | Val Loss: 0.692935\n",
      "Epoch [300/500] | Train Loss: 0.275242 | Val Loss: 0.675706\n",
      "Epoch [400/500] | Train Loss: 0.279002 | Val Loss: 0.689568\n",
      "Epoch [500/500] | Train Loss: 0.260870 | Val Loss: 0.716228\n",
      "Epoch [100/500] | Train Loss: 0.384311 | Val Loss: 0.292013\n",
      "Epoch [200/500] | Train Loss: 0.351468 | Val Loss: 0.297156\n",
      "Epoch [300/500] | Train Loss: 0.341022 | Val Loss: 0.306312\n",
      "Epoch [400/500] | Train Loss: 0.314352 | Val Loss: 0.301810\n",
      "Epoch [500/500] | Train Loss: 0.327639 | Val Loss: 0.305642\n",
      "Epoch [100/500] | Train Loss: 0.371546 | Val Loss: 0.345151\n",
      "Epoch [200/500] | Train Loss: 0.357832 | Val Loss: 0.353340\n",
      "Epoch [300/500] | Train Loss: 0.312236 | Val Loss: 0.358210\n",
      "Epoch [400/500] | Train Loss: 0.305559 | Val Loss: 0.359572\n",
      "Epoch [500/500] | Train Loss: 0.309537 | Val Loss: 0.377100\n",
      "Epoch [100/500] | Train Loss: 0.388373 | Val Loss: 0.359443\n",
      "Epoch [200/500] | Train Loss: 0.348038 | Val Loss: 0.366589\n",
      "Epoch [300/500] | Train Loss: 0.315129 | Val Loss: 0.362007\n",
      "Epoch [400/500] | Train Loss: 0.313219 | Val Loss: 0.366271\n",
      "Epoch [500/500] | Train Loss: 0.314339 | Val Loss: 0.379180\n",
      "Epoch [100/500] | Train Loss: 0.376803 | Val Loss: 0.358565\n",
      "Epoch [200/500] | Train Loss: 0.311565 | Val Loss: 0.389432\n",
      "Epoch [300/500] | Train Loss: 0.264265 | Val Loss: 0.421177\n",
      "Epoch [400/500] | Train Loss: 0.201387 | Val Loss: 0.455576\n",
      "Epoch [500/500] | Train Loss: 0.178354 | Val Loss: 0.488495\n",
      "Epoch [100/500] | Train Loss: 0.354893 | Val Loss: 0.686705\n",
      "Epoch [200/500] | Train Loss: 0.311139 | Val Loss: 0.723185\n",
      "Epoch [300/500] | Train Loss: 0.272559 | Val Loss: 0.781630\n",
      "Epoch [400/500] | Train Loss: 0.242269 | Val Loss: 0.825133\n",
      "Epoch [500/500] | Train Loss: 0.223547 | Val Loss: 0.850721\n",
      "Epoch [100/500] | Train Loss: 0.451382 | Val Loss: 0.300005\n",
      "Epoch [200/500] | Train Loss: 0.383657 | Val Loss: 0.303209\n",
      "Epoch [300/500] | Train Loss: 0.331074 | Val Loss: 0.317023\n",
      "Epoch [400/500] | Train Loss: 0.314608 | Val Loss: 0.324115\n",
      "Epoch [500/500] | Train Loss: 0.319340 | Val Loss: 0.325721\n",
      "Epoch [100/500] | Train Loss: 0.429277 | Val Loss: 0.366336\n",
      "Epoch [200/500] | Train Loss: 0.359358 | Val Loss: 0.365591\n",
      "Epoch [300/500] | Train Loss: 0.326521 | Val Loss: 0.372543\n",
      "Epoch [400/500] | Train Loss: 0.306316 | Val Loss: 0.373254\n",
      "Epoch [500/500] | Train Loss: 0.296570 | Val Loss: 0.378448\n",
      "Epoch [100/500] | Train Loss: 0.390361 | Val Loss: 0.353130\n",
      "Epoch [200/500] | Train Loss: 0.342066 | Val Loss: 0.368309\n",
      "Epoch [300/500] | Train Loss: 0.323559 | Val Loss: 0.370814\n",
      "Epoch [400/500] | Train Loss: 0.310087 | Val Loss: 0.386049\n",
      "Epoch [500/500] | Train Loss: 0.277216 | Val Loss: 0.400002\n",
      "Epoch [100/500] | Train Loss: 0.201898 | Val Loss: 0.488475\n",
      "Epoch [200/500] | Train Loss: 0.109916 | Val Loss: 0.502890\n",
      "Epoch [300/500] | Train Loss: 0.093763 | Val Loss: 0.530519\n",
      "Epoch [400/500] | Train Loss: 0.081235 | Val Loss: 0.604428\n",
      "Epoch [500/500] | Train Loss: 0.085858 | Val Loss: 0.550612\n",
      "Epoch [100/500] | Train Loss: 0.282094 | Val Loss: 0.744551\n",
      "Epoch [200/500] | Train Loss: 0.214461 | Val Loss: 0.753815\n",
      "Epoch [300/500] | Train Loss: 0.177495 | Val Loss: 0.823258\n",
      "Epoch [400/500] | Train Loss: 0.176707 | Val Loss: 0.802567\n",
      "Epoch [500/500] | Train Loss: 0.162377 | Val Loss: 0.854514\n",
      "Epoch [100/500] | Train Loss: 0.354107 | Val Loss: 0.303242\n",
      "Epoch [200/500] | Train Loss: 0.269450 | Val Loss: 0.321817\n",
      "Epoch [300/500] | Train Loss: 0.272258 | Val Loss: 0.321252\n",
      "Epoch [400/500] | Train Loss: 0.246610 | Val Loss: 0.311416\n",
      "Epoch [500/500] | Train Loss: 0.207243 | Val Loss: 0.338800\n",
      "Epoch [100/500] | Train Loss: 0.299665 | Val Loss: 0.380457\n",
      "Epoch [200/500] | Train Loss: 0.239120 | Val Loss: 0.367943\n",
      "Epoch [300/500] | Train Loss: 0.231676 | Val Loss: 0.379678\n",
      "Epoch [400/500] | Train Loss: 0.217429 | Val Loss: 0.376378\n",
      "Epoch [500/500] | Train Loss: 0.190587 | Val Loss: 0.398826\n",
      "Epoch [100/500] | Train Loss: 0.325501 | Val Loss: 0.401572\n",
      "Epoch [200/500] | Train Loss: 0.283179 | Val Loss: 0.425893\n",
      "Epoch [300/500] | Train Loss: 0.260449 | Val Loss: 0.447629\n",
      "Epoch [400/500] | Train Loss: 0.252618 | Val Loss: 0.446559\n",
      "Epoch [500/500] | Train Loss: 0.244142 | Val Loss: 0.467527\n",
      "Epoch [100/500] | Train Loss: 0.399447 | Val Loss: 0.359332\n",
      "Epoch [200/500] | Train Loss: 0.346595 | Val Loss: 0.371132\n",
      "Epoch [300/500] | Train Loss: 0.326814 | Val Loss: 0.381086\n",
      "Epoch [400/500] | Train Loss: 0.282587 | Val Loss: 0.398273\n",
      "Epoch [500/500] | Train Loss: 0.273879 | Val Loss: 0.401517\n",
      "Epoch [100/500] | Train Loss: 0.383687 | Val Loss: 0.669104\n",
      "Epoch [200/500] | Train Loss: 0.347296 | Val Loss: 0.727062\n",
      "Epoch [300/500] | Train Loss: 0.331374 | Val Loss: 0.724358\n",
      "Epoch [400/500] | Train Loss: 0.304183 | Val Loss: 0.731776\n",
      "Epoch [500/500] | Train Loss: 0.305929 | Val Loss: 0.695161\n",
      "Epoch [100/500] | Train Loss: 0.467399 | Val Loss: 0.292643\n",
      "Epoch [200/500] | Train Loss: 0.447338 | Val Loss: 0.300155\n",
      "Epoch [300/500] | Train Loss: 0.411648 | Val Loss: 0.290719\n",
      "Epoch [400/500] | Train Loss: 0.397450 | Val Loss: 0.290373\n",
      "Epoch [500/500] | Train Loss: 0.355611 | Val Loss: 0.289103\n",
      "Epoch [100/500] | Train Loss: 0.424165 | Val Loss: 0.363501\n",
      "Epoch [200/500] | Train Loss: 0.405374 | Val Loss: 0.358169\n",
      "Epoch [300/500] | Train Loss: 0.373346 | Val Loss: 0.364247\n",
      "Epoch [400/500] | Train Loss: 0.365961 | Val Loss: 0.370245\n",
      "Epoch [500/500] | Train Loss: 0.343130 | Val Loss: 0.372272\n",
      "Epoch [100/500] | Train Loss: 0.425257 | Val Loss: 0.357619\n",
      "Epoch [200/500] | Train Loss: 0.409574 | Val Loss: 0.352770\n",
      "Epoch [300/500] | Train Loss: 0.396730 | Val Loss: 0.360704\n",
      "Epoch [400/500] | Train Loss: 0.360923 | Val Loss: 0.368089\n",
      "Epoch [500/500] | Train Loss: 0.358461 | Val Loss: 0.370008\n",
      "Epoch [100/500] | Train Loss: 0.274805 | Val Loss: 0.431487\n",
      "Epoch [200/500] | Train Loss: 0.217652 | Val Loss: 0.485404\n",
      "Epoch [300/500] | Train Loss: 0.164470 | Val Loss: 0.491237\n",
      "Epoch [400/500] | Train Loss: 0.163160 | Val Loss: 0.490992\n",
      "Epoch [500/500] | Train Loss: 0.157977 | Val Loss: 0.503571\n",
      "Epoch [100/500] | Train Loss: 0.286231 | Val Loss: 0.812477\n",
      "Epoch [200/500] | Train Loss: 0.254927 | Val Loss: 0.838212\n",
      "Epoch [300/500] | Train Loss: 0.245164 | Val Loss: 0.815429\n",
      "Epoch [400/500] | Train Loss: 0.216779 | Val Loss: 0.785437\n",
      "Epoch [500/500] | Train Loss: 0.203122 | Val Loss: 0.841095\n",
      "Epoch [100/500] | Train Loss: 0.366129 | Val Loss: 0.286228\n",
      "Epoch [200/500] | Train Loss: 0.331149 | Val Loss: 0.305197\n",
      "Epoch [300/500] | Train Loss: 0.293220 | Val Loss: 0.297458\n",
      "Epoch [400/500] | Train Loss: 0.299554 | Val Loss: 0.307895\n",
      "Epoch [500/500] | Train Loss: 0.270746 | Val Loss: 0.300580\n",
      "Epoch [100/500] | Train Loss: 0.373159 | Val Loss: 0.361832\n",
      "Epoch [200/500] | Train Loss: 0.353060 | Val Loss: 0.365878\n",
      "Epoch [300/500] | Train Loss: 0.348305 | Val Loss: 0.367599\n",
      "Epoch [400/500] | Train Loss: 0.348183 | Val Loss: 0.364841\n",
      "Epoch [500/500] | Train Loss: 0.325683 | Val Loss: 0.383098\n",
      "Epoch [100/500] | Train Loss: 0.352213 | Val Loss: 0.357951\n",
      "Epoch [200/500] | Train Loss: 0.327822 | Val Loss: 0.370746\n",
      "Epoch [300/500] | Train Loss: 0.318162 | Val Loss: 0.364991\n",
      "Epoch [400/500] | Train Loss: 0.299606 | Val Loss: 0.376567\n",
      "Epoch [500/500] | Train Loss: 0.293722 | Val Loss: 0.384670\n",
      "[Year=1961] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.425612 Test MSE=0.235946\n",
      "Year 1961 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.540671 | Val Loss: 0.457510\n",
      "Epoch [200/500] | Train Loss: 0.461127 | Val Loss: 0.464898\n",
      "Epoch [300/500] | Train Loss: 0.400504 | Val Loss: 0.478854\n",
      "Epoch [400/500] | Train Loss: 0.295856 | Val Loss: 0.515657\n",
      "Epoch [500/500] | Train Loss: 0.301446 | Val Loss: 0.523094\n",
      "Epoch [100/500] | Train Loss: 0.452803 | Val Loss: 0.304475\n",
      "Epoch [200/500] | Train Loss: 0.396834 | Val Loss: 0.295413\n",
      "Epoch [300/500] | Train Loss: 0.392977 | Val Loss: 0.300517\n",
      "Epoch [400/500] | Train Loss: 0.349493 | Val Loss: 0.303789\n",
      "Epoch [500/500] | Train Loss: 0.304629 | Val Loss: 0.313297\n",
      "Epoch [100/500] | Train Loss: 0.408504 | Val Loss: 0.371351\n",
      "Epoch [200/500] | Train Loss: 0.328955 | Val Loss: 0.373596\n",
      "Epoch [300/500] | Train Loss: 0.299079 | Val Loss: 0.381213\n",
      "Epoch [400/500] | Train Loss: 0.282138 | Val Loss: 0.384356\n",
      "Epoch [500/500] | Train Loss: 0.290506 | Val Loss: 0.391019\n",
      "Epoch [100/500] | Train Loss: 0.401691 | Val Loss: 0.329695\n",
      "Epoch [200/500] | Train Loss: 0.356095 | Val Loss: 0.331314\n",
      "Epoch [300/500] | Train Loss: 0.358357 | Val Loss: 0.340433\n",
      "Epoch [400/500] | Train Loss: 0.329089 | Val Loss: 0.340301\n",
      "Epoch [500/500] | Train Loss: 0.323404 | Val Loss: 0.343517\n",
      "Epoch [100/500] | Train Loss: 0.387267 | Val Loss: 0.223146\n",
      "Epoch [200/500] | Train Loss: 0.353353 | Val Loss: 0.228216\n",
      "Epoch [300/500] | Train Loss: 0.319213 | Val Loss: 0.233419\n",
      "Epoch [400/500] | Train Loss: 0.314615 | Val Loss: 0.234730\n",
      "Epoch [500/500] | Train Loss: 0.318367 | Val Loss: 0.235116\n",
      "Epoch [100/500] | Train Loss: 0.333829 | Val Loss: 0.562525\n",
      "Epoch [200/500] | Train Loss: 0.202931 | Val Loss: 0.521476\n",
      "Epoch [300/500] | Train Loss: 0.154968 | Val Loss: 0.552134\n",
      "Epoch [400/500] | Train Loss: 0.163530 | Val Loss: 0.566903\n",
      "Epoch [500/500] | Train Loss: 0.151231 | Val Loss: 0.556872\n",
      "Epoch [100/500] | Train Loss: 0.389668 | Val Loss: 0.315902\n",
      "Epoch [200/500] | Train Loss: 0.266110 | Val Loss: 0.357125\n",
      "Epoch [300/500] | Train Loss: 0.243554 | Val Loss: 0.382563\n",
      "Epoch [400/500] | Train Loss: 0.220613 | Val Loss: 0.398443\n",
      "Epoch [500/500] | Train Loss: 0.194123 | Val Loss: 0.438294\n",
      "Epoch [100/500] | Train Loss: 0.321729 | Val Loss: 0.378691\n",
      "Epoch [200/500] | Train Loss: 0.278292 | Val Loss: 0.398804\n",
      "Epoch [300/500] | Train Loss: 0.248011 | Val Loss: 0.418159\n",
      "Epoch [400/500] | Train Loss: 0.232651 | Val Loss: 0.433815\n",
      "Epoch [500/500] | Train Loss: 0.230964 | Val Loss: 0.441201\n",
      "Epoch [100/500] | Train Loss: 0.313731 | Val Loss: 0.343539\n",
      "Epoch [200/500] | Train Loss: 0.290951 | Val Loss: 0.339220\n",
      "Epoch [300/500] | Train Loss: 0.272520 | Val Loss: 0.368207\n",
      "Epoch [400/500] | Train Loss: 0.263294 | Val Loss: 0.353194\n",
      "Epoch [500/500] | Train Loss: 0.235172 | Val Loss: 0.362219\n",
      "Epoch [100/500] | Train Loss: 0.318300 | Val Loss: 0.252384\n",
      "Epoch [200/500] | Train Loss: 0.257965 | Val Loss: 0.277068\n",
      "Epoch [300/500] | Train Loss: 0.245208 | Val Loss: 0.274564\n",
      "Epoch [400/500] | Train Loss: 0.230624 | Val Loss: 0.269774\n",
      "Epoch [500/500] | Train Loss: 0.248281 | Val Loss: 0.277881\n",
      "Epoch [100/500] | Train Loss: 0.568334 | Val Loss: 0.448465\n",
      "Epoch [200/500] | Train Loss: 0.544227 | Val Loss: 0.454198\n",
      "Epoch [300/500] | Train Loss: 0.420376 | Val Loss: 0.469792\n",
      "Epoch [400/500] | Train Loss: 0.453975 | Val Loss: 0.481183\n",
      "Epoch [500/500] | Train Loss: 0.356532 | Val Loss: 0.488345\n",
      "Epoch [100/500] | Train Loss: 0.537902 | Val Loss: 0.329691\n",
      "Epoch [200/500] | Train Loss: 0.476555 | Val Loss: 0.310369\n",
      "Epoch [300/500] | Train Loss: 0.465008 | Val Loss: 0.302695\n",
      "Epoch [400/500] | Train Loss: 0.458203 | Val Loss: 0.303937\n",
      "Epoch [500/500] | Train Loss: 0.418301 | Val Loss: 0.307150\n",
      "Epoch [100/500] | Train Loss: 0.443268 | Val Loss: 0.372166\n",
      "Epoch [200/500] | Train Loss: 0.412897 | Val Loss: 0.369007\n",
      "Epoch [300/500] | Train Loss: 0.381032 | Val Loss: 0.366404\n",
      "Epoch [400/500] | Train Loss: 0.376243 | Val Loss: 0.367646\n",
      "Epoch [500/500] | Train Loss: 0.354387 | Val Loss: 0.361020\n",
      "Epoch [100/500] | Train Loss: 0.418106 | Val Loss: 0.342310\n",
      "Epoch [200/500] | Train Loss: 0.394158 | Val Loss: 0.321815\n",
      "Epoch [300/500] | Train Loss: 0.374919 | Val Loss: 0.318926\n",
      "Epoch [400/500] | Train Loss: 0.371047 | Val Loss: 0.314361\n",
      "Epoch [500/500] | Train Loss: 0.354134 | Val Loss: 0.314902\n",
      "Epoch [100/500] | Train Loss: 0.396426 | Val Loss: 0.227963\n",
      "Epoch [200/500] | Train Loss: 0.388773 | Val Loss: 0.227415\n",
      "Epoch [300/500] | Train Loss: 0.372327 | Val Loss: 0.225993\n",
      "Epoch [400/500] | Train Loss: 0.370937 | Val Loss: 0.228115\n",
      "Epoch [500/500] | Train Loss: 0.354548 | Val Loss: 0.232708\n",
      "Epoch [100/500] | Train Loss: 0.368879 | Val Loss: 0.472925\n",
      "Epoch [200/500] | Train Loss: 0.233796 | Val Loss: 0.476146\n",
      "Epoch [300/500] | Train Loss: 0.226877 | Val Loss: 0.495408\n",
      "Epoch [400/500] | Train Loss: 0.277221 | Val Loss: 0.522206\n",
      "Epoch [500/500] | Train Loss: 0.233181 | Val Loss: 0.512392\n",
      "Epoch [100/500] | Train Loss: 0.419166 | Val Loss: 0.308657\n",
      "Epoch [200/500] | Train Loss: 0.364684 | Val Loss: 0.293041\n",
      "Epoch [300/500] | Train Loss: 0.292533 | Val Loss: 0.288553\n",
      "Epoch [400/500] | Train Loss: 0.322364 | Val Loss: 0.298078\n",
      "Epoch [500/500] | Train Loss: 0.301607 | Val Loss: 0.312283\n",
      "Epoch [100/500] | Train Loss: 0.368240 | Val Loss: 0.380931\n",
      "Epoch [200/500] | Train Loss: 0.359115 | Val Loss: 0.377861\n",
      "Epoch [300/500] | Train Loss: 0.272206 | Val Loss: 0.382873\n",
      "Epoch [400/500] | Train Loss: 0.288119 | Val Loss: 0.379193\n",
      "Epoch [500/500] | Train Loss: 0.281467 | Val Loss: 0.371668\n",
      "Epoch [100/500] | Train Loss: 0.363357 | Val Loss: 0.328288\n",
      "Epoch [200/500] | Train Loss: 0.307959 | Val Loss: 0.324782\n",
      "Epoch [300/500] | Train Loss: 0.299768 | Val Loss: 0.331593\n",
      "Epoch [400/500] | Train Loss: 0.305125 | Val Loss: 0.336143\n",
      "Epoch [500/500] | Train Loss: 0.292995 | Val Loss: 0.339460\n",
      "Epoch [100/500] | Train Loss: 0.355069 | Val Loss: 0.231500\n",
      "Epoch [200/500] | Train Loss: 0.334071 | Val Loss: 0.241173\n",
      "Epoch [300/500] | Train Loss: 0.319952 | Val Loss: 0.253131\n",
      "Epoch [400/500] | Train Loss: 0.291638 | Val Loss: 0.252390\n",
      "Epoch [500/500] | Train Loss: 0.304466 | Val Loss: 0.268441\n",
      "Epoch [100/500] | Train Loss: 0.495004 | Val Loss: 0.454928\n",
      "Epoch [200/500] | Train Loss: 0.325434 | Val Loss: 0.520643\n",
      "Epoch [300/500] | Train Loss: 0.250012 | Val Loss: 0.560497\n",
      "Epoch [400/500] | Train Loss: 0.238403 | Val Loss: 0.592978\n",
      "Epoch [500/500] | Train Loss: 0.232122 | Val Loss: 0.616278\n",
      "Epoch [100/500] | Train Loss: 0.464169 | Val Loss: 0.308130\n",
      "Epoch [200/500] | Train Loss: 0.370909 | Val Loss: 0.321684\n",
      "Epoch [300/500] | Train Loss: 0.339723 | Val Loss: 0.312740\n",
      "Epoch [400/500] | Train Loss: 0.265236 | Val Loss: 0.310955\n",
      "Epoch [500/500] | Train Loss: 0.260428 | Val Loss: 0.306885\n",
      "Epoch [100/500] | Train Loss: 0.410704 | Val Loss: 0.372897\n",
      "Epoch [200/500] | Train Loss: 0.347251 | Val Loss: 0.385851\n",
      "Epoch [300/500] | Train Loss: 0.303987 | Val Loss: 0.399187\n",
      "Epoch [400/500] | Train Loss: 0.282419 | Val Loss: 0.394177\n",
      "Epoch [500/500] | Train Loss: 0.264134 | Val Loss: 0.394866\n",
      "Epoch [100/500] | Train Loss: 0.396806 | Val Loss: 0.325846\n",
      "Epoch [200/500] | Train Loss: 0.353872 | Val Loss: 0.321343\n",
      "Epoch [300/500] | Train Loss: 0.338774 | Val Loss: 0.325683\n",
      "Epoch [400/500] | Train Loss: 0.313038 | Val Loss: 0.330652\n",
      "Epoch [500/500] | Train Loss: 0.290893 | Val Loss: 0.330021\n",
      "Epoch [100/500] | Train Loss: 0.413610 | Val Loss: 0.227719\n",
      "Epoch [200/500] | Train Loss: 0.378660 | Val Loss: 0.223355\n",
      "Epoch [300/500] | Train Loss: 0.360604 | Val Loss: 0.224653\n",
      "Epoch [400/500] | Train Loss: 0.325821 | Val Loss: 0.233251\n",
      "Epoch [500/500] | Train Loss: 0.308928 | Val Loss: 0.246417\n",
      "Epoch [100/500] | Train Loss: 0.354969 | Val Loss: 0.505550\n",
      "Epoch [200/500] | Train Loss: 0.180689 | Val Loss: 0.521478\n",
      "Epoch [300/500] | Train Loss: 0.178356 | Val Loss: 0.571014\n",
      "Epoch [400/500] | Train Loss: 0.141758 | Val Loss: 0.587314\n",
      "Epoch [500/500] | Train Loss: 0.113943 | Val Loss: 0.603468\n",
      "Epoch [100/500] | Train Loss: 0.378100 | Val Loss: 0.308106\n",
      "Epoch [200/500] | Train Loss: 0.314344 | Val Loss: 0.363299\n",
      "Epoch [300/500] | Train Loss: 0.245926 | Val Loss: 0.363419\n",
      "Epoch [400/500] | Train Loss: 0.230460 | Val Loss: 0.366769\n",
      "Epoch [500/500] | Train Loss: 0.229769 | Val Loss: 0.364712\n",
      "Epoch [100/500] | Train Loss: 0.266239 | Val Loss: 0.398620\n",
      "Epoch [200/500] | Train Loss: 0.209139 | Val Loss: 0.428696\n",
      "Epoch [300/500] | Train Loss: 0.186032 | Val Loss: 0.416364\n",
      "Epoch [400/500] | Train Loss: 0.183216 | Val Loss: 0.417140\n",
      "Epoch [500/500] | Train Loss: 0.162821 | Val Loss: 0.428539\n",
      "Epoch [100/500] | Train Loss: 0.331646 | Val Loss: 0.336021\n",
      "Epoch [200/500] | Train Loss: 0.252043 | Val Loss: 0.365271\n",
      "Epoch [300/500] | Train Loss: 0.218640 | Val Loss: 0.400843\n",
      "Epoch [400/500] | Train Loss: 0.205777 | Val Loss: 0.406873\n",
      "Epoch [500/500] | Train Loss: 0.186153 | Val Loss: 0.432014\n",
      "Epoch [100/500] | Train Loss: 0.351293 | Val Loss: 0.229063\n",
      "Epoch [200/500] | Train Loss: 0.288156 | Val Loss: 0.274401\n",
      "Epoch [300/500] | Train Loss: 0.248608 | Val Loss: 0.268655\n",
      "Epoch [400/500] | Train Loss: 0.230793 | Val Loss: 0.287481\n",
      "Epoch [500/500] | Train Loss: 0.222311 | Val Loss: 0.279000\n",
      "Epoch [100/500] | Train Loss: 0.522721 | Val Loss: 0.451434\n",
      "Epoch [200/500] | Train Loss: 0.399548 | Val Loss: 0.455203\n",
      "Epoch [300/500] | Train Loss: 0.365431 | Val Loss: 0.468280\n",
      "Epoch [400/500] | Train Loss: 0.275855 | Val Loss: 0.496498\n",
      "Epoch [500/500] | Train Loss: 0.300914 | Val Loss: 0.486844\n",
      "Epoch [100/500] | Train Loss: 0.472488 | Val Loss: 0.314231\n",
      "Epoch [200/500] | Train Loss: 0.431627 | Val Loss: 0.312084\n",
      "Epoch [300/500] | Train Loss: 0.382952 | Val Loss: 0.299531\n",
      "Epoch [400/500] | Train Loss: 0.372070 | Val Loss: 0.303124\n",
      "Epoch [500/500] | Train Loss: 0.335124 | Val Loss: 0.306707\n",
      "Epoch [100/500] | Train Loss: 0.419294 | Val Loss: 0.377298\n",
      "Epoch [200/500] | Train Loss: 0.386163 | Val Loss: 0.369835\n",
      "Epoch [300/500] | Train Loss: 0.374134 | Val Loss: 0.370234\n",
      "Epoch [400/500] | Train Loss: 0.355723 | Val Loss: 0.371558\n",
      "Epoch [500/500] | Train Loss: 0.338828 | Val Loss: 0.373868\n",
      "Epoch [100/500] | Train Loss: 0.407081 | Val Loss: 0.329645\n",
      "Epoch [200/500] | Train Loss: 0.385529 | Val Loss: 0.315852\n",
      "Epoch [300/500] | Train Loss: 0.347466 | Val Loss: 0.320411\n",
      "Epoch [400/500] | Train Loss: 0.321969 | Val Loss: 0.331094\n",
      "Epoch [500/500] | Train Loss: 0.323473 | Val Loss: 0.327217\n",
      "Epoch [100/500] | Train Loss: 0.396838 | Val Loss: 0.223090\n",
      "Epoch [200/500] | Train Loss: 0.357961 | Val Loss: 0.224996\n",
      "Epoch [300/500] | Train Loss: 0.335659 | Val Loss: 0.228094\n",
      "Epoch [400/500] | Train Loss: 0.329432 | Val Loss: 0.229108\n",
      "Epoch [500/500] | Train Loss: 0.323970 | Val Loss: 0.228813\n",
      "Epoch [100/500] | Train Loss: 0.413987 | Val Loss: 0.489909\n",
      "Epoch [200/500] | Train Loss: 0.319994 | Val Loss: 0.534514\n",
      "Epoch [300/500] | Train Loss: 0.226006 | Val Loss: 0.537091\n",
      "Epoch [400/500] | Train Loss: 0.216153 | Val Loss: 0.527887\n",
      "Epoch [500/500] | Train Loss: 0.216250 | Val Loss: 0.584548\n",
      "Epoch [100/500] | Train Loss: 0.374624 | Val Loss: 0.296565\n",
      "Epoch [200/500] | Train Loss: 0.355384 | Val Loss: 0.292999\n",
      "Epoch [300/500] | Train Loss: 0.308946 | Val Loss: 0.302597\n",
      "Epoch [400/500] | Train Loss: 0.331443 | Val Loss: 0.298205\n",
      "Epoch [500/500] | Train Loss: 0.270409 | Val Loss: 0.316071\n",
      "Epoch [100/500] | Train Loss: 0.364121 | Val Loss: 0.391587\n",
      "Epoch [200/500] | Train Loss: 0.299545 | Val Loss: 0.374282\n",
      "Epoch [300/500] | Train Loss: 0.258936 | Val Loss: 0.398677\n",
      "Epoch [400/500] | Train Loss: 0.227221 | Val Loss: 0.426194\n",
      "Epoch [500/500] | Train Loss: 0.231705 | Val Loss: 0.409597\n",
      "Epoch [100/500] | Train Loss: 0.362297 | Val Loss: 0.323411\n",
      "Epoch [200/500] | Train Loss: 0.278588 | Val Loss: 0.346715\n",
      "Epoch [300/500] | Train Loss: 0.261851 | Val Loss: 0.358131\n",
      "Epoch [400/500] | Train Loss: 0.267500 | Val Loss: 0.365045\n",
      "Epoch [500/500] | Train Loss: 0.248860 | Val Loss: 0.369598\n",
      "Epoch [100/500] | Train Loss: 0.357191 | Val Loss: 0.231184\n",
      "Epoch [200/500] | Train Loss: 0.327452 | Val Loss: 0.240180\n",
      "Epoch [300/500] | Train Loss: 0.315040 | Val Loss: 0.255280\n",
      "Epoch [400/500] | Train Loss: 0.306021 | Val Loss: 0.257267\n",
      "Epoch [500/500] | Train Loss: 0.274968 | Val Loss: 0.262576\n",
      "[Year=1962] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.340825 Test MSE=1.179197\n",
      "Year 1962 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.293690 | Val Loss: 0.354020\n",
      "Epoch [200/500] | Train Loss: 0.233959 | Val Loss: 0.336605\n",
      "Epoch [300/500] | Train Loss: 0.217360 | Val Loss: 0.336392\n",
      "Epoch [400/500] | Train Loss: 0.212130 | Val Loss: 0.351460\n",
      "Epoch [500/500] | Train Loss: 0.166761 | Val Loss: 0.355548\n",
      "Epoch [100/500] | Train Loss: 0.268652 | Val Loss: 0.340582\n",
      "Epoch [200/500] | Train Loss: 0.243396 | Val Loss: 0.357828\n",
      "Epoch [300/500] | Train Loss: 0.213994 | Val Loss: 0.383823\n",
      "Epoch [400/500] | Train Loss: 0.223750 | Val Loss: 0.403946\n",
      "Epoch [500/500] | Train Loss: 0.197668 | Val Loss: 0.417489\n",
      "Epoch [100/500] | Train Loss: 0.295403 | Val Loss: 0.360237\n",
      "Epoch [200/500] | Train Loss: 0.284059 | Val Loss: 0.365939\n",
      "Epoch [300/500] | Train Loss: 0.254147 | Val Loss: 0.366241\n",
      "Epoch [400/500] | Train Loss: 0.237289 | Val Loss: 0.374756\n",
      "Epoch [500/500] | Train Loss: 0.245024 | Val Loss: 0.389209\n",
      "Epoch [100/500] | Train Loss: 0.319562 | Val Loss: 0.203974\n",
      "Epoch [200/500] | Train Loss: 0.308979 | Val Loss: 0.201353\n",
      "Epoch [300/500] | Train Loss: 0.289362 | Val Loss: 0.204409\n",
      "Epoch [400/500] | Train Loss: 0.274522 | Val Loss: 0.216226\n",
      "Epoch [500/500] | Train Loss: 0.256668 | Val Loss: 0.219649\n",
      "Epoch [100/500] | Train Loss: 0.298100 | Val Loss: 1.239222\n",
      "Epoch [200/500] | Train Loss: 0.285712 | Val Loss: 1.255558\n",
      "Epoch [300/500] | Train Loss: 0.271928 | Val Loss: 1.307482\n",
      "Epoch [400/500] | Train Loss: 0.268558 | Val Loss: 1.293975\n",
      "Epoch [500/500] | Train Loss: 0.252469 | Val Loss: 1.312945\n",
      "Epoch [100/500] | Train Loss: 0.134835 | Val Loss: 0.427430\n",
      "Epoch [200/500] | Train Loss: 0.098723 | Val Loss: 0.446344\n",
      "Epoch [300/500] | Train Loss: 0.076932 | Val Loss: 0.432377\n",
      "Epoch [400/500] | Train Loss: 0.084979 | Val Loss: 0.430748\n",
      "Epoch [500/500] | Train Loss: 0.060902 | Val Loss: 0.467020\n",
      "Epoch [100/500] | Train Loss: 0.229146 | Val Loss: 0.386721\n",
      "Epoch [200/500] | Train Loss: 0.206934 | Val Loss: 0.428084\n",
      "Epoch [300/500] | Train Loss: 0.177460 | Val Loss: 0.444265\n",
      "Epoch [400/500] | Train Loss: 0.170359 | Val Loss: 0.414400\n",
      "Epoch [500/500] | Train Loss: 0.158023 | Val Loss: 0.410871\n",
      "Epoch [100/500] | Train Loss: 0.266614 | Val Loss: 0.372608\n",
      "Epoch [200/500] | Train Loss: 0.241254 | Val Loss: 0.382284\n",
      "Epoch [300/500] | Train Loss: 0.216180 | Val Loss: 0.397163\n",
      "Epoch [400/500] | Train Loss: 0.181806 | Val Loss: 0.385546\n",
      "Epoch [500/500] | Train Loss: 0.182224 | Val Loss: 0.377746\n",
      "Epoch [100/500] | Train Loss: 0.285410 | Val Loss: 0.216592\n",
      "Epoch [200/500] | Train Loss: 0.233513 | Val Loss: 0.253626\n",
      "Epoch [300/500] | Train Loss: 0.216365 | Val Loss: 0.252085\n",
      "Epoch [400/500] | Train Loss: 0.217549 | Val Loss: 0.267365\n",
      "Epoch [500/500] | Train Loss: 0.191770 | Val Loss: 0.269534\n",
      "Epoch [100/500] | Train Loss: 0.250735 | Val Loss: 1.512466\n",
      "Epoch [200/500] | Train Loss: 0.214771 | Val Loss: 1.522470\n",
      "Epoch [300/500] | Train Loss: 0.204983 | Val Loss: 1.449672\n",
      "Epoch [400/500] | Train Loss: 0.192582 | Val Loss: 1.364384\n",
      "Epoch [500/500] | Train Loss: 0.190360 | Val Loss: 1.450695\n",
      "Epoch [100/500] | Train Loss: 0.252707 | Val Loss: 0.335328\n",
      "Epoch [200/500] | Train Loss: 0.243353 | Val Loss: 0.335613\n",
      "Epoch [300/500] | Train Loss: 0.228975 | Val Loss: 0.343448\n",
      "Epoch [400/500] | Train Loss: 0.206066 | Val Loss: 0.357691\n",
      "Epoch [500/500] | Train Loss: 0.171736 | Val Loss: 0.359537\n",
      "Epoch [100/500] | Train Loss: 0.282533 | Val Loss: 0.349210\n",
      "Epoch [200/500] | Train Loss: 0.260943 | Val Loss: 0.360077\n",
      "Epoch [300/500] | Train Loss: 0.244762 | Val Loss: 0.366426\n",
      "Epoch [400/500] | Train Loss: 0.235085 | Val Loss: 0.367988\n",
      "Epoch [500/500] | Train Loss: 0.245838 | Val Loss: 0.381959\n",
      "Epoch [100/500] | Train Loss: 0.299883 | Val Loss: 0.360469\n",
      "Epoch [200/500] | Train Loss: 0.292211 | Val Loss: 0.357551\n",
      "Epoch [300/500] | Train Loss: 0.287123 | Val Loss: 0.362257\n",
      "Epoch [400/500] | Train Loss: 0.274320 | Val Loss: 0.369019\n",
      "Epoch [500/500] | Train Loss: 0.269665 | Val Loss: 0.370322\n",
      "Epoch [100/500] | Train Loss: 0.328283 | Val Loss: 0.211327\n",
      "Epoch [200/500] | Train Loss: 0.314961 | Val Loss: 0.202976\n",
      "Epoch [300/500] | Train Loss: 0.310722 | Val Loss: 0.203009\n",
      "Epoch [400/500] | Train Loss: 0.299464 | Val Loss: 0.205051\n",
      "Epoch [500/500] | Train Loss: 0.283447 | Val Loss: 0.213380\n",
      "Epoch [100/500] | Train Loss: 0.308479 | Val Loss: 1.244583\n",
      "Epoch [200/500] | Train Loss: 0.296439 | Val Loss: 1.247568\n",
      "Epoch [300/500] | Train Loss: 0.287740 | Val Loss: 1.298437\n",
      "Epoch [400/500] | Train Loss: 0.275741 | Val Loss: 1.345614\n",
      "Epoch [500/500] | Train Loss: 0.266107 | Val Loss: 1.382670\n",
      "Epoch [100/500] | Train Loss: 0.215144 | Val Loss: 0.354105\n",
      "Epoch [200/500] | Train Loss: 0.187098 | Val Loss: 0.390883\n",
      "Epoch [300/500] | Train Loss: 0.176886 | Val Loss: 0.385388\n",
      "Epoch [400/500] | Train Loss: 0.144707 | Val Loss: 0.403217\n",
      "Epoch [500/500] | Train Loss: 0.152825 | Val Loss: 0.397346\n",
      "Epoch [100/500] | Train Loss: 0.251668 | Val Loss: 0.389441\n",
      "Epoch [200/500] | Train Loss: 0.225716 | Val Loss: 0.413421\n",
      "Epoch [300/500] | Train Loss: 0.186320 | Val Loss: 0.424914\n",
      "Epoch [400/500] | Train Loss: 0.179698 | Val Loss: 0.427495\n",
      "Epoch [500/500] | Train Loss: 0.198399 | Val Loss: 0.437545\n",
      "Epoch [100/500] | Train Loss: 0.290844 | Val Loss: 0.367257\n",
      "Epoch [200/500] | Train Loss: 0.271488 | Val Loss: 0.362118\n",
      "Epoch [300/500] | Train Loss: 0.255113 | Val Loss: 0.379119\n",
      "Epoch [400/500] | Train Loss: 0.245597 | Val Loss: 0.388662\n",
      "Epoch [500/500] | Train Loss: 0.210591 | Val Loss: 0.393400\n",
      "Epoch [100/500] | Train Loss: 0.287241 | Val Loss: 0.217302\n",
      "Epoch [200/500] | Train Loss: 0.270316 | Val Loss: 0.221307\n",
      "Epoch [300/500] | Train Loss: 0.254192 | Val Loss: 0.221609\n",
      "Epoch [400/500] | Train Loss: 0.260997 | Val Loss: 0.228524\n",
      "Epoch [500/500] | Train Loss: 0.238880 | Val Loss: 0.240658\n",
      "Epoch [100/500] | Train Loss: 0.281921 | Val Loss: 1.334165\n",
      "Epoch [200/500] | Train Loss: 0.260336 | Val Loss: 1.591086\n",
      "Epoch [300/500] | Train Loss: 0.253474 | Val Loss: 1.534352\n",
      "Epoch [400/500] | Train Loss: 0.244852 | Val Loss: 1.617352\n",
      "Epoch [500/500] | Train Loss: 0.245083 | Val Loss: 1.623140\n",
      "Epoch [100/500] | Train Loss: 0.243314 | Val Loss: 0.337890\n",
      "Epoch [200/500] | Train Loss: 0.218518 | Val Loss: 0.353677\n",
      "Epoch [300/500] | Train Loss: 0.167928 | Val Loss: 0.401818\n",
      "Epoch [400/500] | Train Loss: 0.146299 | Val Loss: 0.408152\n",
      "Epoch [500/500] | Train Loss: 0.118030 | Val Loss: 0.403893\n",
      "Epoch [100/500] | Train Loss: 0.284259 | Val Loss: 0.349225\n",
      "Epoch [200/500] | Train Loss: 0.240756 | Val Loss: 0.370865\n",
      "Epoch [300/500] | Train Loss: 0.212216 | Val Loss: 0.390856\n",
      "Epoch [400/500] | Train Loss: 0.197139 | Val Loss: 0.414243\n",
      "Epoch [500/500] | Train Loss: 0.178934 | Val Loss: 0.433703\n",
      "Epoch [100/500] | Train Loss: 0.308928 | Val Loss: 0.362307\n",
      "Epoch [200/500] | Train Loss: 0.287930 | Val Loss: 0.370167\n",
      "Epoch [300/500] | Train Loss: 0.254051 | Val Loss: 0.379540\n",
      "Epoch [400/500] | Train Loss: 0.234680 | Val Loss: 0.389564\n",
      "Epoch [500/500] | Train Loss: 0.229859 | Val Loss: 0.394400\n",
      "Epoch [100/500] | Train Loss: 0.325987 | Val Loss: 0.210240\n",
      "Epoch [200/500] | Train Loss: 0.307047 | Val Loss: 0.201000\n",
      "Epoch [300/500] | Train Loss: 0.277260 | Val Loss: 0.214632\n",
      "Epoch [400/500] | Train Loss: 0.262870 | Val Loss: 0.222132\n",
      "Epoch [500/500] | Train Loss: 0.252522 | Val Loss: 0.233294\n",
      "Epoch [100/500] | Train Loss: 0.299927 | Val Loss: 1.251079\n",
      "Epoch [200/500] | Train Loss: 0.286638 | Val Loss: 1.254015\n",
      "Epoch [300/500] | Train Loss: 0.267580 | Val Loss: 1.283985\n",
      "Epoch [400/500] | Train Loss: 0.257253 | Val Loss: 1.346081\n",
      "Epoch [500/500] | Train Loss: 0.238138 | Val Loss: 1.414118\n",
      "Epoch [100/500] | Train Loss: 0.143847 | Val Loss: 0.409125\n",
      "Epoch [200/500] | Train Loss: 0.087901 | Val Loss: 0.426452\n",
      "Epoch [300/500] | Train Loss: 0.069752 | Val Loss: 0.450440\n",
      "Epoch [400/500] | Train Loss: 0.073991 | Val Loss: 0.423916\n",
      "Epoch [500/500] | Train Loss: 0.052244 | Val Loss: 0.448892\n",
      "Epoch [100/500] | Train Loss: 0.251355 | Val Loss: 0.375463\n",
      "Epoch [200/500] | Train Loss: 0.211067 | Val Loss: 0.397729\n",
      "Epoch [300/500] | Train Loss: 0.168405 | Val Loss: 0.464042\n",
      "Epoch [400/500] | Train Loss: 0.145854 | Val Loss: 0.506266\n",
      "Epoch [500/500] | Train Loss: 0.132180 | Val Loss: 0.489595\n",
      "Epoch [100/500] | Train Loss: 0.244521 | Val Loss: 0.375948\n",
      "Epoch [200/500] | Train Loss: 0.199349 | Val Loss: 0.375134\n",
      "Epoch [300/500] | Train Loss: 0.173355 | Val Loss: 0.397211\n",
      "Epoch [400/500] | Train Loss: 0.164663 | Val Loss: 0.407928\n",
      "Epoch [500/500] | Train Loss: 0.151435 | Val Loss: 0.428400\n",
      "Epoch [100/500] | Train Loss: 0.273102 | Val Loss: 0.219986\n",
      "Epoch [200/500] | Train Loss: 0.216341 | Val Loss: 0.254958\n",
      "Epoch [300/500] | Train Loss: 0.194255 | Val Loss: 0.263050\n",
      "Epoch [400/500] | Train Loss: 0.163235 | Val Loss: 0.256155\n",
      "Epoch [500/500] | Train Loss: 0.147336 | Val Loss: 0.284625\n",
      "Epoch [100/500] | Train Loss: 0.244045 | Val Loss: 1.460754\n",
      "Epoch [200/500] | Train Loss: 0.211092 | Val Loss: 1.604846\n",
      "Epoch [300/500] | Train Loss: 0.189842 | Val Loss: 1.435541\n",
      "Epoch [400/500] | Train Loss: 0.180690 | Val Loss: 1.482287\n",
      "Epoch [500/500] | Train Loss: 0.156776 | Val Loss: 1.575704\n",
      "Epoch [100/500] | Train Loss: 0.271080 | Val Loss: 0.338434\n",
      "Epoch [200/500] | Train Loss: 0.245066 | Val Loss: 0.355666\n",
      "Epoch [300/500] | Train Loss: 0.202824 | Val Loss: 0.358507\n",
      "Epoch [400/500] | Train Loss: 0.181487 | Val Loss: 0.357610\n",
      "Epoch [500/500] | Train Loss: 0.155215 | Val Loss: 0.363983\n",
      "Epoch [100/500] | Train Loss: 0.293015 | Val Loss: 0.343829\n",
      "Epoch [200/500] | Train Loss: 0.271622 | Val Loss: 0.355805\n",
      "Epoch [300/500] | Train Loss: 0.248532 | Val Loss: 0.367970\n",
      "Epoch [400/500] | Train Loss: 0.237630 | Val Loss: 0.387429\n",
      "Epoch [500/500] | Train Loss: 0.232267 | Val Loss: 0.404572\n",
      "Epoch [100/500] | Train Loss: 0.299894 | Val Loss: 0.360608\n",
      "Epoch [200/500] | Train Loss: 0.284769 | Val Loss: 0.369772\n",
      "Epoch [300/500] | Train Loss: 0.262539 | Val Loss: 0.386874\n",
      "Epoch [400/500] | Train Loss: 0.246463 | Val Loss: 0.391846\n",
      "Epoch [500/500] | Train Loss: 0.236116 | Val Loss: 0.404931\n",
      "Epoch [100/500] | Train Loss: 0.317525 | Val Loss: 0.200285\n",
      "Epoch [200/500] | Train Loss: 0.297217 | Val Loss: 0.209609\n",
      "Epoch [300/500] | Train Loss: 0.277706 | Val Loss: 0.223247\n",
      "Epoch [400/500] | Train Loss: 0.262994 | Val Loss: 0.232861\n",
      "Epoch [500/500] | Train Loss: 0.259797 | Val Loss: 0.235263\n",
      "Epoch [100/500] | Train Loss: 0.300670 | Val Loss: 1.280792\n",
      "Epoch [200/500] | Train Loss: 0.282892 | Val Loss: 1.278417\n",
      "Epoch [300/500] | Train Loss: 0.268879 | Val Loss: 1.305544\n",
      "Epoch [400/500] | Train Loss: 0.263265 | Val Loss: 1.320547\n",
      "Epoch [500/500] | Train Loss: 0.256184 | Val Loss: 1.335039\n",
      "Epoch [100/500] | Train Loss: 0.188954 | Val Loss: 0.369622\n",
      "Epoch [200/500] | Train Loss: 0.124504 | Val Loss: 0.381031\n",
      "Epoch [300/500] | Train Loss: 0.096464 | Val Loss: 0.412388\n",
      "Epoch [400/500] | Train Loss: 0.103630 | Val Loss: 0.432737\n",
      "Epoch [500/500] | Train Loss: 0.094605 | Val Loss: 0.418807\n",
      "Epoch [100/500] | Train Loss: 0.235920 | Val Loss: 0.365329\n",
      "Epoch [200/500] | Train Loss: 0.201724 | Val Loss: 0.413529\n",
      "Epoch [300/500] | Train Loss: 0.188048 | Val Loss: 0.453364\n",
      "Epoch [400/500] | Train Loss: 0.164710 | Val Loss: 0.435239\n",
      "Epoch [500/500] | Train Loss: 0.164929 | Val Loss: 0.456014\n",
      "Epoch [100/500] | Train Loss: 0.258210 | Val Loss: 0.365367\n",
      "Epoch [200/500] | Train Loss: 0.201283 | Val Loss: 0.396177\n",
      "Epoch [300/500] | Train Loss: 0.191240 | Val Loss: 0.398121\n",
      "Epoch [400/500] | Train Loss: 0.181791 | Val Loss: 0.392480\n",
      "Epoch [500/500] | Train Loss: 0.181481 | Val Loss: 0.439352\n",
      "Epoch [100/500] | Train Loss: 0.272880 | Val Loss: 0.227101\n",
      "Epoch [200/500] | Train Loss: 0.249311 | Val Loss: 0.229178\n",
      "Epoch [300/500] | Train Loss: 0.226416 | Val Loss: 0.230068\n",
      "Epoch [400/500] | Train Loss: 0.219079 | Val Loss: 0.245207\n",
      "Epoch [500/500] | Train Loss: 0.214698 | Val Loss: 0.241495\n",
      "Epoch [100/500] | Train Loss: 0.276042 | Val Loss: 1.374551\n",
      "Epoch [200/500] | Train Loss: 0.264363 | Val Loss: 1.472985\n",
      "Epoch [300/500] | Train Loss: 0.237216 | Val Loss: 1.429579\n",
      "Epoch [400/500] | Train Loss: 0.224720 | Val Loss: 1.600315\n",
      "Epoch [500/500] | Train Loss: 0.228347 | Val Loss: 1.471702\n",
      "[Year=1963] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.1, 'learning_rate': 0.001} CV-MSE=0.538968 Test MSE=0.300712\n",
      "Year 1963 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.326722 | Val Loss: 0.312274\n",
      "Epoch [200/500] | Train Loss: 0.248427 | Val Loss: 0.356294\n",
      "Epoch [300/500] | Train Loss: 0.207157 | Val Loss: 0.399941\n",
      "Epoch [400/500] | Train Loss: 0.210414 | Val Loss: 0.402531\n",
      "Epoch [500/500] | Train Loss: 0.153835 | Val Loss: 0.433231\n",
      "Epoch [100/500] | Train Loss: 0.295052 | Val Loss: 0.335585\n",
      "Epoch [200/500] | Train Loss: 0.267814 | Val Loss: 0.346084\n",
      "Epoch [300/500] | Train Loss: 0.251670 | Val Loss: 0.359896\n",
      "Epoch [400/500] | Train Loss: 0.220453 | Val Loss: 0.372460\n",
      "Epoch [500/500] | Train Loss: 0.208389 | Val Loss: 0.384981\n",
      "Epoch [100/500] | Train Loss: 0.315400 | Val Loss: 0.215295\n",
      "Epoch [200/500] | Train Loss: 0.295021 | Val Loss: 0.224907\n",
      "Epoch [300/500] | Train Loss: 0.267116 | Val Loss: 0.232868\n",
      "Epoch [400/500] | Train Loss: 0.263279 | Val Loss: 0.238616\n",
      "Epoch [500/500] | Train Loss: 0.250463 | Val Loss: 0.245291\n",
      "Epoch [100/500] | Train Loss: 0.289637 | Val Loss: 1.215036\n",
      "Epoch [200/500] | Train Loss: 0.276077 | Val Loss: 1.229903\n",
      "Epoch [300/500] | Train Loss: 0.256463 | Val Loss: 1.247307\n",
      "Epoch [400/500] | Train Loss: 0.232771 | Val Loss: 1.237677\n",
      "Epoch [500/500] | Train Loss: 0.229297 | Val Loss: 1.286113\n",
      "Epoch [100/500] | Train Loss: 0.457422 | Val Loss: 0.279239\n",
      "Epoch [200/500] | Train Loss: 0.402464 | Val Loss: 0.273906\n",
      "Epoch [300/500] | Train Loss: 0.381930 | Val Loss: 0.277534\n",
      "Epoch [400/500] | Train Loss: 0.347571 | Val Loss: 0.293091\n",
      "Epoch [500/500] | Train Loss: 0.341853 | Val Loss: 0.294479\n",
      "Epoch [100/500] | Train Loss: 0.235953 | Val Loss: 0.347391\n",
      "Epoch [200/500] | Train Loss: 0.164262 | Val Loss: 0.383694\n",
      "Epoch [300/500] | Train Loss: 0.113310 | Val Loss: 0.414505\n",
      "Epoch [400/500] | Train Loss: 0.121593 | Val Loss: 0.411794\n",
      "Epoch [500/500] | Train Loss: 0.088576 | Val Loss: 0.448836\n",
      "Epoch [100/500] | Train Loss: 0.259854 | Val Loss: 0.351766\n",
      "Epoch [200/500] | Train Loss: 0.194367 | Val Loss: 0.408820\n",
      "Epoch [300/500] | Train Loss: 0.171779 | Val Loss: 0.383613\n",
      "Epoch [400/500] | Train Loss: 0.159535 | Val Loss: 0.409829\n",
      "Epoch [500/500] | Train Loss: 0.163547 | Val Loss: 0.402620\n",
      "Epoch [100/500] | Train Loss: 0.271561 | Val Loss: 0.241444\n",
      "Epoch [200/500] | Train Loss: 0.239878 | Val Loss: 0.297305\n",
      "Epoch [300/500] | Train Loss: 0.209116 | Val Loss: 0.309000\n",
      "Epoch [400/500] | Train Loss: 0.202518 | Val Loss: 0.320924\n",
      "Epoch [500/500] | Train Loss: 0.191583 | Val Loss: 0.314889\n",
      "Epoch [100/500] | Train Loss: 0.257033 | Val Loss: 1.521982\n",
      "Epoch [200/500] | Train Loss: 0.225832 | Val Loss: 1.530416\n",
      "Epoch [300/500] | Train Loss: 0.214646 | Val Loss: 1.668420\n",
      "Epoch [400/500] | Train Loss: 0.195570 | Val Loss: 1.469245\n",
      "Epoch [500/500] | Train Loss: 0.192250 | Val Loss: 1.464129\n",
      "Epoch [100/500] | Train Loss: 0.413729 | Val Loss: 0.258936\n",
      "Epoch [200/500] | Train Loss: 0.333264 | Val Loss: 0.305983\n",
      "Epoch [300/500] | Train Loss: 0.358351 | Val Loss: 0.289117\n",
      "Epoch [400/500] | Train Loss: 0.306522 | Val Loss: 0.294978\n",
      "Epoch [500/500] | Train Loss: 0.278402 | Val Loss: 0.299051\n",
      "Epoch [100/500] | Train Loss: 0.331762 | Val Loss: 0.326473\n",
      "Epoch [200/500] | Train Loss: 0.291573 | Val Loss: 0.352447\n",
      "Epoch [300/500] | Train Loss: 0.267910 | Val Loss: 0.362146\n",
      "Epoch [400/500] | Train Loss: 0.231730 | Val Loss: 0.379511\n",
      "Epoch [500/500] | Train Loss: 0.222224 | Val Loss: 0.400618\n",
      "Epoch [100/500] | Train Loss: 0.324607 | Val Loss: 0.346225\n",
      "Epoch [200/500] | Train Loss: 0.320171 | Val Loss: 0.341673\n",
      "Epoch [300/500] | Train Loss: 0.304679 | Val Loss: 0.343434\n",
      "Epoch [400/500] | Train Loss: 0.290170 | Val Loss: 0.345304\n",
      "Epoch [500/500] | Train Loss: 0.275350 | Val Loss: 0.348881\n",
      "Epoch [100/500] | Train Loss: 0.328448 | Val Loss: 0.223627\n",
      "Epoch [200/500] | Train Loss: 0.314572 | Val Loss: 0.219633\n",
      "Epoch [300/500] | Train Loss: 0.305766 | Val Loss: 0.225399\n",
      "Epoch [400/500] | Train Loss: 0.296839 | Val Loss: 0.229494\n",
      "Epoch [500/500] | Train Loss: 0.289777 | Val Loss: 0.234495\n",
      "Epoch [100/500] | Train Loss: 0.304259 | Val Loss: 1.245175\n",
      "Epoch [200/500] | Train Loss: 0.288031 | Val Loss: 1.210586\n",
      "Epoch [300/500] | Train Loss: 0.279706 | Val Loss: 1.212697\n",
      "Epoch [400/500] | Train Loss: 0.279224 | Val Loss: 1.215653\n",
      "Epoch [500/500] | Train Loss: 0.267642 | Val Loss: 1.234568\n",
      "Epoch [100/500] | Train Loss: 0.487129 | Val Loss: 0.285286\n",
      "Epoch [200/500] | Train Loss: 0.466290 | Val Loss: 0.282643\n",
      "Epoch [300/500] | Train Loss: 0.422474 | Val Loss: 0.272468\n",
      "Epoch [400/500] | Train Loss: 0.434470 | Val Loss: 0.272364\n",
      "Epoch [500/500] | Train Loss: 0.441855 | Val Loss: 0.267605\n",
      "Epoch [100/500] | Train Loss: 0.289270 | Val Loss: 0.333862\n",
      "Epoch [200/500] | Train Loss: 0.211137 | Val Loss: 0.395880\n",
      "Epoch [300/500] | Train Loss: 0.160621 | Val Loss: 0.403136\n",
      "Epoch [400/500] | Train Loss: 0.172628 | Val Loss: 0.418529\n",
      "Epoch [500/500] | Train Loss: 0.145490 | Val Loss: 0.440992\n",
      "Epoch [100/500] | Train Loss: 0.263936 | Val Loss: 0.343574\n",
      "Epoch [200/500] | Train Loss: 0.256733 | Val Loss: 0.342997\n",
      "Epoch [300/500] | Train Loss: 0.255303 | Val Loss: 0.343284\n",
      "Epoch [400/500] | Train Loss: 0.248856 | Val Loss: 0.337734\n",
      "Epoch [500/500] | Train Loss: 0.227179 | Val Loss: 0.346888\n",
      "Epoch [100/500] | Train Loss: 0.298606 | Val Loss: 0.237027\n",
      "Epoch [200/500] | Train Loss: 0.275320 | Val Loss: 0.246073\n",
      "Epoch [300/500] | Train Loss: 0.245961 | Val Loss: 0.248380\n",
      "Epoch [400/500] | Train Loss: 0.235592 | Val Loss: 0.253429\n",
      "Epoch [500/500] | Train Loss: 0.232922 | Val Loss: 0.251188\n",
      "Epoch [100/500] | Train Loss: 0.257673 | Val Loss: 1.243456\n",
      "Epoch [200/500] | Train Loss: 0.243548 | Val Loss: 1.304296\n",
      "Epoch [300/500] | Train Loss: 0.228652 | Val Loss: 1.365579\n",
      "Epoch [400/500] | Train Loss: 0.223784 | Val Loss: 1.357788\n",
      "Epoch [500/500] | Train Loss: 0.231161 | Val Loss: 1.407578\n",
      "Epoch [100/500] | Train Loss: 0.429926 | Val Loss: 0.250469\n",
      "Epoch [200/500] | Train Loss: 0.371667 | Val Loss: 0.279952\n",
      "Epoch [300/500] | Train Loss: 0.351542 | Val Loss: 0.285495\n",
      "Epoch [400/500] | Train Loss: 0.358743 | Val Loss: 0.293236\n",
      "Epoch [500/500] | Train Loss: 0.334623 | Val Loss: 0.284749\n",
      "Epoch [100/500] | Train Loss: 0.344997 | Val Loss: 0.326378\n",
      "Epoch [200/500] | Train Loss: 0.291984 | Val Loss: 0.386488\n",
      "Epoch [300/500] | Train Loss: 0.261689 | Val Loss: 0.399609\n",
      "Epoch [400/500] | Train Loss: 0.233727 | Val Loss: 0.395304\n",
      "Epoch [500/500] | Train Loss: 0.209558 | Val Loss: 0.397625\n",
      "Epoch [100/500] | Train Loss: 0.294330 | Val Loss: 0.331611\n",
      "Epoch [200/500] | Train Loss: 0.237787 | Val Loss: 0.348951\n",
      "Epoch [300/500] | Train Loss: 0.221886 | Val Loss: 0.366312\n",
      "Epoch [400/500] | Train Loss: 0.198275 | Val Loss: 0.378367\n",
      "Epoch [500/500] | Train Loss: 0.182663 | Val Loss: 0.389432\n",
      "Epoch [100/500] | Train Loss: 0.323283 | Val Loss: 0.218620\n",
      "Epoch [200/500] | Train Loss: 0.289071 | Val Loss: 0.231466\n",
      "Epoch [300/500] | Train Loss: 0.265537 | Val Loss: 0.245484\n",
      "Epoch [400/500] | Train Loss: 0.249297 | Val Loss: 0.256394\n",
      "Epoch [500/500] | Train Loss: 0.248272 | Val Loss: 0.255354\n",
      "Epoch [100/500] | Train Loss: 0.294104 | Val Loss: 1.217162\n",
      "Epoch [200/500] | Train Loss: 0.276018 | Val Loss: 1.230459\n",
      "Epoch [300/500] | Train Loss: 0.254187 | Val Loss: 1.352173\n",
      "Epoch [400/500] | Train Loss: 0.234872 | Val Loss: 1.334353\n",
      "Epoch [500/500] | Train Loss: 0.222886 | Val Loss: 1.329961\n",
      "Epoch [100/500] | Train Loss: 0.450472 | Val Loss: 0.285209\n",
      "Epoch [200/500] | Train Loss: 0.410923 | Val Loss: 0.254580\n",
      "Epoch [300/500] | Train Loss: 0.351208 | Val Loss: 0.262375\n",
      "Epoch [400/500] | Train Loss: 0.334917 | Val Loss: 0.283359\n",
      "Epoch [500/500] | Train Loss: 0.334453 | Val Loss: 0.294423\n",
      "Epoch [100/500] | Train Loss: 0.174242 | Val Loss: 0.450872\n",
      "Epoch [200/500] | Train Loss: 0.111800 | Val Loss: 0.496443\n",
      "Epoch [300/500] | Train Loss: 0.108084 | Val Loss: 0.528707\n",
      "Epoch [400/500] | Train Loss: 0.099193 | Val Loss: 0.504839\n",
      "Epoch [500/500] | Train Loss: 0.077910 | Val Loss: 0.501137\n",
      "Epoch [100/500] | Train Loss: 0.216842 | Val Loss: 0.351178\n",
      "Epoch [200/500] | Train Loss: 0.156552 | Val Loss: 0.374724\n",
      "Epoch [300/500] | Train Loss: 0.153600 | Val Loss: 0.402502\n",
      "Epoch [400/500] | Train Loss: 0.132547 | Val Loss: 0.394519\n",
      "Epoch [500/500] | Train Loss: 0.111708 | Val Loss: 0.419867\n",
      "Epoch [100/500] | Train Loss: 0.230495 | Val Loss: 0.255140\n",
      "Epoch [200/500] | Train Loss: 0.175168 | Val Loss: 0.273183\n",
      "Epoch [300/500] | Train Loss: 0.154009 | Val Loss: 0.299831\n",
      "Epoch [400/500] | Train Loss: 0.148609 | Val Loss: 0.272598\n",
      "Epoch [500/500] | Train Loss: 0.136106 | Val Loss: 0.292199\n",
      "Epoch [100/500] | Train Loss: 0.257723 | Val Loss: 1.315751\n",
      "Epoch [200/500] | Train Loss: 0.200972 | Val Loss: 1.318905\n",
      "Epoch [300/500] | Train Loss: 0.168641 | Val Loss: 1.332116\n",
      "Epoch [400/500] | Train Loss: 0.153800 | Val Loss: 1.355264\n",
      "Epoch [500/500] | Train Loss: 0.161075 | Val Loss: 1.352999\n",
      "Epoch [100/500] | Train Loss: 0.343586 | Val Loss: 0.303220\n",
      "Epoch [200/500] | Train Loss: 0.308999 | Val Loss: 0.277644\n",
      "Epoch [300/500] | Train Loss: 0.251450 | Val Loss: 0.280464\n",
      "Epoch [400/500] | Train Loss: 0.249403 | Val Loss: 0.283861\n",
      "Epoch [500/500] | Train Loss: 0.239316 | Val Loss: 0.293712\n",
      "Epoch [100/500] | Train Loss: 0.319488 | Val Loss: 0.310591\n",
      "Epoch [200/500] | Train Loss: 0.269668 | Val Loss: 0.350521\n",
      "Epoch [300/500] | Train Loss: 0.265827 | Val Loss: 0.384354\n",
      "Epoch [400/500] | Train Loss: 0.202694 | Val Loss: 0.397760\n",
      "Epoch [500/500] | Train Loss: 0.186942 | Val Loss: 0.417164\n",
      "Epoch [100/500] | Train Loss: 0.305438 | Val Loss: 0.334482\n",
      "Epoch [200/500] | Train Loss: 0.275374 | Val Loss: 0.338273\n",
      "Epoch [300/500] | Train Loss: 0.270175 | Val Loss: 0.344027\n",
      "Epoch [400/500] | Train Loss: 0.243224 | Val Loss: 0.352488\n",
      "Epoch [500/500] | Train Loss: 0.223526 | Val Loss: 0.365974\n",
      "Epoch [100/500] | Train Loss: 0.314200 | Val Loss: 0.217031\n",
      "Epoch [200/500] | Train Loss: 0.302394 | Val Loss: 0.223597\n",
      "Epoch [300/500] | Train Loss: 0.273265 | Val Loss: 0.232456\n",
      "Epoch [400/500] | Train Loss: 0.259445 | Val Loss: 0.239056\n",
      "Epoch [500/500] | Train Loss: 0.263786 | Val Loss: 0.239946\n",
      "Epoch [100/500] | Train Loss: 0.302918 | Val Loss: 1.210159\n",
      "Epoch [200/500] | Train Loss: 0.280163 | Val Loss: 1.229150\n",
      "Epoch [300/500] | Train Loss: 0.264850 | Val Loss: 1.245199\n",
      "Epoch [400/500] | Train Loss: 0.261266 | Val Loss: 1.256714\n",
      "Epoch [500/500] | Train Loss: 0.247360 | Val Loss: 1.280610\n",
      "Epoch [100/500] | Train Loss: 0.489095 | Val Loss: 0.283559\n",
      "Epoch [200/500] | Train Loss: 0.444605 | Val Loss: 0.281920\n",
      "Epoch [300/500] | Train Loss: 0.421329 | Val Loss: 0.257026\n",
      "Epoch [400/500] | Train Loss: 0.410131 | Val Loss: 0.262796\n",
      "Epoch [500/500] | Train Loss: 0.381969 | Val Loss: 0.261850\n",
      "Epoch [100/500] | Train Loss: 0.245684 | Val Loss: 0.364983\n",
      "Epoch [200/500] | Train Loss: 0.169982 | Val Loss: 0.414887\n",
      "Epoch [300/500] | Train Loss: 0.125763 | Val Loss: 0.432101\n",
      "Epoch [400/500] | Train Loss: 0.129446 | Val Loss: 0.442238\n",
      "Epoch [500/500] | Train Loss: 0.120652 | Val Loss: 0.469156\n",
      "Epoch [100/500] | Train Loss: 0.292736 | Val Loss: 0.336257\n",
      "Epoch [200/500] | Train Loss: 0.241812 | Val Loss: 0.364501\n",
      "Epoch [300/500] | Train Loss: 0.203989 | Val Loss: 0.363599\n",
      "Epoch [400/500] | Train Loss: 0.197443 | Val Loss: 0.378138\n",
      "Epoch [500/500] | Train Loss: 0.164607 | Val Loss: 0.382357\n",
      "Epoch [100/500] | Train Loss: 0.249860 | Val Loss: 0.246347\n",
      "Epoch [200/500] | Train Loss: 0.219384 | Val Loss: 0.284131\n",
      "Epoch [300/500] | Train Loss: 0.202813 | Val Loss: 0.288084\n",
      "Epoch [400/500] | Train Loss: 0.188984 | Val Loss: 0.289922\n",
      "Epoch [500/500] | Train Loss: 0.192261 | Val Loss: 0.295572\n",
      "Epoch [100/500] | Train Loss: 0.275974 | Val Loss: 1.257805\n",
      "Epoch [200/500] | Train Loss: 0.244593 | Val Loss: 1.240438\n",
      "Epoch [300/500] | Train Loss: 0.234193 | Val Loss: 1.238613\n",
      "Epoch [400/500] | Train Loss: 0.223042 | Val Loss: 1.223884\n",
      "Epoch [500/500] | Train Loss: 0.209577 | Val Loss: 1.307278\n",
      "Epoch [100/500] | Train Loss: 0.399137 | Val Loss: 0.269475\n",
      "Epoch [200/500] | Train Loss: 0.357645 | Val Loss: 0.329887\n",
      "Epoch [300/500] | Train Loss: 0.320583 | Val Loss: 0.316139\n",
      "Epoch [400/500] | Train Loss: 0.292020 | Val Loss: 0.319702\n",
      "Epoch [500/500] | Train Loss: 0.291001 | Val Loss: 0.329974\n",
      "[Year=1964] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.497233 Test MSE=0.097470\n",
      "Year 1964 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.337976 | Val Loss: 0.272665\n",
      "Epoch [200/500] | Train Loss: 0.294484 | Val Loss: 0.307845\n",
      "Epoch [300/500] | Train Loss: 0.262124 | Val Loss: 0.345916\n",
      "Epoch [400/500] | Train Loss: 0.211469 | Val Loss: 0.372955\n",
      "Epoch [500/500] | Train Loss: 0.210664 | Val Loss: 0.381123\n",
      "Epoch [100/500] | Train Loss: 0.308376 | Val Loss: 0.953382\n",
      "Epoch [200/500] | Train Loss: 0.287693 | Val Loss: 0.949344\n",
      "Epoch [300/500] | Train Loss: 0.266414 | Val Loss: 0.971657\n",
      "Epoch [400/500] | Train Loss: 0.242207 | Val Loss: 1.023378\n",
      "Epoch [500/500] | Train Loss: 0.236422 | Val Loss: 1.072227\n",
      "Epoch [100/500] | Train Loss: 0.506969 | Val Loss: 0.454448\n",
      "Epoch [200/500] | Train Loss: 0.438858 | Val Loss: 0.494727\n",
      "Epoch [300/500] | Train Loss: 0.419504 | Val Loss: 0.500961\n",
      "Epoch [400/500] | Train Loss: 0.404238 | Val Loss: 0.500818\n",
      "Epoch [500/500] | Train Loss: 0.372762 | Val Loss: 0.506394\n",
      "Epoch [100/500] | Train Loss: 0.496447 | Val Loss: 0.270880\n",
      "Epoch [200/500] | Train Loss: 0.445472 | Val Loss: 0.239948\n",
      "Epoch [300/500] | Train Loss: 0.414336 | Val Loss: 0.232607\n",
      "Epoch [400/500] | Train Loss: 0.391984 | Val Loss: 0.236410\n",
      "Epoch [500/500] | Train Loss: 0.376599 | Val Loss: 0.233548\n",
      "Epoch [100/500] | Train Loss: 0.440511 | Val Loss: 0.104882\n",
      "Epoch [200/500] | Train Loss: 0.387435 | Val Loss: 0.113766\n",
      "Epoch [300/500] | Train Loss: 0.363601 | Val Loss: 0.113537\n",
      "Epoch [400/500] | Train Loss: 0.343415 | Val Loss: 0.115371\n",
      "Epoch [500/500] | Train Loss: 0.330411 | Val Loss: 0.114884\n",
      "Epoch [100/500] | Train Loss: 0.234567 | Val Loss: 0.335587\n",
      "Epoch [200/500] | Train Loss: 0.170786 | Val Loss: 0.360454\n",
      "Epoch [300/500] | Train Loss: 0.118745 | Val Loss: 0.437269\n",
      "Epoch [400/500] | Train Loss: 0.115957 | Val Loss: 0.409336\n",
      "Epoch [500/500] | Train Loss: 0.095158 | Val Loss: 0.434466\n",
      "Epoch [100/500] | Train Loss: 0.245726 | Val Loss: 1.085929\n",
      "Epoch [200/500] | Train Loss: 0.185038 | Val Loss: 1.041924\n",
      "Epoch [300/500] | Train Loss: 0.149504 | Val Loss: 1.159660\n",
      "Epoch [400/500] | Train Loss: 0.149033 | Val Loss: 1.172730\n",
      "Epoch [500/500] | Train Loss: 0.137092 | Val Loss: 1.310598\n",
      "Epoch [100/500] | Train Loss: 0.400397 | Val Loss: 0.476840\n",
      "Epoch [200/500] | Train Loss: 0.282563 | Val Loss: 0.482643\n",
      "Epoch [300/500] | Train Loss: 0.291983 | Val Loss: 0.484868\n",
      "Epoch [400/500] | Train Loss: 0.253874 | Val Loss: 0.539443\n",
      "Epoch [500/500] | Train Loss: 0.253469 | Val Loss: 0.545988\n",
      "Epoch [100/500] | Train Loss: 0.395350 | Val Loss: 0.299118\n",
      "Epoch [200/500] | Train Loss: 0.370669 | Val Loss: 0.289763\n",
      "Epoch [300/500] | Train Loss: 0.294128 | Val Loss: 0.278158\n",
      "Epoch [400/500] | Train Loss: 0.267587 | Val Loss: 0.273573\n",
      "Epoch [500/500] | Train Loss: 0.259824 | Val Loss: 0.286097\n",
      "Epoch [100/500] | Train Loss: 0.350364 | Val Loss: 0.113987\n",
      "Epoch [200/500] | Train Loss: 0.308011 | Val Loss: 0.115723\n",
      "Epoch [300/500] | Train Loss: 0.267304 | Val Loss: 0.121122\n",
      "Epoch [400/500] | Train Loss: 0.228807 | Val Loss: 0.129325\n",
      "Epoch [500/500] | Train Loss: 0.237296 | Val Loss: 0.126149\n",
      "Epoch [100/500] | Train Loss: 0.385116 | Val Loss: 0.252744\n",
      "Epoch [200/500] | Train Loss: 0.360880 | Val Loss: 0.271645\n",
      "Epoch [300/500] | Train Loss: 0.314272 | Val Loss: 0.278970\n",
      "Epoch [400/500] | Train Loss: 0.309249 | Val Loss: 0.288134\n",
      "Epoch [500/500] | Train Loss: 0.283632 | Val Loss: 0.294265\n",
      "Epoch [100/500] | Train Loss: 0.312420 | Val Loss: 0.962065\n",
      "Epoch [200/500] | Train Loss: 0.301916 | Val Loss: 0.955966\n",
      "Epoch [300/500] | Train Loss: 0.283819 | Val Loss: 0.929970\n",
      "Epoch [400/500] | Train Loss: 0.267069 | Val Loss: 0.909375\n",
      "Epoch [500/500] | Train Loss: 0.264113 | Val Loss: 0.897319\n",
      "Epoch [100/500] | Train Loss: 0.520535 | Val Loss: 0.464292\n",
      "Epoch [200/500] | Train Loss: 0.504435 | Val Loss: 0.482478\n",
      "Epoch [300/500] | Train Loss: 0.462970 | Val Loss: 0.483190\n",
      "Epoch [400/500] | Train Loss: 0.471689 | Val Loss: 0.487523\n",
      "Epoch [500/500] | Train Loss: 0.422684 | Val Loss: 0.463565\n",
      "Epoch [100/500] | Train Loss: 0.504283 | Val Loss: 0.270030\n",
      "Epoch [200/500] | Train Loss: 0.481806 | Val Loss: 0.269145\n",
      "Epoch [300/500] | Train Loss: 0.450688 | Val Loss: 0.269454\n",
      "Epoch [400/500] | Train Loss: 0.431385 | Val Loss: 0.290185\n",
      "Epoch [500/500] | Train Loss: 0.391041 | Val Loss: 0.291495\n",
      "Epoch [100/500] | Train Loss: 0.457311 | Val Loss: 0.104931\n",
      "Epoch [200/500] | Train Loss: 0.425287 | Val Loss: 0.110882\n",
      "Epoch [300/500] | Train Loss: 0.408232 | Val Loss: 0.111600\n",
      "Epoch [400/500] | Train Loss: 0.378199 | Val Loss: 0.111287\n",
      "Epoch [500/500] | Train Loss: 0.365526 | Val Loss: 0.110577\n",
      "Epoch [100/500] | Train Loss: 0.278240 | Val Loss: 0.322171\n",
      "Epoch [200/500] | Train Loss: 0.212883 | Val Loss: 0.358316\n",
      "Epoch [300/500] | Train Loss: 0.187590 | Val Loss: 0.365313\n",
      "Epoch [400/500] | Train Loss: 0.172627 | Val Loss: 0.365813\n",
      "Epoch [500/500] | Train Loss: 0.195932 | Val Loss: 0.346257\n",
      "Epoch [100/500] | Train Loss: 0.273317 | Val Loss: 0.945525\n",
      "Epoch [200/500] | Train Loss: 0.232170 | Val Loss: 0.941853\n",
      "Epoch [300/500] | Train Loss: 0.213404 | Val Loss: 1.037098\n",
      "Epoch [400/500] | Train Loss: 0.208967 | Val Loss: 0.936490\n",
      "Epoch [500/500] | Train Loss: 0.211797 | Val Loss: 0.951677\n",
      "Epoch [100/500] | Train Loss: 0.466432 | Val Loss: 0.497330\n",
      "Epoch [200/500] | Train Loss: 0.401734 | Val Loss: 0.511629\n",
      "Epoch [300/500] | Train Loss: 0.385638 | Val Loss: 0.524056\n",
      "Epoch [400/500] | Train Loss: 0.340144 | Val Loss: 0.504251\n",
      "Epoch [500/500] | Train Loss: 0.308502 | Val Loss: 0.496186\n",
      "Epoch [100/500] | Train Loss: 0.440931 | Val Loss: 0.280670\n",
      "Epoch [200/500] | Train Loss: 0.390613 | Val Loss: 0.252757\n",
      "Epoch [300/500] | Train Loss: 0.352791 | Val Loss: 0.250728\n",
      "Epoch [400/500] | Train Loss: 0.377921 | Val Loss: 0.274122\n",
      "Epoch [500/500] | Train Loss: 0.349660 | Val Loss: 0.270724\n",
      "Epoch [100/500] | Train Loss: 0.381092 | Val Loss: 0.113077\n",
      "Epoch [200/500] | Train Loss: 0.353340 | Val Loss: 0.116564\n",
      "Epoch [300/500] | Train Loss: 0.317665 | Val Loss: 0.118313\n",
      "Epoch [400/500] | Train Loss: 0.364901 | Val Loss: 0.112398\n",
      "Epoch [500/500] | Train Loss: 0.323017 | Val Loss: 0.115179\n",
      "Epoch [100/500] | Train Loss: 0.362206 | Val Loss: 0.261357\n",
      "Epoch [200/500] | Train Loss: 0.302197 | Val Loss: 0.298070\n",
      "Epoch [300/500] | Train Loss: 0.249049 | Val Loss: 0.338220\n",
      "Epoch [400/500] | Train Loss: 0.225571 | Val Loss: 0.354704\n",
      "Epoch [500/500] | Train Loss: 0.207566 | Val Loss: 0.376260\n",
      "Epoch [100/500] | Train Loss: 0.298147 | Val Loss: 0.951084\n",
      "Epoch [200/500] | Train Loss: 0.264837 | Val Loss: 0.986015\n",
      "Epoch [300/500] | Train Loss: 0.233325 | Val Loss: 1.017199\n",
      "Epoch [400/500] | Train Loss: 0.211659 | Val Loss: 1.101611\n",
      "Epoch [500/500] | Train Loss: 0.185027 | Val Loss: 1.239288\n",
      "Epoch [100/500] | Train Loss: 0.468123 | Val Loss: 0.492137\n",
      "Epoch [200/500] | Train Loss: 0.415589 | Val Loss: 0.479219\n",
      "Epoch [300/500] | Train Loss: 0.369212 | Val Loss: 0.483280\n",
      "Epoch [400/500] | Train Loss: 0.324885 | Val Loss: 0.492153\n",
      "Epoch [500/500] | Train Loss: 0.318125 | Val Loss: 0.512965\n",
      "Epoch [100/500] | Train Loss: 0.471685 | Val Loss: 0.259073\n",
      "Epoch [200/500] | Train Loss: 0.422594 | Val Loss: 0.245348\n",
      "Epoch [300/500] | Train Loss: 0.389411 | Val Loss: 0.259208\n",
      "Epoch [400/500] | Train Loss: 0.337247 | Val Loss: 0.258792\n",
      "Epoch [500/500] | Train Loss: 0.295947 | Val Loss: 0.260658\n",
      "Epoch [100/500] | Train Loss: 0.434830 | Val Loss: 0.113619\n",
      "Epoch [200/500] | Train Loss: 0.379186 | Val Loss: 0.114136\n",
      "Epoch [300/500] | Train Loss: 0.350528 | Val Loss: 0.112721\n",
      "Epoch [400/500] | Train Loss: 0.337122 | Val Loss: 0.111980\n",
      "Epoch [500/500] | Train Loss: 0.286792 | Val Loss: 0.112077\n",
      "Epoch [100/500] | Train Loss: 0.236364 | Val Loss: 0.299969\n",
      "Epoch [200/500] | Train Loss: 0.142908 | Val Loss: 0.351277\n",
      "Epoch [300/500] | Train Loss: 0.097826 | Val Loss: 0.399789\n",
      "Epoch [400/500] | Train Loss: 0.099004 | Val Loss: 0.385592\n",
      "Epoch [500/500] | Train Loss: 0.086153 | Val Loss: 0.394306\n",
      "Epoch [100/500] | Train Loss: 0.235979 | Val Loss: 1.052329\n",
      "Epoch [200/500] | Train Loss: 0.230225 | Val Loss: 1.081687\n",
      "Epoch [300/500] | Train Loss: 0.165911 | Val Loss: 1.087546\n",
      "Epoch [400/500] | Train Loss: 0.140361 | Val Loss: 1.104558\n",
      "Epoch [500/500] | Train Loss: 0.131252 | Val Loss: 1.127153\n",
      "Epoch [100/500] | Train Loss: 0.368084 | Val Loss: 0.483390\n",
      "Epoch [200/500] | Train Loss: 0.291997 | Val Loss: 0.512250\n",
      "Epoch [300/500] | Train Loss: 0.259723 | Val Loss: 0.517977\n",
      "Epoch [400/500] | Train Loss: 0.212893 | Val Loss: 0.511550\n",
      "Epoch [500/500] | Train Loss: 0.241964 | Val Loss: 0.528630\n",
      "Epoch [100/500] | Train Loss: 0.356598 | Val Loss: 0.279056\n",
      "Epoch [200/500] | Train Loss: 0.276584 | Val Loss: 0.281602\n",
      "Epoch [300/500] | Train Loss: 0.237221 | Val Loss: 0.276985\n",
      "Epoch [400/500] | Train Loss: 0.243891 | Val Loss: 0.294782\n",
      "Epoch [500/500] | Train Loss: 0.223617 | Val Loss: 0.280225\n",
      "Epoch [100/500] | Train Loss: 0.285102 | Val Loss: 0.113201\n",
      "Epoch [200/500] | Train Loss: 0.230860 | Val Loss: 0.123528\n",
      "Epoch [300/500] | Train Loss: 0.223433 | Val Loss: 0.138721\n",
      "Epoch [400/500] | Train Loss: 0.203903 | Val Loss: 0.156213\n",
      "Epoch [500/500] | Train Loss: 0.203469 | Val Loss: 0.153998\n",
      "Epoch [100/500] | Train Loss: 0.355527 | Val Loss: 0.271304\n",
      "Epoch [200/500] | Train Loss: 0.294744 | Val Loss: 0.284962\n",
      "Epoch [300/500] | Train Loss: 0.308355 | Val Loss: 0.303814\n",
      "Epoch [400/500] | Train Loss: 0.270539 | Val Loss: 0.306178\n",
      "Epoch [500/500] | Train Loss: 0.220805 | Val Loss: 0.334741\n",
      "Epoch [100/500] | Train Loss: 0.305181 | Val Loss: 0.967177\n",
      "Epoch [200/500] | Train Loss: 0.284222 | Val Loss: 0.977600\n",
      "Epoch [300/500] | Train Loss: 0.269076 | Val Loss: 1.010045\n",
      "Epoch [400/500] | Train Loss: 0.259517 | Val Loss: 1.023420\n",
      "Epoch [500/500] | Train Loss: 0.247603 | Val Loss: 1.104316\n",
      "Epoch [100/500] | Train Loss: 0.526238 | Val Loss: 0.464721\n",
      "Epoch [200/500] | Train Loss: 0.476517 | Val Loss: 0.487876\n",
      "Epoch [300/500] | Train Loss: 0.410682 | Val Loss: 0.483639\n",
      "Epoch [400/500] | Train Loss: 0.398275 | Val Loss: 0.469368\n",
      "Epoch [500/500] | Train Loss: 0.387050 | Val Loss: 0.489171\n",
      "Epoch [100/500] | Train Loss: 0.500208 | Val Loss: 0.267828\n",
      "Epoch [200/500] | Train Loss: 0.441109 | Val Loss: 0.248443\n",
      "Epoch [300/500] | Train Loss: 0.429892 | Val Loss: 0.264925\n",
      "Epoch [400/500] | Train Loss: 0.427222 | Val Loss: 0.270926\n",
      "Epoch [500/500] | Train Loss: 0.370890 | Val Loss: 0.289008\n",
      "Epoch [100/500] | Train Loss: 0.447823 | Val Loss: 0.106175\n",
      "Epoch [200/500] | Train Loss: 0.413012 | Val Loss: 0.106341\n",
      "Epoch [300/500] | Train Loss: 0.392246 | Val Loss: 0.110398\n",
      "Epoch [400/500] | Train Loss: 0.364476 | Val Loss: 0.115040\n",
      "Epoch [500/500] | Train Loss: 0.351207 | Val Loss: 0.112593\n",
      "Epoch [100/500] | Train Loss: 0.252498 | Val Loss: 0.314473\n",
      "Epoch [200/500] | Train Loss: 0.190613 | Val Loss: 0.374580\n",
      "Epoch [300/500] | Train Loss: 0.176853 | Val Loss: 0.365212\n",
      "Epoch [400/500] | Train Loss: 0.169754 | Val Loss: 0.373743\n",
      "Epoch [500/500] | Train Loss: 0.143141 | Val Loss: 0.363968\n",
      "Epoch [100/500] | Train Loss: 0.267515 | Val Loss: 0.997854\n",
      "Epoch [200/500] | Train Loss: 0.224100 | Val Loss: 1.110673\n",
      "Epoch [300/500] | Train Loss: 0.179158 | Val Loss: 1.210239\n",
      "Epoch [400/500] | Train Loss: 0.202142 | Val Loss: 1.117335\n",
      "Epoch [500/500] | Train Loss: 0.172570 | Val Loss: 1.109501\n",
      "Epoch [100/500] | Train Loss: 0.441046 | Val Loss: 0.480029\n",
      "Epoch [200/500] | Train Loss: 0.306486 | Val Loss: 0.485351\n",
      "Epoch [300/500] | Train Loss: 0.324924 | Val Loss: 0.475934\n",
      "Epoch [400/500] | Train Loss: 0.313438 | Val Loss: 0.477722\n",
      "Epoch [500/500] | Train Loss: 0.287032 | Val Loss: 0.474289\n",
      "Epoch [100/500] | Train Loss: 0.395565 | Val Loss: 0.279643\n",
      "Epoch [200/500] | Train Loss: 0.341999 | Val Loss: 0.265867\n",
      "Epoch [300/500] | Train Loss: 0.340097 | Val Loss: 0.293042\n",
      "Epoch [400/500] | Train Loss: 0.299403 | Val Loss: 0.301875\n",
      "Epoch [500/500] | Train Loss: 0.282579 | Val Loss: 0.296122\n",
      "Epoch [100/500] | Train Loss: 0.347441 | Val Loss: 0.111805\n",
      "Epoch [200/500] | Train Loss: 0.315272 | Val Loss: 0.111002\n",
      "Epoch [300/500] | Train Loss: 0.292663 | Val Loss: 0.116491\n",
      "Epoch [400/500] | Train Loss: 0.296419 | Val Loss: 0.124395\n",
      "Epoch [500/500] | Train Loss: 0.292592 | Val Loss: 0.119704\n",
      "[Year=1965] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.411444 Test MSE=0.158115\n",
      "Year 1965 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.241017 | Val Loss: 1.127424\n",
      "Epoch [200/500] | Train Loss: 0.196509 | Val Loss: 2.148152\n",
      "Epoch [300/500] | Train Loss: 0.176708 | Val Loss: 2.578532\n",
      "Epoch [400/500] | Train Loss: 0.158018 | Val Loss: 2.628220\n",
      "Epoch [500/500] | Train Loss: 0.139682 | Val Loss: 2.615617\n",
      "Epoch [100/500] | Train Loss: 0.561650 | Val Loss: 0.425847\n",
      "Epoch [200/500] | Train Loss: 0.435274 | Val Loss: 0.463272\n",
      "Epoch [300/500] | Train Loss: 0.425482 | Val Loss: 0.475841\n",
      "Epoch [400/500] | Train Loss: 0.369729 | Val Loss: 0.493029\n",
      "Epoch [500/500] | Train Loss: 0.302298 | Val Loss: 0.512073\n",
      "Epoch [100/500] | Train Loss: 0.532835 | Val Loss: 0.254912\n",
      "Epoch [200/500] | Train Loss: 0.445269 | Val Loss: 0.236283\n",
      "Epoch [300/500] | Train Loss: 0.360219 | Val Loss: 0.238724\n",
      "Epoch [400/500] | Train Loss: 0.336223 | Val Loss: 0.253829\n",
      "Epoch [500/500] | Train Loss: 0.298256 | Val Loss: 0.270939\n",
      "Epoch [100/500] | Train Loss: 0.435836 | Val Loss: 0.106948\n",
      "Epoch [200/500] | Train Loss: 0.376337 | Val Loss: 0.112657\n",
      "Epoch [300/500] | Train Loss: 0.358650 | Val Loss: 0.114186\n",
      "Epoch [400/500] | Train Loss: 0.366258 | Val Loss: 0.115376\n",
      "Epoch [500/500] | Train Loss: 0.329768 | Val Loss: 0.113930\n",
      "Epoch [100/500] | Train Loss: 0.379367 | Val Loss: 0.182307\n",
      "Epoch [200/500] | Train Loss: 0.314585 | Val Loss: 0.189564\n",
      "Epoch [300/500] | Train Loss: 0.313895 | Val Loss: 0.184214\n",
      "Epoch [400/500] | Train Loss: 0.289135 | Val Loss: 0.187592\n",
      "Epoch [500/500] | Train Loss: 0.273972 | Val Loss: 0.192707\n",
      "Epoch [100/500] | Train Loss: 0.173003 | Val Loss: 1.567098\n",
      "Epoch [200/500] | Train Loss: 0.118708 | Val Loss: 1.580497\n",
      "Epoch [300/500] | Train Loss: 0.070586 | Val Loss: 1.468675\n",
      "Epoch [400/500] | Train Loss: 0.068646 | Val Loss: 1.324492\n",
      "Epoch [500/500] | Train Loss: 0.060146 | Val Loss: 1.332990\n",
      "Epoch [100/500] | Train Loss: 0.456336 | Val Loss: 0.418385\n",
      "Epoch [200/500] | Train Loss: 0.365964 | Val Loss: 0.409363\n",
      "Epoch [300/500] | Train Loss: 0.353010 | Val Loss: 0.405845\n",
      "Epoch [400/500] | Train Loss: 0.328468 | Val Loss: 0.376472\n",
      "Epoch [500/500] | Train Loss: 0.306754 | Val Loss: 0.432845\n",
      "Epoch [100/500] | Train Loss: 0.309369 | Val Loss: 0.223351\n",
      "Epoch [200/500] | Train Loss: 0.291926 | Val Loss: 0.219163\n",
      "Epoch [300/500] | Train Loss: 0.244565 | Val Loss: 0.232868\n",
      "Epoch [400/500] | Train Loss: 0.211448 | Val Loss: 0.248708\n",
      "Epoch [500/500] | Train Loss: 0.208743 | Val Loss: 0.246119\n",
      "Epoch [100/500] | Train Loss: 0.309525 | Val Loss: 0.118710\n",
      "Epoch [200/500] | Train Loss: 0.263247 | Val Loss: 0.115628\n",
      "Epoch [300/500] | Train Loss: 0.291707 | Val Loss: 0.133332\n",
      "Epoch [400/500] | Train Loss: 0.204227 | Val Loss: 0.138662\n",
      "Epoch [500/500] | Train Loss: 0.224319 | Val Loss: 0.135500\n",
      "Epoch [100/500] | Train Loss: 0.323030 | Val Loss: 0.179728\n",
      "Epoch [200/500] | Train Loss: 0.236920 | Val Loss: 0.180053\n",
      "Epoch [300/500] | Train Loss: 0.252119 | Val Loss: 0.191761\n",
      "Epoch [400/500] | Train Loss: 0.203525 | Val Loss: 0.192135\n",
      "Epoch [500/500] | Train Loss: 0.238194 | Val Loss: 0.179417\n",
      "Epoch [100/500] | Train Loss: 0.257390 | Val Loss: 1.062278\n",
      "Epoch [200/500] | Train Loss: 0.233533 | Val Loss: 1.086970\n",
      "Epoch [300/500] | Train Loss: 0.225181 | Val Loss: 1.162091\n",
      "Epoch [400/500] | Train Loss: 0.201951 | Val Loss: 1.290414\n",
      "Epoch [500/500] | Train Loss: 0.181471 | Val Loss: 1.308779\n",
      "Epoch [100/500] | Train Loss: 0.614233 | Val Loss: 0.396417\n",
      "Epoch [200/500] | Train Loss: 0.545653 | Val Loss: 0.410630\n",
      "Epoch [300/500] | Train Loss: 0.452542 | Val Loss: 0.398723\n",
      "Epoch [400/500] | Train Loss: 0.445196 | Val Loss: 0.398202\n",
      "Epoch [500/500] | Train Loss: 0.465686 | Val Loss: 0.396845\n",
      "Epoch [100/500] | Train Loss: 0.568658 | Val Loss: 0.254527\n",
      "Epoch [200/500] | Train Loss: 0.510050 | Val Loss: 0.237562\n",
      "Epoch [300/500] | Train Loss: 0.461729 | Val Loss: 0.230209\n",
      "Epoch [400/500] | Train Loss: 0.487037 | Val Loss: 0.219323\n",
      "Epoch [500/500] | Train Loss: 0.405485 | Val Loss: 0.225635\n",
      "Epoch [100/500] | Train Loss: 0.469304 | Val Loss: 0.107545\n",
      "Epoch [200/500] | Train Loss: 0.441720 | Val Loss: 0.110170\n",
      "Epoch [300/500] | Train Loss: 0.439886 | Val Loss: 0.114870\n",
      "Epoch [400/500] | Train Loss: 0.395389 | Val Loss: 0.116412\n",
      "Epoch [500/500] | Train Loss: 0.338031 | Val Loss: 0.115299\n",
      "Epoch [100/500] | Train Loss: 0.396572 | Val Loss: 0.177176\n",
      "Epoch [200/500] | Train Loss: 0.352856 | Val Loss: 0.180374\n",
      "Epoch [300/500] | Train Loss: 0.361785 | Val Loss: 0.180923\n",
      "Epoch [400/500] | Train Loss: 0.339852 | Val Loss: 0.176488\n",
      "Epoch [500/500] | Train Loss: 0.300525 | Val Loss: 0.173293\n",
      "Epoch [100/500] | Train Loss: 0.169900 | Val Loss: 1.544555\n",
      "Epoch [200/500] | Train Loss: 0.160961 | Val Loss: 1.625558\n",
      "Epoch [300/500] | Train Loss: 0.136191 | Val Loss: 1.414740\n",
      "Epoch [400/500] | Train Loss: 0.139164 | Val Loss: 1.473701\n",
      "Epoch [500/500] | Train Loss: 0.127481 | Val Loss: 1.449120\n",
      "Epoch [100/500] | Train Loss: 0.475033 | Val Loss: 0.459786\n",
      "Epoch [200/500] | Train Loss: 0.373499 | Val Loss: 0.425827\n",
      "Epoch [300/500] | Train Loss: 0.298023 | Val Loss: 0.395135\n",
      "Epoch [400/500] | Train Loss: 0.342498 | Val Loss: 0.422575\n",
      "Epoch [500/500] | Train Loss: 0.313241 | Val Loss: 0.481013\n",
      "Epoch [100/500] | Train Loss: 0.410992 | Val Loss: 0.224663\n",
      "Epoch [200/500] | Train Loss: 0.400796 | Val Loss: 0.222345\n",
      "Epoch [300/500] | Train Loss: 0.294603 | Val Loss: 0.239373\n",
      "Epoch [400/500] | Train Loss: 0.284015 | Val Loss: 0.246367\n",
      "Epoch [500/500] | Train Loss: 0.302402 | Val Loss: 0.245341\n",
      "Epoch [100/500] | Train Loss: 0.367969 | Val Loss: 0.118258\n",
      "Epoch [200/500] | Train Loss: 0.371304 | Val Loss: 0.123872\n",
      "Epoch [300/500] | Train Loss: 0.264704 | Val Loss: 0.131653\n",
      "Epoch [400/500] | Train Loss: 0.275964 | Val Loss: 0.124991\n",
      "Epoch [500/500] | Train Loss: 0.306253 | Val Loss: 0.120506\n",
      "Epoch [100/500] | Train Loss: 0.317470 | Val Loss: 0.180058\n",
      "Epoch [200/500] | Train Loss: 0.272987 | Val Loss: 0.182556\n",
      "Epoch [300/500] | Train Loss: 0.263401 | Val Loss: 0.180071\n",
      "Epoch [400/500] | Train Loss: 0.270548 | Val Loss: 0.176184\n",
      "Epoch [500/500] | Train Loss: 0.242667 | Val Loss: 0.183021\n",
      "Epoch [100/500] | Train Loss: 0.221316 | Val Loss: 1.073662\n",
      "Epoch [200/500] | Train Loss: 0.183799 | Val Loss: 1.206850\n",
      "Epoch [300/500] | Train Loss: 0.131526 | Val Loss: 1.617359\n",
      "Epoch [400/500] | Train Loss: 0.120761 | Val Loss: 1.783594\n",
      "Epoch [500/500] | Train Loss: 0.098388 | Val Loss: 1.805201\n",
      "Epoch [100/500] | Train Loss: 0.545249 | Val Loss: 0.434429\n",
      "Epoch [200/500] | Train Loss: 0.522523 | Val Loss: 0.419567\n",
      "Epoch [300/500] | Train Loss: 0.343898 | Val Loss: 0.424294\n",
      "Epoch [400/500] | Train Loss: 0.326892 | Val Loss: 0.471652\n",
      "Epoch [500/500] | Train Loss: 0.273902 | Val Loss: 0.507369\n",
      "Epoch [100/500] | Train Loss: 0.534770 | Val Loss: 0.246939\n",
      "Epoch [200/500] | Train Loss: 0.430388 | Val Loss: 0.234690\n",
      "Epoch [300/500] | Train Loss: 0.388582 | Val Loss: 0.248696\n",
      "Epoch [400/500] | Train Loss: 0.314417 | Val Loss: 0.270212\n",
      "Epoch [500/500] | Train Loss: 0.276221 | Val Loss: 0.276368\n",
      "Epoch [100/500] | Train Loss: 0.425781 | Val Loss: 0.107599\n",
      "Epoch [200/500] | Train Loss: 0.391242 | Val Loss: 0.115239\n",
      "Epoch [300/500] | Train Loss: 0.321111 | Val Loss: 0.122387\n",
      "Epoch [400/500] | Train Loss: 0.257554 | Val Loss: 0.121113\n",
      "Epoch [500/500] | Train Loss: 0.260159 | Val Loss: 0.128108\n",
      "Epoch [100/500] | Train Loss: 0.357509 | Val Loss: 0.173168\n",
      "Epoch [200/500] | Train Loss: 0.328232 | Val Loss: 0.177118\n",
      "Epoch [300/500] | Train Loss: 0.276715 | Val Loss: 0.180514\n",
      "Epoch [400/500] | Train Loss: 0.282856 | Val Loss: 0.191943\n",
      "Epoch [500/500] | Train Loss: 0.246608 | Val Loss: 0.206384\n",
      "Epoch [100/500] | Train Loss: 0.145146 | Val Loss: 2.488349\n",
      "Epoch [200/500] | Train Loss: 0.116552 | Val Loss: 3.055882\n",
      "Epoch [300/500] | Train Loss: 0.101250 | Val Loss: 3.307353\n",
      "Epoch [400/500] | Train Loss: 0.093171 | Val Loss: 2.685779\n",
      "Epoch [500/500] | Train Loss: 0.077907 | Val Loss: 2.248653\n",
      "Epoch [100/500] | Train Loss: 0.269437 | Val Loss: 0.587391\n",
      "Epoch [200/500] | Train Loss: 0.235404 | Val Loss: 0.591828\n",
      "Epoch [300/500] | Train Loss: 0.188945 | Val Loss: 0.496822\n",
      "Epoch [400/500] | Train Loss: 0.190127 | Val Loss: 0.525013\n",
      "Epoch [500/500] | Train Loss: 0.190054 | Val Loss: 0.519192\n",
      "Epoch [100/500] | Train Loss: 0.403182 | Val Loss: 0.271850\n",
      "Epoch [200/500] | Train Loss: 0.285880 | Val Loss: 0.268713\n",
      "Epoch [300/500] | Train Loss: 0.223182 | Val Loss: 0.256097\n",
      "Epoch [400/500] | Train Loss: 0.236545 | Val Loss: 0.279254\n",
      "Epoch [500/500] | Train Loss: 0.196895 | Val Loss: 0.279847\n",
      "Epoch [100/500] | Train Loss: 0.364524 | Val Loss: 0.117144\n",
      "Epoch [200/500] | Train Loss: 0.290959 | Val Loss: 0.143725\n",
      "Epoch [300/500] | Train Loss: 0.260904 | Val Loss: 0.143671\n",
      "Epoch [400/500] | Train Loss: 0.236925 | Val Loss: 0.137468\n",
      "Epoch [500/500] | Train Loss: 0.217587 | Val Loss: 0.141207\n",
      "Epoch [100/500] | Train Loss: 0.289137 | Val Loss: 0.184191\n",
      "Epoch [200/500] | Train Loss: 0.203673 | Val Loss: 0.250245\n",
      "Epoch [300/500] | Train Loss: 0.188239 | Val Loss: 0.254953\n",
      "Epoch [400/500] | Train Loss: 0.166930 | Val Loss: 0.253240\n",
      "Epoch [500/500] | Train Loss: 0.172646 | Val Loss: 0.241971\n",
      "Epoch [100/500] | Train Loss: 0.237164 | Val Loss: 1.071060\n",
      "Epoch [200/500] | Train Loss: 0.202087 | Val Loss: 1.271778\n",
      "Epoch [300/500] | Train Loss: 0.167755 | Val Loss: 1.534482\n",
      "Epoch [400/500] | Train Loss: 0.165709 | Val Loss: 1.685283\n",
      "Epoch [500/500] | Train Loss: 0.142797 | Val Loss: 1.738899\n",
      "Epoch [100/500] | Train Loss: 0.611323 | Val Loss: 0.407650\n",
      "Epoch [200/500] | Train Loss: 0.528143 | Val Loss: 0.421845\n",
      "Epoch [300/500] | Train Loss: 0.501600 | Val Loss: 0.435703\n",
      "Epoch [400/500] | Train Loss: 0.495915 | Val Loss: 0.432479\n",
      "Epoch [500/500] | Train Loss: 0.417948 | Val Loss: 0.437974\n",
      "Epoch [100/500] | Train Loss: 0.498712 | Val Loss: 0.248724\n",
      "Epoch [200/500] | Train Loss: 0.461915 | Val Loss: 0.225097\n",
      "Epoch [300/500] | Train Loss: 0.412349 | Val Loss: 0.224947\n",
      "Epoch [400/500] | Train Loss: 0.376006 | Val Loss: 0.242439\n",
      "Epoch [500/500] | Train Loss: 0.327630 | Val Loss: 0.255656\n",
      "Epoch [100/500] | Train Loss: 0.488275 | Val Loss: 0.107763\n",
      "Epoch [200/500] | Train Loss: 0.449263 | Val Loss: 0.110495\n",
      "Epoch [300/500] | Train Loss: 0.391926 | Val Loss: 0.116444\n",
      "Epoch [400/500] | Train Loss: 0.354584 | Val Loss: 0.117844\n",
      "Epoch [500/500] | Train Loss: 0.342710 | Val Loss: 0.113789\n",
      "Epoch [100/500] | Train Loss: 0.392512 | Val Loss: 0.175475\n",
      "Epoch [200/500] | Train Loss: 0.363918 | Val Loss: 0.176719\n",
      "Epoch [300/500] | Train Loss: 0.337805 | Val Loss: 0.178273\n",
      "Epoch [400/500] | Train Loss: 0.315154 | Val Loss: 0.175614\n",
      "Epoch [500/500] | Train Loss: 0.312866 | Val Loss: 0.174569\n",
      "Epoch [100/500] | Train Loss: 0.147249 | Val Loss: 1.429543\n",
      "Epoch [200/500] | Train Loss: 0.123847 | Val Loss: 1.360140\n",
      "Epoch [300/500] | Train Loss: 0.106231 | Val Loss: 1.320512\n",
      "Epoch [400/500] | Train Loss: 0.106171 | Val Loss: 1.268584\n",
      "Epoch [500/500] | Train Loss: 0.092027 | Val Loss: 1.223897\n",
      "Epoch [100/500] | Train Loss: 0.433552 | Val Loss: 0.457694\n",
      "Epoch [200/500] | Train Loss: 0.370678 | Val Loss: 0.646731\n",
      "Epoch [300/500] | Train Loss: 0.309768 | Val Loss: 0.466340\n",
      "Epoch [400/500] | Train Loss: 0.248675 | Val Loss: 0.471073\n",
      "Epoch [500/500] | Train Loss: 0.263723 | Val Loss: 0.460377\n",
      "Epoch [100/500] | Train Loss: 0.419208 | Val Loss: 0.269332\n",
      "Epoch [200/500] | Train Loss: 0.312488 | Val Loss: 0.273004\n",
      "Epoch [300/500] | Train Loss: 0.326406 | Val Loss: 0.276394\n",
      "Epoch [400/500] | Train Loss: 0.300707 | Val Loss: 0.294943\n",
      "Epoch [500/500] | Train Loss: 0.282729 | Val Loss: 0.283031\n",
      "Epoch [100/500] | Train Loss: 0.384410 | Val Loss: 0.117539\n",
      "Epoch [200/500] | Train Loss: 0.269744 | Val Loss: 0.115768\n",
      "Epoch [300/500] | Train Loss: 0.290222 | Val Loss: 0.109705\n",
      "Epoch [400/500] | Train Loss: 0.255217 | Val Loss: 0.120425\n",
      "Epoch [500/500] | Train Loss: 0.241411 | Val Loss: 0.132592\n",
      "Epoch [100/500] | Train Loss: 0.312024 | Val Loss: 0.189264\n",
      "Epoch [200/500] | Train Loss: 0.250945 | Val Loss: 0.202694\n",
      "Epoch [300/500] | Train Loss: 0.269401 | Val Loss: 0.182440\n",
      "Epoch [400/500] | Train Loss: 0.241311 | Val Loss: 0.192229\n",
      "Epoch [500/500] | Train Loss: 0.221453 | Val Loss: 0.206802\n",
      "[Year=1966] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.443970 Test MSE=0.548799\n",
      "Year 1966 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.050722 | Val Loss: 0.270945\n",
      "Epoch [200/500] | Train Loss: 0.797391 | Val Loss: 0.280312\n",
      "Epoch [300/500] | Train Loss: 0.581560 | Val Loss: 0.285228\n",
      "Epoch [400/500] | Train Loss: 0.496188 | Val Loss: 0.283412\n",
      "Epoch [500/500] | Train Loss: 0.587881 | Val Loss: 0.301287\n",
      "Epoch [100/500] | Train Loss: 0.655220 | Val Loss: 0.250367\n",
      "Epoch [200/500] | Train Loss: 0.576944 | Val Loss: 0.242511\n",
      "Epoch [300/500] | Train Loss: 0.463354 | Val Loss: 0.234216\n",
      "Epoch [400/500] | Train Loss: 0.450525 | Val Loss: 0.233805\n",
      "Epoch [500/500] | Train Loss: 0.386464 | Val Loss: 0.241210\n",
      "Epoch [100/500] | Train Loss: 0.533583 | Val Loss: 0.095713\n",
      "Epoch [200/500] | Train Loss: 0.434072 | Val Loss: 0.102551\n",
      "Epoch [300/500] | Train Loss: 0.410602 | Val Loss: 0.100614\n",
      "Epoch [400/500] | Train Loss: 0.315707 | Val Loss: 0.102136\n",
      "Epoch [500/500] | Train Loss: 0.355035 | Val Loss: 0.100451\n",
      "Epoch [100/500] | Train Loss: 0.411305 | Val Loss: 0.197585\n",
      "Epoch [200/500] | Train Loss: 0.332185 | Val Loss: 0.199728\n",
      "Epoch [300/500] | Train Loss: 0.317714 | Val Loss: 0.207499\n",
      "Epoch [400/500] | Train Loss: 0.301806 | Val Loss: 0.218011\n",
      "Epoch [500/500] | Train Loss: 0.299444 | Val Loss: 0.222779\n",
      "Epoch [100/500] | Train Loss: 0.389011 | Val Loss: 0.595337\n",
      "Epoch [200/500] | Train Loss: 0.331632 | Val Loss: 0.596418\n",
      "Epoch [300/500] | Train Loss: 0.302057 | Val Loss: 0.631108\n",
      "Epoch [400/500] | Train Loss: 0.282595 | Val Loss: 0.648796\n",
      "Epoch [500/500] | Train Loss: 0.258361 | Val Loss: 0.653788\n",
      "Epoch [100/500] | Train Loss: 0.536633 | Val Loss: 0.240479\n",
      "Epoch [200/500] | Train Loss: 0.429501 | Val Loss: 0.267854\n",
      "Epoch [300/500] | Train Loss: 0.285045 | Val Loss: 0.283073\n",
      "Epoch [400/500] | Train Loss: 0.384694 | Val Loss: 0.292375\n",
      "Epoch [500/500] | Train Loss: 0.246284 | Val Loss: 0.317388\n",
      "Epoch [100/500] | Train Loss: 0.411707 | Val Loss: 0.272487\n",
      "Epoch [200/500] | Train Loss: 0.294870 | Val Loss: 0.339056\n",
      "Epoch [300/500] | Train Loss: 0.285974 | Val Loss: 0.340383\n",
      "Epoch [400/500] | Train Loss: 0.243593 | Val Loss: 0.360141\n",
      "Epoch [500/500] | Train Loss: 0.197036 | Val Loss: 0.329561\n",
      "Epoch [100/500] | Train Loss: 0.412798 | Val Loss: 0.104734\n",
      "Epoch [200/500] | Train Loss: 0.296869 | Val Loss: 0.097293\n",
      "Epoch [300/500] | Train Loss: 0.282416 | Val Loss: 0.096604\n",
      "Epoch [400/500] | Train Loss: 0.252320 | Val Loss: 0.094829\n",
      "Epoch [500/500] | Train Loss: 0.240875 | Val Loss: 0.103467\n",
      "Epoch [100/500] | Train Loss: 0.245327 | Val Loss: 0.228457\n",
      "Epoch [200/500] | Train Loss: 0.269051 | Val Loss: 0.215626\n",
      "Epoch [300/500] | Train Loss: 0.206252 | Val Loss: 0.240971\n",
      "Epoch [400/500] | Train Loss: 0.223902 | Val Loss: 0.224629\n",
      "Epoch [500/500] | Train Loss: 0.184694 | Val Loss: 0.236007\n",
      "Epoch [100/500] | Train Loss: 0.268831 | Val Loss: 0.620955\n",
      "Epoch [200/500] | Train Loss: 0.203031 | Val Loss: 0.663995\n",
      "Epoch [300/500] | Train Loss: 0.237343 | Val Loss: 0.635037\n",
      "Epoch [400/500] | Train Loss: 0.168351 | Val Loss: 0.682778\n",
      "Epoch [500/500] | Train Loss: 0.172554 | Val Loss: 0.679339\n",
      "Epoch [100/500] | Train Loss: 1.211741 | Val Loss: 0.239447\n",
      "Epoch [200/500] | Train Loss: 1.085414 | Val Loss: 0.277276\n",
      "Epoch [300/500] | Train Loss: 0.954109 | Val Loss: 0.276248\n",
      "Epoch [400/500] | Train Loss: 0.687095 | Val Loss: 0.275580\n",
      "Epoch [500/500] | Train Loss: 0.743335 | Val Loss: 0.271872\n",
      "Epoch [100/500] | Train Loss: 0.675452 | Val Loss: 0.257548\n",
      "Epoch [200/500] | Train Loss: 0.623212 | Val Loss: 0.244819\n",
      "Epoch [300/500] | Train Loss: 0.567776 | Val Loss: 0.227898\n",
      "Epoch [400/500] | Train Loss: 0.518274 | Val Loss: 0.250116\n",
      "Epoch [500/500] | Train Loss: 0.538657 | Val Loss: 0.274418\n",
      "Epoch [100/500] | Train Loss: 0.538880 | Val Loss: 0.096612\n",
      "Epoch [200/500] | Train Loss: 0.465778 | Val Loss: 0.097205\n",
      "Epoch [300/500] | Train Loss: 0.404655 | Val Loss: 0.102453\n",
      "Epoch [400/500] | Train Loss: 0.384319 | Val Loss: 0.103823\n",
      "Epoch [500/500] | Train Loss: 0.381592 | Val Loss: 0.105092\n",
      "Epoch [100/500] | Train Loss: 0.435795 | Val Loss: 0.195797\n",
      "Epoch [200/500] | Train Loss: 0.412892 | Val Loss: 0.206690\n",
      "Epoch [300/500] | Train Loss: 0.375409 | Val Loss: 0.208844\n",
      "Epoch [400/500] | Train Loss: 0.325271 | Val Loss: 0.210552\n",
      "Epoch [500/500] | Train Loss: 0.345029 | Val Loss: 0.207368\n",
      "Epoch [100/500] | Train Loss: 0.390559 | Val Loss: 0.603217\n",
      "Epoch [200/500] | Train Loss: 0.339354 | Val Loss: 0.599772\n",
      "Epoch [300/500] | Train Loss: 0.313483 | Val Loss: 0.616972\n",
      "Epoch [400/500] | Train Loss: 0.330011 | Val Loss: 0.635241\n",
      "Epoch [500/500] | Train Loss: 0.289838 | Val Loss: 0.649780\n",
      "Epoch [100/500] | Train Loss: 0.680962 | Val Loss: 0.275392\n",
      "Epoch [200/500] | Train Loss: 0.635125 | Val Loss: 0.259873\n",
      "Epoch [300/500] | Train Loss: 0.423651 | Val Loss: 0.286411\n",
      "Epoch [400/500] | Train Loss: 0.437380 | Val Loss: 0.269780\n",
      "Epoch [500/500] | Train Loss: 0.358586 | Val Loss: 0.281178\n",
      "Epoch [100/500] | Train Loss: 0.582761 | Val Loss: 0.277611\n",
      "Epoch [200/500] | Train Loss: 0.412537 | Val Loss: 0.347847\n",
      "Epoch [300/500] | Train Loss: 0.373325 | Val Loss: 0.320369\n",
      "Epoch [400/500] | Train Loss: 0.334925 | Val Loss: 0.337686\n",
      "Epoch [500/500] | Train Loss: 0.402804 | Val Loss: 0.334114\n",
      "Epoch [100/500] | Train Loss: 0.427526 | Val Loss: 0.097520\n",
      "Epoch [200/500] | Train Loss: 0.341314 | Val Loss: 0.099239\n",
      "Epoch [300/500] | Train Loss: 0.350154 | Val Loss: 0.100797\n",
      "Epoch [400/500] | Train Loss: 0.275755 | Val Loss: 0.102919\n",
      "Epoch [500/500] | Train Loss: 0.310028 | Val Loss: 0.101882\n",
      "Epoch [100/500] | Train Loss: 0.358082 | Val Loss: 0.210215\n",
      "Epoch [200/500] | Train Loss: 0.250783 | Val Loss: 0.218509\n",
      "Epoch [300/500] | Train Loss: 0.297275 | Val Loss: 0.218989\n",
      "Epoch [400/500] | Train Loss: 0.348589 | Val Loss: 0.212685\n",
      "Epoch [500/500] | Train Loss: 0.240914 | Val Loss: 0.232493\n",
      "Epoch [100/500] | Train Loss: 0.357537 | Val Loss: 0.623537\n",
      "Epoch [200/500] | Train Loss: 0.320451 | Val Loss: 0.664657\n",
      "Epoch [300/500] | Train Loss: 0.242429 | Val Loss: 0.699459\n",
      "Epoch [400/500] | Train Loss: 0.272836 | Val Loss: 0.735088\n",
      "Epoch [500/500] | Train Loss: 0.238871 | Val Loss: 0.706734\n",
      "Epoch [100/500] | Train Loss: 1.024300 | Val Loss: 0.256288\n",
      "Epoch [200/500] | Train Loss: 0.813766 | Val Loss: 0.302430\n",
      "Epoch [300/500] | Train Loss: 0.719222 | Val Loss: 0.317025\n",
      "Epoch [400/500] | Train Loss: 0.557404 | Val Loss: 0.324527\n",
      "Epoch [500/500] | Train Loss: 0.376561 | Val Loss: 0.329324\n",
      "Epoch [100/500] | Train Loss: 0.586175 | Val Loss: 0.249065\n",
      "Epoch [200/500] | Train Loss: 0.453648 | Val Loss: 0.252617\n",
      "Epoch [300/500] | Train Loss: 0.310562 | Val Loss: 0.265954\n",
      "Epoch [400/500] | Train Loss: 0.285912 | Val Loss: 0.289807\n",
      "Epoch [500/500] | Train Loss: 0.337179 | Val Loss: 0.278762\n",
      "Epoch [100/500] | Train Loss: 0.466158 | Val Loss: 0.095273\n",
      "Epoch [200/500] | Train Loss: 0.361867 | Val Loss: 0.100300\n",
      "Epoch [300/500] | Train Loss: 0.323012 | Val Loss: 0.101632\n",
      "Epoch [400/500] | Train Loss: 0.287540 | Val Loss: 0.101458\n",
      "Epoch [500/500] | Train Loss: 0.276951 | Val Loss: 0.104484\n",
      "Epoch [100/500] | Train Loss: 0.411277 | Val Loss: 0.208544\n",
      "Epoch [200/500] | Train Loss: 0.350143 | Val Loss: 0.214296\n",
      "Epoch [300/500] | Train Loss: 0.286299 | Val Loss: 0.212053\n",
      "Epoch [400/500] | Train Loss: 0.278868 | Val Loss: 0.215129\n",
      "Epoch [500/500] | Train Loss: 0.219007 | Val Loss: 0.222773\n",
      "Epoch [100/500] | Train Loss: 0.312090 | Val Loss: 0.640118\n",
      "Epoch [200/500] | Train Loss: 0.269661 | Val Loss: 0.710762\n",
      "Epoch [300/500] | Train Loss: 0.242497 | Val Loss: 0.758712\n",
      "Epoch [400/500] | Train Loss: 0.228327 | Val Loss: 0.807374\n",
      "Epoch [500/500] | Train Loss: 0.210368 | Val Loss: 0.797208\n",
      "Epoch [100/500] | Train Loss: 0.493081 | Val Loss: 0.266702\n",
      "Epoch [200/500] | Train Loss: 0.249129 | Val Loss: 0.359370\n",
      "Epoch [300/500] | Train Loss: 0.265446 | Val Loss: 0.339983\n",
      "Epoch [400/500] | Train Loss: 0.226100 | Val Loss: 0.335656\n",
      "Epoch [500/500] | Train Loss: 0.268292 | Val Loss: 0.320530\n",
      "Epoch [100/500] | Train Loss: 0.394967 | Val Loss: 0.272857\n",
      "Epoch [200/500] | Train Loss: 0.315651 | Val Loss: 0.370087\n",
      "Epoch [300/500] | Train Loss: 0.279316 | Val Loss: 0.340695\n",
      "Epoch [400/500] | Train Loss: 0.228429 | Val Loss: 0.360991\n",
      "Epoch [500/500] | Train Loss: 0.204136 | Val Loss: 0.383180\n",
      "Epoch [100/500] | Train Loss: 0.336622 | Val Loss: 0.101545\n",
      "Epoch [200/500] | Train Loss: 0.247265 | Val Loss: 0.111143\n",
      "Epoch [300/500] | Train Loss: 0.262850 | Val Loss: 0.111372\n",
      "Epoch [400/500] | Train Loss: 0.219859 | Val Loss: 0.121279\n",
      "Epoch [500/500] | Train Loss: 0.213633 | Val Loss: 0.117769\n",
      "Epoch [100/500] | Train Loss: 0.251847 | Val Loss: 0.275981\n",
      "Epoch [200/500] | Train Loss: 0.205005 | Val Loss: 0.251145\n",
      "Epoch [300/500] | Train Loss: 0.169647 | Val Loss: 0.264081\n",
      "Epoch [400/500] | Train Loss: 0.156875 | Val Loss: 0.279377\n",
      "Epoch [500/500] | Train Loss: 0.153773 | Val Loss: 0.261608\n",
      "Epoch [100/500] | Train Loss: 0.272555 | Val Loss: 0.681705\n",
      "Epoch [200/500] | Train Loss: 0.184837 | Val Loss: 0.795760\n",
      "Epoch [300/500] | Train Loss: 0.178084 | Val Loss: 0.750026\n",
      "Epoch [400/500] | Train Loss: 0.160864 | Val Loss: 0.751057\n",
      "Epoch [500/500] | Train Loss: 0.156638 | Val Loss: 0.799462\n",
      "Epoch [100/500] | Train Loss: 1.149986 | Val Loss: 0.267718\n",
      "Epoch [200/500] | Train Loss: 0.986053 | Val Loss: 0.291055\n",
      "Epoch [300/500] | Train Loss: 0.754297 | Val Loss: 0.298266\n",
      "Epoch [400/500] | Train Loss: 0.485451 | Val Loss: 0.291851\n",
      "Epoch [500/500] | Train Loss: 0.615789 | Val Loss: 0.291603\n",
      "Epoch [100/500] | Train Loss: 0.665914 | Val Loss: 0.242364\n",
      "Epoch [200/500] | Train Loss: 0.472480 | Val Loss: 0.224060\n",
      "Epoch [300/500] | Train Loss: 0.500703 | Val Loss: 0.244939\n",
      "Epoch [400/500] | Train Loss: 0.428604 | Val Loss: 0.247261\n",
      "Epoch [500/500] | Train Loss: 0.485155 | Val Loss: 0.260412\n",
      "Epoch [100/500] | Train Loss: 0.501218 | Val Loss: 0.096712\n",
      "Epoch [200/500] | Train Loss: 0.467014 | Val Loss: 0.097773\n",
      "Epoch [300/500] | Train Loss: 0.414948 | Val Loss: 0.102051\n",
      "Epoch [400/500] | Train Loss: 0.374174 | Val Loss: 0.101886\n",
      "Epoch [500/500] | Train Loss: 0.328549 | Val Loss: 0.101305\n",
      "Epoch [100/500] | Train Loss: 0.436207 | Val Loss: 0.203790\n",
      "Epoch [200/500] | Train Loss: 0.391712 | Val Loss: 0.206120\n",
      "Epoch [300/500] | Train Loss: 0.333915 | Val Loss: 0.203366\n",
      "Epoch [400/500] | Train Loss: 0.330090 | Val Loss: 0.201157\n",
      "Epoch [500/500] | Train Loss: 0.315196 | Val Loss: 0.198271\n",
      "Epoch [100/500] | Train Loss: 0.384393 | Val Loss: 0.598812\n",
      "Epoch [200/500] | Train Loss: 0.323735 | Val Loss: 0.617423\n",
      "Epoch [300/500] | Train Loss: 0.319628 | Val Loss: 0.624964\n",
      "Epoch [400/500] | Train Loss: 0.273001 | Val Loss: 0.637703\n",
      "Epoch [500/500] | Train Loss: 0.292024 | Val Loss: 0.646169\n",
      "Epoch [100/500] | Train Loss: 0.690697 | Val Loss: 0.253394\n",
      "Epoch [200/500] | Train Loss: 0.553320 | Val Loss: 0.270324\n",
      "Epoch [300/500] | Train Loss: 0.323569 | Val Loss: 0.290214\n",
      "Epoch [400/500] | Train Loss: 0.440175 | Val Loss: 0.309489\n",
      "Epoch [500/500] | Train Loss: 0.382461 | Val Loss: 0.306725\n",
      "Epoch [100/500] | Train Loss: 0.576653 | Val Loss: 0.278488\n",
      "Epoch [200/500] | Train Loss: 0.504817 | Val Loss: 0.254607\n",
      "Epoch [300/500] | Train Loss: 0.378469 | Val Loss: 0.309454\n",
      "Epoch [400/500] | Train Loss: 0.377331 | Val Loss: 0.284244\n",
      "Epoch [500/500] | Train Loss: 0.282243 | Val Loss: 0.327709\n",
      "Epoch [100/500] | Train Loss: 0.418775 | Val Loss: 0.101494\n",
      "Epoch [200/500] | Train Loss: 0.328164 | Val Loss: 0.103536\n",
      "Epoch [300/500] | Train Loss: 0.384278 | Val Loss: 0.106542\n",
      "Epoch [400/500] | Train Loss: 0.304035 | Val Loss: 0.104995\n",
      "Epoch [500/500] | Train Loss: 0.287719 | Val Loss: 0.111908\n",
      "Epoch [100/500] | Train Loss: 0.293426 | Val Loss: 0.197105\n",
      "Epoch [200/500] | Train Loss: 0.323370 | Val Loss: 0.215681\n",
      "Epoch [300/500] | Train Loss: 0.228854 | Val Loss: 0.227439\n",
      "Epoch [400/500] | Train Loss: 0.253208 | Val Loss: 0.235367\n",
      "Epoch [500/500] | Train Loss: 0.209181 | Val Loss: 0.233937\n",
      "Epoch [100/500] | Train Loss: 0.313042 | Val Loss: 0.625606\n",
      "Epoch [200/500] | Train Loss: 0.247191 | Val Loss: 0.689342\n",
      "Epoch [300/500] | Train Loss: 0.216585 | Val Loss: 0.736543\n",
      "Epoch [400/500] | Train Loss: 0.210644 | Val Loss: 0.722529\n",
      "Epoch [500/500] | Train Loss: 0.182046 | Val Loss: 0.762748\n",
      "[Year=1967] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.299552 Test MSE=0.287515\n",
      "Year 1967 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.151894 | Val Loss: 0.234089\n",
      "Epoch [200/500] | Train Loss: 0.140510 | Val Loss: 0.236280\n",
      "Epoch [300/500] | Train Loss: 0.121295 | Val Loss: 0.260347\n",
      "Epoch [400/500] | Train Loss: 0.096463 | Val Loss: 0.302861\n",
      "Epoch [500/500] | Train Loss: 0.092226 | Val Loss: 0.338084\n",
      "Epoch [100/500] | Train Loss: 0.182819 | Val Loss: 0.185413\n",
      "Epoch [200/500] | Train Loss: 0.152325 | Val Loss: 0.207893\n",
      "Epoch [300/500] | Train Loss: 0.135442 | Val Loss: 0.223158\n",
      "Epoch [400/500] | Train Loss: 0.125761 | Val Loss: 0.225017\n",
      "Epoch [500/500] | Train Loss: 0.108668 | Val Loss: 0.227372\n",
      "Epoch [100/500] | Train Loss: 0.177731 | Val Loss: 0.152169\n",
      "Epoch [200/500] | Train Loss: 0.150750 | Val Loss: 0.150422\n",
      "Epoch [300/500] | Train Loss: 0.148960 | Val Loss: 0.150227\n",
      "Epoch [400/500] | Train Loss: 0.133054 | Val Loss: 0.155271\n",
      "Epoch [500/500] | Train Loss: 0.129656 | Val Loss: 0.158251\n",
      "Epoch [100/500] | Train Loss: 0.171130 | Val Loss: 0.627805\n",
      "Epoch [200/500] | Train Loss: 0.158748 | Val Loss: 0.732125\n",
      "Epoch [300/500] | Train Loss: 0.136350 | Val Loss: 0.866534\n",
      "Epoch [400/500] | Train Loss: 0.129985 | Val Loss: 0.942821\n",
      "Epoch [500/500] | Train Loss: 0.120194 | Val Loss: 0.955780\n",
      "Epoch [100/500] | Train Loss: 0.259710 | Val Loss: 0.255033\n",
      "Epoch [200/500] | Train Loss: 0.245405 | Val Loss: 0.263807\n",
      "Epoch [300/500] | Train Loss: 0.217335 | Val Loss: 0.278395\n",
      "Epoch [400/500] | Train Loss: 0.205695 | Val Loss: 0.292565\n",
      "Epoch [500/500] | Train Loss: 0.184958 | Val Loss: 0.307673\n",
      "Epoch [100/500] | Train Loss: 0.099293 | Val Loss: 0.249761\n",
      "Epoch [200/500] | Train Loss: 0.083614 | Val Loss: 0.289573\n",
      "Epoch [300/500] | Train Loss: 0.076763 | Val Loss: 0.300341\n",
      "Epoch [400/500] | Train Loss: 0.051220 | Val Loss: 0.283986\n",
      "Epoch [500/500] | Train Loss: 0.053331 | Val Loss: 0.303488\n",
      "Epoch [100/500] | Train Loss: 0.118261 | Val Loss: 0.239890\n",
      "Epoch [200/500] | Train Loss: 0.097675 | Val Loss: 0.246960\n",
      "Epoch [300/500] | Train Loss: 0.079929 | Val Loss: 0.228135\n",
      "Epoch [400/500] | Train Loss: 0.080686 | Val Loss: 0.268041\n",
      "Epoch [500/500] | Train Loss: 0.076305 | Val Loss: 0.236793\n",
      "Epoch [100/500] | Train Loss: 0.134749 | Val Loss: 0.161321\n",
      "Epoch [200/500] | Train Loss: 0.108486 | Val Loss: 0.179529\n",
      "Epoch [300/500] | Train Loss: 0.089342 | Val Loss: 0.183728\n",
      "Epoch [400/500] | Train Loss: 0.085891 | Val Loss: 0.197178\n",
      "Epoch [500/500] | Train Loss: 0.084635 | Val Loss: 0.196054\n",
      "Epoch [100/500] | Train Loss: 0.147411 | Val Loss: 0.786366\n",
      "Epoch [200/500] | Train Loss: 0.128978 | Val Loss: 0.791586\n",
      "Epoch [300/500] | Train Loss: 0.117087 | Val Loss: 0.853200\n",
      "Epoch [400/500] | Train Loss: 0.109800 | Val Loss: 0.870959\n",
      "Epoch [500/500] | Train Loss: 0.105858 | Val Loss: 0.879983\n",
      "Epoch [100/500] | Train Loss: 0.200677 | Val Loss: 0.295063\n",
      "Epoch [200/500] | Train Loss: 0.186093 | Val Loss: 0.289558\n",
      "Epoch [300/500] | Train Loss: 0.161647 | Val Loss: 0.297476\n",
      "Epoch [400/500] | Train Loss: 0.150975 | Val Loss: 0.321810\n",
      "Epoch [500/500] | Train Loss: 0.152313 | Val Loss: 0.344232\n",
      "Epoch [100/500] | Train Loss: 0.161388 | Val Loss: 0.242002\n",
      "Epoch [200/500] | Train Loss: 0.155739 | Val Loss: 0.255736\n",
      "Epoch [300/500] | Train Loss: 0.145815 | Val Loss: 0.269391\n",
      "Epoch [400/500] | Train Loss: 0.133982 | Val Loss: 0.272141\n",
      "Epoch [500/500] | Train Loss: 0.124265 | Val Loss: 0.267390\n",
      "Epoch [100/500] | Train Loss: 0.188954 | Val Loss: 0.184316\n",
      "Epoch [200/500] | Train Loss: 0.157795 | Val Loss: 0.202543\n",
      "Epoch [300/500] | Train Loss: 0.150994 | Val Loss: 0.204936\n",
      "Epoch [400/500] | Train Loss: 0.146277 | Val Loss: 0.213936\n",
      "Epoch [500/500] | Train Loss: 0.157213 | Val Loss: 0.223346\n",
      "Epoch [100/500] | Train Loss: 0.184297 | Val Loss: 0.148274\n",
      "Epoch [200/500] | Train Loss: 0.157680 | Val Loss: 0.147787\n",
      "Epoch [300/500] | Train Loss: 0.151954 | Val Loss: 0.149038\n",
      "Epoch [400/500] | Train Loss: 0.149064 | Val Loss: 0.149744\n",
      "Epoch [500/500] | Train Loss: 0.137665 | Val Loss: 0.150930\n",
      "Epoch [100/500] | Train Loss: 0.192562 | Val Loss: 0.617802\n",
      "Epoch [200/500] | Train Loss: 0.174391 | Val Loss: 0.640694\n",
      "Epoch [300/500] | Train Loss: 0.172312 | Val Loss: 0.693728\n",
      "Epoch [400/500] | Train Loss: 0.146165 | Val Loss: 0.763140\n",
      "Epoch [500/500] | Train Loss: 0.172952 | Val Loss: 0.794474\n",
      "Epoch [100/500] | Train Loss: 0.276935 | Val Loss: 0.261384\n",
      "Epoch [200/500] | Train Loss: 0.255519 | Val Loss: 0.263448\n",
      "Epoch [300/500] | Train Loss: 0.232993 | Val Loss: 0.260932\n",
      "Epoch [400/500] | Train Loss: 0.237452 | Val Loss: 0.265746\n",
      "Epoch [500/500] | Train Loss: 0.221294 | Val Loss: 0.272059\n",
      "Epoch [100/500] | Train Loss: 0.126288 | Val Loss: 0.239206\n",
      "Epoch [200/500] | Train Loss: 0.103785 | Val Loss: 0.287220\n",
      "Epoch [300/500] | Train Loss: 0.096655 | Val Loss: 0.311221\n",
      "Epoch [400/500] | Train Loss: 0.077590 | Val Loss: 0.328820\n",
      "Epoch [500/500] | Train Loss: 0.079175 | Val Loss: 0.348459\n",
      "Epoch [100/500] | Train Loss: 0.162924 | Val Loss: 0.188308\n",
      "Epoch [200/500] | Train Loss: 0.138902 | Val Loss: 0.209070\n",
      "Epoch [300/500] | Train Loss: 0.135449 | Val Loss: 0.210225\n",
      "Epoch [400/500] | Train Loss: 0.136680 | Val Loss: 0.195484\n",
      "Epoch [500/500] | Train Loss: 0.094714 | Val Loss: 0.218112\n",
      "Epoch [100/500] | Train Loss: 0.149823 | Val Loss: 0.150056\n",
      "Epoch [200/500] | Train Loss: 0.134631 | Val Loss: 0.162867\n",
      "Epoch [300/500] | Train Loss: 0.116603 | Val Loss: 0.178893\n",
      "Epoch [400/500] | Train Loss: 0.126650 | Val Loss: 0.172162\n",
      "Epoch [500/500] | Train Loss: 0.115562 | Val Loss: 0.167182\n",
      "Epoch [100/500] | Train Loss: 0.167235 | Val Loss: 0.654688\n",
      "Epoch [200/500] | Train Loss: 0.148622 | Val Loss: 0.760526\n",
      "Epoch [300/500] | Train Loss: 0.147041 | Val Loss: 0.806202\n",
      "Epoch [400/500] | Train Loss: 0.139253 | Val Loss: 0.809868\n",
      "Epoch [500/500] | Train Loss: 0.127511 | Val Loss: 0.957736\n",
      "Epoch [100/500] | Train Loss: 0.233819 | Val Loss: 0.299157\n",
      "Epoch [200/500] | Train Loss: 0.198168 | Val Loss: 0.302815\n",
      "Epoch [300/500] | Train Loss: 0.178804 | Val Loss: 0.288915\n",
      "Epoch [400/500] | Train Loss: 0.187993 | Val Loss: 0.295624\n",
      "Epoch [500/500] | Train Loss: 0.169671 | Val Loss: 0.286026\n",
      "Epoch [100/500] | Train Loss: 0.145695 | Val Loss: 0.241792\n",
      "Epoch [200/500] | Train Loss: 0.121373 | Val Loss: 0.294033\n",
      "Epoch [300/500] | Train Loss: 0.102326 | Val Loss: 0.304193\n",
      "Epoch [400/500] | Train Loss: 0.103239 | Val Loss: 0.320354\n",
      "Epoch [500/500] | Train Loss: 0.083952 | Val Loss: 0.303884\n",
      "Epoch [100/500] | Train Loss: 0.165790 | Val Loss: 0.203906\n",
      "Epoch [200/500] | Train Loss: 0.134340 | Val Loss: 0.229546\n",
      "Epoch [300/500] | Train Loss: 0.125828 | Val Loss: 0.243563\n",
      "Epoch [400/500] | Train Loss: 0.112401 | Val Loss: 0.247729\n",
      "Epoch [500/500] | Train Loss: 0.101749 | Val Loss: 0.255545\n",
      "Epoch [100/500] | Train Loss: 0.172971 | Val Loss: 0.150886\n",
      "Epoch [200/500] | Train Loss: 0.148222 | Val Loss: 0.149786\n",
      "Epoch [300/500] | Train Loss: 0.139948 | Val Loss: 0.153490\n",
      "Epoch [400/500] | Train Loss: 0.139578 | Val Loss: 0.159304\n",
      "Epoch [500/500] | Train Loss: 0.133704 | Val Loss: 0.167290\n",
      "Epoch [100/500] | Train Loss: 0.182390 | Val Loss: 0.617537\n",
      "Epoch [200/500] | Train Loss: 0.169908 | Val Loss: 0.687804\n",
      "Epoch [300/500] | Train Loss: 0.148069 | Val Loss: 0.754163\n",
      "Epoch [400/500] | Train Loss: 0.129973 | Val Loss: 0.789581\n",
      "Epoch [500/500] | Train Loss: 0.117953 | Val Loss: 0.895754\n",
      "Epoch [100/500] | Train Loss: 0.262464 | Val Loss: 0.263421\n",
      "Epoch [200/500] | Train Loss: 0.215594 | Val Loss: 0.279309\n",
      "Epoch [300/500] | Train Loss: 0.203642 | Val Loss: 0.287279\n",
      "Epoch [400/500] | Train Loss: 0.189853 | Val Loss: 0.289151\n",
      "Epoch [500/500] | Train Loss: 0.177233 | Val Loss: 0.290782\n",
      "Epoch [100/500] | Train Loss: 0.090132 | Val Loss: 0.400278\n",
      "Epoch [200/500] | Train Loss: 0.064934 | Val Loss: 0.369872\n",
      "Epoch [300/500] | Train Loss: 0.047654 | Val Loss: 0.342466\n",
      "Epoch [400/500] | Train Loss: 0.045509 | Val Loss: 0.385607\n",
      "Epoch [500/500] | Train Loss: 0.043887 | Val Loss: 0.346017\n",
      "Epoch [100/500] | Train Loss: 0.106217 | Val Loss: 0.292519\n",
      "Epoch [200/500] | Train Loss: 0.095869 | Val Loss: 0.282379\n",
      "Epoch [300/500] | Train Loss: 0.081910 | Val Loss: 0.313958\n",
      "Epoch [400/500] | Train Loss: 0.068545 | Val Loss: 0.313854\n",
      "Epoch [500/500] | Train Loss: 0.058141 | Val Loss: 0.305323\n",
      "Epoch [100/500] | Train Loss: 0.141084 | Val Loss: 0.149169\n",
      "Epoch [200/500] | Train Loss: 0.100993 | Val Loss: 0.175332\n",
      "Epoch [300/500] | Train Loss: 0.096613 | Val Loss: 0.193009\n",
      "Epoch [400/500] | Train Loss: 0.085661 | Val Loss: 0.195479\n",
      "Epoch [500/500] | Train Loss: 0.071963 | Val Loss: 0.197960\n",
      "Epoch [100/500] | Train Loss: 0.134041 | Val Loss: 0.817098\n",
      "Epoch [200/500] | Train Loss: 0.102957 | Val Loss: 0.843663\n",
      "Epoch [300/500] | Train Loss: 0.088188 | Val Loss: 0.927762\n",
      "Epoch [400/500] | Train Loss: 0.087300 | Val Loss: 0.992792\n",
      "Epoch [500/500] | Train Loss: 0.079198 | Val Loss: 0.890179\n",
      "Epoch [100/500] | Train Loss: 0.196504 | Val Loss: 0.286707\n",
      "Epoch [200/500] | Train Loss: 0.166698 | Val Loss: 0.282632\n",
      "Epoch [300/500] | Train Loss: 0.158370 | Val Loss: 0.299647\n",
      "Epoch [400/500] | Train Loss: 0.141671 | Val Loss: 0.305913\n",
      "Epoch [500/500] | Train Loss: 0.131910 | Val Loss: 0.310351\n",
      "Epoch [100/500] | Train Loss: 0.168994 | Val Loss: 0.231194\n",
      "Epoch [200/500] | Train Loss: 0.142013 | Val Loss: 0.231963\n",
      "Epoch [300/500] | Train Loss: 0.126264 | Val Loss: 0.236002\n",
      "Epoch [400/500] | Train Loss: 0.115831 | Val Loss: 0.241042\n",
      "Epoch [500/500] | Train Loss: 0.107130 | Val Loss: 0.245051\n",
      "Epoch [100/500] | Train Loss: 0.174910 | Val Loss: 0.189554\n",
      "Epoch [200/500] | Train Loss: 0.157679 | Val Loss: 0.211867\n",
      "Epoch [300/500] | Train Loss: 0.152643 | Val Loss: 0.220807\n",
      "Epoch [400/500] | Train Loss: 0.152488 | Val Loss: 0.217762\n",
      "Epoch [500/500] | Train Loss: 0.158457 | Val Loss: 0.210349\n",
      "Epoch [100/500] | Train Loss: 0.179815 | Val Loss: 0.151428\n",
      "Epoch [200/500] | Train Loss: 0.158843 | Val Loss: 0.146877\n",
      "Epoch [300/500] | Train Loss: 0.156574 | Val Loss: 0.148285\n",
      "Epoch [400/500] | Train Loss: 0.149046 | Val Loss: 0.149000\n",
      "Epoch [500/500] | Train Loss: 0.134933 | Val Loss: 0.154058\n",
      "Epoch [100/500] | Train Loss: 0.172762 | Val Loss: 0.626223\n",
      "Epoch [200/500] | Train Loss: 0.158567 | Val Loss: 0.667311\n",
      "Epoch [300/500] | Train Loss: 0.156115 | Val Loss: 0.722636\n",
      "Epoch [400/500] | Train Loss: 0.144234 | Val Loss: 0.767499\n",
      "Epoch [500/500] | Train Loss: 0.132557 | Val Loss: 0.745416\n",
      "Epoch [100/500] | Train Loss: 0.254751 | Val Loss: 0.259412\n",
      "Epoch [200/500] | Train Loss: 0.237655 | Val Loss: 0.276612\n",
      "Epoch [300/500] | Train Loss: 0.215618 | Val Loss: 0.301130\n",
      "Epoch [400/500] | Train Loss: 0.209619 | Val Loss: 0.308755\n",
      "Epoch [500/500] | Train Loss: 0.213293 | Val Loss: 0.300000\n",
      "Epoch [100/500] | Train Loss: 0.106294 | Val Loss: 0.256093\n",
      "Epoch [200/500] | Train Loss: 0.111251 | Val Loss: 0.283736\n",
      "Epoch [300/500] | Train Loss: 0.083293 | Val Loss: 0.293113\n",
      "Epoch [400/500] | Train Loss: 0.067029 | Val Loss: 0.302108\n",
      "Epoch [500/500] | Train Loss: 0.071113 | Val Loss: 0.292897\n",
      "Epoch [100/500] | Train Loss: 0.146431 | Val Loss: 0.202020\n",
      "Epoch [200/500] | Train Loss: 0.129920 | Val Loss: 0.222382\n",
      "Epoch [300/500] | Train Loss: 0.129805 | Val Loss: 0.268951\n",
      "Epoch [400/500] | Train Loss: 0.107348 | Val Loss: 0.236718\n",
      "Epoch [500/500] | Train Loss: 0.109610 | Val Loss: 0.247541\n",
      "Epoch [100/500] | Train Loss: 0.128944 | Val Loss: 0.167305\n",
      "Epoch [200/500] | Train Loss: 0.128392 | Val Loss: 0.155774\n",
      "Epoch [300/500] | Train Loss: 0.113907 | Val Loss: 0.161894\n",
      "Epoch [400/500] | Train Loss: 0.110648 | Val Loss: 0.156926\n",
      "Epoch [500/500] | Train Loss: 0.110773 | Val Loss: 0.170704\n",
      "Epoch [100/500] | Train Loss: 0.152154 | Val Loss: 0.724991\n",
      "Epoch [200/500] | Train Loss: 0.139254 | Val Loss: 0.726562\n",
      "Epoch [300/500] | Train Loss: 0.130308 | Val Loss: 0.735310\n",
      "Epoch [400/500] | Train Loss: 0.118156 | Val Loss: 0.773648\n",
      "Epoch [500/500] | Train Loss: 0.119567 | Val Loss: 0.779941\n",
      "Epoch [100/500] | Train Loss: 0.223885 | Val Loss: 0.276705\n",
      "Epoch [200/500] | Train Loss: 0.203005 | Val Loss: 0.295420\n",
      "Epoch [300/500] | Train Loss: 0.197868 | Val Loss: 0.297180\n",
      "Epoch [400/500] | Train Loss: 0.192502 | Val Loss: 0.293902\n",
      "Epoch [500/500] | Train Loss: 0.187712 | Val Loss: 0.300734\n",
      "[Year=1968] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.330975 Test MSE=0.313351\n",
      "Year 1968 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.083091 | Val Loss: 0.197731\n",
      "Epoch [200/500] | Train Loss: 0.080374 | Val Loss: 0.223029\n",
      "Epoch [300/500] | Train Loss: 0.072307 | Val Loss: 0.235942\n",
      "Epoch [400/500] | Train Loss: 0.062233 | Val Loss: 0.245814\n",
      "Epoch [500/500] | Train Loss: 0.057581 | Val Loss: 0.260257\n",
      "Epoch [100/500] | Train Loss: 0.147468 | Val Loss: 0.238314\n",
      "Epoch [200/500] | Train Loss: 0.120361 | Val Loss: 0.239995\n",
      "Epoch [300/500] | Train Loss: 0.113682 | Val Loss: 0.249448\n",
      "Epoch [400/500] | Train Loss: 0.111394 | Val Loss: 0.263506\n",
      "Epoch [500/500] | Train Loss: 0.103621 | Val Loss: 0.267340\n",
      "Epoch [100/500] | Train Loss: 0.165607 | Val Loss: 0.527185\n",
      "Epoch [200/500] | Train Loss: 0.148215 | Val Loss: 0.580240\n",
      "Epoch [300/500] | Train Loss: 0.135108 | Val Loss: 0.653777\n",
      "Epoch [400/500] | Train Loss: 0.129942 | Val Loss: 0.630072\n",
      "Epoch [500/500] | Train Loss: 0.121868 | Val Loss: 0.662940\n",
      "Epoch [100/500] | Train Loss: 0.247056 | Val Loss: 0.271887\n",
      "Epoch [200/500] | Train Loss: 0.220340 | Val Loss: 0.307421\n",
      "Epoch [300/500] | Train Loss: 0.206871 | Val Loss: 0.326128\n",
      "Epoch [400/500] | Train Loss: 0.174679 | Val Loss: 0.336425\n",
      "Epoch [500/500] | Train Loss: 0.172746 | Val Loss: 0.338799\n",
      "Epoch [100/500] | Train Loss: 0.264653 | Val Loss: 0.340956\n",
      "Epoch [200/500] | Train Loss: 0.243714 | Val Loss: 0.324787\n",
      "Epoch [300/500] | Train Loss: 0.231729 | Val Loss: 0.331201\n",
      "Epoch [400/500] | Train Loss: 0.221019 | Val Loss: 0.342523\n",
      "Epoch [500/500] | Train Loss: 0.206214 | Val Loss: 0.352815\n",
      "Epoch [100/500] | Train Loss: 0.061870 | Val Loss: 0.306355\n",
      "Epoch [200/500] | Train Loss: 0.044127 | Val Loss: 0.327072\n",
      "Epoch [300/500] | Train Loss: 0.036998 | Val Loss: 0.373915\n",
      "Epoch [400/500] | Train Loss: 0.033020 | Val Loss: 0.337462\n",
      "Epoch [500/500] | Train Loss: 0.025198 | Val Loss: 0.347104\n",
      "Epoch [100/500] | Train Loss: 0.094221 | Val Loss: 0.262031\n",
      "Epoch [200/500] | Train Loss: 0.081617 | Val Loss: 0.267055\n",
      "Epoch [300/500] | Train Loss: 0.071370 | Val Loss: 0.283418\n",
      "Epoch [400/500] | Train Loss: 0.063196 | Val Loss: 0.282599\n",
      "Epoch [500/500] | Train Loss: 0.060718 | Val Loss: 0.270797\n",
      "Epoch [100/500] | Train Loss: 0.138784 | Val Loss: 0.607249\n",
      "Epoch [200/500] | Train Loss: 0.117799 | Val Loss: 0.765430\n",
      "Epoch [300/500] | Train Loss: 0.114574 | Val Loss: 0.723005\n",
      "Epoch [400/500] | Train Loss: 0.096486 | Val Loss: 0.802081\n",
      "Epoch [500/500] | Train Loss: 0.098270 | Val Loss: 0.660767\n",
      "Epoch [100/500] | Train Loss: 0.183587 | Val Loss: 0.315292\n",
      "Epoch [200/500] | Train Loss: 0.163231 | Val Loss: 0.320229\n",
      "Epoch [300/500] | Train Loss: 0.147997 | Val Loss: 0.320979\n",
      "Epoch [400/500] | Train Loss: 0.145283 | Val Loss: 0.336528\n",
      "Epoch [500/500] | Train Loss: 0.135296 | Val Loss: 0.347204\n",
      "Epoch [100/500] | Train Loss: 0.203162 | Val Loss: 0.321152\n",
      "Epoch [200/500] | Train Loss: 0.183945 | Val Loss: 0.340562\n",
      "Epoch [300/500] | Train Loss: 0.168998 | Val Loss: 0.326688\n",
      "Epoch [400/500] | Train Loss: 0.153615 | Val Loss: 0.329970\n",
      "Epoch [500/500] | Train Loss: 0.143618 | Val Loss: 0.344893\n",
      "Epoch [100/500] | Train Loss: 0.094645 | Val Loss: 0.201970\n",
      "Epoch [200/500] | Train Loss: 0.079838 | Val Loss: 0.217198\n",
      "Epoch [300/500] | Train Loss: 0.070876 | Val Loss: 0.243530\n",
      "Epoch [400/500] | Train Loss: 0.071492 | Val Loss: 0.254106\n",
      "Epoch [500/500] | Train Loss: 0.060590 | Val Loss: 0.262464\n",
      "Epoch [100/500] | Train Loss: 0.133497 | Val Loss: 0.235785\n",
      "Epoch [200/500] | Train Loss: 0.122611 | Val Loss: 0.246915\n",
      "Epoch [300/500] | Train Loss: 0.105277 | Val Loss: 0.247038\n",
      "Epoch [400/500] | Train Loss: 0.102198 | Val Loss: 0.253185\n",
      "Epoch [500/500] | Train Loss: 0.099177 | Val Loss: 0.257472\n",
      "Epoch [100/500] | Train Loss: 0.168859 | Val Loss: 0.520971\n",
      "Epoch [200/500] | Train Loss: 0.159581 | Val Loss: 0.506543\n",
      "Epoch [300/500] | Train Loss: 0.152843 | Val Loss: 0.531541\n",
      "Epoch [400/500] | Train Loss: 0.140271 | Val Loss: 0.554008\n",
      "Epoch [500/500] | Train Loss: 0.130785 | Val Loss: 0.561944\n",
      "Epoch [100/500] | Train Loss: 0.251171 | Val Loss: 0.255056\n",
      "Epoch [200/500] | Train Loss: 0.240260 | Val Loss: 0.273443\n",
      "Epoch [300/500] | Train Loss: 0.226406 | Val Loss: 0.296295\n",
      "Epoch [400/500] | Train Loss: 0.219512 | Val Loss: 0.305779\n",
      "Epoch [500/500] | Train Loss: 0.209292 | Val Loss: 0.308402\n",
      "Epoch [100/500] | Train Loss: 0.273839 | Val Loss: 0.337999\n",
      "Epoch [200/500] | Train Loss: 0.258586 | Val Loss: 0.331484\n",
      "Epoch [300/500] | Train Loss: 0.251710 | Val Loss: 0.328629\n",
      "Epoch [400/500] | Train Loss: 0.245213 | Val Loss: 0.324700\n",
      "Epoch [500/500] | Train Loss: 0.233597 | Val Loss: 0.322723\n",
      "Epoch [100/500] | Train Loss: 0.076237 | Val Loss: 0.222563\n",
      "Epoch [200/500] | Train Loss: 0.070730 | Val Loss: 0.226546\n",
      "Epoch [300/500] | Train Loss: 0.064851 | Val Loss: 0.243314\n",
      "Epoch [400/500] | Train Loss: 0.056647 | Val Loss: 0.251960\n",
      "Epoch [500/500] | Train Loss: 0.051433 | Val Loss: 0.247900\n",
      "Epoch [100/500] | Train Loss: 0.115162 | Val Loss: 0.251551\n",
      "Epoch [200/500] | Train Loss: 0.092073 | Val Loss: 0.248049\n",
      "Epoch [300/500] | Train Loss: 0.081326 | Val Loss: 0.257775\n",
      "Epoch [400/500] | Train Loss: 0.083348 | Val Loss: 0.271149\n",
      "Epoch [500/500] | Train Loss: 0.077913 | Val Loss: 0.265335\n",
      "Epoch [100/500] | Train Loss: 0.144014 | Val Loss: 0.522528\n",
      "Epoch [200/500] | Train Loss: 0.123342 | Val Loss: 0.628738\n",
      "Epoch [300/500] | Train Loss: 0.109407 | Val Loss: 0.619843\n",
      "Epoch [400/500] | Train Loss: 0.103990 | Val Loss: 0.578656\n",
      "Epoch [500/500] | Train Loss: 0.100780 | Val Loss: 0.642822\n",
      "Epoch [100/500] | Train Loss: 0.219289 | Val Loss: 0.278197\n",
      "Epoch [200/500] | Train Loss: 0.180334 | Val Loss: 0.281643\n",
      "Epoch [300/500] | Train Loss: 0.186648 | Val Loss: 0.301883\n",
      "Epoch [400/500] | Train Loss: 0.177442 | Val Loss: 0.295846\n",
      "Epoch [500/500] | Train Loss: 0.183047 | Val Loss: 0.304986\n",
      "Epoch [100/500] | Train Loss: 0.229850 | Val Loss: 0.332272\n",
      "Epoch [200/500] | Train Loss: 0.213726 | Val Loss: 0.345812\n",
      "Epoch [300/500] | Train Loss: 0.203192 | Val Loss: 0.354885\n",
      "Epoch [400/500] | Train Loss: 0.197735 | Val Loss: 0.361268\n",
      "Epoch [500/500] | Train Loss: 0.199604 | Val Loss: 0.348820\n",
      "Epoch [100/500] | Train Loss: 0.092265 | Val Loss: 0.199572\n",
      "Epoch [200/500] | Train Loss: 0.070537 | Val Loss: 0.244942\n",
      "Epoch [300/500] | Train Loss: 0.057198 | Val Loss: 0.279451\n",
      "Epoch [400/500] | Train Loss: 0.059485 | Val Loss: 0.293665\n",
      "Epoch [500/500] | Train Loss: 0.047606 | Val Loss: 0.321670\n",
      "Epoch [100/500] | Train Loss: 0.132194 | Val Loss: 0.236214\n",
      "Epoch [200/500] | Train Loss: 0.112917 | Val Loss: 0.240968\n",
      "Epoch [300/500] | Train Loss: 0.087653 | Val Loss: 0.280303\n",
      "Epoch [400/500] | Train Loss: 0.085338 | Val Loss: 0.299807\n",
      "Epoch [500/500] | Train Loss: 0.074911 | Val Loss: 0.299670\n",
      "Epoch [100/500] | Train Loss: 0.168283 | Val Loss: 0.503731\n",
      "Epoch [200/500] | Train Loss: 0.151833 | Val Loss: 0.522114\n",
      "Epoch [300/500] | Train Loss: 0.132540 | Val Loss: 0.596520\n",
      "Epoch [400/500] | Train Loss: 0.109842 | Val Loss: 0.635986\n",
      "Epoch [500/500] | Train Loss: 0.106134 | Val Loss: 0.684074\n",
      "Epoch [100/500] | Train Loss: 0.238209 | Val Loss: 0.274229\n",
      "Epoch [200/500] | Train Loss: 0.214320 | Val Loss: 0.319660\n",
      "Epoch [300/500] | Train Loss: 0.196857 | Val Loss: 0.321387\n",
      "Epoch [400/500] | Train Loss: 0.179029 | Val Loss: 0.331250\n",
      "Epoch [500/500] | Train Loss: 0.161448 | Val Loss: 0.346868\n",
      "Epoch [100/500] | Train Loss: 0.251990 | Val Loss: 0.324347\n",
      "Epoch [200/500] | Train Loss: 0.240414 | Val Loss: 0.314740\n",
      "Epoch [300/500] | Train Loss: 0.225644 | Val Loss: 0.318239\n",
      "Epoch [400/500] | Train Loss: 0.198772 | Val Loss: 0.325224\n",
      "Epoch [500/500] | Train Loss: 0.181920 | Val Loss: 0.340189\n",
      "Epoch [100/500] | Train Loss: 0.070113 | Val Loss: 0.286869\n",
      "Epoch [200/500] | Train Loss: 0.058182 | Val Loss: 0.304702\n",
      "Epoch [300/500] | Train Loss: 0.046340 | Val Loss: 0.303514\n",
      "Epoch [400/500] | Train Loss: 0.030937 | Val Loss: 0.315008\n",
      "Epoch [500/500] | Train Loss: 0.030853 | Val Loss: 0.300756\n",
      "Epoch [100/500] | Train Loss: 0.079450 | Val Loss: 0.310293\n",
      "Epoch [200/500] | Train Loss: 0.068956 | Val Loss: 0.310140\n",
      "Epoch [300/500] | Train Loss: 0.052692 | Val Loss: 0.298275\n",
      "Epoch [400/500] | Train Loss: 0.050707 | Val Loss: 0.314817\n",
      "Epoch [500/500] | Train Loss: 0.044514 | Val Loss: 0.289645\n",
      "Epoch [100/500] | Train Loss: 0.108711 | Val Loss: 0.634995\n",
      "Epoch [200/500] | Train Loss: 0.083984 | Val Loss: 0.671307\n",
      "Epoch [300/500] | Train Loss: 0.077668 | Val Loss: 0.688330\n",
      "Epoch [400/500] | Train Loss: 0.074457 | Val Loss: 0.708560\n",
      "Epoch [500/500] | Train Loss: 0.078271 | Val Loss: 0.702463\n",
      "Epoch [100/500] | Train Loss: 0.181481 | Val Loss: 0.343205\n",
      "Epoch [200/500] | Train Loss: 0.141921 | Val Loss: 0.368196\n",
      "Epoch [300/500] | Train Loss: 0.126275 | Val Loss: 0.400002\n",
      "Epoch [400/500] | Train Loss: 0.127847 | Val Loss: 0.404228\n",
      "Epoch [500/500] | Train Loss: 0.116904 | Val Loss: 0.379936\n",
      "Epoch [100/500] | Train Loss: 0.230133 | Val Loss: 0.331316\n",
      "Epoch [200/500] | Train Loss: 0.206783 | Val Loss: 0.332545\n",
      "Epoch [300/500] | Train Loss: 0.204197 | Val Loss: 0.338916\n",
      "Epoch [400/500] | Train Loss: 0.178859 | Val Loss: 0.340986\n",
      "Epoch [500/500] | Train Loss: 0.177748 | Val Loss: 0.344353\n",
      "Epoch [100/500] | Train Loss: 0.088204 | Val Loss: 0.195926\n",
      "Epoch [200/500] | Train Loss: 0.075781 | Val Loss: 0.220562\n",
      "Epoch [300/500] | Train Loss: 0.067871 | Val Loss: 0.248984\n",
      "Epoch [400/500] | Train Loss: 0.063087 | Val Loss: 0.262186\n",
      "Epoch [500/500] | Train Loss: 0.057085 | Val Loss: 0.272479\n",
      "Epoch [100/500] | Train Loss: 0.134231 | Val Loss: 0.236681\n",
      "Epoch [200/500] | Train Loss: 0.120678 | Val Loss: 0.250238\n",
      "Epoch [300/500] | Train Loss: 0.106035 | Val Loss: 0.246546\n",
      "Epoch [400/500] | Train Loss: 0.112679 | Val Loss: 0.255181\n",
      "Epoch [500/500] | Train Loss: 0.102291 | Val Loss: 0.257182\n",
      "Epoch [100/500] | Train Loss: 0.160633 | Val Loss: 0.508089\n",
      "Epoch [200/500] | Train Loss: 0.149321 | Val Loss: 0.513419\n",
      "Epoch [300/500] | Train Loss: 0.130880 | Val Loss: 0.583348\n",
      "Epoch [400/500] | Train Loss: 0.115313 | Val Loss: 0.594428\n",
      "Epoch [500/500] | Train Loss: 0.115620 | Val Loss: 0.640883\n",
      "Epoch [100/500] | Train Loss: 0.242894 | Val Loss: 0.265570\n",
      "Epoch [200/500] | Train Loss: 0.227682 | Val Loss: 0.286883\n",
      "Epoch [300/500] | Train Loss: 0.216727 | Val Loss: 0.304040\n",
      "Epoch [400/500] | Train Loss: 0.208962 | Val Loss: 0.307571\n",
      "Epoch [500/500] | Train Loss: 0.191436 | Val Loss: 0.303581\n",
      "Epoch [100/500] | Train Loss: 0.263389 | Val Loss: 0.334531\n",
      "Epoch [200/500] | Train Loss: 0.252023 | Val Loss: 0.324541\n",
      "Epoch [300/500] | Train Loss: 0.223767 | Val Loss: 0.328875\n",
      "Epoch [400/500] | Train Loss: 0.216524 | Val Loss: 0.323197\n",
      "Epoch [500/500] | Train Loss: 0.208856 | Val Loss: 0.326144\n",
      "Epoch [100/500] | Train Loss: 0.072752 | Val Loss: 0.221728\n",
      "Epoch [200/500] | Train Loss: 0.058217 | Val Loss: 0.240090\n",
      "Epoch [300/500] | Train Loss: 0.053149 | Val Loss: 0.239189\n",
      "Epoch [400/500] | Train Loss: 0.049272 | Val Loss: 0.257491\n",
      "Epoch [500/500] | Train Loss: 0.052269 | Val Loss: 0.242170\n",
      "Epoch [100/500] | Train Loss: 0.102079 | Val Loss: 0.270646\n",
      "Epoch [200/500] | Train Loss: 0.080108 | Val Loss: 0.276853\n",
      "Epoch [300/500] | Train Loss: 0.077498 | Val Loss: 0.282129\n",
      "Epoch [400/500] | Train Loss: 0.088993 | Val Loss: 0.299405\n",
      "Epoch [500/500] | Train Loss: 0.066324 | Val Loss: 0.294028\n",
      "Epoch [100/500] | Train Loss: 0.149526 | Val Loss: 0.561506\n",
      "Epoch [200/500] | Train Loss: 0.126172 | Val Loss: 0.555155\n",
      "Epoch [300/500] | Train Loss: 0.132074 | Val Loss: 0.556403\n",
      "Epoch [400/500] | Train Loss: 0.119580 | Val Loss: 0.567950\n",
      "Epoch [500/500] | Train Loss: 0.117245 | Val Loss: 0.541373\n",
      "Epoch [100/500] | Train Loss: 0.200223 | Val Loss: 0.303710\n",
      "Epoch [200/500] | Train Loss: 0.175761 | Val Loss: 0.317638\n",
      "Epoch [300/500] | Train Loss: 0.166146 | Val Loss: 0.309542\n",
      "Epoch [400/500] | Train Loss: 0.156060 | Val Loss: 0.314684\n",
      "Epoch [500/500] | Train Loss: 0.162890 | Val Loss: 0.336273\n",
      "Epoch [100/500] | Train Loss: 0.228149 | Val Loss: 0.329061\n",
      "Epoch [200/500] | Train Loss: 0.205515 | Val Loss: 0.329555\n",
      "Epoch [300/500] | Train Loss: 0.172836 | Val Loss: 0.330920\n",
      "Epoch [400/500] | Train Loss: 0.185940 | Val Loss: 0.330011\n",
      "Epoch [500/500] | Train Loss: 0.166168 | Val Loss: 0.336779\n",
      "[Year=1969] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.342601 Test MSE=0.431077\n",
      "Year 1969 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.152336 | Val Loss: 0.303246\n",
      "Epoch [200/500] | Train Loss: 0.125350 | Val Loss: 0.323681\n",
      "Epoch [300/500] | Train Loss: 0.122929 | Val Loss: 0.328587\n",
      "Epoch [400/500] | Train Loss: 0.085630 | Val Loss: 0.363187\n",
      "Epoch [500/500] | Train Loss: 0.086823 | Val Loss: 0.377798\n",
      "Epoch [100/500] | Train Loss: 0.227589 | Val Loss: 0.546792\n",
      "Epoch [200/500] | Train Loss: 0.196085 | Val Loss: 0.571805\n",
      "Epoch [300/500] | Train Loss: 0.173389 | Val Loss: 0.613310\n",
      "Epoch [400/500] | Train Loss: 0.144827 | Val Loss: 0.652421\n",
      "Epoch [500/500] | Train Loss: 0.135374 | Val Loss: 0.660569\n",
      "Epoch [100/500] | Train Loss: 0.329725 | Val Loss: 0.295902\n",
      "Epoch [200/500] | Train Loss: 0.282881 | Val Loss: 0.305660\n",
      "Epoch [300/500] | Train Loss: 0.253689 | Val Loss: 0.328506\n",
      "Epoch [400/500] | Train Loss: 0.234162 | Val Loss: 0.329894\n",
      "Epoch [500/500] | Train Loss: 0.234429 | Val Loss: 0.333517\n",
      "Epoch [100/500] | Train Loss: 0.338683 | Val Loss: 0.254824\n",
      "Epoch [200/500] | Train Loss: 0.306086 | Val Loss: 0.259723\n",
      "Epoch [300/500] | Train Loss: 0.292872 | Val Loss: 0.261445\n",
      "Epoch [400/500] | Train Loss: 0.266310 | Val Loss: 0.267466\n",
      "Epoch [500/500] | Train Loss: 0.263614 | Val Loss: 0.269875\n",
      "Epoch [100/500] | Train Loss: 0.307042 | Val Loss: 0.412889\n",
      "Epoch [200/500] | Train Loss: 0.294069 | Val Loss: 0.412336\n",
      "Epoch [300/500] | Train Loss: 0.281772 | Val Loss: 0.414483\n",
      "Epoch [400/500] | Train Loss: 0.261624 | Val Loss: 0.419597\n",
      "Epoch [500/500] | Train Loss: 0.249060 | Val Loss: 0.426016\n",
      "Epoch [100/500] | Train Loss: 0.082681 | Val Loss: 0.366195\n",
      "Epoch [200/500] | Train Loss: 0.078759 | Val Loss: 0.378893\n",
      "Epoch [300/500] | Train Loss: 0.055744 | Val Loss: 0.384546\n",
      "Epoch [400/500] | Train Loss: 0.047440 | Val Loss: 0.400689\n",
      "Epoch [500/500] | Train Loss: 0.058903 | Val Loss: 0.406476\n",
      "Epoch [100/500] | Train Loss: 0.169211 | Val Loss: 0.636957\n",
      "Epoch [200/500] | Train Loss: 0.134955 | Val Loss: 0.624913\n",
      "Epoch [300/500] | Train Loss: 0.107833 | Val Loss: 0.738077\n",
      "Epoch [400/500] | Train Loss: 0.108079 | Val Loss: 0.744012\n",
      "Epoch [500/500] | Train Loss: 0.107978 | Val Loss: 0.765218\n",
      "Epoch [100/500] | Train Loss: 0.229294 | Val Loss: 0.335760\n",
      "Epoch [200/500] | Train Loss: 0.194774 | Val Loss: 0.325741\n",
      "Epoch [300/500] | Train Loss: 0.173815 | Val Loss: 0.376619\n",
      "Epoch [400/500] | Train Loss: 0.165640 | Val Loss: 0.385889\n",
      "Epoch [500/500] | Train Loss: 0.147303 | Val Loss: 0.361964\n",
      "Epoch [100/500] | Train Loss: 0.251478 | Val Loss: 0.280659\n",
      "Epoch [200/500] | Train Loss: 0.214279 | Val Loss: 0.287725\n",
      "Epoch [300/500] | Train Loss: 0.196484 | Val Loss: 0.307940\n",
      "Epoch [400/500] | Train Loss: 0.170069 | Val Loss: 0.292477\n",
      "Epoch [500/500] | Train Loss: 0.184966 | Val Loss: 0.270040\n",
      "Epoch [100/500] | Train Loss: 0.273053 | Val Loss: 0.424410\n",
      "Epoch [200/500] | Train Loss: 0.249486 | Val Loss: 0.455376\n",
      "Epoch [300/500] | Train Loss: 0.232198 | Val Loss: 0.469045\n",
      "Epoch [400/500] | Train Loss: 0.221121 | Val Loss: 0.487374\n",
      "Epoch [500/500] | Train Loss: 0.212460 | Val Loss: 0.487093\n",
      "Epoch [100/500] | Train Loss: 0.179386 | Val Loss: 0.304406\n",
      "Epoch [200/500] | Train Loss: 0.163000 | Val Loss: 0.295835\n",
      "Epoch [300/500] | Train Loss: 0.132693 | Val Loss: 0.297853\n",
      "Epoch [400/500] | Train Loss: 0.120426 | Val Loss: 0.299337\n",
      "Epoch [500/500] | Train Loss: 0.124724 | Val Loss: 0.300873\n",
      "Epoch [100/500] | Train Loss: 0.239866 | Val Loss: 0.544797\n",
      "Epoch [200/500] | Train Loss: 0.218597 | Val Loss: 0.533904\n",
      "Epoch [300/500] | Train Loss: 0.193281 | Val Loss: 0.559121\n",
      "Epoch [400/500] | Train Loss: 0.177378 | Val Loss: 0.584854\n",
      "Epoch [500/500] | Train Loss: 0.167456 | Val Loss: 0.609888\n",
      "Epoch [100/500] | Train Loss: 0.337294 | Val Loss: 0.293358\n",
      "Epoch [200/500] | Train Loss: 0.327668 | Val Loss: 0.297606\n",
      "Epoch [300/500] | Train Loss: 0.321877 | Val Loss: 0.306771\n",
      "Epoch [400/500] | Train Loss: 0.291743 | Val Loss: 0.318077\n",
      "Epoch [500/500] | Train Loss: 0.283918 | Val Loss: 0.327330\n",
      "Epoch [100/500] | Train Loss: 0.342872 | Val Loss: 0.254945\n",
      "Epoch [200/500] | Train Loss: 0.329036 | Val Loss: 0.252650\n",
      "Epoch [300/500] | Train Loss: 0.325438 | Val Loss: 0.253462\n",
      "Epoch [400/500] | Train Loss: 0.309676 | Val Loss: 0.250191\n",
      "Epoch [500/500] | Train Loss: 0.309009 | Val Loss: 0.250063\n",
      "Epoch [100/500] | Train Loss: 0.320518 | Val Loss: 0.413116\n",
      "Epoch [200/500] | Train Loss: 0.303008 | Val Loss: 0.410833\n",
      "Epoch [300/500] | Train Loss: 0.294315 | Val Loss: 0.415420\n",
      "Epoch [400/500] | Train Loss: 0.290239 | Val Loss: 0.423524\n",
      "Epoch [500/500] | Train Loss: 0.291155 | Val Loss: 0.423797\n",
      "Epoch [100/500] | Train Loss: 0.109658 | Val Loss: 0.350141\n",
      "Epoch [200/500] | Train Loss: 0.089407 | Val Loss: 0.417314\n",
      "Epoch [300/500] | Train Loss: 0.087409 | Val Loss: 0.395927\n",
      "Epoch [400/500] | Train Loss: 0.075786 | Val Loss: 0.422231\n",
      "Epoch [500/500] | Train Loss: 0.078866 | Val Loss: 0.454129\n",
      "Epoch [100/500] | Train Loss: 0.225340 | Val Loss: 0.541506\n",
      "Epoch [200/500] | Train Loss: 0.177801 | Val Loss: 0.585872\n",
      "Epoch [300/500] | Train Loss: 0.160791 | Val Loss: 0.624743\n",
      "Epoch [400/500] | Train Loss: 0.140451 | Val Loss: 0.627031\n",
      "Epoch [500/500] | Train Loss: 0.139481 | Val Loss: 0.656614\n",
      "Epoch [100/500] | Train Loss: 0.265074 | Val Loss: 0.315969\n",
      "Epoch [200/500] | Train Loss: 0.248760 | Val Loss: 0.328313\n",
      "Epoch [300/500] | Train Loss: 0.219660 | Val Loss: 0.370287\n",
      "Epoch [400/500] | Train Loss: 0.217575 | Val Loss: 0.377793\n",
      "Epoch [500/500] | Train Loss: 0.194692 | Val Loss: 0.407468\n",
      "Epoch [100/500] | Train Loss: 0.262143 | Val Loss: 0.259264\n",
      "Epoch [200/500] | Train Loss: 0.252088 | Val Loss: 0.256743\n",
      "Epoch [300/500] | Train Loss: 0.229237 | Val Loss: 0.273337\n",
      "Epoch [400/500] | Train Loss: 0.218724 | Val Loss: 0.245689\n",
      "Epoch [500/500] | Train Loss: 0.240405 | Val Loss: 0.281705\n",
      "Epoch [100/500] | Train Loss: 0.274038 | Val Loss: 0.414691\n",
      "Epoch [200/500] | Train Loss: 0.274034 | Val Loss: 0.451647\n",
      "Epoch [300/500] | Train Loss: 0.245322 | Val Loss: 0.432714\n",
      "Epoch [400/500] | Train Loss: 0.239040 | Val Loss: 0.432456\n",
      "Epoch [500/500] | Train Loss: 0.224968 | Val Loss: 0.440427\n",
      "Epoch [100/500] | Train Loss: 0.166189 | Val Loss: 0.303785\n",
      "Epoch [200/500] | Train Loss: 0.128276 | Val Loss: 0.341346\n",
      "Epoch [300/500] | Train Loss: 0.096611 | Val Loss: 0.324042\n",
      "Epoch [400/500] | Train Loss: 0.079069 | Val Loss: 0.333458\n",
      "Epoch [500/500] | Train Loss: 0.072703 | Val Loss: 0.329432\n",
      "Epoch [100/500] | Train Loss: 0.221815 | Val Loss: 0.548096\n",
      "Epoch [200/500] | Train Loss: 0.187211 | Val Loss: 0.581490\n",
      "Epoch [300/500] | Train Loss: 0.154313 | Val Loss: 0.652414\n",
      "Epoch [400/500] | Train Loss: 0.137930 | Val Loss: 0.723259\n",
      "Epoch [500/500] | Train Loss: 0.129620 | Val Loss: 0.738422\n",
      "Epoch [100/500] | Train Loss: 0.319131 | Val Loss: 0.300756\n",
      "Epoch [200/500] | Train Loss: 0.265999 | Val Loss: 0.329153\n",
      "Epoch [300/500] | Train Loss: 0.235578 | Val Loss: 0.345500\n",
      "Epoch [400/500] | Train Loss: 0.217344 | Val Loss: 0.353469\n",
      "Epoch [500/500] | Train Loss: 0.194217 | Val Loss: 0.371256\n",
      "Epoch [100/500] | Train Loss: 0.317921 | Val Loss: 0.248496\n",
      "Epoch [200/500] | Train Loss: 0.288399 | Val Loss: 0.257312\n",
      "Epoch [300/500] | Train Loss: 0.248738 | Val Loss: 0.276493\n",
      "Epoch [400/500] | Train Loss: 0.213096 | Val Loss: 0.286623\n",
      "Epoch [500/500] | Train Loss: 0.206277 | Val Loss: 0.285612\n",
      "Epoch [100/500] | Train Loss: 0.303154 | Val Loss: 0.422770\n",
      "Epoch [200/500] | Train Loss: 0.271853 | Val Loss: 0.432526\n",
      "Epoch [300/500] | Train Loss: 0.251539 | Val Loss: 0.451575\n",
      "Epoch [400/500] | Train Loss: 0.241151 | Val Loss: 0.461535\n",
      "Epoch [500/500] | Train Loss: 0.226889 | Val Loss: 0.467125\n",
      "Epoch [100/500] | Train Loss: 0.097867 | Val Loss: 0.421051\n",
      "Epoch [200/500] | Train Loss: 0.058190 | Val Loss: 0.474968\n",
      "Epoch [300/500] | Train Loss: 0.041039 | Val Loss: 0.467855\n",
      "Epoch [400/500] | Train Loss: 0.045884 | Val Loss: 0.477910\n",
      "Epoch [500/500] | Train Loss: 0.036217 | Val Loss: 0.479199\n",
      "Epoch [100/500] | Train Loss: 0.150530 | Val Loss: 0.709879\n",
      "Epoch [200/500] | Train Loss: 0.093590 | Val Loss: 0.825976\n",
      "Epoch [300/500] | Train Loss: 0.101351 | Val Loss: 0.846035\n",
      "Epoch [400/500] | Train Loss: 0.100446 | Val Loss: 0.822505\n",
      "Epoch [500/500] | Train Loss: 0.082017 | Val Loss: 0.824153\n",
      "Epoch [100/500] | Train Loss: 0.224339 | Val Loss: 0.383454\n",
      "Epoch [200/500] | Train Loss: 0.181468 | Val Loss: 0.446272\n",
      "Epoch [300/500] | Train Loss: 0.146293 | Val Loss: 0.429480\n",
      "Epoch [400/500] | Train Loss: 0.124448 | Val Loss: 0.447707\n",
      "Epoch [500/500] | Train Loss: 0.117208 | Val Loss: 0.443462\n",
      "Epoch [100/500] | Train Loss: 0.255657 | Val Loss: 0.275965\n",
      "Epoch [200/500] | Train Loss: 0.219619 | Val Loss: 0.332301\n",
      "Epoch [300/500] | Train Loss: 0.188599 | Val Loss: 0.375046\n",
      "Epoch [400/500] | Train Loss: 0.186697 | Val Loss: 0.362371\n",
      "Epoch [500/500] | Train Loss: 0.162093 | Val Loss: 0.351065\n",
      "Epoch [100/500] | Train Loss: 0.204991 | Val Loss: 0.506509\n",
      "Epoch [200/500] | Train Loss: 0.187617 | Val Loss: 0.531828\n",
      "Epoch [300/500] | Train Loss: 0.176143 | Val Loss: 0.572034\n",
      "Epoch [400/500] | Train Loss: 0.153377 | Val Loss: 0.588258\n",
      "Epoch [500/500] | Train Loss: 0.156625 | Val Loss: 0.592749\n",
      "Epoch [100/500] | Train Loss: 0.159693 | Val Loss: 0.310276\n",
      "Epoch [200/500] | Train Loss: 0.154968 | Val Loss: 0.334695\n",
      "Epoch [300/500] | Train Loss: 0.114925 | Val Loss: 0.335708\n",
      "Epoch [400/500] | Train Loss: 0.100729 | Val Loss: 0.348842\n",
      "Epoch [500/500] | Train Loss: 0.103420 | Val Loss: 0.353162\n",
      "Epoch [100/500] | Train Loss: 0.222611 | Val Loss: 0.537662\n",
      "Epoch [200/500] | Train Loss: 0.198558 | Val Loss: 0.562104\n",
      "Epoch [300/500] | Train Loss: 0.196404 | Val Loss: 0.603122\n",
      "Epoch [400/500] | Train Loss: 0.174778 | Val Loss: 0.631319\n",
      "Epoch [500/500] | Train Loss: 0.164998 | Val Loss: 0.633205\n",
      "Epoch [100/500] | Train Loss: 0.333666 | Val Loss: 0.294890\n",
      "Epoch [200/500] | Train Loss: 0.321469 | Val Loss: 0.292909\n",
      "Epoch [300/500] | Train Loss: 0.303856 | Val Loss: 0.304813\n",
      "Epoch [400/500] | Train Loss: 0.290958 | Val Loss: 0.319155\n",
      "Epoch [500/500] | Train Loss: 0.275381 | Val Loss: 0.331273\n",
      "Epoch [100/500] | Train Loss: 0.320928 | Val Loss: 0.252497\n",
      "Epoch [200/500] | Train Loss: 0.315124 | Val Loss: 0.257865\n",
      "Epoch [300/500] | Train Loss: 0.292467 | Val Loss: 0.261420\n",
      "Epoch [400/500] | Train Loss: 0.278260 | Val Loss: 0.254907\n",
      "Epoch [500/500] | Train Loss: 0.259286 | Val Loss: 0.259307\n",
      "Epoch [100/500] | Train Loss: 0.322542 | Val Loss: 0.425284\n",
      "Epoch [200/500] | Train Loss: 0.308449 | Val Loss: 0.412900\n",
      "Epoch [300/500] | Train Loss: 0.291756 | Val Loss: 0.422552\n",
      "Epoch [400/500] | Train Loss: 0.281877 | Val Loss: 0.433880\n",
      "Epoch [500/500] | Train Loss: 0.265386 | Val Loss: 0.435402\n",
      "Epoch [100/500] | Train Loss: 0.133947 | Val Loss: 0.364462\n",
      "Epoch [200/500] | Train Loss: 0.116702 | Val Loss: 0.377363\n",
      "Epoch [300/500] | Train Loss: 0.098112 | Val Loss: 0.384454\n",
      "Epoch [400/500] | Train Loss: 0.087870 | Val Loss: 0.381138\n",
      "Epoch [500/500] | Train Loss: 0.076538 | Val Loss: 0.388368\n",
      "Epoch [100/500] | Train Loss: 0.184781 | Val Loss: 0.612721\n",
      "Epoch [200/500] | Train Loss: 0.135899 | Val Loss: 0.635732\n",
      "Epoch [300/500] | Train Loss: 0.132551 | Val Loss: 0.719081\n",
      "Epoch [400/500] | Train Loss: 0.114680 | Val Loss: 0.693288\n",
      "Epoch [500/500] | Train Loss: 0.105570 | Val Loss: 0.669667\n",
      "Epoch [100/500] | Train Loss: 0.250527 | Val Loss: 0.364844\n",
      "Epoch [200/500] | Train Loss: 0.220573 | Val Loss: 0.356222\n",
      "Epoch [300/500] | Train Loss: 0.182271 | Val Loss: 0.382344\n",
      "Epoch [400/500] | Train Loss: 0.198539 | Val Loss: 0.389384\n",
      "Epoch [500/500] | Train Loss: 0.169165 | Val Loss: 0.418840\n",
      "Epoch [100/500] | Train Loss: 0.257398 | Val Loss: 0.256177\n",
      "Epoch [200/500] | Train Loss: 0.231247 | Val Loss: 0.262732\n",
      "Epoch [300/500] | Train Loss: 0.224157 | Val Loss: 0.255960\n",
      "Epoch [400/500] | Train Loss: 0.214278 | Val Loss: 0.286662\n",
      "Epoch [500/500] | Train Loss: 0.206998 | Val Loss: 0.261137\n",
      "Epoch [100/500] | Train Loss: 0.288766 | Val Loss: 0.434519\n",
      "Epoch [200/500] | Train Loss: 0.268998 | Val Loss: 0.445869\n",
      "Epoch [300/500] | Train Loss: 0.259716 | Val Loss: 0.466380\n",
      "Epoch [400/500] | Train Loss: 0.240151 | Val Loss: 0.479436\n",
      "Epoch [500/500] | Train Loss: 0.238075 | Val Loss: 0.488299\n",
      "[Year=1970] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.382390 Test MSE=0.854670\n",
      "Year 1970 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.470727 | Val Loss: 0.307583\n",
      "Epoch [200/500] | Train Loss: 0.426206 | Val Loss: 0.348264\n",
      "Epoch [300/500] | Train Loss: 0.329279 | Val Loss: 0.364349\n",
      "Epoch [400/500] | Train Loss: 0.265470 | Val Loss: 0.382395\n",
      "Epoch [500/500] | Train Loss: 0.243410 | Val Loss: 0.395682\n",
      "Epoch [100/500] | Train Loss: 0.392919 | Val Loss: 0.350930\n",
      "Epoch [200/500] | Train Loss: 0.342979 | Val Loss: 0.377692\n",
      "Epoch [300/500] | Train Loss: 0.311384 | Val Loss: 0.404821\n",
      "Epoch [400/500] | Train Loss: 0.261113 | Val Loss: 0.418706\n",
      "Epoch [500/500] | Train Loss: 0.280115 | Val Loss: 0.413713\n",
      "Epoch [100/500] | Train Loss: 0.394365 | Val Loss: 0.228247\n",
      "Epoch [200/500] | Train Loss: 0.357543 | Val Loss: 0.229615\n",
      "Epoch [300/500] | Train Loss: 0.326103 | Val Loss: 0.239359\n",
      "Epoch [400/500] | Train Loss: 0.305441 | Val Loss: 0.247247\n",
      "Epoch [500/500] | Train Loss: 0.274156 | Val Loss: 0.254196\n",
      "Epoch [100/500] | Train Loss: 0.345897 | Val Loss: 0.474923\n",
      "Epoch [200/500] | Train Loss: 0.328307 | Val Loss: 0.483269\n",
      "Epoch [300/500] | Train Loss: 0.303661 | Val Loss: 0.501817\n",
      "Epoch [400/500] | Train Loss: 0.282888 | Val Loss: 0.522144\n",
      "Epoch [500/500] | Train Loss: 0.279796 | Val Loss: 0.514421\n",
      "Epoch [100/500] | Train Loss: 0.388473 | Val Loss: 0.967401\n",
      "Epoch [200/500] | Train Loss: 0.360882 | Val Loss: 0.928990\n",
      "Epoch [300/500] | Train Loss: 0.343815 | Val Loss: 0.955990\n",
      "Epoch [400/500] | Train Loss: 0.330883 | Val Loss: 1.010332\n",
      "Epoch [500/500] | Train Loss: 0.318766 | Val Loss: 1.069273\n",
      "Epoch [100/500] | Train Loss: 0.302397 | Val Loss: 0.318559\n",
      "Epoch [200/500] | Train Loss: 0.168386 | Val Loss: 0.356763\n",
      "Epoch [300/500] | Train Loss: 0.138740 | Val Loss: 0.386091\n",
      "Epoch [400/500] | Train Loss: 0.134722 | Val Loss: 0.390554\n",
      "Epoch [500/500] | Train Loss: 0.124303 | Val Loss: 0.390915\n",
      "Epoch [100/500] | Train Loss: 0.238085 | Val Loss: 0.413820\n",
      "Epoch [200/500] | Train Loss: 0.214745 | Val Loss: 0.428661\n",
      "Epoch [300/500] | Train Loss: 0.205160 | Val Loss: 0.505965\n",
      "Epoch [400/500] | Train Loss: 0.179812 | Val Loss: 0.445493\n",
      "Epoch [500/500] | Train Loss: 0.177096 | Val Loss: 0.434525\n",
      "Epoch [100/500] | Train Loss: 0.284352 | Val Loss: 0.249791\n",
      "Epoch [200/500] | Train Loss: 0.274000 | Val Loss: 0.257407\n",
      "Epoch [300/500] | Train Loss: 0.243876 | Val Loss: 0.265174\n",
      "Epoch [400/500] | Train Loss: 0.211408 | Val Loss: 0.256777\n",
      "Epoch [500/500] | Train Loss: 0.208093 | Val Loss: 0.256355\n",
      "Epoch [100/500] | Train Loss: 0.280553 | Val Loss: 0.521618\n",
      "Epoch [200/500] | Train Loss: 0.236548 | Val Loss: 0.553540\n",
      "Epoch [300/500] | Train Loss: 0.204109 | Val Loss: 0.580851\n",
      "Epoch [400/500] | Train Loss: 0.210907 | Val Loss: 0.583259\n",
      "Epoch [500/500] | Train Loss: 0.210561 | Val Loss: 0.595819\n",
      "Epoch [100/500] | Train Loss: 0.329898 | Val Loss: 1.019721\n",
      "Epoch [200/500] | Train Loss: 0.288635 | Val Loss: 1.249182\n",
      "Epoch [300/500] | Train Loss: 0.269515 | Val Loss: 1.331226\n",
      "Epoch [400/500] | Train Loss: 0.262751 | Val Loss: 1.363626\n",
      "Epoch [500/500] | Train Loss: 0.235933 | Val Loss: 1.342032\n",
      "Epoch [100/500] | Train Loss: 0.568535 | Val Loss: 0.302943\n",
      "Epoch [200/500] | Train Loss: 0.480661 | Val Loss: 0.309521\n",
      "Epoch [300/500] | Train Loss: 0.456394 | Val Loss: 0.325782\n",
      "Epoch [400/500] | Train Loss: 0.425619 | Val Loss: 0.338107\n",
      "Epoch [500/500] | Train Loss: 0.390916 | Val Loss: 0.336315\n",
      "Epoch [100/500] | Train Loss: 0.400519 | Val Loss: 0.353302\n",
      "Epoch [200/500] | Train Loss: 0.384075 | Val Loss: 0.363406\n",
      "Epoch [300/500] | Train Loss: 0.368772 | Val Loss: 0.368412\n",
      "Epoch [400/500] | Train Loss: 0.348018 | Val Loss: 0.382361\n",
      "Epoch [500/500] | Train Loss: 0.331242 | Val Loss: 0.390115\n",
      "Epoch [100/500] | Train Loss: 0.413495 | Val Loss: 0.237753\n",
      "Epoch [200/500] | Train Loss: 0.391673 | Val Loss: 0.228828\n",
      "Epoch [300/500] | Train Loss: 0.379614 | Val Loss: 0.228384\n",
      "Epoch [400/500] | Train Loss: 0.357752 | Val Loss: 0.220381\n",
      "Epoch [500/500] | Train Loss: 0.350215 | Val Loss: 0.224317\n",
      "Epoch [100/500] | Train Loss: 0.342582 | Val Loss: 0.472678\n",
      "Epoch [200/500] | Train Loss: 0.340271 | Val Loss: 0.466950\n",
      "Epoch [300/500] | Train Loss: 0.332837 | Val Loss: 0.468349\n",
      "Epoch [400/500] | Train Loss: 0.326768 | Val Loss: 0.472908\n",
      "Epoch [500/500] | Train Loss: 0.307988 | Val Loss: 0.478170\n",
      "Epoch [100/500] | Train Loss: 0.369491 | Val Loss: 0.953094\n",
      "Epoch [200/500] | Train Loss: 0.363193 | Val Loss: 0.942709\n",
      "Epoch [300/500] | Train Loss: 0.355090 | Val Loss: 0.945256\n",
      "Epoch [400/500] | Train Loss: 0.343038 | Val Loss: 0.966252\n",
      "Epoch [500/500] | Train Loss: 0.340215 | Val Loss: 1.011234\n",
      "Epoch [100/500] | Train Loss: 0.420813 | Val Loss: 0.342058\n",
      "Epoch [200/500] | Train Loss: 0.263401 | Val Loss: 0.362351\n",
      "Epoch [300/500] | Train Loss: 0.236811 | Val Loss: 0.381099\n",
      "Epoch [400/500] | Train Loss: 0.285523 | Val Loss: 0.351366\n",
      "Epoch [500/500] | Train Loss: 0.246482 | Val Loss: 0.367472\n",
      "Epoch [100/500] | Train Loss: 0.317288 | Val Loss: 0.383507\n",
      "Epoch [200/500] | Train Loss: 0.264134 | Val Loss: 0.403970\n",
      "Epoch [300/500] | Train Loss: 0.230305 | Val Loss: 0.420922\n",
      "Epoch [400/500] | Train Loss: 0.262351 | Val Loss: 0.426507\n",
      "Epoch [500/500] | Train Loss: 0.231798 | Val Loss: 0.398084\n",
      "Epoch [100/500] | Train Loss: 0.346807 | Val Loss: 0.234815\n",
      "Epoch [200/500] | Train Loss: 0.318337 | Val Loss: 0.246689\n",
      "Epoch [300/500] | Train Loss: 0.302830 | Val Loss: 0.280512\n",
      "Epoch [400/500] | Train Loss: 0.301549 | Val Loss: 0.250067\n",
      "Epoch [500/500] | Train Loss: 0.254236 | Val Loss: 0.269672\n",
      "Epoch [100/500] | Train Loss: 0.342070 | Val Loss: 0.487521\n",
      "Epoch [200/500] | Train Loss: 0.322663 | Val Loss: 0.501085\n",
      "Epoch [300/500] | Train Loss: 0.291724 | Val Loss: 0.492769\n",
      "Epoch [400/500] | Train Loss: 0.296126 | Val Loss: 0.491297\n",
      "Epoch [500/500] | Train Loss: 0.268666 | Val Loss: 0.507048\n",
      "Epoch [100/500] | Train Loss: 0.351918 | Val Loss: 0.963266\n",
      "Epoch [200/500] | Train Loss: 0.329328 | Val Loss: 1.176441\n",
      "Epoch [300/500] | Train Loss: 0.304486 | Val Loss: 1.274077\n",
      "Epoch [400/500] | Train Loss: 0.277496 | Val Loss: 1.325310\n",
      "Epoch [500/500] | Train Loss: 0.284519 | Val Loss: 1.298780\n",
      "Epoch [100/500] | Train Loss: 0.494930 | Val Loss: 0.304399\n",
      "Epoch [200/500] | Train Loss: 0.355800 | Val Loss: 0.358004\n",
      "Epoch [300/500] | Train Loss: 0.262331 | Val Loss: 0.385225\n",
      "Epoch [400/500] | Train Loss: 0.235642 | Val Loss: 0.381963\n",
      "Epoch [500/500] | Train Loss: 0.237444 | Val Loss: 0.385425\n",
      "Epoch [100/500] | Train Loss: 0.394065 | Val Loss: 0.351399\n",
      "Epoch [200/500] | Train Loss: 0.337567 | Val Loss: 0.380076\n",
      "Epoch [300/500] | Train Loss: 0.278061 | Val Loss: 0.393934\n",
      "Epoch [400/500] | Train Loss: 0.243038 | Val Loss: 0.419572\n",
      "Epoch [500/500] | Train Loss: 0.228284 | Val Loss: 0.448792\n",
      "Epoch [100/500] | Train Loss: 0.403001 | Val Loss: 0.224733\n",
      "Epoch [200/500] | Train Loss: 0.360344 | Val Loss: 0.235635\n",
      "Epoch [300/500] | Train Loss: 0.342926 | Val Loss: 0.238860\n",
      "Epoch [400/500] | Train Loss: 0.307356 | Val Loss: 0.240866\n",
      "Epoch [500/500] | Train Loss: 0.296055 | Val Loss: 0.251006\n",
      "Epoch [100/500] | Train Loss: 0.347699 | Val Loss: 0.478988\n",
      "Epoch [200/500] | Train Loss: 0.317763 | Val Loss: 0.484676\n",
      "Epoch [300/500] | Train Loss: 0.293106 | Val Loss: 0.513804\n",
      "Epoch [400/500] | Train Loss: 0.271954 | Val Loss: 0.545735\n",
      "Epoch [500/500] | Train Loss: 0.253747 | Val Loss: 0.556841\n",
      "Epoch [100/500] | Train Loss: 0.374955 | Val Loss: 0.953091\n",
      "Epoch [200/500] | Train Loss: 0.349448 | Val Loss: 0.936720\n",
      "Epoch [300/500] | Train Loss: 0.318925 | Val Loss: 1.030619\n",
      "Epoch [400/500] | Train Loss: 0.299872 | Val Loss: 1.068533\n",
      "Epoch [500/500] | Train Loss: 0.287567 | Val Loss: 1.092565\n",
      "Epoch [100/500] | Train Loss: 0.227782 | Val Loss: 0.419067\n",
      "Epoch [200/500] | Train Loss: 0.160843 | Val Loss: 0.450264\n",
      "Epoch [300/500] | Train Loss: 0.141435 | Val Loss: 0.433940\n",
      "Epoch [400/500] | Train Loss: 0.118863 | Val Loss: 0.423455\n",
      "Epoch [500/500] | Train Loss: 0.090552 | Val Loss: 0.469266\n",
      "Epoch [100/500] | Train Loss: 0.321898 | Val Loss: 0.366139\n",
      "Epoch [200/500] | Train Loss: 0.247570 | Val Loss: 0.394504\n",
      "Epoch [300/500] | Train Loss: 0.205875 | Val Loss: 0.393841\n",
      "Epoch [400/500] | Train Loss: 0.160387 | Val Loss: 0.435663\n",
      "Epoch [500/500] | Train Loss: 0.176535 | Val Loss: 0.431485\n",
      "Epoch [100/500] | Train Loss: 0.255032 | Val Loss: 0.270003\n",
      "Epoch [200/500] | Train Loss: 0.203417 | Val Loss: 0.285481\n",
      "Epoch [300/500] | Train Loss: 0.182821 | Val Loss: 0.305758\n",
      "Epoch [400/500] | Train Loss: 0.159270 | Val Loss: 0.327854\n",
      "Epoch [500/500] | Train Loss: 0.170128 | Val Loss: 0.345748\n",
      "Epoch [100/500] | Train Loss: 0.280099 | Val Loss: 0.517018\n",
      "Epoch [200/500] | Train Loss: 0.239565 | Val Loss: 0.539706\n",
      "Epoch [300/500] | Train Loss: 0.177927 | Val Loss: 0.504867\n",
      "Epoch [400/500] | Train Loss: 0.173718 | Val Loss: 0.539737\n",
      "Epoch [500/500] | Train Loss: 0.173502 | Val Loss: 0.543988\n",
      "Epoch [100/500] | Train Loss: 0.295764 | Val Loss: 1.145179\n",
      "Epoch [200/500] | Train Loss: 0.247232 | Val Loss: 1.199296\n",
      "Epoch [300/500] | Train Loss: 0.233904 | Val Loss: 1.322008\n",
      "Epoch [400/500] | Train Loss: 0.219403 | Val Loss: 1.259388\n",
      "Epoch [500/500] | Train Loss: 0.192272 | Val Loss: 1.142158\n",
      "Epoch [100/500] | Train Loss: 0.486458 | Val Loss: 0.306245\n",
      "Epoch [200/500] | Train Loss: 0.435673 | Val Loss: 0.330818\n",
      "Epoch [300/500] | Train Loss: 0.351439 | Val Loss: 0.328999\n",
      "Epoch [400/500] | Train Loss: 0.294422 | Val Loss: 0.362548\n",
      "Epoch [500/500] | Train Loss: 0.331090 | Val Loss: 0.352929\n",
      "Epoch [100/500] | Train Loss: 0.397474 | Val Loss: 0.355241\n",
      "Epoch [200/500] | Train Loss: 0.348543 | Val Loss: 0.380507\n",
      "Epoch [300/500] | Train Loss: 0.335878 | Val Loss: 0.389397\n",
      "Epoch [400/500] | Train Loss: 0.275839 | Val Loss: 0.405501\n",
      "Epoch [500/500] | Train Loss: 0.280466 | Val Loss: 0.416127\n",
      "Epoch [100/500] | Train Loss: 0.390837 | Val Loss: 0.228421\n",
      "Epoch [200/500] | Train Loss: 0.362119 | Val Loss: 0.222193\n",
      "Epoch [300/500] | Train Loss: 0.335889 | Val Loss: 0.223340\n",
      "Epoch [400/500] | Train Loss: 0.317000 | Val Loss: 0.224222\n",
      "Epoch [500/500] | Train Loss: 0.316787 | Val Loss: 0.232461\n",
      "Epoch [100/500] | Train Loss: 0.343364 | Val Loss: 0.471709\n",
      "Epoch [200/500] | Train Loss: 0.324466 | Val Loss: 0.477001\n",
      "Epoch [300/500] | Train Loss: 0.309128 | Val Loss: 0.488194\n",
      "Epoch [400/500] | Train Loss: 0.309775 | Val Loss: 0.496678\n",
      "Epoch [500/500] | Train Loss: 0.271315 | Val Loss: 0.500011\n",
      "Epoch [100/500] | Train Loss: 0.372034 | Val Loss: 0.944275\n",
      "Epoch [200/500] | Train Loss: 0.363158 | Val Loss: 0.944776\n",
      "Epoch [300/500] | Train Loss: 0.356235 | Val Loss: 0.966779\n",
      "Epoch [400/500] | Train Loss: 0.338004 | Val Loss: 1.052558\n",
      "Epoch [500/500] | Train Loss: 0.332561 | Val Loss: 1.115617\n",
      "Epoch [100/500] | Train Loss: 0.346065 | Val Loss: 0.339769\n",
      "Epoch [200/500] | Train Loss: 0.305308 | Val Loss: 0.350722\n",
      "Epoch [300/500] | Train Loss: 0.291161 | Val Loss: 0.365185\n",
      "Epoch [400/500] | Train Loss: 0.204773 | Val Loss: 0.359750\n",
      "Epoch [500/500] | Train Loss: 0.198213 | Val Loss: 0.357453\n",
      "Epoch [100/500] | Train Loss: 0.352774 | Val Loss: 0.373111\n",
      "Epoch [200/500] | Train Loss: 0.294977 | Val Loss: 0.413604\n",
      "Epoch [300/500] | Train Loss: 0.273736 | Val Loss: 0.426756\n",
      "Epoch [400/500] | Train Loss: 0.270943 | Val Loss: 0.417642\n",
      "Epoch [500/500] | Train Loss: 0.237879 | Val Loss: 0.416652\n",
      "Epoch [100/500] | Train Loss: 0.313261 | Val Loss: 0.252872\n",
      "Epoch [200/500] | Train Loss: 0.249594 | Val Loss: 0.265566\n",
      "Epoch [300/500] | Train Loss: 0.234844 | Val Loss: 0.271215\n",
      "Epoch [400/500] | Train Loss: 0.218798 | Val Loss: 0.281517\n",
      "Epoch [500/500] | Train Loss: 0.208247 | Val Loss: 0.279367\n",
      "Epoch [100/500] | Train Loss: 0.291408 | Val Loss: 0.500274\n",
      "Epoch [200/500] | Train Loss: 0.272491 | Val Loss: 0.516525\n",
      "Epoch [300/500] | Train Loss: 0.236098 | Val Loss: 0.572577\n",
      "Epoch [400/500] | Train Loss: 0.226884 | Val Loss: 0.537974\n",
      "Epoch [500/500] | Train Loss: 0.217099 | Val Loss: 0.555170\n",
      "Epoch [100/500] | Train Loss: 0.330531 | Val Loss: 1.027865\n",
      "Epoch [200/500] | Train Loss: 0.298957 | Val Loss: 1.140408\n",
      "Epoch [300/500] | Train Loss: 0.269959 | Val Loss: 1.228531\n",
      "Epoch [400/500] | Train Loss: 0.276320 | Val Loss: 1.254859\n",
      "Epoch [500/500] | Train Loss: 0.249067 | Val Loss: 1.194049\n",
      "[Year=1971] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.488030 Test MSE=0.387863\n",
      "Year 1971 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.234728 | Val Loss: 0.389223\n",
      "Epoch [200/500] | Train Loss: 0.210915 | Val Loss: 0.400503\n",
      "Epoch [300/500] | Train Loss: 0.167743 | Val Loss: 0.473252\n",
      "Epoch [400/500] | Train Loss: 0.155791 | Val Loss: 0.491083\n",
      "Epoch [500/500] | Train Loss: 0.141856 | Val Loss: 0.503205\n",
      "Epoch [100/500] | Train Loss: 0.297007 | Val Loss: 0.311896\n",
      "Epoch [200/500] | Train Loss: 0.269191 | Val Loss: 0.323999\n",
      "Epoch [300/500] | Train Loss: 0.221537 | Val Loss: 0.352763\n",
      "Epoch [400/500] | Train Loss: 0.218772 | Val Loss: 0.377208\n",
      "Epoch [500/500] | Train Loss: 0.203740 | Val Loss: 0.387290\n",
      "Epoch [100/500] | Train Loss: 0.307599 | Val Loss: 0.615553\n",
      "Epoch [200/500] | Train Loss: 0.279262 | Val Loss: 0.629460\n",
      "Epoch [300/500] | Train Loss: 0.256844 | Val Loss: 0.662288\n",
      "Epoch [400/500] | Train Loss: 0.252981 | Val Loss: 0.719724\n",
      "Epoch [500/500] | Train Loss: 0.230812 | Val Loss: 0.746075\n",
      "Epoch [100/500] | Train Loss: 0.358151 | Val Loss: 0.784626\n",
      "Epoch [200/500] | Train Loss: 0.341772 | Val Loss: 0.781193\n",
      "Epoch [300/500] | Train Loss: 0.308299 | Val Loss: 0.769806\n",
      "Epoch [400/500] | Train Loss: 0.293899 | Val Loss: 0.789299\n",
      "Epoch [500/500] | Train Loss: 0.277882 | Val Loss: 0.812562\n",
      "Epoch [100/500] | Train Loss: 0.428925 | Val Loss: 0.420584\n",
      "Epoch [200/500] | Train Loss: 0.391850 | Val Loss: 0.426663\n",
      "Epoch [300/500] | Train Loss: 0.373062 | Val Loss: 0.425745\n",
      "Epoch [400/500] | Train Loss: 0.370609 | Val Loss: 0.423138\n",
      "Epoch [500/500] | Train Loss: 0.355851 | Val Loss: 0.420321\n",
      "Epoch [100/500] | Train Loss: 0.159763 | Val Loss: 0.453100\n",
      "Epoch [200/500] | Train Loss: 0.130795 | Val Loss: 0.492466\n",
      "Epoch [300/500] | Train Loss: 0.122453 | Val Loss: 0.467706\n",
      "Epoch [400/500] | Train Loss: 0.102179 | Val Loss: 0.493893\n",
      "Epoch [500/500] | Train Loss: 0.090832 | Val Loss: 0.497671\n",
      "Epoch [100/500] | Train Loss: 0.204419 | Val Loss: 0.367770\n",
      "Epoch [200/500] | Train Loss: 0.190508 | Val Loss: 0.367478\n",
      "Epoch [300/500] | Train Loss: 0.160926 | Val Loss: 0.378116\n",
      "Epoch [400/500] | Train Loss: 0.154536 | Val Loss: 0.396652\n",
      "Epoch [500/500] | Train Loss: 0.130413 | Val Loss: 0.402512\n",
      "Epoch [100/500] | Train Loss: 0.247959 | Val Loss: 0.755592\n",
      "Epoch [200/500] | Train Loss: 0.203896 | Val Loss: 0.791775\n",
      "Epoch [300/500] | Train Loss: 0.182542 | Val Loss: 0.842113\n",
      "Epoch [400/500] | Train Loss: 0.159067 | Val Loss: 0.982340\n",
      "Epoch [500/500] | Train Loss: 0.172233 | Val Loss: 0.918036\n",
      "Epoch [100/500] | Train Loss: 0.300783 | Val Loss: 0.715869\n",
      "Epoch [200/500] | Train Loss: 0.251828 | Val Loss: 0.811298\n",
      "Epoch [300/500] | Train Loss: 0.240173 | Val Loss: 0.859156\n",
      "Epoch [400/500] | Train Loss: 0.230390 | Val Loss: 0.904294\n",
      "Epoch [500/500] | Train Loss: 0.226645 | Val Loss: 0.826976\n",
      "Epoch [100/500] | Train Loss: 0.341614 | Val Loss: 0.446955\n",
      "Epoch [200/500] | Train Loss: 0.309850 | Val Loss: 0.486019\n",
      "Epoch [300/500] | Train Loss: 0.272165 | Val Loss: 0.521851\n",
      "Epoch [400/500] | Train Loss: 0.272575 | Val Loss: 0.508196\n",
      "Epoch [500/500] | Train Loss: 0.265622 | Val Loss: 0.484060\n",
      "Epoch [100/500] | Train Loss: 0.244199 | Val Loss: 0.387526\n",
      "Epoch [200/500] | Train Loss: 0.224714 | Val Loss: 0.399589\n",
      "Epoch [300/500] | Train Loss: 0.213965 | Val Loss: 0.404004\n",
      "Epoch [400/500] | Train Loss: 0.185993 | Val Loss: 0.420539\n",
      "Epoch [500/500] | Train Loss: 0.183834 | Val Loss: 0.429658\n",
      "Epoch [100/500] | Train Loss: 0.316808 | Val Loss: 0.327989\n",
      "Epoch [200/500] | Train Loss: 0.294667 | Val Loss: 0.317174\n",
      "Epoch [300/500] | Train Loss: 0.278735 | Val Loss: 0.316288\n",
      "Epoch [400/500] | Train Loss: 0.249193 | Val Loss: 0.316557\n",
      "Epoch [500/500] | Train Loss: 0.253797 | Val Loss: 0.317068\n",
      "Epoch [100/500] | Train Loss: 0.303057 | Val Loss: 0.598749\n",
      "Epoch [200/500] | Train Loss: 0.294452 | Val Loss: 0.601278\n",
      "Epoch [300/500] | Train Loss: 0.274289 | Val Loss: 0.619953\n",
      "Epoch [400/500] | Train Loss: 0.270818 | Val Loss: 0.648093\n",
      "Epoch [500/500] | Train Loss: 0.256486 | Val Loss: 0.647067\n",
      "Epoch [100/500] | Train Loss: 0.389311 | Val Loss: 0.773209\n",
      "Epoch [200/500] | Train Loss: 0.373337 | Val Loss: 0.778246\n",
      "Epoch [300/500] | Train Loss: 0.352174 | Val Loss: 0.767310\n",
      "Epoch [400/500] | Train Loss: 0.353127 | Val Loss: 0.755330\n",
      "Epoch [500/500] | Train Loss: 0.326484 | Val Loss: 0.742403\n",
      "Epoch [100/500] | Train Loss: 0.461512 | Val Loss: 0.413533\n",
      "Epoch [200/500] | Train Loss: 0.427498 | Val Loss: 0.415824\n",
      "Epoch [300/500] | Train Loss: 0.405834 | Val Loss: 0.428631\n",
      "Epoch [400/500] | Train Loss: 0.397750 | Val Loss: 0.434555\n",
      "Epoch [500/500] | Train Loss: 0.383247 | Val Loss: 0.430698\n",
      "Epoch [100/500] | Train Loss: 0.170039 | Val Loss: 0.469683\n",
      "Epoch [200/500] | Train Loss: 0.135094 | Val Loss: 0.450423\n",
      "Epoch [300/500] | Train Loss: 0.125820 | Val Loss: 0.479195\n",
      "Epoch [400/500] | Train Loss: 0.114564 | Val Loss: 0.486732\n",
      "Epoch [500/500] | Train Loss: 0.096178 | Val Loss: 0.467437\n",
      "Epoch [100/500] | Train Loss: 0.259946 | Val Loss: 0.331210\n",
      "Epoch [200/500] | Train Loss: 0.211416 | Val Loss: 0.341847\n",
      "Epoch [300/500] | Train Loss: 0.204817 | Val Loss: 0.359663\n",
      "Epoch [400/500] | Train Loss: 0.182555 | Val Loss: 0.372040\n",
      "Epoch [500/500] | Train Loss: 0.195209 | Val Loss: 0.373656\n",
      "Epoch [100/500] | Train Loss: 0.257930 | Val Loss: 0.647027\n",
      "Epoch [200/500] | Train Loss: 0.219997 | Val Loss: 0.743200\n",
      "Epoch [300/500] | Train Loss: 0.218106 | Val Loss: 0.720957\n",
      "Epoch [400/500] | Train Loss: 0.202294 | Val Loss: 0.745381\n",
      "Epoch [500/500] | Train Loss: 0.210381 | Val Loss: 0.725385\n",
      "Epoch [100/500] | Train Loss: 0.330705 | Val Loss: 0.762474\n",
      "Epoch [200/500] | Train Loss: 0.302003 | Val Loss: 0.698061\n",
      "Epoch [300/500] | Train Loss: 0.288764 | Val Loss: 0.701487\n",
      "Epoch [400/500] | Train Loss: 0.250083 | Val Loss: 0.729279\n",
      "Epoch [500/500] | Train Loss: 0.274179 | Val Loss: 0.724544\n",
      "Epoch [100/500] | Train Loss: 0.379357 | Val Loss: 0.429127\n",
      "Epoch [200/500] | Train Loss: 0.346432 | Val Loss: 0.427759\n",
      "Epoch [300/500] | Train Loss: 0.334891 | Val Loss: 0.424953\n",
      "Epoch [400/500] | Train Loss: 0.311131 | Val Loss: 0.442964\n",
      "Epoch [500/500] | Train Loss: 0.311995 | Val Loss: 0.444767\n",
      "Epoch [100/500] | Train Loss: 0.219399 | Val Loss: 0.392405\n",
      "Epoch [200/500] | Train Loss: 0.175803 | Val Loss: 0.457651\n",
      "Epoch [300/500] | Train Loss: 0.151852 | Val Loss: 0.500966\n",
      "Epoch [400/500] | Train Loss: 0.112411 | Val Loss: 0.519628\n",
      "Epoch [500/500] | Train Loss: 0.105304 | Val Loss: 0.543525\n",
      "Epoch [100/500] | Train Loss: 0.289563 | Val Loss: 0.317003\n",
      "Epoch [200/500] | Train Loss: 0.240689 | Val Loss: 0.342378\n",
      "Epoch [300/500] | Train Loss: 0.222921 | Val Loss: 0.371333\n",
      "Epoch [400/500] | Train Loss: 0.207928 | Val Loss: 0.396889\n",
      "Epoch [500/500] | Train Loss: 0.173139 | Val Loss: 0.415588\n",
      "Epoch [100/500] | Train Loss: 0.282416 | Val Loss: 0.606145\n",
      "Epoch [200/500] | Train Loss: 0.258955 | Val Loss: 0.669475\n",
      "Epoch [300/500] | Train Loss: 0.243048 | Val Loss: 0.724640\n",
      "Epoch [400/500] | Train Loss: 0.211792 | Val Loss: 0.768314\n",
      "Epoch [500/500] | Train Loss: 0.188839 | Val Loss: 0.793968\n",
      "Epoch [100/500] | Train Loss: 0.361665 | Val Loss: 0.765500\n",
      "Epoch [200/500] | Train Loss: 0.336941 | Val Loss: 0.768477\n",
      "Epoch [300/500] | Train Loss: 0.312521 | Val Loss: 0.778532\n",
      "Epoch [400/500] | Train Loss: 0.279401 | Val Loss: 0.797729\n",
      "Epoch [500/500] | Train Loss: 0.279213 | Val Loss: 0.805617\n",
      "Epoch [100/500] | Train Loss: 0.426360 | Val Loss: 0.427999\n",
      "Epoch [200/500] | Train Loss: 0.379848 | Val Loss: 0.432490\n",
      "Epoch [300/500] | Train Loss: 0.350612 | Val Loss: 0.445404\n",
      "Epoch [400/500] | Train Loss: 0.331044 | Val Loss: 0.457964\n",
      "Epoch [500/500] | Train Loss: 0.316580 | Val Loss: 0.466492\n",
      "Epoch [100/500] | Train Loss: 0.156629 | Val Loss: 0.526332\n",
      "Epoch [200/500] | Train Loss: 0.130280 | Val Loss: 0.500596\n",
      "Epoch [300/500] | Train Loss: 0.078097 | Val Loss: 0.514624\n",
      "Epoch [400/500] | Train Loss: 0.070789 | Val Loss: 0.554499\n",
      "Epoch [500/500] | Train Loss: 0.064581 | Val Loss: 0.503594\n",
      "Epoch [100/500] | Train Loss: 0.192584 | Val Loss: 0.390012\n",
      "Epoch [200/500] | Train Loss: 0.147166 | Val Loss: 0.385556\n",
      "Epoch [300/500] | Train Loss: 0.127630 | Val Loss: 0.398975\n",
      "Epoch [400/500] | Train Loss: 0.115477 | Val Loss: 0.419424\n",
      "Epoch [500/500] | Train Loss: 0.098099 | Val Loss: 0.466791\n",
      "Epoch [100/500] | Train Loss: 0.248117 | Val Loss: 0.685430\n",
      "Epoch [200/500] | Train Loss: 0.207541 | Val Loss: 0.783443\n",
      "Epoch [300/500] | Train Loss: 0.177837 | Val Loss: 0.721596\n",
      "Epoch [400/500] | Train Loss: 0.175928 | Val Loss: 0.762583\n",
      "Epoch [500/500] | Train Loss: 0.157763 | Val Loss: 0.708432\n",
      "Epoch [100/500] | Train Loss: 0.298601 | Val Loss: 0.737793\n",
      "Epoch [200/500] | Train Loss: 0.262039 | Val Loss: 0.792458\n",
      "Epoch [300/500] | Train Loss: 0.214783 | Val Loss: 0.932170\n",
      "Epoch [400/500] | Train Loss: 0.211923 | Val Loss: 0.915566\n",
      "Epoch [500/500] | Train Loss: 0.188934 | Val Loss: 0.934193\n",
      "Epoch [100/500] | Train Loss: 0.328793 | Val Loss: 0.471677\n",
      "Epoch [200/500] | Train Loss: 0.294365 | Val Loss: 0.470946\n",
      "Epoch [300/500] | Train Loss: 0.246157 | Val Loss: 0.506554\n",
      "Epoch [400/500] | Train Loss: 0.257625 | Val Loss: 0.497497\n",
      "Epoch [500/500] | Train Loss: 0.226376 | Val Loss: 0.531438\n",
      "Epoch [100/500] | Train Loss: 0.235645 | Val Loss: 0.386489\n",
      "Epoch [200/500] | Train Loss: 0.206213 | Val Loss: 0.432057\n",
      "Epoch [300/500] | Train Loss: 0.198861 | Val Loss: 0.435737\n",
      "Epoch [400/500] | Train Loss: 0.178332 | Val Loss: 0.459219\n",
      "Epoch [500/500] | Train Loss: 0.140714 | Val Loss: 0.463887\n",
      "Epoch [100/500] | Train Loss: 0.312925 | Val Loss: 0.304057\n",
      "Epoch [200/500] | Train Loss: 0.289880 | Val Loss: 0.339654\n",
      "Epoch [300/500] | Train Loss: 0.262899 | Val Loss: 0.357515\n",
      "Epoch [400/500] | Train Loss: 0.240050 | Val Loss: 0.385103\n",
      "Epoch [500/500] | Train Loss: 0.225906 | Val Loss: 0.381395\n",
      "Epoch [100/500] | Train Loss: 0.303097 | Val Loss: 0.606121\n",
      "Epoch [200/500] | Train Loss: 0.283546 | Val Loss: 0.604903\n",
      "Epoch [300/500] | Train Loss: 0.273180 | Val Loss: 0.612662\n",
      "Epoch [400/500] | Train Loss: 0.244319 | Val Loss: 0.635182\n",
      "Epoch [500/500] | Train Loss: 0.240597 | Val Loss: 0.666967\n",
      "Epoch [100/500] | Train Loss: 0.385511 | Val Loss: 0.777380\n",
      "Epoch [200/500] | Train Loss: 0.358561 | Val Loss: 0.770176\n",
      "Epoch [300/500] | Train Loss: 0.342963 | Val Loss: 0.759419\n",
      "Epoch [400/500] | Train Loss: 0.314381 | Val Loss: 0.759695\n",
      "Epoch [500/500] | Train Loss: 0.302153 | Val Loss: 0.744372\n",
      "Epoch [100/500] | Train Loss: 0.429206 | Val Loss: 0.423374\n",
      "Epoch [200/500] | Train Loss: 0.400285 | Val Loss: 0.425811\n",
      "Epoch [300/500] | Train Loss: 0.392927 | Val Loss: 0.426151\n",
      "Epoch [400/500] | Train Loss: 0.375840 | Val Loss: 0.426908\n",
      "Epoch [500/500] | Train Loss: 0.350169 | Val Loss: 0.429344\n",
      "Epoch [100/500] | Train Loss: 0.161269 | Val Loss: 0.499912\n",
      "Epoch [200/500] | Train Loss: 0.127300 | Val Loss: 0.507247\n",
      "Epoch [300/500] | Train Loss: 0.135605 | Val Loss: 0.468389\n",
      "Epoch [400/500] | Train Loss: 0.103781 | Val Loss: 0.432927\n",
      "Epoch [500/500] | Train Loss: 0.093111 | Val Loss: 0.487912\n",
      "Epoch [100/500] | Train Loss: 0.272080 | Val Loss: 0.351158\n",
      "Epoch [200/500] | Train Loss: 0.229984 | Val Loss: 0.393437\n",
      "Epoch [300/500] | Train Loss: 0.187051 | Val Loss: 0.379974\n",
      "Epoch [400/500] | Train Loss: 0.197382 | Val Loss: 0.404624\n",
      "Epoch [500/500] | Train Loss: 0.188339 | Val Loss: 0.394983\n",
      "Epoch [100/500] | Train Loss: 0.263191 | Val Loss: 0.697312\n",
      "Epoch [200/500] | Train Loss: 0.206581 | Val Loss: 0.713686\n",
      "Epoch [300/500] | Train Loss: 0.205996 | Val Loss: 0.831947\n",
      "Epoch [400/500] | Train Loss: 0.164410 | Val Loss: 0.777120\n",
      "Epoch [500/500] | Train Loss: 0.177140 | Val Loss: 0.799769\n",
      "Epoch [100/500] | Train Loss: 0.310168 | Val Loss: 0.744707\n",
      "Epoch [200/500] | Train Loss: 0.275224 | Val Loss: 0.732282\n",
      "Epoch [300/500] | Train Loss: 0.248835 | Val Loss: 0.738053\n",
      "Epoch [400/500] | Train Loss: 0.256476 | Val Loss: 0.734638\n",
      "Epoch [500/500] | Train Loss: 0.218606 | Val Loss: 0.700056\n",
      "Epoch [100/500] | Train Loss: 0.362336 | Val Loss: 0.418447\n",
      "Epoch [200/500] | Train Loss: 0.315520 | Val Loss: 0.442730\n",
      "Epoch [300/500] | Train Loss: 0.311051 | Val Loss: 0.440612\n",
      "Epoch [400/500] | Train Loss: 0.281629 | Val Loss: 0.446453\n",
      "Epoch [500/500] | Train Loss: 0.294471 | Val Loss: 0.456859\n",
      "[Year=1972] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.513379 Test MSE=0.230384\n",
      "Year 1972 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.329179 | Val Loss: 0.425678\n",
      "Epoch [200/500] | Train Loss: 0.273621 | Val Loss: 0.443781\n",
      "Epoch [300/500] | Train Loss: 0.227132 | Val Loss: 0.470355\n",
      "Epoch [400/500] | Train Loss: 0.190727 | Val Loss: 0.508838\n",
      "Epoch [500/500] | Train Loss: 0.190541 | Val Loss: 0.537528\n",
      "Epoch [100/500] | Train Loss: 0.353182 | Val Loss: 0.964753\n",
      "Epoch [200/500] | Train Loss: 0.331295 | Val Loss: 0.923866\n",
      "Epoch [300/500] | Train Loss: 0.301498 | Val Loss: 0.953943\n",
      "Epoch [400/500] | Train Loss: 0.289754 | Val Loss: 1.015341\n",
      "Epoch [500/500] | Train Loss: 0.250536 | Val Loss: 1.079749\n",
      "Epoch [100/500] | Train Loss: 0.522010 | Val Loss: 0.323598\n",
      "Epoch [200/500] | Train Loss: 0.458302 | Val Loss: 0.336190\n",
      "Epoch [300/500] | Train Loss: 0.400036 | Val Loss: 0.349158\n",
      "Epoch [400/500] | Train Loss: 0.379801 | Val Loss: 0.361144\n",
      "Epoch [500/500] | Train Loss: 0.356681 | Val Loss: 0.364700\n",
      "Epoch [100/500] | Train Loss: 0.488068 | Val Loss: 0.436918\n",
      "Epoch [200/500] | Train Loss: 0.422373 | Val Loss: 0.434359\n",
      "Epoch [300/500] | Train Loss: 0.381979 | Val Loss: 0.428180\n",
      "Epoch [400/500] | Train Loss: 0.387920 | Val Loss: 0.432055\n",
      "Epoch [500/500] | Train Loss: 0.343834 | Val Loss: 0.440249\n",
      "Epoch [100/500] | Train Loss: 0.474305 | Val Loss: 0.234684\n",
      "Epoch [200/500] | Train Loss: 0.450422 | Val Loss: 0.244469\n",
      "Epoch [300/500] | Train Loss: 0.412131 | Val Loss: 0.245210\n",
      "Epoch [400/500] | Train Loss: 0.392284 | Val Loss: 0.247651\n",
      "Epoch [500/500] | Train Loss: 0.367239 | Val Loss: 0.246475\n",
      "Epoch [100/500] | Train Loss: 0.195878 | Val Loss: 0.537276\n",
      "Epoch [200/500] | Train Loss: 0.115439 | Val Loss: 0.575591\n",
      "Epoch [300/500] | Train Loss: 0.094913 | Val Loss: 0.562313\n",
      "Epoch [400/500] | Train Loss: 0.112555 | Val Loss: 0.552190\n",
      "Epoch [500/500] | Train Loss: 0.101557 | Val Loss: 0.538605\n",
      "Epoch [100/500] | Train Loss: 0.268308 | Val Loss: 0.926520\n",
      "Epoch [200/500] | Train Loss: 0.203506 | Val Loss: 0.992175\n",
      "Epoch [300/500] | Train Loss: 0.199080 | Val Loss: 0.941429\n",
      "Epoch [400/500] | Train Loss: 0.172432 | Val Loss: 0.945873\n",
      "Epoch [500/500] | Train Loss: 0.148270 | Val Loss: 0.942660\n",
      "Epoch [100/500] | Train Loss: 0.382777 | Val Loss: 0.341731\n",
      "Epoch [200/500] | Train Loss: 0.325432 | Val Loss: 0.363388\n",
      "Epoch [300/500] | Train Loss: 0.273294 | Val Loss: 0.382456\n",
      "Epoch [400/500] | Train Loss: 0.271918 | Val Loss: 0.392550\n",
      "Epoch [500/500] | Train Loss: 0.237770 | Val Loss: 0.407506\n",
      "Epoch [100/500] | Train Loss: 0.383377 | Val Loss: 0.447891\n",
      "Epoch [200/500] | Train Loss: 0.308572 | Val Loss: 0.449363\n",
      "Epoch [300/500] | Train Loss: 0.297930 | Val Loss: 0.455993\n",
      "Epoch [400/500] | Train Loss: 0.277516 | Val Loss: 0.442329\n",
      "Epoch [500/500] | Train Loss: 0.275420 | Val Loss: 0.452720\n",
      "Epoch [100/500] | Train Loss: 0.397685 | Val Loss: 0.236364\n",
      "Epoch [200/500] | Train Loss: 0.355771 | Val Loss: 0.238327\n",
      "Epoch [300/500] | Train Loss: 0.310059 | Val Loss: 0.238416\n",
      "Epoch [400/500] | Train Loss: 0.320392 | Val Loss: 0.246775\n",
      "Epoch [500/500] | Train Loss: 0.286028 | Val Loss: 0.250763\n",
      "Epoch [100/500] | Train Loss: 0.326973 | Val Loss: 0.407709\n",
      "Epoch [200/500] | Train Loss: 0.285204 | Val Loss: 0.440087\n",
      "Epoch [300/500] | Train Loss: 0.235736 | Val Loss: 0.462704\n",
      "Epoch [400/500] | Train Loss: 0.237837 | Val Loss: 0.482685\n",
      "Epoch [500/500] | Train Loss: 0.229917 | Val Loss: 0.526695\n",
      "Epoch [100/500] | Train Loss: 0.358478 | Val Loss: 0.958488\n",
      "Epoch [200/500] | Train Loss: 0.341435 | Val Loss: 0.941442\n",
      "Epoch [300/500] | Train Loss: 0.320222 | Val Loss: 0.936620\n",
      "Epoch [400/500] | Train Loss: 0.320390 | Val Loss: 0.956949\n",
      "Epoch [500/500] | Train Loss: 0.293769 | Val Loss: 1.004360\n",
      "Epoch [100/500] | Train Loss: 0.542923 | Val Loss: 0.331771\n",
      "Epoch [200/500] | Train Loss: 0.522001 | Val Loss: 0.326887\n",
      "Epoch [300/500] | Train Loss: 0.467209 | Val Loss: 0.338455\n",
      "Epoch [400/500] | Train Loss: 0.428237 | Val Loss: 0.333549\n",
      "Epoch [500/500] | Train Loss: 0.408993 | Val Loss: 0.328252\n",
      "Epoch [100/500] | Train Loss: 0.508138 | Val Loss: 0.430792\n",
      "Epoch [200/500] | Train Loss: 0.469971 | Val Loss: 0.433347\n",
      "Epoch [300/500] | Train Loss: 0.466476 | Val Loss: 0.431783\n",
      "Epoch [400/500] | Train Loss: 0.445899 | Val Loss: 0.434140\n",
      "Epoch [500/500] | Train Loss: 0.405902 | Val Loss: 0.438508\n",
      "Epoch [100/500] | Train Loss: 0.484957 | Val Loss: 0.235625\n",
      "Epoch [200/500] | Train Loss: 0.458166 | Val Loss: 0.241491\n",
      "Epoch [300/500] | Train Loss: 0.446479 | Val Loss: 0.239205\n",
      "Epoch [400/500] | Train Loss: 0.418078 | Val Loss: 0.237478\n",
      "Epoch [500/500] | Train Loss: 0.413980 | Val Loss: 0.235911\n",
      "Epoch [100/500] | Train Loss: 0.269261 | Val Loss: 0.434100\n",
      "Epoch [200/500] | Train Loss: 0.244407 | Val Loss: 0.516807\n",
      "Epoch [300/500] | Train Loss: 0.180477 | Val Loss: 0.548365\n",
      "Epoch [400/500] | Train Loss: 0.172288 | Val Loss: 0.527266\n",
      "Epoch [500/500] | Train Loss: 0.146874 | Val Loss: 0.522955\n",
      "Epoch [100/500] | Train Loss: 0.311531 | Val Loss: 0.998438\n",
      "Epoch [200/500] | Train Loss: 0.270197 | Val Loss: 1.010090\n",
      "Epoch [300/500] | Train Loss: 0.226451 | Val Loss: 1.038295\n",
      "Epoch [400/500] | Train Loss: 0.221701 | Val Loss: 1.088189\n",
      "Epoch [500/500] | Train Loss: 0.212085 | Val Loss: 1.041811\n",
      "Epoch [100/500] | Train Loss: 0.426502 | Val Loss: 0.339147\n",
      "Epoch [200/500] | Train Loss: 0.374862 | Val Loss: 0.324428\n",
      "Epoch [300/500] | Train Loss: 0.362865 | Val Loss: 0.344669\n",
      "Epoch [400/500] | Train Loss: 0.339187 | Val Loss: 0.369481\n",
      "Epoch [500/500] | Train Loss: 0.347740 | Val Loss: 0.386483\n",
      "Epoch [100/500] | Train Loss: 0.380707 | Val Loss: 0.432252\n",
      "Epoch [200/500] | Train Loss: 0.362767 | Val Loss: 0.429393\n",
      "Epoch [300/500] | Train Loss: 0.349817 | Val Loss: 0.432681\n",
      "Epoch [400/500] | Train Loss: 0.327747 | Val Loss: 0.455678\n",
      "Epoch [500/500] | Train Loss: 0.334637 | Val Loss: 0.453784\n",
      "Epoch [100/500] | Train Loss: 0.443110 | Val Loss: 0.243763\n",
      "Epoch [200/500] | Train Loss: 0.388925 | Val Loss: 0.239498\n",
      "Epoch [300/500] | Train Loss: 0.375112 | Val Loss: 0.239476\n",
      "Epoch [400/500] | Train Loss: 0.375487 | Val Loss: 0.250422\n",
      "Epoch [500/500] | Train Loss: 0.350549 | Val Loss: 0.245166\n",
      "Epoch [100/500] | Train Loss: 0.329483 | Val Loss: 0.393745\n",
      "Epoch [200/500] | Train Loss: 0.238682 | Val Loss: 0.448836\n",
      "Epoch [300/500] | Train Loss: 0.206178 | Val Loss: 0.466939\n",
      "Epoch [400/500] | Train Loss: 0.175136 | Val Loss: 0.464498\n",
      "Epoch [500/500] | Train Loss: 0.137209 | Val Loss: 0.488677\n",
      "Epoch [100/500] | Train Loss: 0.327626 | Val Loss: 0.918039\n",
      "Epoch [200/500] | Train Loss: 0.292341 | Val Loss: 0.891025\n",
      "Epoch [300/500] | Train Loss: 0.260690 | Val Loss: 0.887043\n",
      "Epoch [400/500] | Train Loss: 0.248795 | Val Loss: 0.881852\n",
      "Epoch [500/500] | Train Loss: 0.206468 | Val Loss: 0.888530\n",
      "Epoch [100/500] | Train Loss: 0.500239 | Val Loss: 0.319484\n",
      "Epoch [200/500] | Train Loss: 0.393507 | Val Loss: 0.339303\n",
      "Epoch [300/500] | Train Loss: 0.374307 | Val Loss: 0.353859\n",
      "Epoch [400/500] | Train Loss: 0.335252 | Val Loss: 0.362093\n",
      "Epoch [500/500] | Train Loss: 0.330012 | Val Loss: 0.369466\n",
      "Epoch [100/500] | Train Loss: 0.476217 | Val Loss: 0.428706\n",
      "Epoch [200/500] | Train Loss: 0.403152 | Val Loss: 0.438818\n",
      "Epoch [300/500] | Train Loss: 0.375654 | Val Loss: 0.441965\n",
      "Epoch [400/500] | Train Loss: 0.383132 | Val Loss: 0.454206\n",
      "Epoch [500/500] | Train Loss: 0.331593 | Val Loss: 0.457391\n",
      "Epoch [100/500] | Train Loss: 0.498477 | Val Loss: 0.257980\n",
      "Epoch [200/500] | Train Loss: 0.446283 | Val Loss: 0.242715\n",
      "Epoch [300/500] | Train Loss: 0.400350 | Val Loss: 0.243219\n",
      "Epoch [400/500] | Train Loss: 0.382637 | Val Loss: 0.237234\n",
      "Epoch [500/500] | Train Loss: 0.351801 | Val Loss: 0.235844\n",
      "Epoch [100/500] | Train Loss: 0.138735 | Val Loss: 0.555488\n",
      "Epoch [200/500] | Train Loss: 0.086536 | Val Loss: 0.528874\n",
      "Epoch [300/500] | Train Loss: 0.078002 | Val Loss: 0.574139\n",
      "Epoch [400/500] | Train Loss: 0.073957 | Val Loss: 0.581807\n",
      "Epoch [500/500] | Train Loss: 0.061588 | Val Loss: 0.582090\n",
      "Epoch [100/500] | Train Loss: 0.213583 | Val Loss: 0.889176\n",
      "Epoch [200/500] | Train Loss: 0.169439 | Val Loss: 0.971969\n",
      "Epoch [300/500] | Train Loss: 0.152951 | Val Loss: 1.009286\n",
      "Epoch [400/500] | Train Loss: 0.115781 | Val Loss: 1.054541\n",
      "Epoch [500/500] | Train Loss: 0.111157 | Val Loss: 0.973393\n",
      "Epoch [100/500] | Train Loss: 0.358999 | Val Loss: 0.335384\n",
      "Epoch [200/500] | Train Loss: 0.316225 | Val Loss: 0.378319\n",
      "Epoch [300/500] | Train Loss: 0.256920 | Val Loss: 0.398451\n",
      "Epoch [400/500] | Train Loss: 0.221284 | Val Loss: 0.405686\n",
      "Epoch [500/500] | Train Loss: 0.218447 | Val Loss: 0.383537\n",
      "Epoch [100/500] | Train Loss: 0.356678 | Val Loss: 0.486179\n",
      "Epoch [200/500] | Train Loss: 0.289145 | Val Loss: 0.514867\n",
      "Epoch [300/500] | Train Loss: 0.255743 | Val Loss: 0.541344\n",
      "Epoch [400/500] | Train Loss: 0.221878 | Val Loss: 0.555465\n",
      "Epoch [500/500] | Train Loss: 0.220000 | Val Loss: 0.547917\n",
      "Epoch [100/500] | Train Loss: 0.380652 | Val Loss: 0.236654\n",
      "Epoch [200/500] | Train Loss: 0.314861 | Val Loss: 0.250570\n",
      "Epoch [300/500] | Train Loss: 0.297282 | Val Loss: 0.265324\n",
      "Epoch [400/500] | Train Loss: 0.257243 | Val Loss: 0.253571\n",
      "Epoch [500/500] | Train Loss: 0.258212 | Val Loss: 0.261772\n",
      "Epoch [100/500] | Train Loss: 0.297758 | Val Loss: 0.407699\n",
      "Epoch [200/500] | Train Loss: 0.260604 | Val Loss: 0.454298\n",
      "Epoch [300/500] | Train Loss: 0.239303 | Val Loss: 0.470899\n",
      "Epoch [400/500] | Train Loss: 0.229131 | Val Loss: 0.512287\n",
      "Epoch [500/500] | Train Loss: 0.194869 | Val Loss: 0.519915\n",
      "Epoch [100/500] | Train Loss: 0.364371 | Val Loss: 0.935854\n",
      "Epoch [200/500] | Train Loss: 0.337318 | Val Loss: 0.924078\n",
      "Epoch [300/500] | Train Loss: 0.309196 | Val Loss: 0.958187\n",
      "Epoch [400/500] | Train Loss: 0.288794 | Val Loss: 0.999352\n",
      "Epoch [500/500] | Train Loss: 0.263756 | Val Loss: 1.008926\n",
      "Epoch [100/500] | Train Loss: 0.527418 | Val Loss: 0.319055\n",
      "Epoch [200/500] | Train Loss: 0.465631 | Val Loss: 0.324940\n",
      "Epoch [300/500] | Train Loss: 0.429944 | Val Loss: 0.336718\n",
      "Epoch [400/500] | Train Loss: 0.430154 | Val Loss: 0.336871\n",
      "Epoch [500/500] | Train Loss: 0.400224 | Val Loss: 0.343620\n",
      "Epoch [100/500] | Train Loss: 0.482731 | Val Loss: 0.425053\n",
      "Epoch [200/500] | Train Loss: 0.432018 | Val Loss: 0.427445\n",
      "Epoch [300/500] | Train Loss: 0.413070 | Val Loss: 0.427116\n",
      "Epoch [400/500] | Train Loss: 0.403022 | Val Loss: 0.437899\n",
      "Epoch [500/500] | Train Loss: 0.385178 | Val Loss: 0.446144\n",
      "Epoch [100/500] | Train Loss: 0.464865 | Val Loss: 0.236634\n",
      "Epoch [200/500] | Train Loss: 0.438787 | Val Loss: 0.238917\n",
      "Epoch [300/500] | Train Loss: 0.404054 | Val Loss: 0.239512\n",
      "Epoch [400/500] | Train Loss: 0.375920 | Val Loss: 0.241315\n",
      "Epoch [500/500] | Train Loss: 0.370276 | Val Loss: 0.239331\n",
      "Epoch [100/500] | Train Loss: 0.220111 | Val Loss: 0.507402\n",
      "Epoch [200/500] | Train Loss: 0.174016 | Val Loss: 0.504936\n",
      "Epoch [300/500] | Train Loss: 0.158661 | Val Loss: 0.506461\n",
      "Epoch [400/500] | Train Loss: 0.119879 | Val Loss: 0.502466\n",
      "Epoch [500/500] | Train Loss: 0.115581 | Val Loss: 0.527870\n",
      "Epoch [100/500] | Train Loss: 0.279022 | Val Loss: 0.984933\n",
      "Epoch [200/500] | Train Loss: 0.231530 | Val Loss: 1.056018\n",
      "Epoch [300/500] | Train Loss: 0.196140 | Val Loss: 1.047539\n",
      "Epoch [400/500] | Train Loss: 0.195038 | Val Loss: 1.063099\n",
      "Epoch [500/500] | Train Loss: 0.159873 | Val Loss: 1.008989\n",
      "Epoch [100/500] | Train Loss: 0.392577 | Val Loss: 0.336081\n",
      "Epoch [200/500] | Train Loss: 0.406816 | Val Loss: 0.338334\n",
      "Epoch [300/500] | Train Loss: 0.314456 | Val Loss: 0.360761\n",
      "Epoch [400/500] | Train Loss: 0.314007 | Val Loss: 0.384454\n",
      "Epoch [500/500] | Train Loss: 0.295341 | Val Loss: 0.404502\n",
      "Epoch [100/500] | Train Loss: 0.401901 | Val Loss: 0.437095\n",
      "Epoch [200/500] | Train Loss: 0.336311 | Val Loss: 0.437075\n",
      "Epoch [300/500] | Train Loss: 0.351812 | Val Loss: 0.444182\n",
      "Epoch [400/500] | Train Loss: 0.329792 | Val Loss: 0.447161\n",
      "Epoch [500/500] | Train Loss: 0.312951 | Val Loss: 0.456636\n",
      "Epoch [100/500] | Train Loss: 0.418151 | Val Loss: 0.240111\n",
      "Epoch [200/500] | Train Loss: 0.368047 | Val Loss: 0.240368\n",
      "Epoch [300/500] | Train Loss: 0.362040 | Val Loss: 0.246531\n",
      "Epoch [400/500] | Train Loss: 0.332460 | Val Loss: 0.243725\n",
      "Epoch [500/500] | Train Loss: 0.325847 | Val Loss: 0.238522\n",
      "[Year=1973] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.1, 'learning_rate': 0.001} CV-MSE=0.487981 Test MSE=0.992286\n",
      "Year 1973 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.376083 | Val Loss: 0.968872\n",
      "Epoch [200/500] | Train Loss: 0.338531 | Val Loss: 0.914427\n",
      "Epoch [300/500] | Train Loss: 0.291897 | Val Loss: 0.939072\n",
      "Epoch [400/500] | Train Loss: 0.274335 | Val Loss: 0.952246\n",
      "Epoch [500/500] | Train Loss: 0.243087 | Val Loss: 0.969720\n",
      "Epoch [100/500] | Train Loss: 0.647762 | Val Loss: 0.284471\n",
      "Epoch [200/500] | Train Loss: 0.558683 | Val Loss: 0.278464\n",
      "Epoch [300/500] | Train Loss: 0.491697 | Val Loss: 0.297125\n",
      "Epoch [400/500] | Train Loss: 0.456624 | Val Loss: 0.298743\n",
      "Epoch [500/500] | Train Loss: 0.385531 | Val Loss: 0.300200\n",
      "Epoch [100/500] | Train Loss: 0.485711 | Val Loss: 0.426523\n",
      "Epoch [200/500] | Train Loss: 0.426197 | Val Loss: 0.437444\n",
      "Epoch [300/500] | Train Loss: 0.379985 | Val Loss: 0.452526\n",
      "Epoch [400/500] | Train Loss: 0.392055 | Val Loss: 0.465565\n",
      "Epoch [500/500] | Train Loss: 0.356497 | Val Loss: 0.467502\n",
      "Epoch [100/500] | Train Loss: 0.485733 | Val Loss: 0.285233\n",
      "Epoch [200/500] | Train Loss: 0.420764 | Val Loss: 0.297661\n",
      "Epoch [300/500] | Train Loss: 0.427629 | Val Loss: 0.294872\n",
      "Epoch [400/500] | Train Loss: 0.384979 | Val Loss: 0.297666\n",
      "Epoch [500/500] | Train Loss: 0.380757 | Val Loss: 0.297237\n",
      "Epoch [100/500] | Train Loss: 0.454585 | Val Loss: 0.976271\n",
      "Epoch [200/500] | Train Loss: 0.404925 | Val Loss: 0.971427\n",
      "Epoch [300/500] | Train Loss: 0.365579 | Val Loss: 0.999849\n",
      "Epoch [400/500] | Train Loss: 0.349987 | Val Loss: 1.034594\n",
      "Epoch [500/500] | Train Loss: 0.347483 | Val Loss: 1.066901\n",
      "Epoch [100/500] | Train Loss: 0.248499 | Val Loss: 0.920496\n",
      "Epoch [200/500] | Train Loss: 0.213422 | Val Loss: 0.976016\n",
      "Epoch [300/500] | Train Loss: 0.131767 | Val Loss: 1.029066\n",
      "Epoch [400/500] | Train Loss: 0.162805 | Val Loss: 1.003137\n",
      "Epoch [500/500] | Train Loss: 0.121981 | Val Loss: 0.978430\n",
      "Epoch [100/500] | Train Loss: 0.417268 | Val Loss: 0.281919\n",
      "Epoch [200/500] | Train Loss: 0.314483 | Val Loss: 0.301323\n",
      "Epoch [300/500] | Train Loss: 0.293248 | Val Loss: 0.325580\n",
      "Epoch [400/500] | Train Loss: 0.316921 | Val Loss: 0.336381\n",
      "Epoch [500/500] | Train Loss: 0.246329 | Val Loss: 0.318184\n",
      "Epoch [100/500] | Train Loss: 0.374274 | Val Loss: 0.429954\n",
      "Epoch [200/500] | Train Loss: 0.332116 | Val Loss: 0.432000\n",
      "Epoch [300/500] | Train Loss: 0.266351 | Val Loss: 0.445419\n",
      "Epoch [400/500] | Train Loss: 0.271206 | Val Loss: 0.494884\n",
      "Epoch [500/500] | Train Loss: 0.256034 | Val Loss: 0.483793\n",
      "Epoch [100/500] | Train Loss: 0.380500 | Val Loss: 0.289392\n",
      "Epoch [200/500] | Train Loss: 0.311494 | Val Loss: 0.310580\n",
      "Epoch [300/500] | Train Loss: 0.285733 | Val Loss: 0.328347\n",
      "Epoch [400/500] | Train Loss: 0.278587 | Val Loss: 0.341562\n",
      "Epoch [500/500] | Train Loss: 0.254122 | Val Loss: 0.332389\n",
      "Epoch [100/500] | Train Loss: 0.361190 | Val Loss: 1.019029\n",
      "Epoch [200/500] | Train Loss: 0.334262 | Val Loss: 1.057125\n",
      "Epoch [300/500] | Train Loss: 0.304578 | Val Loss: 0.986926\n",
      "Epoch [400/500] | Train Loss: 0.271316 | Val Loss: 0.994941\n",
      "Epoch [500/500] | Train Loss: 0.265278 | Val Loss: 1.046125\n",
      "Epoch [100/500] | Train Loss: 0.386219 | Val Loss: 0.977203\n",
      "Epoch [200/500] | Train Loss: 0.367727 | Val Loss: 0.937916\n",
      "Epoch [300/500] | Train Loss: 0.343345 | Val Loss: 0.937464\n",
      "Epoch [400/500] | Train Loss: 0.324306 | Val Loss: 0.917691\n",
      "Epoch [500/500] | Train Loss: 0.311182 | Val Loss: 0.902782\n",
      "Epoch [100/500] | Train Loss: 0.641318 | Val Loss: 0.279396\n",
      "Epoch [200/500] | Train Loss: 0.605351 | Val Loss: 0.274169\n",
      "Epoch [300/500] | Train Loss: 0.509760 | Val Loss: 0.280717\n",
      "Epoch [400/500] | Train Loss: 0.528339 | Val Loss: 0.287457\n",
      "Epoch [500/500] | Train Loss: 0.503742 | Val Loss: 0.286140\n",
      "Epoch [100/500] | Train Loss: 0.528377 | Val Loss: 0.406768\n",
      "Epoch [200/500] | Train Loss: 0.448282 | Val Loss: 0.419053\n",
      "Epoch [300/500] | Train Loss: 0.441388 | Val Loss: 0.418884\n",
      "Epoch [400/500] | Train Loss: 0.414750 | Val Loss: 0.415688\n",
      "Epoch [500/500] | Train Loss: 0.403526 | Val Loss: 0.411565\n",
      "Epoch [100/500] | Train Loss: 0.498718 | Val Loss: 0.278732\n",
      "Epoch [200/500] | Train Loss: 0.477894 | Val Loss: 0.287588\n",
      "Epoch [300/500] | Train Loss: 0.433393 | Val Loss: 0.290047\n",
      "Epoch [400/500] | Train Loss: 0.408735 | Val Loss: 0.288248\n",
      "Epoch [500/500] | Train Loss: 0.399666 | Val Loss: 0.285235\n",
      "Epoch [100/500] | Train Loss: 0.453907 | Val Loss: 0.968835\n",
      "Epoch [200/500] | Train Loss: 0.421334 | Val Loss: 0.953882\n",
      "Epoch [300/500] | Train Loss: 0.420666 | Val Loss: 0.952287\n",
      "Epoch [400/500] | Train Loss: 0.392376 | Val Loss: 0.940989\n",
      "Epoch [500/500] | Train Loss: 0.405250 | Val Loss: 0.956940\n",
      "Epoch [100/500] | Train Loss: 0.303647 | Val Loss: 0.913190\n",
      "Epoch [200/500] | Train Loss: 0.267423 | Val Loss: 1.009685\n",
      "Epoch [300/500] | Train Loss: 0.207348 | Val Loss: 1.031600\n",
      "Epoch [400/500] | Train Loss: 0.208345 | Val Loss: 0.971345\n",
      "Epoch [500/500] | Train Loss: 0.201068 | Val Loss: 1.000191\n",
      "Epoch [100/500] | Train Loss: 0.490340 | Val Loss: 0.300677\n",
      "Epoch [200/500] | Train Loss: 0.461850 | Val Loss: 0.316407\n",
      "Epoch [300/500] | Train Loss: 0.400266 | Val Loss: 0.316656\n",
      "Epoch [400/500] | Train Loss: 0.417753 | Val Loss: 0.317162\n",
      "Epoch [500/500] | Train Loss: 0.332932 | Val Loss: 0.317436\n",
      "Epoch [100/500] | Train Loss: 0.454579 | Val Loss: 0.424697\n",
      "Epoch [200/500] | Train Loss: 0.367647 | Val Loss: 0.441714\n",
      "Epoch [300/500] | Train Loss: 0.345248 | Val Loss: 0.427864\n",
      "Epoch [400/500] | Train Loss: 0.337887 | Val Loss: 0.435641\n",
      "Epoch [500/500] | Train Loss: 0.322994 | Val Loss: 0.450214\n",
      "Epoch [100/500] | Train Loss: 0.415858 | Val Loss: 0.285966\n",
      "Epoch [200/500] | Train Loss: 0.393740 | Val Loss: 0.299215\n",
      "Epoch [300/500] | Train Loss: 0.377717 | Val Loss: 0.293058\n",
      "Epoch [400/500] | Train Loss: 0.384024 | Val Loss: 0.309372\n",
      "Epoch [500/500] | Train Loss: 0.356150 | Val Loss: 0.296258\n",
      "Epoch [100/500] | Train Loss: 0.378355 | Val Loss: 0.943889\n",
      "Epoch [200/500] | Train Loss: 0.369534 | Val Loss: 0.977413\n",
      "Epoch [300/500] | Train Loss: 0.362476 | Val Loss: 1.024115\n",
      "Epoch [400/500] | Train Loss: 0.341672 | Val Loss: 1.027550\n",
      "Epoch [500/500] | Train Loss: 0.357376 | Val Loss: 1.004559\n",
      "Epoch [100/500] | Train Loss: 0.377345 | Val Loss: 0.987418\n",
      "Epoch [200/500] | Train Loss: 0.324356 | Val Loss: 0.954907\n",
      "Epoch [300/500] | Train Loss: 0.272250 | Val Loss: 0.960213\n",
      "Epoch [400/500] | Train Loss: 0.220042 | Val Loss: 1.029953\n",
      "Epoch [500/500] | Train Loss: 0.192055 | Val Loss: 1.072733\n",
      "Epoch [100/500] | Train Loss: 0.604530 | Val Loss: 0.298743\n",
      "Epoch [200/500] | Train Loss: 0.531028 | Val Loss: 0.303358\n",
      "Epoch [300/500] | Train Loss: 0.430254 | Val Loss: 0.295008\n",
      "Epoch [400/500] | Train Loss: 0.404812 | Val Loss: 0.288407\n",
      "Epoch [500/500] | Train Loss: 0.391848 | Val Loss: 0.292190\n",
      "Epoch [100/500] | Train Loss: 0.510095 | Val Loss: 0.419126\n",
      "Epoch [200/500] | Train Loss: 0.407666 | Val Loss: 0.438308\n",
      "Epoch [300/500] | Train Loss: 0.397459 | Val Loss: 0.444857\n",
      "Epoch [400/500] | Train Loss: 0.357824 | Val Loss: 0.456068\n",
      "Epoch [500/500] | Train Loss: 0.335184 | Val Loss: 0.455657\n",
      "Epoch [100/500] | Train Loss: 0.468075 | Val Loss: 0.289091\n",
      "Epoch [200/500] | Train Loss: 0.423388 | Val Loss: 0.292192\n",
      "Epoch [300/500] | Train Loss: 0.384970 | Val Loss: 0.285155\n",
      "Epoch [400/500] | Train Loss: 0.367999 | Val Loss: 0.284846\n",
      "Epoch [500/500] | Train Loss: 0.369268 | Val Loss: 0.286522\n",
      "Epoch [100/500] | Train Loss: 0.460977 | Val Loss: 0.998276\n",
      "Epoch [200/500] | Train Loss: 0.426069 | Val Loss: 0.950062\n",
      "Epoch [300/500] | Train Loss: 0.403960 | Val Loss: 0.952761\n",
      "Epoch [400/500] | Train Loss: 0.347421 | Val Loss: 0.992401\n",
      "Epoch [500/500] | Train Loss: 0.361733 | Val Loss: 1.007871\n",
      "Epoch [100/500] | Train Loss: 0.270352 | Val Loss: 1.100067\n",
      "Epoch [200/500] | Train Loss: 0.231278 | Val Loss: 1.085253\n",
      "Epoch [300/500] | Train Loss: 0.214955 | Val Loss: 1.071820\n",
      "Epoch [400/500] | Train Loss: 0.210754 | Val Loss: 1.016083\n",
      "Epoch [500/500] | Train Loss: 0.219603 | Val Loss: 1.032061\n",
      "Epoch [100/500] | Train Loss: 0.412263 | Val Loss: 0.299856\n",
      "Epoch [200/500] | Train Loss: 0.311330 | Val Loss: 0.345760\n",
      "Epoch [300/500] | Train Loss: 0.310940 | Val Loss: 0.360613\n",
      "Epoch [400/500] | Train Loss: 0.260192 | Val Loss: 0.336149\n",
      "Epoch [500/500] | Train Loss: 0.252785 | Val Loss: 0.353774\n",
      "Epoch [100/500] | Train Loss: 0.374302 | Val Loss: 0.474146\n",
      "Epoch [200/500] | Train Loss: 0.320055 | Val Loss: 0.448097\n",
      "Epoch [300/500] | Train Loss: 0.282498 | Val Loss: 0.438214\n",
      "Epoch [400/500] | Train Loss: 0.233114 | Val Loss: 0.502652\n",
      "Epoch [500/500] | Train Loss: 0.229084 | Val Loss: 0.474786\n",
      "Epoch [100/500] | Train Loss: 0.372092 | Val Loss: 0.287583\n",
      "Epoch [200/500] | Train Loss: 0.296859 | Val Loss: 0.317733\n",
      "Epoch [300/500] | Train Loss: 0.262551 | Val Loss: 0.318882\n",
      "Epoch [400/500] | Train Loss: 0.242004 | Val Loss: 0.321408\n",
      "Epoch [500/500] | Train Loss: 0.226074 | Val Loss: 0.352267\n",
      "Epoch [100/500] | Train Loss: 0.351119 | Val Loss: 1.063213\n",
      "Epoch [200/500] | Train Loss: 0.315364 | Val Loss: 1.134595\n",
      "Epoch [300/500] | Train Loss: 0.263150 | Val Loss: 1.195173\n",
      "Epoch [400/500] | Train Loss: 0.248682 | Val Loss: 1.116618\n",
      "Epoch [500/500] | Train Loss: 0.226825 | Val Loss: 1.156213\n",
      "Epoch [100/500] | Train Loss: 0.353895 | Val Loss: 0.939042\n",
      "Epoch [200/500] | Train Loss: 0.324545 | Val Loss: 0.914591\n",
      "Epoch [300/500] | Train Loss: 0.309469 | Val Loss: 0.897836\n",
      "Epoch [400/500] | Train Loss: 0.291591 | Val Loss: 0.907674\n",
      "Epoch [500/500] | Train Loss: 0.295977 | Val Loss: 0.905842\n",
      "Epoch [100/500] | Train Loss: 0.675261 | Val Loss: 0.277447\n",
      "Epoch [200/500] | Train Loss: 0.614827 | Val Loss: 0.271524\n",
      "Epoch [300/500] | Train Loss: 0.466203 | Val Loss: 0.291672\n",
      "Epoch [400/500] | Train Loss: 0.496376 | Val Loss: 0.303068\n",
      "Epoch [500/500] | Train Loss: 0.419647 | Val Loss: 0.293824\n",
      "Epoch [100/500] | Train Loss: 0.504883 | Val Loss: 0.421753\n",
      "Epoch [200/500] | Train Loss: 0.493513 | Val Loss: 0.424883\n",
      "Epoch [300/500] | Train Loss: 0.437697 | Val Loss: 0.423270\n",
      "Epoch [400/500] | Train Loss: 0.411573 | Val Loss: 0.430894\n",
      "Epoch [500/500] | Train Loss: 0.397498 | Val Loss: 0.432689\n",
      "Epoch [100/500] | Train Loss: 0.517672 | Val Loss: 0.291246\n",
      "Epoch [200/500] | Train Loss: 0.474186 | Val Loss: 0.290029\n",
      "Epoch [300/500] | Train Loss: 0.423750 | Val Loss: 0.289142\n",
      "Epoch [400/500] | Train Loss: 0.418292 | Val Loss: 0.287716\n",
      "Epoch [500/500] | Train Loss: 0.414309 | Val Loss: 0.283840\n",
      "Epoch [100/500] | Train Loss: 0.479147 | Val Loss: 0.998249\n",
      "Epoch [200/500] | Train Loss: 0.422113 | Val Loss: 0.971561\n",
      "Epoch [300/500] | Train Loss: 0.414302 | Val Loss: 0.970388\n",
      "Epoch [400/500] | Train Loss: 0.379259 | Val Loss: 0.967802\n",
      "Epoch [500/500] | Train Loss: 0.397505 | Val Loss: 0.947163\n",
      "Epoch [100/500] | Train Loss: 0.281559 | Val Loss: 0.961782\n",
      "Epoch [200/500] | Train Loss: 0.215850 | Val Loss: 1.082616\n",
      "Epoch [300/500] | Train Loss: 0.198772 | Val Loss: 1.147586\n",
      "Epoch [400/500] | Train Loss: 0.166793 | Val Loss: 1.151857\n",
      "Epoch [500/500] | Train Loss: 0.160611 | Val Loss: 1.149694\n",
      "Epoch [100/500] | Train Loss: 0.461022 | Val Loss: 0.279878\n",
      "Epoch [200/500] | Train Loss: 0.399806 | Val Loss: 0.311027\n",
      "Epoch [300/500] | Train Loss: 0.351030 | Val Loss: 0.324010\n",
      "Epoch [400/500] | Train Loss: 0.354284 | Val Loss: 0.333098\n",
      "Epoch [500/500] | Train Loss: 0.328118 | Val Loss: 0.348246\n",
      "Epoch [100/500] | Train Loss: 0.385628 | Val Loss: 0.428847\n",
      "Epoch [200/500] | Train Loss: 0.374225 | Val Loss: 0.462696\n",
      "Epoch [300/500] | Train Loss: 0.360257 | Val Loss: 0.470153\n",
      "Epoch [400/500] | Train Loss: 0.332467 | Val Loss: 0.479315\n",
      "Epoch [500/500] | Train Loss: 0.295339 | Val Loss: 0.479774\n",
      "Epoch [100/500] | Train Loss: 0.376390 | Val Loss: 0.288192\n",
      "Epoch [200/500] | Train Loss: 0.362105 | Val Loss: 0.307546\n",
      "Epoch [300/500] | Train Loss: 0.339944 | Val Loss: 0.302012\n",
      "Epoch [400/500] | Train Loss: 0.346014 | Val Loss: 0.314307\n",
      "Epoch [500/500] | Train Loss: 0.313781 | Val Loss: 0.313676\n",
      "Epoch [100/500] | Train Loss: 0.387247 | Val Loss: 0.972573\n",
      "Epoch [200/500] | Train Loss: 0.356222 | Val Loss: 1.008644\n",
      "Epoch [300/500] | Train Loss: 0.355601 | Val Loss: 1.018637\n",
      "Epoch [400/500] | Train Loss: 0.343380 | Val Loss: 1.065776\n",
      "Epoch [500/500] | Train Loss: 0.358199 | Val Loss: 1.067551\n",
      "[Year=1974] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.568532 Test MSE=1.696230\n",
      "Year 1974 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.837371 | Val Loss: 0.365205\n",
      "Epoch [200/500] | Train Loss: 0.607470 | Val Loss: 0.405804\n",
      "Epoch [300/500] | Train Loss: 0.549279 | Val Loss: 0.414415\n",
      "Epoch [400/500] | Train Loss: 0.504200 | Val Loss: 0.450898\n",
      "Epoch [500/500] | Train Loss: 0.447995 | Val Loss: 0.459598\n",
      "Epoch [100/500] | Train Loss: 0.579417 | Val Loss: 0.312453\n",
      "Epoch [200/500] | Train Loss: 0.491153 | Val Loss: 0.319102\n",
      "Epoch [300/500] | Train Loss: 0.465154 | Val Loss: 0.319024\n",
      "Epoch [400/500] | Train Loss: 0.398103 | Val Loss: 0.321010\n",
      "Epoch [500/500] | Train Loss: 0.386615 | Val Loss: 0.318268\n",
      "Epoch [100/500] | Train Loss: 0.506782 | Val Loss: 0.372547\n",
      "Epoch [200/500] | Train Loss: 0.454787 | Val Loss: 0.391550\n",
      "Epoch [300/500] | Train Loss: 0.392984 | Val Loss: 0.386852\n",
      "Epoch [400/500] | Train Loss: 0.384974 | Val Loss: 0.383395\n",
      "Epoch [500/500] | Train Loss: 0.384042 | Val Loss: 0.380080\n",
      "Epoch [100/500] | Train Loss: 0.479499 | Val Loss: 1.060596\n",
      "Epoch [200/500] | Train Loss: 0.463984 | Val Loss: 1.027966\n",
      "Epoch [300/500] | Train Loss: 0.409482 | Val Loss: 1.037133\n",
      "Epoch [400/500] | Train Loss: 0.387034 | Val Loss: 1.076403\n",
      "Epoch [500/500] | Train Loss: 0.359519 | Val Loss: 1.107697\n",
      "Epoch [100/500] | Train Loss: 0.578465 | Val Loss: 1.705154\n",
      "Epoch [200/500] | Train Loss: 0.528172 | Val Loss: 1.836681\n",
      "Epoch [300/500] | Train Loss: 0.496823 | Val Loss: 2.011535\n",
      "Epoch [400/500] | Train Loss: 0.468857 | Val Loss: 2.129630\n",
      "Epoch [500/500] | Train Loss: 0.428110 | Val Loss: 2.132630\n",
      "Epoch [100/500] | Train Loss: 0.515949 | Val Loss: 0.397553\n",
      "Epoch [200/500] | Train Loss: 0.425299 | Val Loss: 0.456426\n",
      "Epoch [300/500] | Train Loss: 0.326624 | Val Loss: 0.570695\n",
      "Epoch [400/500] | Train Loss: 0.291846 | Val Loss: 0.559036\n",
      "Epoch [500/500] | Train Loss: 0.333755 | Val Loss: 0.627197\n",
      "Epoch [100/500] | Train Loss: 0.407943 | Val Loss: 0.331582\n",
      "Epoch [200/500] | Train Loss: 0.338068 | Val Loss: 0.370000\n",
      "Epoch [300/500] | Train Loss: 0.279256 | Val Loss: 0.361921\n",
      "Epoch [400/500] | Train Loss: 0.280372 | Val Loss: 0.397222\n",
      "Epoch [500/500] | Train Loss: 0.252937 | Val Loss: 0.396985\n",
      "Epoch [100/500] | Train Loss: 0.345512 | Val Loss: 0.408729\n",
      "Epoch [200/500] | Train Loss: 0.338660 | Val Loss: 0.432476\n",
      "Epoch [300/500] | Train Loss: 0.302438 | Val Loss: 0.425424\n",
      "Epoch [400/500] | Train Loss: 0.290623 | Val Loss: 0.440415\n",
      "Epoch [500/500] | Train Loss: 0.249385 | Val Loss: 0.462671\n",
      "Epoch [100/500] | Train Loss: 0.370434 | Val Loss: 1.141196\n",
      "Epoch [200/500] | Train Loss: 0.351460 | Val Loss: 1.266637\n",
      "Epoch [300/500] | Train Loss: 0.306396 | Val Loss: 1.203321\n",
      "Epoch [400/500] | Train Loss: 0.307539 | Val Loss: 1.229206\n",
      "Epoch [500/500] | Train Loss: 0.276893 | Val Loss: 1.259113\n",
      "Epoch [100/500] | Train Loss: 0.477256 | Val Loss: 1.966698\n",
      "Epoch [200/500] | Train Loss: 0.423554 | Val Loss: 2.058712\n",
      "Epoch [300/500] | Train Loss: 0.389983 | Val Loss: 2.197568\n",
      "Epoch [400/500] | Train Loss: 0.374870 | Val Loss: 2.288329\n",
      "Epoch [500/500] | Train Loss: 0.373377 | Val Loss: 2.212043\n",
      "Epoch [100/500] | Train Loss: 0.873411 | Val Loss: 0.355321\n",
      "Epoch [200/500] | Train Loss: 0.765125 | Val Loss: 0.370770\n",
      "Epoch [300/500] | Train Loss: 0.577693 | Val Loss: 0.384419\n",
      "Epoch [400/500] | Train Loss: 0.625254 | Val Loss: 0.380763\n",
      "Epoch [500/500] | Train Loss: 0.625258 | Val Loss: 0.376019\n",
      "Epoch [100/500] | Train Loss: 0.607766 | Val Loss: 0.305858\n",
      "Epoch [200/500] | Train Loss: 0.551447 | Val Loss: 0.305620\n",
      "Epoch [300/500] | Train Loss: 0.496161 | Val Loss: 0.311019\n",
      "Epoch [400/500] | Train Loss: 0.526700 | Val Loss: 0.317770\n",
      "Epoch [500/500] | Train Loss: 0.462114 | Val Loss: 0.320262\n",
      "Epoch [100/500] | Train Loss: 0.529466 | Val Loss: 0.370051\n",
      "Epoch [200/500] | Train Loss: 0.486059 | Val Loss: 0.379166\n",
      "Epoch [300/500] | Train Loss: 0.437096 | Val Loss: 0.387201\n",
      "Epoch [400/500] | Train Loss: 0.423973 | Val Loss: 0.392585\n",
      "Epoch [500/500] | Train Loss: 0.403703 | Val Loss: 0.392740\n",
      "Epoch [100/500] | Train Loss: 0.500923 | Val Loss: 1.038299\n",
      "Epoch [200/500] | Train Loss: 0.445888 | Val Loss: 1.018729\n",
      "Epoch [300/500] | Train Loss: 0.441705 | Val Loss: 1.032306\n",
      "Epoch [400/500] | Train Loss: 0.401937 | Val Loss: 1.017081\n",
      "Epoch [500/500] | Train Loss: 0.371148 | Val Loss: 1.038918\n",
      "Epoch [100/500] | Train Loss: 0.606285 | Val Loss: 1.750588\n",
      "Epoch [200/500] | Train Loss: 0.570369 | Val Loss: 1.760773\n",
      "Epoch [300/500] | Train Loss: 0.560258 | Val Loss: 1.775633\n",
      "Epoch [400/500] | Train Loss: 0.533427 | Val Loss: 1.788713\n",
      "Epoch [500/500] | Train Loss: 0.543038 | Val Loss: 1.809324\n",
      "Epoch [100/500] | Train Loss: 0.583232 | Val Loss: 0.395270\n",
      "Epoch [200/500] | Train Loss: 0.462421 | Val Loss: 0.510912\n",
      "Epoch [300/500] | Train Loss: 0.460163 | Val Loss: 0.469229\n",
      "Epoch [400/500] | Train Loss: 0.510381 | Val Loss: 0.487587\n",
      "Epoch [500/500] | Train Loss: 0.498172 | Val Loss: 0.503488\n",
      "Epoch [100/500] | Train Loss: 0.477062 | Val Loss: 0.323429\n",
      "Epoch [200/500] | Train Loss: 0.401578 | Val Loss: 0.309175\n",
      "Epoch [300/500] | Train Loss: 0.389493 | Val Loss: 0.323598\n",
      "Epoch [400/500] | Train Loss: 0.395192 | Val Loss: 0.338439\n",
      "Epoch [500/500] | Train Loss: 0.390426 | Val Loss: 0.334134\n",
      "Epoch [100/500] | Train Loss: 0.417376 | Val Loss: 0.399758\n",
      "Epoch [200/500] | Train Loss: 0.364265 | Val Loss: 0.410789\n",
      "Epoch [300/500] | Train Loss: 0.379344 | Val Loss: 0.398422\n",
      "Epoch [400/500] | Train Loss: 0.318949 | Val Loss: 0.414022\n",
      "Epoch [500/500] | Train Loss: 0.369963 | Val Loss: 0.417313\n",
      "Epoch [100/500] | Train Loss: 0.422801 | Val Loss: 1.044835\n",
      "Epoch [200/500] | Train Loss: 0.365073 | Val Loss: 1.058154\n",
      "Epoch [300/500] | Train Loss: 0.364807 | Val Loss: 1.081112\n",
      "Epoch [400/500] | Train Loss: 0.396568 | Val Loss: 1.120835\n",
      "Epoch [500/500] | Train Loss: 0.365887 | Val Loss: 1.136112\n",
      "Epoch [100/500] | Train Loss: 0.504722 | Val Loss: 1.857849\n",
      "Epoch [200/500] | Train Loss: 0.482953 | Val Loss: 2.010988\n",
      "Epoch [300/500] | Train Loss: 0.447175 | Val Loss: 1.995771\n",
      "Epoch [400/500] | Train Loss: 0.460078 | Val Loss: 1.923000\n",
      "Epoch [500/500] | Train Loss: 0.460013 | Val Loss: 1.959650\n",
      "Epoch [100/500] | Train Loss: 0.770465 | Val Loss: 0.360261\n",
      "Epoch [200/500] | Train Loss: 0.521864 | Val Loss: 0.386750\n",
      "Epoch [300/500] | Train Loss: 0.450560 | Val Loss: 0.432814\n",
      "Epoch [400/500] | Train Loss: 0.379927 | Val Loss: 0.479431\n",
      "Epoch [500/500] | Train Loss: 0.296481 | Val Loss: 0.518278\n",
      "Epoch [100/500] | Train Loss: 0.568946 | Val Loss: 0.301112\n",
      "Epoch [200/500] | Train Loss: 0.459072 | Val Loss: 0.325959\n",
      "Epoch [300/500] | Train Loss: 0.474874 | Val Loss: 0.325465\n",
      "Epoch [400/500] | Train Loss: 0.375319 | Val Loss: 0.326338\n",
      "Epoch [500/500] | Train Loss: 0.347383 | Val Loss: 0.325906\n",
      "Epoch [100/500] | Train Loss: 0.460984 | Val Loss: 0.386822\n",
      "Epoch [200/500] | Train Loss: 0.408313 | Val Loss: 0.405405\n",
      "Epoch [300/500] | Train Loss: 0.369547 | Val Loss: 0.400469\n",
      "Epoch [400/500] | Train Loss: 0.340290 | Val Loss: 0.408609\n",
      "Epoch [500/500] | Train Loss: 0.317186 | Val Loss: 0.413405\n",
      "Epoch [100/500] | Train Loss: 0.455782 | Val Loss: 1.021398\n",
      "Epoch [200/500] | Train Loss: 0.402163 | Val Loss: 1.080946\n",
      "Epoch [300/500] | Train Loss: 0.370200 | Val Loss: 1.101149\n",
      "Epoch [400/500] | Train Loss: 0.342344 | Val Loss: 1.157933\n",
      "Epoch [500/500] | Train Loss: 0.332482 | Val Loss: 1.188604\n",
      "Epoch [100/500] | Train Loss: 0.566538 | Val Loss: 1.722651\n",
      "Epoch [200/500] | Train Loss: 0.524012 | Val Loss: 1.868576\n",
      "Epoch [300/500] | Train Loss: 0.489827 | Val Loss: 2.026340\n",
      "Epoch [400/500] | Train Loss: 0.461667 | Val Loss: 2.065830\n",
      "Epoch [500/500] | Train Loss: 0.429626 | Val Loss: 2.155967\n",
      "Epoch [100/500] | Train Loss: 0.368195 | Val Loss: 0.464148\n",
      "Epoch [200/500] | Train Loss: 0.239921 | Val Loss: 0.669772\n",
      "Epoch [300/500] | Train Loss: 0.225133 | Val Loss: 0.747550\n",
      "Epoch [400/500] | Train Loss: 0.202357 | Val Loss: 0.753567\n",
      "Epoch [500/500] | Train Loss: 0.155379 | Val Loss: 0.897801\n",
      "Epoch [100/500] | Train Loss: 0.357089 | Val Loss: 0.330888\n",
      "Epoch [200/500] | Train Loss: 0.287419 | Val Loss: 0.378052\n",
      "Epoch [300/500] | Train Loss: 0.242975 | Val Loss: 0.403681\n",
      "Epoch [400/500] | Train Loss: 0.213675 | Val Loss: 0.404076\n",
      "Epoch [500/500] | Train Loss: 0.211911 | Val Loss: 0.397833\n",
      "Epoch [100/500] | Train Loss: 0.354289 | Val Loss: 0.400470\n",
      "Epoch [200/500] | Train Loss: 0.307714 | Val Loss: 0.446053\n",
      "Epoch [300/500] | Train Loss: 0.270348 | Val Loss: 0.466543\n",
      "Epoch [400/500] | Train Loss: 0.258960 | Val Loss: 0.465902\n",
      "Epoch [500/500] | Train Loss: 0.248453 | Val Loss: 0.462248\n",
      "Epoch [100/500] | Train Loss: 0.345877 | Val Loss: 1.197583\n",
      "Epoch [200/500] | Train Loss: 0.291491 | Val Loss: 1.364440\n",
      "Epoch [300/500] | Train Loss: 0.268692 | Val Loss: 1.344554\n",
      "Epoch [400/500] | Train Loss: 0.247140 | Val Loss: 1.454748\n",
      "Epoch [500/500] | Train Loss: 0.226921 | Val Loss: 1.593967\n",
      "Epoch [100/500] | Train Loss: 0.471617 | Val Loss: 1.954857\n",
      "Epoch [200/500] | Train Loss: 0.403862 | Val Loss: 2.090782\n",
      "Epoch [300/500] | Train Loss: 0.372244 | Val Loss: 2.205057\n",
      "Epoch [400/500] | Train Loss: 0.336197 | Val Loss: 2.207495\n",
      "Epoch [500/500] | Train Loss: 0.314457 | Val Loss: 2.337018\n",
      "Epoch [100/500] | Train Loss: 0.912842 | Val Loss: 0.355884\n",
      "Epoch [200/500] | Train Loss: 0.667781 | Val Loss: 0.371304\n",
      "Epoch [300/500] | Train Loss: 0.648415 | Val Loss: 0.382191\n",
      "Epoch [400/500] | Train Loss: 0.588776 | Val Loss: 0.387677\n",
      "Epoch [500/500] | Train Loss: 0.511488 | Val Loss: 0.402565\n",
      "Epoch [100/500] | Train Loss: 0.639417 | Val Loss: 0.306781\n",
      "Epoch [200/500] | Train Loss: 0.570101 | Val Loss: 0.313842\n",
      "Epoch [300/500] | Train Loss: 0.490588 | Val Loss: 0.320566\n",
      "Epoch [400/500] | Train Loss: 0.491859 | Val Loss: 0.318908\n",
      "Epoch [500/500] | Train Loss: 0.440144 | Val Loss: 0.317743\n",
      "Epoch [100/500] | Train Loss: 0.524768 | Val Loss: 0.366846\n",
      "Epoch [200/500] | Train Loss: 0.456688 | Val Loss: 0.398188\n",
      "Epoch [300/500] | Train Loss: 0.437959 | Val Loss: 0.400980\n",
      "Epoch [400/500] | Train Loss: 0.394566 | Val Loss: 0.406149\n",
      "Epoch [500/500] | Train Loss: 0.367246 | Val Loss: 0.415228\n",
      "Epoch [100/500] | Train Loss: 0.466761 | Val Loss: 1.027277\n",
      "Epoch [200/500] | Train Loss: 0.441331 | Val Loss: 1.013083\n",
      "Epoch [300/500] | Train Loss: 0.413946 | Val Loss: 1.022762\n",
      "Epoch [400/500] | Train Loss: 0.392552 | Val Loss: 1.037103\n",
      "Epoch [500/500] | Train Loss: 0.407859 | Val Loss: 1.042050\n",
      "Epoch [100/500] | Train Loss: 0.617319 | Val Loss: 1.713651\n",
      "Epoch [200/500] | Train Loss: 0.562590 | Val Loss: 1.773702\n",
      "Epoch [300/500] | Train Loss: 0.544361 | Val Loss: 1.866059\n",
      "Epoch [400/500] | Train Loss: 0.513925 | Val Loss: 1.892834\n",
      "Epoch [500/500] | Train Loss: 0.464459 | Val Loss: 1.959947\n",
      "Epoch [100/500] | Train Loss: 0.601041 | Val Loss: 0.376505\n",
      "Epoch [200/500] | Train Loss: 0.434974 | Val Loss: 0.487339\n",
      "Epoch [300/500] | Train Loss: 0.428240 | Val Loss: 0.481654\n",
      "Epoch [400/500] | Train Loss: 0.465589 | Val Loss: 0.518201\n",
      "Epoch [500/500] | Train Loss: 0.319935 | Val Loss: 0.510987\n",
      "Epoch [100/500] | Train Loss: 0.463766 | Val Loss: 0.311390\n",
      "Epoch [200/500] | Train Loss: 0.419777 | Val Loss: 0.327945\n",
      "Epoch [300/500] | Train Loss: 0.377894 | Val Loss: 0.350433\n",
      "Epoch [400/500] | Train Loss: 0.342452 | Val Loss: 0.346682\n",
      "Epoch [500/500] | Train Loss: 0.332106 | Val Loss: 0.362287\n",
      "Epoch [100/500] | Train Loss: 0.419952 | Val Loss: 0.413274\n",
      "Epoch [200/500] | Train Loss: 0.362097 | Val Loss: 0.447631\n",
      "Epoch [300/500] | Train Loss: 0.340502 | Val Loss: 0.434292\n",
      "Epoch [400/500] | Train Loss: 0.339308 | Val Loss: 0.433497\n",
      "Epoch [500/500] | Train Loss: 0.309189 | Val Loss: 0.444902\n",
      "Epoch [100/500] | Train Loss: 0.399398 | Val Loss: 1.038691\n",
      "Epoch [200/500] | Train Loss: 0.351972 | Val Loss: 1.120480\n",
      "Epoch [300/500] | Train Loss: 0.319978 | Val Loss: 1.179724\n",
      "Epoch [400/500] | Train Loss: 0.289606 | Val Loss: 1.153751\n",
      "Epoch [500/500] | Train Loss: 0.287100 | Val Loss: 1.152318\n",
      "Epoch [100/500] | Train Loss: 0.517921 | Val Loss: 1.897278\n",
      "Epoch [200/500] | Train Loss: 0.468733 | Val Loss: 1.978553\n",
      "Epoch [300/500] | Train Loss: 0.448915 | Val Loss: 2.089061\n",
      "Epoch [400/500] | Train Loss: 0.415244 | Val Loss: 1.966501\n",
      "Epoch [500/500] | Train Loss: 0.417747 | Val Loss: 1.940671\n",
      "[Year=1975] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.787453 Test MSE=0.832244\n",
      "Year 1975 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.340354 | Val Loss: 0.304804\n",
      "Epoch [200/500] | Train Loss: 0.291567 | Val Loss: 0.313584\n",
      "Epoch [300/500] | Train Loss: 0.250993 | Val Loss: 0.323884\n",
      "Epoch [400/500] | Train Loss: 0.211292 | Val Loss: 0.335131\n",
      "Epoch [500/500] | Train Loss: 0.188640 | Val Loss: 0.343250\n",
      "Epoch [100/500] | Train Loss: 0.332731 | Val Loss: 0.570918\n",
      "Epoch [200/500] | Train Loss: 0.311119 | Val Loss: 0.578703\n",
      "Epoch [300/500] | Train Loss: 0.274167 | Val Loss: 0.611176\n",
      "Epoch [400/500] | Train Loss: 0.271141 | Val Loss: 0.636697\n",
      "Epoch [500/500] | Train Loss: 0.238923 | Val Loss: 0.627174\n",
      "Epoch [100/500] | Train Loss: 0.380302 | Val Loss: 0.979900\n",
      "Epoch [200/500] | Train Loss: 0.367839 | Val Loss: 0.964279\n",
      "Epoch [300/500] | Train Loss: 0.329150 | Val Loss: 0.998838\n",
      "Epoch [400/500] | Train Loss: 0.332060 | Val Loss: 1.047959\n",
      "Epoch [500/500] | Train Loss: 0.294569 | Val Loss: 1.090810\n",
      "Epoch [100/500] | Train Loss: 0.514986 | Val Loss: 1.857488\n",
      "Epoch [200/500] | Train Loss: 0.490577 | Val Loss: 1.950331\n",
      "Epoch [300/500] | Train Loss: 0.470966 | Val Loss: 2.039523\n",
      "Epoch [400/500] | Train Loss: 0.426094 | Val Loss: 2.086730\n",
      "Epoch [500/500] | Train Loss: 0.416860 | Val Loss: 2.113846\n",
      "Epoch [100/500] | Train Loss: 0.781616 | Val Loss: 0.701085\n",
      "Epoch [200/500] | Train Loss: 0.741874 | Val Loss: 0.699084\n",
      "Epoch [300/500] | Train Loss: 0.704539 | Val Loss: 0.730673\n",
      "Epoch [400/500] | Train Loss: 0.669997 | Val Loss: 0.762304\n",
      "Epoch [500/500] | Train Loss: 0.650951 | Val Loss: 0.778349\n",
      "Epoch [100/500] | Train Loss: 0.238265 | Val Loss: 0.348984\n",
      "Epoch [200/500] | Train Loss: 0.178219 | Val Loss: 0.406838\n",
      "Epoch [300/500] | Train Loss: 0.135385 | Val Loss: 0.443555\n",
      "Epoch [400/500] | Train Loss: 0.156656 | Val Loss: 0.450131\n",
      "Epoch [500/500] | Train Loss: 0.118071 | Val Loss: 0.486641\n",
      "Epoch [100/500] | Train Loss: 0.250341 | Val Loss: 0.578352\n",
      "Epoch [200/500] | Train Loss: 0.205500 | Val Loss: 0.587103\n",
      "Epoch [300/500] | Train Loss: 0.204055 | Val Loss: 0.621411\n",
      "Epoch [400/500] | Train Loss: 0.191413 | Val Loss: 0.611194\n",
      "Epoch [500/500] | Train Loss: 0.193811 | Val Loss: 0.625520\n",
      "Epoch [100/500] | Train Loss: 0.310279 | Val Loss: 1.198883\n",
      "Epoch [200/500] | Train Loss: 0.238803 | Val Loss: 1.426365\n",
      "Epoch [300/500] | Train Loss: 0.221811 | Val Loss: 1.439760\n",
      "Epoch [400/500] | Train Loss: 0.207587 | Val Loss: 1.495164\n",
      "Epoch [500/500] | Train Loss: 0.205506 | Val Loss: 1.504065\n",
      "Epoch [100/500] | Train Loss: 0.412226 | Val Loss: 2.228701\n",
      "Epoch [200/500] | Train Loss: 0.375439 | Val Loss: 2.600859\n",
      "Epoch [300/500] | Train Loss: 0.344991 | Val Loss: 2.639403\n",
      "Epoch [400/500] | Train Loss: 0.288426 | Val Loss: 2.729791\n",
      "Epoch [500/500] | Train Loss: 0.298381 | Val Loss: 2.718957\n",
      "Epoch [100/500] | Train Loss: 0.616622 | Val Loss: 0.744019\n",
      "Epoch [200/500] | Train Loss: 0.581878 | Val Loss: 0.784970\n",
      "Epoch [300/500] | Train Loss: 0.496997 | Val Loss: 0.798641\n",
      "Epoch [400/500] | Train Loss: 0.479566 | Val Loss: 0.852502\n",
      "Epoch [500/500] | Train Loss: 0.481641 | Val Loss: 0.823149\n",
      "Epoch [100/500] | Train Loss: 0.346035 | Val Loss: 0.304112\n",
      "Epoch [200/500] | Train Loss: 0.309704 | Val Loss: 0.318320\n",
      "Epoch [300/500] | Train Loss: 0.293722 | Val Loss: 0.320996\n",
      "Epoch [400/500] | Train Loss: 0.255355 | Val Loss: 0.316731\n",
      "Epoch [500/500] | Train Loss: 0.275590 | Val Loss: 0.320611\n",
      "Epoch [100/500] | Train Loss: 0.308472 | Val Loss: 0.555567\n",
      "Epoch [200/500] | Train Loss: 0.299278 | Val Loss: 0.567046\n",
      "Epoch [300/500] | Train Loss: 0.296352 | Val Loss: 0.581306\n",
      "Epoch [400/500] | Train Loss: 0.285073 | Val Loss: 0.607011\n",
      "Epoch [500/500] | Train Loss: 0.260383 | Val Loss: 0.612037\n",
      "Epoch [100/500] | Train Loss: 0.398211 | Val Loss: 0.996794\n",
      "Epoch [200/500] | Train Loss: 0.384572 | Val Loss: 0.963882\n",
      "Epoch [300/500] | Train Loss: 0.367034 | Val Loss: 0.966193\n",
      "Epoch [400/500] | Train Loss: 0.357522 | Val Loss: 0.990681\n",
      "Epoch [500/500] | Train Loss: 0.355263 | Val Loss: 1.011265\n",
      "Epoch [100/500] | Train Loss: 0.537853 | Val Loss: 1.867903\n",
      "Epoch [200/500] | Train Loss: 0.499669 | Val Loss: 1.940729\n",
      "Epoch [300/500] | Train Loss: 0.493665 | Val Loss: 2.016091\n",
      "Epoch [400/500] | Train Loss: 0.451065 | Val Loss: 2.060447\n",
      "Epoch [500/500] | Train Loss: 0.460926 | Val Loss: 2.105347\n",
      "Epoch [100/500] | Train Loss: 0.800257 | Val Loss: 0.702889\n",
      "Epoch [200/500] | Train Loss: 0.778672 | Val Loss: 0.699458\n",
      "Epoch [300/500] | Train Loss: 0.764413 | Val Loss: 0.700213\n",
      "Epoch [400/500] | Train Loss: 0.749857 | Val Loss: 0.711663\n",
      "Epoch [500/500] | Train Loss: 0.733875 | Val Loss: 0.717434\n",
      "Epoch [100/500] | Train Loss: 0.239166 | Val Loss: 0.365585\n",
      "Epoch [200/500] | Train Loss: 0.177310 | Val Loss: 0.357019\n",
      "Epoch [300/500] | Train Loss: 0.225230 | Val Loss: 0.371275\n",
      "Epoch [400/500] | Train Loss: 0.220338 | Val Loss: 0.371232\n",
      "Epoch [500/500] | Train Loss: 0.197692 | Val Loss: 0.399722\n",
      "Epoch [100/500] | Train Loss: 0.285161 | Val Loss: 0.586219\n",
      "Epoch [200/500] | Train Loss: 0.241371 | Val Loss: 0.588171\n",
      "Epoch [300/500] | Train Loss: 0.249730 | Val Loss: 0.630767\n",
      "Epoch [400/500] | Train Loss: 0.201012 | Val Loss: 0.639559\n",
      "Epoch [500/500] | Train Loss: 0.203547 | Val Loss: 0.680682\n",
      "Epoch [100/500] | Train Loss: 0.340504 | Val Loss: 0.999311\n",
      "Epoch [200/500] | Train Loss: 0.314158 | Val Loss: 1.056211\n",
      "Epoch [300/500] | Train Loss: 0.300815 | Val Loss: 1.040174\n",
      "Epoch [400/500] | Train Loss: 0.291744 | Val Loss: 1.072335\n",
      "Epoch [500/500] | Train Loss: 0.289614 | Val Loss: 1.104902\n",
      "Epoch [100/500] | Train Loss: 0.482493 | Val Loss: 1.934034\n",
      "Epoch [200/500] | Train Loss: 0.418517 | Val Loss: 2.089150\n",
      "Epoch [300/500] | Train Loss: 0.426108 | Val Loss: 2.093843\n",
      "Epoch [400/500] | Train Loss: 0.409656 | Val Loss: 2.244215\n",
      "Epoch [500/500] | Train Loss: 0.361299 | Val Loss: 2.288839\n",
      "Epoch [100/500] | Train Loss: 0.722242 | Val Loss: 0.727662\n",
      "Epoch [200/500] | Train Loss: 0.660453 | Val Loss: 0.734074\n",
      "Epoch [300/500] | Train Loss: 0.626110 | Val Loss: 0.732178\n",
      "Epoch [400/500] | Train Loss: 0.601429 | Val Loss: 0.726725\n",
      "Epoch [500/500] | Train Loss: 0.610472 | Val Loss: 0.720447\n",
      "Epoch [100/500] | Train Loss: 0.303896 | Val Loss: 0.307503\n",
      "Epoch [200/500] | Train Loss: 0.240841 | Val Loss: 0.336778\n",
      "Epoch [300/500] | Train Loss: 0.219025 | Val Loss: 0.355738\n",
      "Epoch [400/500] | Train Loss: 0.189516 | Val Loss: 0.375355\n",
      "Epoch [500/500] | Train Loss: 0.196672 | Val Loss: 0.373549\n",
      "Epoch [100/500] | Train Loss: 0.301468 | Val Loss: 0.575558\n",
      "Epoch [200/500] | Train Loss: 0.280411 | Val Loss: 0.594873\n",
      "Epoch [300/500] | Train Loss: 0.235211 | Val Loss: 0.610967\n",
      "Epoch [400/500] | Train Loss: 0.211869 | Val Loss: 0.621152\n",
      "Epoch [500/500] | Train Loss: 0.204175 | Val Loss: 0.637230\n",
      "Epoch [100/500] | Train Loss: 0.432257 | Val Loss: 1.002035\n",
      "Epoch [200/500] | Train Loss: 0.396418 | Val Loss: 0.987929\n",
      "Epoch [300/500] | Train Loss: 0.327035 | Val Loss: 1.019328\n",
      "Epoch [400/500] | Train Loss: 0.323497 | Val Loss: 1.044430\n",
      "Epoch [500/500] | Train Loss: 0.314837 | Val Loss: 1.072355\n",
      "Epoch [100/500] | Train Loss: 0.510877 | Val Loss: 1.874304\n",
      "Epoch [200/500] | Train Loss: 0.454209 | Val Loss: 2.068862\n",
      "Epoch [300/500] | Train Loss: 0.418937 | Val Loss: 2.190150\n",
      "Epoch [400/500] | Train Loss: 0.391712 | Val Loss: 2.320224\n",
      "Epoch [500/500] | Train Loss: 0.368927 | Val Loss: 2.374701\n",
      "Epoch [100/500] | Train Loss: 0.788757 | Val Loss: 0.705337\n",
      "Epoch [200/500] | Train Loss: 0.704694 | Val Loss: 0.726636\n",
      "Epoch [300/500] | Train Loss: 0.648027 | Val Loss: 0.753855\n",
      "Epoch [400/500] | Train Loss: 0.593808 | Val Loss: 0.762053\n",
      "Epoch [500/500] | Train Loss: 0.552484 | Val Loss: 0.770372\n",
      "Epoch [100/500] | Train Loss: 0.227300 | Val Loss: 0.355993\n",
      "Epoch [200/500] | Train Loss: 0.196605 | Val Loss: 0.411045\n",
      "Epoch [300/500] | Train Loss: 0.132684 | Val Loss: 0.417497\n",
      "Epoch [400/500] | Train Loss: 0.112341 | Val Loss: 0.464778\n",
      "Epoch [500/500] | Train Loss: 0.103554 | Val Loss: 0.444040\n",
      "Epoch [100/500] | Train Loss: 0.300862 | Val Loss: 0.575040\n",
      "Epoch [200/500] | Train Loss: 0.213308 | Val Loss: 0.634889\n",
      "Epoch [300/500] | Train Loss: 0.175200 | Val Loss: 0.634150\n",
      "Epoch [400/500] | Train Loss: 0.161439 | Val Loss: 0.642424\n",
      "Epoch [500/500] | Train Loss: 0.137376 | Val Loss: 0.641131\n",
      "Epoch [100/500] | Train Loss: 0.292722 | Val Loss: 1.295572\n",
      "Epoch [200/500] | Train Loss: 0.241798 | Val Loss: 1.759170\n",
      "Epoch [300/500] | Train Loss: 0.221587 | Val Loss: 1.545536\n",
      "Epoch [400/500] | Train Loss: 0.201893 | Val Loss: 1.748768\n",
      "Epoch [500/500] | Train Loss: 0.172806 | Val Loss: 1.488177\n",
      "Epoch [100/500] | Train Loss: 0.421041 | Val Loss: 2.204786\n",
      "Epoch [200/500] | Train Loss: 0.341493 | Val Loss: 2.447959\n",
      "Epoch [300/500] | Train Loss: 0.303160 | Val Loss: 2.497483\n",
      "Epoch [400/500] | Train Loss: 0.277218 | Val Loss: 2.648077\n",
      "Epoch [500/500] | Train Loss: 0.246433 | Val Loss: 2.711731\n",
      "Epoch [100/500] | Train Loss: 0.642557 | Val Loss: 0.770023\n",
      "Epoch [200/500] | Train Loss: 0.534668 | Val Loss: 0.733737\n",
      "Epoch [300/500] | Train Loss: 0.479194 | Val Loss: 0.748916\n",
      "Epoch [400/500] | Train Loss: 0.438166 | Val Loss: 0.803519\n",
      "Epoch [500/500] | Train Loss: 0.430229 | Val Loss: 0.783995\n",
      "Epoch [100/500] | Train Loss: 0.317073 | Val Loss: 0.298036\n",
      "Epoch [200/500] | Train Loss: 0.284232 | Val Loss: 0.312656\n",
      "Epoch [300/500] | Train Loss: 0.269489 | Val Loss: 0.328676\n",
      "Epoch [400/500] | Train Loss: 0.255153 | Val Loss: 0.342568\n",
      "Epoch [500/500] | Train Loss: 0.198492 | Val Loss: 0.361799\n",
      "Epoch [100/500] | Train Loss: 0.313842 | Val Loss: 0.566716\n",
      "Epoch [200/500] | Train Loss: 0.292865 | Val Loss: 0.581464\n",
      "Epoch [300/500] | Train Loss: 0.275677 | Val Loss: 0.604207\n",
      "Epoch [400/500] | Train Loss: 0.253671 | Val Loss: 0.608699\n",
      "Epoch [500/500] | Train Loss: 0.254794 | Val Loss: 0.644141\n",
      "Epoch [100/500] | Train Loss: 0.394608 | Val Loss: 0.976415\n",
      "Epoch [200/500] | Train Loss: 0.364755 | Val Loss: 0.972298\n",
      "Epoch [300/500] | Train Loss: 0.352316 | Val Loss: 0.987500\n",
      "Epoch [400/500] | Train Loss: 0.344616 | Val Loss: 1.013594\n",
      "Epoch [500/500] | Train Loss: 0.336143 | Val Loss: 1.037528\n",
      "Epoch [100/500] | Train Loss: 0.534936 | Val Loss: 1.833123\n",
      "Epoch [200/500] | Train Loss: 0.513120 | Val Loss: 1.852582\n",
      "Epoch [300/500] | Train Loss: 0.503998 | Val Loss: 1.910705\n",
      "Epoch [400/500] | Train Loss: 0.481140 | Val Loss: 1.979882\n",
      "Epoch [500/500] | Train Loss: 0.452810 | Val Loss: 2.050490\n",
      "Epoch [100/500] | Train Loss: 0.810606 | Val Loss: 0.699680\n",
      "Epoch [200/500] | Train Loss: 0.775451 | Val Loss: 0.705427\n",
      "Epoch [300/500] | Train Loss: 0.751723 | Val Loss: 0.717111\n",
      "Epoch [400/500] | Train Loss: 0.702256 | Val Loss: 0.746543\n",
      "Epoch [500/500] | Train Loss: 0.652479 | Val Loss: 0.740604\n",
      "Epoch [100/500] | Train Loss: 0.266813 | Val Loss: 0.320002\n",
      "Epoch [200/500] | Train Loss: 0.202433 | Val Loss: 0.351221\n",
      "Epoch [300/500] | Train Loss: 0.145314 | Val Loss: 0.374657\n",
      "Epoch [400/500] | Train Loss: 0.151101 | Val Loss: 0.394738\n",
      "Epoch [500/500] | Train Loss: 0.177714 | Val Loss: 0.411727\n",
      "Epoch [100/500] | Train Loss: 0.279346 | Val Loss: 0.593331\n",
      "Epoch [200/500] | Train Loss: 0.252016 | Val Loss: 0.627296\n",
      "Epoch [300/500] | Train Loss: 0.216941 | Val Loss: 0.638077\n",
      "Epoch [400/500] | Train Loss: 0.200807 | Val Loss: 0.656782\n",
      "Epoch [500/500] | Train Loss: 0.179251 | Val Loss: 0.614464\n",
      "Epoch [100/500] | Train Loss: 0.349936 | Val Loss: 0.996317\n",
      "Epoch [200/500] | Train Loss: 0.278954 | Val Loss: 1.127375\n",
      "Epoch [300/500] | Train Loss: 0.249243 | Val Loss: 1.091250\n",
      "Epoch [400/500] | Train Loss: 0.227496 | Val Loss: 1.141289\n",
      "Epoch [500/500] | Train Loss: 0.239049 | Val Loss: 1.098708\n",
      "Epoch [100/500] | Train Loss: 0.485924 | Val Loss: 1.950506\n",
      "Epoch [200/500] | Train Loss: 0.427967 | Val Loss: 2.171993\n",
      "Epoch [300/500] | Train Loss: 0.376382 | Val Loss: 2.250719\n",
      "Epoch [400/500] | Train Loss: 0.359481 | Val Loss: 2.337806\n",
      "Epoch [500/500] | Train Loss: 0.365650 | Val Loss: 2.330870\n",
      "Epoch [100/500] | Train Loss: 0.659621 | Val Loss: 0.741478\n",
      "Epoch [200/500] | Train Loss: 0.596213 | Val Loss: 0.742073\n",
      "Epoch [300/500] | Train Loss: 0.524062 | Val Loss: 0.764652\n",
      "Epoch [400/500] | Train Loss: 0.532601 | Val Loss: 0.759986\n",
      "Epoch [500/500] | Train Loss: 0.490814 | Val Loss: 0.761287\n",
      "[Year=1976] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.953339 Test MSE=0.437978\n",
      "Year 1976 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.248690 | Val Loss: 0.613937\n",
      "Epoch [200/500] | Train Loss: 0.213046 | Val Loss: 0.640651\n",
      "Epoch [300/500] | Train Loss: 0.198493 | Val Loss: 0.640629\n",
      "Epoch [400/500] | Train Loss: 0.181018 | Val Loss: 0.673684\n",
      "Epoch [500/500] | Train Loss: 0.167603 | Val Loss: 0.733079\n",
      "Epoch [100/500] | Train Loss: 0.391362 | Val Loss: 1.100125\n",
      "Epoch [200/500] | Train Loss: 0.358414 | Val Loss: 1.176999\n",
      "Epoch [300/500] | Train Loss: 0.313625 | Val Loss: 1.295282\n",
      "Epoch [400/500] | Train Loss: 0.288013 | Val Loss: 1.465448\n",
      "Epoch [500/500] | Train Loss: 0.275394 | Val Loss: 1.664282\n",
      "Epoch [100/500] | Train Loss: 0.632333 | Val Loss: 1.836243\n",
      "Epoch [200/500] | Train Loss: 0.562955 | Val Loss: 1.897400\n",
      "Epoch [300/500] | Train Loss: 0.511863 | Val Loss: 2.081473\n",
      "Epoch [400/500] | Train Loss: 0.476061 | Val Loss: 2.184958\n",
      "Epoch [500/500] | Train Loss: 0.456043 | Val Loss: 2.266445\n",
      "Epoch [100/500] | Train Loss: 0.906654 | Val Loss: 0.671147\n",
      "Epoch [200/500] | Train Loss: 0.845801 | Val Loss: 0.712319\n",
      "Epoch [300/500] | Train Loss: 0.800229 | Val Loss: 0.713377\n",
      "Epoch [400/500] | Train Loss: 0.738122 | Val Loss: 0.710512\n",
      "Epoch [500/500] | Train Loss: 0.690498 | Val Loss: 0.722460\n",
      "Epoch [100/500] | Train Loss: 0.904339 | Val Loss: 0.370831\n",
      "Epoch [200/500] | Train Loss: 0.839343 | Val Loss: 0.384447\n",
      "Epoch [300/500] | Train Loss: 0.775417 | Val Loss: 0.384426\n",
      "Epoch [400/500] | Train Loss: 0.754383 | Val Loss: 0.380218\n",
      "Epoch [500/500] | Train Loss: 0.714664 | Val Loss: 0.385883\n",
      "Epoch [100/500] | Train Loss: 0.138509 | Val Loss: 0.977603\n",
      "Epoch [200/500] | Train Loss: 0.104121 | Val Loss: 1.039208\n",
      "Epoch [300/500] | Train Loss: 0.070734 | Val Loss: 1.090278\n",
      "Epoch [400/500] | Train Loss: 0.066289 | Val Loss: 0.970136\n",
      "Epoch [500/500] | Train Loss: 0.074541 | Val Loss: 1.141586\n",
      "Epoch [100/500] | Train Loss: 0.298052 | Val Loss: 1.239312\n",
      "Epoch [200/500] | Train Loss: 0.238609 | Val Loss: 1.421100\n",
      "Epoch [300/500] | Train Loss: 0.207709 | Val Loss: 1.387392\n",
      "Epoch [400/500] | Train Loss: 0.188923 | Val Loss: 1.436506\n",
      "Epoch [500/500] | Train Loss: 0.185543 | Val Loss: 1.375649\n",
      "Epoch [100/500] | Train Loss: 0.473412 | Val Loss: 2.191190\n",
      "Epoch [200/500] | Train Loss: 0.392212 | Val Loss: 2.425762\n",
      "Epoch [300/500] | Train Loss: 0.359943 | Val Loss: 2.636021\n",
      "Epoch [400/500] | Train Loss: 0.318813 | Val Loss: 2.672953\n",
      "Epoch [500/500] | Train Loss: 0.303492 | Val Loss: 2.642346\n",
      "Epoch [100/500] | Train Loss: 0.720002 | Val Loss: 0.745036\n",
      "Epoch [200/500] | Train Loss: 0.608139 | Val Loss: 0.767394\n",
      "Epoch [300/500] | Train Loss: 0.561359 | Val Loss: 0.767334\n",
      "Epoch [400/500] | Train Loss: 0.539659 | Val Loss: 0.741392\n",
      "Epoch [500/500] | Train Loss: 0.514109 | Val Loss: 0.783847\n",
      "Epoch [100/500] | Train Loss: 0.732013 | Val Loss: 0.373257\n",
      "Epoch [200/500] | Train Loss: 0.637866 | Val Loss: 0.393336\n",
      "Epoch [300/500] | Train Loss: 0.597571 | Val Loss: 0.398052\n",
      "Epoch [400/500] | Train Loss: 0.542192 | Val Loss: 0.424905\n",
      "Epoch [500/500] | Train Loss: 0.519410 | Val Loss: 0.427194\n",
      "Epoch [100/500] | Train Loss: 0.227289 | Val Loss: 0.599859\n",
      "Epoch [200/500] | Train Loss: 0.214995 | Val Loss: 0.602879\n",
      "Epoch [300/500] | Train Loss: 0.197207 | Val Loss: 0.635617\n",
      "Epoch [400/500] | Train Loss: 0.175959 | Val Loss: 0.677099\n",
      "Epoch [500/500] | Train Loss: 0.147953 | Val Loss: 0.730947\n",
      "Epoch [100/500] | Train Loss: 0.404434 | Val Loss: 1.115405\n",
      "Epoch [200/500] | Train Loss: 0.373373 | Val Loss: 1.104147\n",
      "Epoch [300/500] | Train Loss: 0.345057 | Val Loss: 1.108396\n",
      "Epoch [400/500] | Train Loss: 0.338910 | Val Loss: 1.175644\n",
      "Epoch [500/500] | Train Loss: 0.321938 | Val Loss: 1.224727\n",
      "Epoch [100/500] | Train Loss: 0.629764 | Val Loss: 1.822493\n",
      "Epoch [200/500] | Train Loss: 0.598924 | Val Loss: 1.847638\n",
      "Epoch [300/500] | Train Loss: 0.580475 | Val Loss: 1.846070\n",
      "Epoch [400/500] | Train Loss: 0.573029 | Val Loss: 1.881023\n",
      "Epoch [500/500] | Train Loss: 0.567427 | Val Loss: 1.911134\n",
      "Epoch [100/500] | Train Loss: 0.918062 | Val Loss: 0.684573\n",
      "Epoch [200/500] | Train Loss: 0.887320 | Val Loss: 0.685987\n",
      "Epoch [300/500] | Train Loss: 0.822074 | Val Loss: 0.702878\n",
      "Epoch [400/500] | Train Loss: 0.824631 | Val Loss: 0.717358\n",
      "Epoch [500/500] | Train Loss: 0.775196 | Val Loss: 0.721856\n",
      "Epoch [100/500] | Train Loss: 0.881669 | Val Loss: 0.370035\n",
      "Epoch [200/500] | Train Loss: 0.846578 | Val Loss: 0.382407\n",
      "Epoch [300/500] | Train Loss: 0.838156 | Val Loss: 0.378981\n",
      "Epoch [400/500] | Train Loss: 0.814911 | Val Loss: 0.382967\n",
      "Epoch [500/500] | Train Loss: 0.790355 | Val Loss: 0.383819\n",
      "Epoch [100/500] | Train Loss: 0.193936 | Val Loss: 0.662624\n",
      "Epoch [200/500] | Train Loss: 0.158725 | Val Loss: 0.689310\n",
      "Epoch [300/500] | Train Loss: 0.128281 | Val Loss: 0.719398\n",
      "Epoch [400/500] | Train Loss: 0.132240 | Val Loss: 0.696964\n",
      "Epoch [500/500] | Train Loss: 0.132690 | Val Loss: 0.702963\n",
      "Epoch [100/500] | Train Loss: 0.360183 | Val Loss: 1.281796\n",
      "Epoch [200/500] | Train Loss: 0.287899 | Val Loss: 1.418654\n",
      "Epoch [300/500] | Train Loss: 0.284212 | Val Loss: 1.397364\n",
      "Epoch [400/500] | Train Loss: 0.283776 | Val Loss: 1.421828\n",
      "Epoch [500/500] | Train Loss: 0.263920 | Val Loss: 1.382561\n",
      "Epoch [100/500] | Train Loss: 0.540172 | Val Loss: 1.969969\n",
      "Epoch [200/500] | Train Loss: 0.515601 | Val Loss: 2.070089\n",
      "Epoch [300/500] | Train Loss: 0.434228 | Val Loss: 2.070562\n",
      "Epoch [400/500] | Train Loss: 0.440741 | Val Loss: 2.174067\n",
      "Epoch [500/500] | Train Loss: 0.416228 | Val Loss: 2.076414\n",
      "Epoch [100/500] | Train Loss: 0.800253 | Val Loss: 0.706889\n",
      "Epoch [200/500] | Train Loss: 0.755077 | Val Loss: 0.735412\n",
      "Epoch [300/500] | Train Loss: 0.691740 | Val Loss: 0.746164\n",
      "Epoch [400/500] | Train Loss: 0.705133 | Val Loss: 0.747333\n",
      "Epoch [500/500] | Train Loss: 0.655744 | Val Loss: 0.754129\n",
      "Epoch [100/500] | Train Loss: 0.768573 | Val Loss: 0.390278\n",
      "Epoch [200/500] | Train Loss: 0.745761 | Val Loss: 0.392130\n",
      "Epoch [300/500] | Train Loss: 0.691826 | Val Loss: 0.403931\n",
      "Epoch [400/500] | Train Loss: 0.685073 | Val Loss: 0.416347\n",
      "Epoch [500/500] | Train Loss: 0.667820 | Val Loss: 0.447963\n",
      "Epoch [100/500] | Train Loss: 0.218377 | Val Loss: 0.643698\n",
      "Epoch [200/500] | Train Loss: 0.215640 | Val Loss: 0.698837\n",
      "Epoch [300/500] | Train Loss: 0.172007 | Val Loss: 0.881005\n",
      "Epoch [400/500] | Train Loss: 0.132076 | Val Loss: 0.966451\n",
      "Epoch [500/500] | Train Loss: 0.120687 | Val Loss: 1.030686\n",
      "Epoch [100/500] | Train Loss: 0.380120 | Val Loss: 1.112548\n",
      "Epoch [200/500] | Train Loss: 0.319286 | Val Loss: 1.233862\n",
      "Epoch [300/500] | Train Loss: 0.269120 | Val Loss: 1.408237\n",
      "Epoch [400/500] | Train Loss: 0.239635 | Val Loss: 1.443590\n",
      "Epoch [500/500] | Train Loss: 0.234405 | Val Loss: 1.540191\n",
      "Epoch [100/500] | Train Loss: 0.576816 | Val Loss: 1.882757\n",
      "Epoch [200/500] | Train Loss: 0.525269 | Val Loss: 2.035638\n",
      "Epoch [300/500] | Train Loss: 0.435375 | Val Loss: 2.223719\n",
      "Epoch [400/500] | Train Loss: 0.425723 | Val Loss: 2.292922\n",
      "Epoch [500/500] | Train Loss: 0.401167 | Val Loss: 2.414833\n",
      "Epoch [100/500] | Train Loss: 0.872365 | Val Loss: 0.700786\n",
      "Epoch [200/500] | Train Loss: 0.803401 | Val Loss: 0.726952\n",
      "Epoch [300/500] | Train Loss: 0.678608 | Val Loss: 0.761828\n",
      "Epoch [400/500] | Train Loss: 0.703220 | Val Loss: 0.767919\n",
      "Epoch [500/500] | Train Loss: 0.588847 | Val Loss: 0.766989\n",
      "Epoch [100/500] | Train Loss: 0.878024 | Val Loss: 0.377162\n",
      "Epoch [200/500] | Train Loss: 0.819396 | Val Loss: 0.381516\n",
      "Epoch [300/500] | Train Loss: 0.759467 | Val Loss: 0.380542\n",
      "Epoch [400/500] | Train Loss: 0.723114 | Val Loss: 0.380707\n",
      "Epoch [500/500] | Train Loss: 0.664387 | Val Loss: 0.373567\n",
      "Epoch [100/500] | Train Loss: 0.121637 | Val Loss: 0.754079\n",
      "Epoch [200/500] | Train Loss: 0.092934 | Val Loss: 0.765412\n",
      "Epoch [300/500] | Train Loss: 0.051757 | Val Loss: 0.790117\n",
      "Epoch [400/500] | Train Loss: 0.047941 | Val Loss: 0.735372\n",
      "Epoch [500/500] | Train Loss: 0.051171 | Val Loss: 0.786230\n",
      "Epoch [100/500] | Train Loss: 0.322012 | Val Loss: 1.243900\n",
      "Epoch [200/500] | Train Loss: 0.242561 | Val Loss: 1.473999\n",
      "Epoch [300/500] | Train Loss: 0.199620 | Val Loss: 1.474298\n",
      "Epoch [400/500] | Train Loss: 0.177042 | Val Loss: 1.396568\n",
      "Epoch [500/500] | Train Loss: 0.154566 | Val Loss: 1.524646\n",
      "Epoch [100/500] | Train Loss: 0.407921 | Val Loss: 2.609848\n",
      "Epoch [200/500] | Train Loss: 0.361590 | Val Loss: 2.576480\n",
      "Epoch [300/500] | Train Loss: 0.296104 | Val Loss: 2.529217\n",
      "Epoch [400/500] | Train Loss: 0.239366 | Val Loss: 2.651346\n",
      "Epoch [500/500] | Train Loss: 0.260549 | Val Loss: 2.627557\n",
      "Epoch [100/500] | Train Loss: 0.655513 | Val Loss: 0.786021\n",
      "Epoch [200/500] | Train Loss: 0.504280 | Val Loss: 0.809150\n",
      "Epoch [300/500] | Train Loss: 0.497795 | Val Loss: 0.833759\n",
      "Epoch [400/500] | Train Loss: 0.425184 | Val Loss: 0.831445\n",
      "Epoch [500/500] | Train Loss: 0.427263 | Val Loss: 0.823046\n",
      "Epoch [100/500] | Train Loss: 0.701416 | Val Loss: 0.383971\n",
      "Epoch [200/500] | Train Loss: 0.594906 | Val Loss: 0.407624\n",
      "Epoch [300/500] | Train Loss: 0.551998 | Val Loss: 0.419574\n",
      "Epoch [400/500] | Train Loss: 0.489493 | Val Loss: 0.470527\n",
      "Epoch [500/500] | Train Loss: 0.447627 | Val Loss: 0.472912\n",
      "Epoch [100/500] | Train Loss: 0.223750 | Val Loss: 0.606863\n",
      "Epoch [200/500] | Train Loss: 0.210297 | Val Loss: 0.605723\n",
      "Epoch [300/500] | Train Loss: 0.194119 | Val Loss: 0.630645\n",
      "Epoch [400/500] | Train Loss: 0.165319 | Val Loss: 0.687125\n",
      "Epoch [500/500] | Train Loss: 0.164046 | Val Loss: 0.724344\n",
      "Epoch [100/500] | Train Loss: 0.398824 | Val Loss: 1.136994\n",
      "Epoch [200/500] | Train Loss: 0.346512 | Val Loss: 1.176201\n",
      "Epoch [300/500] | Train Loss: 0.331672 | Val Loss: 1.240963\n",
      "Epoch [400/500] | Train Loss: 0.329801 | Val Loss: 1.295787\n",
      "Epoch [500/500] | Train Loss: 0.303001 | Val Loss: 1.336493\n",
      "Epoch [100/500] | Train Loss: 0.607481 | Val Loss: 1.851335\n",
      "Epoch [200/500] | Train Loss: 0.566297 | Val Loss: 1.916551\n",
      "Epoch [300/500] | Train Loss: 0.507401 | Val Loss: 2.003491\n",
      "Epoch [400/500] | Train Loss: 0.500121 | Val Loss: 2.113028\n",
      "Epoch [500/500] | Train Loss: 0.510440 | Val Loss: 2.162727\n",
      "Epoch [100/500] | Train Loss: 0.902274 | Val Loss: 0.683089\n",
      "Epoch [200/500] | Train Loss: 0.883834 | Val Loss: 0.687815\n",
      "Epoch [300/500] | Train Loss: 0.831170 | Val Loss: 0.687025\n",
      "Epoch [400/500] | Train Loss: 0.819777 | Val Loss: 0.692490\n",
      "Epoch [500/500] | Train Loss: 0.760812 | Val Loss: 0.696533\n",
      "Epoch [100/500] | Train Loss: 0.855837 | Val Loss: 0.373456\n",
      "Epoch [200/500] | Train Loss: 0.819714 | Val Loss: 0.378171\n",
      "Epoch [300/500] | Train Loss: 0.802831 | Val Loss: 0.373263\n",
      "Epoch [400/500] | Train Loss: 0.768455 | Val Loss: 0.379027\n",
      "Epoch [500/500] | Train Loss: 0.766947 | Val Loss: 0.393186\n",
      "Epoch [100/500] | Train Loss: 0.157436 | Val Loss: 0.690207\n",
      "Epoch [200/500] | Train Loss: 0.129085 | Val Loss: 0.668266\n",
      "Epoch [300/500] | Train Loss: 0.114515 | Val Loss: 0.678439\n",
      "Epoch [400/500] | Train Loss: 0.089490 | Val Loss: 0.691674\n",
      "Epoch [500/500] | Train Loss: 0.099103 | Val Loss: 0.731721\n",
      "Epoch [100/500] | Train Loss: 0.310467 | Val Loss: 1.268401\n",
      "Epoch [200/500] | Train Loss: 0.241965 | Val Loss: 1.485849\n",
      "Epoch [300/500] | Train Loss: 0.224280 | Val Loss: 1.396486\n",
      "Epoch [400/500] | Train Loss: 0.212622 | Val Loss: 1.360505\n",
      "Epoch [500/500] | Train Loss: 0.201175 | Val Loss: 1.333379\n",
      "Epoch [100/500] | Train Loss: 0.550081 | Val Loss: 2.025672\n",
      "Epoch [200/500] | Train Loss: 0.494972 | Val Loss: 2.247394\n",
      "Epoch [300/500] | Train Loss: 0.449831 | Val Loss: 2.248079\n",
      "Epoch [400/500] | Train Loss: 0.407403 | Val Loss: 2.316680\n",
      "Epoch [500/500] | Train Loss: 0.378057 | Val Loss: 2.326085\n",
      "Epoch [100/500] | Train Loss: 0.772158 | Val Loss: 0.722049\n",
      "Epoch [200/500] | Train Loss: 0.690437 | Val Loss: 0.713114\n",
      "Epoch [300/500] | Train Loss: 0.679714 | Val Loss: 0.731175\n",
      "Epoch [400/500] | Train Loss: 0.620143 | Val Loss: 0.726739\n",
      "Epoch [500/500] | Train Loss: 0.586373 | Val Loss: 0.747341\n",
      "Epoch [100/500] | Train Loss: 0.780746 | Val Loss: 0.373427\n",
      "Epoch [200/500] | Train Loss: 0.680159 | Val Loss: 0.383668\n",
      "Epoch [300/500] | Train Loss: 0.617307 | Val Loss: 0.401073\n",
      "Epoch [400/500] | Train Loss: 0.653879 | Val Loss: 0.387446\n",
      "Epoch [500/500] | Train Loss: 0.578405 | Val Loss: 0.397426\n",
      "[Year=1977] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.994497 Test MSE=0.273390\n",
      "Year 1977 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.639772 | Val Loss: 1.437534\n",
      "Epoch [200/500] | Train Loss: 0.561143 | Val Loss: 1.449182\n",
      "Epoch [300/500] | Train Loss: 0.481281 | Val Loss: 1.540490\n",
      "Epoch [400/500] | Train Loss: 0.400408 | Val Loss: 1.610060\n",
      "Epoch [500/500] | Train Loss: 0.382220 | Val Loss: 1.705971\n",
      "Epoch [100/500] | Train Loss: 0.982771 | Val Loss: 1.593941\n",
      "Epoch [200/500] | Train Loss: 0.900131 | Val Loss: 1.639962\n",
      "Epoch [300/500] | Train Loss: 0.815025 | Val Loss: 1.738927\n",
      "Epoch [400/500] | Train Loss: 0.757624 | Val Loss: 1.780809\n",
      "Epoch [500/500] | Train Loss: 0.755324 | Val Loss: 1.807056\n",
      "Epoch [100/500] | Train Loss: 1.139630 | Val Loss: 0.648163\n",
      "Epoch [200/500] | Train Loss: 1.069345 | Val Loss: 0.681060\n",
      "Epoch [300/500] | Train Loss: 1.032986 | Val Loss: 0.706148\n",
      "Epoch [400/500] | Train Loss: 0.938543 | Val Loss: 0.710861\n",
      "Epoch [500/500] | Train Loss: 0.886144 | Val Loss: 0.721343\n",
      "Epoch [100/500] | Train Loss: 1.013668 | Val Loss: 0.347951\n",
      "Epoch [200/500] | Train Loss: 0.930555 | Val Loss: 0.348810\n",
      "Epoch [300/500] | Train Loss: 0.894277 | Val Loss: 0.349097\n",
      "Epoch [400/500] | Train Loss: 0.857343 | Val Loss: 0.350538\n",
      "Epoch [500/500] | Train Loss: 0.844109 | Val Loss: 0.356394\n",
      "Epoch [100/500] | Train Loss: 0.865402 | Val Loss: 0.277705\n",
      "Epoch [200/500] | Train Loss: 0.824519 | Val Loss: 0.281157\n",
      "Epoch [300/500] | Train Loss: 0.782701 | Val Loss: 0.287201\n",
      "Epoch [400/500] | Train Loss: 0.774746 | Val Loss: 0.286994\n",
      "Epoch [500/500] | Train Loss: 0.733182 | Val Loss: 0.288449\n",
      "Epoch [100/500] | Train Loss: 0.375175 | Val Loss: 1.772539\n",
      "Epoch [200/500] | Train Loss: 0.220493 | Val Loss: 2.248329\n",
      "Epoch [300/500] | Train Loss: 0.201210 | Val Loss: 2.152109\n",
      "Epoch [400/500] | Train Loss: 0.272222 | Val Loss: 1.989930\n",
      "Epoch [500/500] | Train Loss: 0.191102 | Val Loss: 2.158205\n",
      "Epoch [100/500] | Train Loss: 0.803999 | Val Loss: 1.672777\n",
      "Epoch [200/500] | Train Loss: 0.626865 | Val Loss: 1.889103\n",
      "Epoch [300/500] | Train Loss: 0.603851 | Val Loss: 2.038164\n",
      "Epoch [400/500] | Train Loss: 0.562590 | Val Loss: 2.180150\n",
      "Epoch [500/500] | Train Loss: 0.502257 | Val Loss: 2.076981\n",
      "Epoch [100/500] | Train Loss: 0.894101 | Val Loss: 0.703645\n",
      "Epoch [200/500] | Train Loss: 0.733566 | Val Loss: 0.800986\n",
      "Epoch [300/500] | Train Loss: 0.665653 | Val Loss: 0.821136\n",
      "Epoch [400/500] | Train Loss: 0.584767 | Val Loss: 0.863797\n",
      "Epoch [500/500] | Train Loss: 0.642673 | Val Loss: 0.887140\n",
      "Epoch [100/500] | Train Loss: 0.873231 | Val Loss: 0.347815\n",
      "Epoch [200/500] | Train Loss: 0.710575 | Val Loss: 0.366575\n",
      "Epoch [300/500] | Train Loss: 0.669942 | Val Loss: 0.414318\n",
      "Epoch [400/500] | Train Loss: 0.599363 | Val Loss: 0.401786\n",
      "Epoch [500/500] | Train Loss: 0.598829 | Val Loss: 0.427115\n",
      "Epoch [100/500] | Train Loss: 0.760056 | Val Loss: 0.307238\n",
      "Epoch [200/500] | Train Loss: 0.648709 | Val Loss: 0.317325\n",
      "Epoch [300/500] | Train Loss: 0.653544 | Val Loss: 0.344697\n",
      "Epoch [400/500] | Train Loss: 0.567851 | Val Loss: 0.353232\n",
      "Epoch [500/500] | Train Loss: 0.548611 | Val Loss: 0.349255\n",
      "Epoch [100/500] | Train Loss: 0.666553 | Val Loss: 1.425373\n",
      "Epoch [200/500] | Train Loss: 0.572079 | Val Loss: 1.419237\n",
      "Epoch [300/500] | Train Loss: 0.594096 | Val Loss: 1.437522\n",
      "Epoch [400/500] | Train Loss: 0.523221 | Val Loss: 1.439290\n",
      "Epoch [500/500] | Train Loss: 0.483012 | Val Loss: 1.489902\n",
      "Epoch [100/500] | Train Loss: 1.062633 | Val Loss: 1.592786\n",
      "Epoch [200/500] | Train Loss: 0.989689 | Val Loss: 1.529796\n",
      "Epoch [300/500] | Train Loss: 0.937921 | Val Loss: 1.541755\n",
      "Epoch [400/500] | Train Loss: 0.926064 | Val Loss: 1.571055\n",
      "Epoch [500/500] | Train Loss: 0.877133 | Val Loss: 1.578367\n",
      "Epoch [100/500] | Train Loss: 1.160019 | Val Loss: 0.661903\n",
      "Epoch [200/500] | Train Loss: 1.143497 | Val Loss: 0.670919\n",
      "Epoch [300/500] | Train Loss: 1.068929 | Val Loss: 0.685025\n",
      "Epoch [400/500] | Train Loss: 1.079986 | Val Loss: 0.702579\n",
      "Epoch [500/500] | Train Loss: 1.039343 | Val Loss: 0.711620\n",
      "Epoch [100/500] | Train Loss: 1.049497 | Val Loss: 0.331617\n",
      "Epoch [200/500] | Train Loss: 0.987968 | Val Loss: 0.337643\n",
      "Epoch [300/500] | Train Loss: 0.982842 | Val Loss: 0.344220\n",
      "Epoch [400/500] | Train Loss: 0.978535 | Val Loss: 0.351278\n",
      "Epoch [500/500] | Train Loss: 0.946205 | Val Loss: 0.355874\n",
      "Epoch [100/500] | Train Loss: 0.871530 | Val Loss: 0.274143\n",
      "Epoch [200/500] | Train Loss: 0.871638 | Val Loss: 0.276319\n",
      "Epoch [300/500] | Train Loss: 0.839869 | Val Loss: 0.275153\n",
      "Epoch [400/500] | Train Loss: 0.817871 | Val Loss: 0.278236\n",
      "Epoch [500/500] | Train Loss: 0.806523 | Val Loss: 0.279020\n",
      "Epoch [100/500] | Train Loss: 0.463940 | Val Loss: 1.588442\n",
      "Epoch [200/500] | Train Loss: 0.348794 | Val Loss: 1.694281\n",
      "Epoch [300/500] | Train Loss: 0.250835 | Val Loss: 1.692514\n",
      "Epoch [400/500] | Train Loss: 0.328321 | Val Loss: 1.711951\n",
      "Epoch [500/500] | Train Loss: 0.227412 | Val Loss: 1.783362\n",
      "Epoch [100/500] | Train Loss: 0.878778 | Val Loss: 1.640652\n",
      "Epoch [200/500] | Train Loss: 0.751825 | Val Loss: 1.809772\n",
      "Epoch [300/500] | Train Loss: 0.722099 | Val Loss: 1.808060\n",
      "Epoch [400/500] | Train Loss: 0.660357 | Val Loss: 1.830916\n",
      "Epoch [500/500] | Train Loss: 0.576988 | Val Loss: 1.922458\n",
      "Epoch [100/500] | Train Loss: 1.009441 | Val Loss: 0.715975\n",
      "Epoch [200/500] | Train Loss: 0.903410 | Val Loss: 0.724193\n",
      "Epoch [300/500] | Train Loss: 0.890645 | Val Loss: 0.710646\n",
      "Epoch [400/500] | Train Loss: 0.870768 | Val Loss: 0.730000\n",
      "Epoch [500/500] | Train Loss: 0.726826 | Val Loss: 0.801397\n",
      "Epoch [100/500] | Train Loss: 0.929734 | Val Loss: 0.361392\n",
      "Epoch [200/500] | Train Loss: 0.868865 | Val Loss: 0.382354\n",
      "Epoch [300/500] | Train Loss: 0.836297 | Val Loss: 0.397051\n",
      "Epoch [400/500] | Train Loss: 0.794235 | Val Loss: 0.384727\n",
      "Epoch [500/500] | Train Loss: 0.819555 | Val Loss: 0.386516\n",
      "Epoch [100/500] | Train Loss: 0.832107 | Val Loss: 0.275310\n",
      "Epoch [200/500] | Train Loss: 0.756651 | Val Loss: 0.279240\n",
      "Epoch [300/500] | Train Loss: 0.727331 | Val Loss: 0.284268\n",
      "Epoch [400/500] | Train Loss: 0.702486 | Val Loss: 0.280594\n",
      "Epoch [500/500] | Train Loss: 0.712134 | Val Loss: 0.273475\n",
      "Epoch [100/500] | Train Loss: 0.629390 | Val Loss: 1.483840\n",
      "Epoch [200/500] | Train Loss: 0.484641 | Val Loss: 1.503054\n",
      "Epoch [300/500] | Train Loss: 0.402265 | Val Loss: 1.654865\n",
      "Epoch [400/500] | Train Loss: 0.288850 | Val Loss: 1.820960\n",
      "Epoch [500/500] | Train Loss: 0.241695 | Val Loss: 1.811928\n",
      "Epoch [100/500] | Train Loss: 0.954901 | Val Loss: 1.575992\n",
      "Epoch [200/500] | Train Loss: 0.845113 | Val Loss: 1.684424\n",
      "Epoch [300/500] | Train Loss: 0.763146 | Val Loss: 1.807259\n",
      "Epoch [400/500] | Train Loss: 0.641662 | Val Loss: 1.822081\n",
      "Epoch [500/500] | Train Loss: 0.584797 | Val Loss: 1.943923\n",
      "Epoch [100/500] | Train Loss: 1.114482 | Val Loss: 0.688810\n",
      "Epoch [200/500] | Train Loss: 1.021775 | Val Loss: 0.735082\n",
      "Epoch [300/500] | Train Loss: 0.890153 | Val Loss: 0.772616\n",
      "Epoch [400/500] | Train Loss: 0.835454 | Val Loss: 0.802689\n",
      "Epoch [500/500] | Train Loss: 0.763310 | Val Loss: 0.813072\n",
      "Epoch [100/500] | Train Loss: 0.986458 | Val Loss: 0.348385\n",
      "Epoch [200/500] | Train Loss: 0.948846 | Val Loss: 0.348196\n",
      "Epoch [300/500] | Train Loss: 0.859647 | Val Loss: 0.346108\n",
      "Epoch [400/500] | Train Loss: 0.785589 | Val Loss: 0.341916\n",
      "Epoch [500/500] | Train Loss: 0.768868 | Val Loss: 0.344266\n",
      "Epoch [100/500] | Train Loss: 0.870377 | Val Loss: 0.277631\n",
      "Epoch [200/500] | Train Loss: 0.813840 | Val Loss: 0.283810\n",
      "Epoch [300/500] | Train Loss: 0.754708 | Val Loss: 0.283940\n",
      "Epoch [400/500] | Train Loss: 0.691409 | Val Loss: 0.290430\n",
      "Epoch [500/500] | Train Loss: 0.689941 | Val Loss: 0.296300\n",
      "Epoch [100/500] | Train Loss: 0.285764 | Val Loss: 1.971546\n",
      "Epoch [200/500] | Train Loss: 0.148969 | Val Loss: 1.875432\n",
      "Epoch [300/500] | Train Loss: 0.151434 | Val Loss: 2.045051\n",
      "Epoch [400/500] | Train Loss: 0.233620 | Val Loss: 1.887571\n",
      "Epoch [500/500] | Train Loss: 0.109973 | Val Loss: 2.012248\n",
      "Epoch [100/500] | Train Loss: 0.664586 | Val Loss: 1.824403\n",
      "Epoch [200/500] | Train Loss: 0.506903 | Val Loss: 1.957757\n",
      "Epoch [300/500] | Train Loss: 0.450707 | Val Loss: 2.118698\n",
      "Epoch [400/500] | Train Loss: 0.449639 | Val Loss: 2.180717\n",
      "Epoch [500/500] | Train Loss: 0.357908 | Val Loss: 2.113630\n",
      "Epoch [100/500] | Train Loss: 0.817019 | Val Loss: 0.723180\n",
      "Epoch [200/500] | Train Loss: 0.680460 | Val Loss: 0.800640\n",
      "Epoch [300/500] | Train Loss: 0.595776 | Val Loss: 0.856357\n",
      "Epoch [400/500] | Train Loss: 0.556791 | Val Loss: 0.859215\n",
      "Epoch [500/500] | Train Loss: 0.501976 | Val Loss: 0.898376\n",
      "Epoch [100/500] | Train Loss: 0.819317 | Val Loss: 0.351433\n",
      "Epoch [200/500] | Train Loss: 0.659069 | Val Loss: 0.389993\n",
      "Epoch [300/500] | Train Loss: 0.587302 | Val Loss: 0.445787\n",
      "Epoch [400/500] | Train Loss: 0.588841 | Val Loss: 0.460460\n",
      "Epoch [500/500] | Train Loss: 0.487595 | Val Loss: 0.488203\n",
      "Epoch [100/500] | Train Loss: 0.775503 | Val Loss: 0.282485\n",
      "Epoch [200/500] | Train Loss: 0.608872 | Val Loss: 0.325128\n",
      "Epoch [300/500] | Train Loss: 0.561251 | Val Loss: 0.338446\n",
      "Epoch [400/500] | Train Loss: 0.505774 | Val Loss: 0.342025\n",
      "Epoch [500/500] | Train Loss: 0.488357 | Val Loss: 0.336841\n",
      "Epoch [100/500] | Train Loss: 0.593720 | Val Loss: 1.460052\n",
      "Epoch [200/500] | Train Loss: 0.553580 | Val Loss: 1.436525\n",
      "Epoch [300/500] | Train Loss: 0.504351 | Val Loss: 1.521595\n",
      "Epoch [400/500] | Train Loss: 0.446876 | Val Loss: 1.629428\n",
      "Epoch [500/500] | Train Loss: 0.473051 | Val Loss: 1.714419\n",
      "Epoch [100/500] | Train Loss: 0.942058 | Val Loss: 1.534109\n",
      "Epoch [200/500] | Train Loss: 0.913108 | Val Loss: 1.582867\n",
      "Epoch [300/500] | Train Loss: 0.835181 | Val Loss: 1.603697\n",
      "Epoch [400/500] | Train Loss: 0.753058 | Val Loss: 1.643733\n",
      "Epoch [500/500] | Train Loss: 0.755063 | Val Loss: 1.638367\n",
      "Epoch [100/500] | Train Loss: 1.140178 | Val Loss: 0.656819\n",
      "Epoch [200/500] | Train Loss: 1.118904 | Val Loss: 0.688848\n",
      "Epoch [300/500] | Train Loss: 0.997590 | Val Loss: 0.701979\n",
      "Epoch [400/500] | Train Loss: 0.968372 | Val Loss: 0.706355\n",
      "Epoch [500/500] | Train Loss: 0.930441 | Val Loss: 0.695816\n",
      "Epoch [100/500] | Train Loss: 1.011448 | Val Loss: 0.338595\n",
      "Epoch [200/500] | Train Loss: 0.974289 | Val Loss: 0.334313\n",
      "Epoch [300/500] | Train Loss: 0.970153 | Val Loss: 0.335285\n",
      "Epoch [400/500] | Train Loss: 0.944858 | Val Loss: 0.340311\n",
      "Epoch [500/500] | Train Loss: 0.889050 | Val Loss: 0.345398\n",
      "Epoch [100/500] | Train Loss: 0.875016 | Val Loss: 0.273141\n",
      "Epoch [200/500] | Train Loss: 0.840527 | Val Loss: 0.277329\n",
      "Epoch [300/500] | Train Loss: 0.847934 | Val Loss: 0.278805\n",
      "Epoch [400/500] | Train Loss: 0.774826 | Val Loss: 0.276283\n",
      "Epoch [500/500] | Train Loss: 0.765719 | Val Loss: 0.282925\n",
      "Epoch [100/500] | Train Loss: 0.416852 | Val Loss: 1.719877\n",
      "Epoch [200/500] | Train Loss: 0.282691 | Val Loss: 1.737251\n",
      "Epoch [300/500] | Train Loss: 0.241869 | Val Loss: 1.896737\n",
      "Epoch [400/500] | Train Loss: 0.176104 | Val Loss: 1.931063\n",
      "Epoch [500/500] | Train Loss: 0.175692 | Val Loss: 1.925415\n",
      "Epoch [100/500] | Train Loss: 0.808082 | Val Loss: 1.704022\n",
      "Epoch [200/500] | Train Loss: 0.697393 | Val Loss: 1.818187\n",
      "Epoch [300/500] | Train Loss: 0.570316 | Val Loss: 1.872103\n",
      "Epoch [400/500] | Train Loss: 0.511239 | Val Loss: 2.081975\n",
      "Epoch [500/500] | Train Loss: 0.546714 | Val Loss: 1.951463\n",
      "Epoch [100/500] | Train Loss: 0.924104 | Val Loss: 0.708309\n",
      "Epoch [200/500] | Train Loss: 0.876800 | Val Loss: 0.768038\n",
      "Epoch [300/500] | Train Loss: 0.816972 | Val Loss: 0.770513\n",
      "Epoch [400/500] | Train Loss: 0.735909 | Val Loss: 0.786846\n",
      "Epoch [500/500] | Train Loss: 0.667263 | Val Loss: 0.739040\n",
      "Epoch [100/500] | Train Loss: 0.939530 | Val Loss: 0.339185\n",
      "Epoch [200/500] | Train Loss: 0.814002 | Val Loss: 0.351843\n",
      "Epoch [300/500] | Train Loss: 0.761272 | Val Loss: 0.368031\n",
      "Epoch [400/500] | Train Loss: 0.697280 | Val Loss: 0.385034\n",
      "Epoch [500/500] | Train Loss: 0.731072 | Val Loss: 0.399776\n",
      "Epoch [100/500] | Train Loss: 0.779715 | Val Loss: 0.287226\n",
      "Epoch [200/500] | Train Loss: 0.725004 | Val Loss: 0.310547\n",
      "Epoch [300/500] | Train Loss: 0.665909 | Val Loss: 0.319069\n",
      "Epoch [400/500] | Train Loss: 0.655276 | Val Loss: 0.340186\n",
      "Epoch [500/500] | Train Loss: 0.646120 | Val Loss: 0.353410\n",
      "[Year=1978] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.882956 Test MSE=0.601060\n",
      "Year 1978 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.402438 | Val Loss: 1.046427\n",
      "Epoch [200/500] | Train Loss: 1.235015 | Val Loss: 1.204153\n",
      "Epoch [300/500] | Train Loss: 1.091269 | Val Loss: 1.257895\n",
      "Epoch [400/500] | Train Loss: 0.900051 | Val Loss: 1.302908\n",
      "Epoch [500/500] | Train Loss: 0.799918 | Val Loss: 1.321529\n",
      "Epoch [100/500] | Train Loss: 1.195301 | Val Loss: 0.582940\n",
      "Epoch [200/500] | Train Loss: 1.097955 | Val Loss: 0.609464\n",
      "Epoch [300/500] | Train Loss: 0.974899 | Val Loss: 0.649105\n",
      "Epoch [400/500] | Train Loss: 0.854506 | Val Loss: 0.685339\n",
      "Epoch [500/500] | Train Loss: 0.791743 | Val Loss: 0.710313\n",
      "Epoch [100/500] | Train Loss: 1.038195 | Val Loss: 0.327284\n",
      "Epoch [200/500] | Train Loss: 0.965049 | Val Loss: 0.350687\n",
      "Epoch [300/500] | Train Loss: 0.883653 | Val Loss: 0.362706\n",
      "Epoch [400/500] | Train Loss: 0.789966 | Val Loss: 0.369777\n",
      "Epoch [500/500] | Train Loss: 0.800312 | Val Loss: 0.376487\n",
      "Epoch [100/500] | Train Loss: 0.838821 | Val Loss: 0.276613\n",
      "Epoch [200/500] | Train Loss: 0.820625 | Val Loss: 0.285043\n",
      "Epoch [300/500] | Train Loss: 0.749214 | Val Loss: 0.284699\n",
      "Epoch [400/500] | Train Loss: 0.663370 | Val Loss: 0.298830\n",
      "Epoch [500/500] | Train Loss: 0.696588 | Val Loss: 0.314424\n",
      "Epoch [100/500] | Train Loss: 0.723326 | Val Loss: 0.641447\n",
      "Epoch [200/500] | Train Loss: 0.698308 | Val Loss: 0.668435\n",
      "Epoch [300/500] | Train Loss: 0.664234 | Val Loss: 0.685103\n",
      "Epoch [400/500] | Train Loss: 0.652342 | Val Loss: 0.701366\n",
      "Epoch [500/500] | Train Loss: 0.590397 | Val Loss: 0.714054\n",
      "Epoch [100/500] | Train Loss: 0.910714 | Val Loss: 1.332707\n",
      "Epoch [200/500] | Train Loss: 0.677598 | Val Loss: 1.363009\n",
      "Epoch [300/500] | Train Loss: 0.611969 | Val Loss: 1.451266\n",
      "Epoch [400/500] | Train Loss: 0.497514 | Val Loss: 1.575521\n",
      "Epoch [500/500] | Train Loss: 0.485775 | Val Loss: 1.493835\n",
      "Epoch [100/500] | Train Loss: 0.908912 | Val Loss: 0.676974\n",
      "Epoch [200/500] | Train Loss: 0.757240 | Val Loss: 0.703988\n",
      "Epoch [300/500] | Train Loss: 0.767326 | Val Loss: 0.798948\n",
      "Epoch [400/500] | Train Loss: 0.558007 | Val Loss: 0.879415\n",
      "Epoch [500/500] | Train Loss: 0.558769 | Val Loss: 0.847984\n",
      "Epoch [100/500] | Train Loss: 0.791259 | Val Loss: 0.390085\n",
      "Epoch [200/500] | Train Loss: 0.732449 | Val Loss: 0.471670\n",
      "Epoch [300/500] | Train Loss: 0.616592 | Val Loss: 0.493070\n",
      "Epoch [400/500] | Train Loss: 0.604234 | Val Loss: 0.514330\n",
      "Epoch [500/500] | Train Loss: 0.528422 | Val Loss: 0.553189\n",
      "Epoch [100/500] | Train Loss: 0.745980 | Val Loss: 0.302662\n",
      "Epoch [200/500] | Train Loss: 0.607585 | Val Loss: 0.325140\n",
      "Epoch [300/500] | Train Loss: 0.595623 | Val Loss: 0.334279\n",
      "Epoch [400/500] | Train Loss: 0.495834 | Val Loss: 0.363210\n",
      "Epoch [500/500] | Train Loss: 0.554477 | Val Loss: 0.376323\n",
      "Epoch [100/500] | Train Loss: 0.604594 | Val Loss: 0.628929\n",
      "Epoch [200/500] | Train Loss: 0.561457 | Val Loss: 0.609307\n",
      "Epoch [300/500] | Train Loss: 0.451059 | Val Loss: 0.631979\n",
      "Epoch [400/500] | Train Loss: 0.449052 | Val Loss: 0.649098\n",
      "Epoch [500/500] | Train Loss: 0.448553 | Val Loss: 0.692187\n",
      "Epoch [100/500] | Train Loss: 1.600691 | Val Loss: 1.085374\n",
      "Epoch [200/500] | Train Loss: 1.397707 | Val Loss: 1.119837\n",
      "Epoch [300/500] | Train Loss: 1.235330 | Val Loss: 1.163024\n",
      "Epoch [400/500] | Train Loss: 1.210485 | Val Loss: 1.175700\n",
      "Epoch [500/500] | Train Loss: 1.175523 | Val Loss: 1.240451\n",
      "Epoch [100/500] | Train Loss: 1.265530 | Val Loss: 0.571060\n",
      "Epoch [200/500] | Train Loss: 1.228007 | Val Loss: 0.592652\n",
      "Epoch [300/500] | Train Loss: 1.146371 | Val Loss: 0.610261\n",
      "Epoch [400/500] | Train Loss: 1.126209 | Val Loss: 0.621687\n",
      "Epoch [500/500] | Train Loss: 1.065158 | Val Loss: 0.639406\n",
      "Epoch [100/500] | Train Loss: 1.050380 | Val Loss: 0.315418\n",
      "Epoch [200/500] | Train Loss: 1.029118 | Val Loss: 0.323781\n",
      "Epoch [300/500] | Train Loss: 1.011388 | Val Loss: 0.334591\n",
      "Epoch [400/500] | Train Loss: 0.939869 | Val Loss: 0.340856\n",
      "Epoch [500/500] | Train Loss: 0.948351 | Val Loss: 0.347503\n",
      "Epoch [100/500] | Train Loss: 0.878362 | Val Loss: 0.279114\n",
      "Epoch [200/500] | Train Loss: 0.845090 | Val Loss: 0.284077\n",
      "Epoch [300/500] | Train Loss: 0.816586 | Val Loss: 0.283770\n",
      "Epoch [400/500] | Train Loss: 0.795476 | Val Loss: 0.288076\n",
      "Epoch [500/500] | Train Loss: 0.793432 | Val Loss: 0.294049\n",
      "Epoch [100/500] | Train Loss: 0.759667 | Val Loss: 0.621845\n",
      "Epoch [200/500] | Train Loss: 0.726196 | Val Loss: 0.637786\n",
      "Epoch [300/500] | Train Loss: 0.688567 | Val Loss: 0.660424\n",
      "Epoch [400/500] | Train Loss: 0.692201 | Val Loss: 0.671855\n",
      "Epoch [500/500] | Train Loss: 0.668378 | Val Loss: 0.673122\n",
      "Epoch [100/500] | Train Loss: 1.230555 | Val Loss: 1.189514\n",
      "Epoch [200/500] | Train Loss: 1.032190 | Val Loss: 1.225906\n",
      "Epoch [300/500] | Train Loss: 0.859902 | Val Loss: 1.391065\n",
      "Epoch [400/500] | Train Loss: 0.774295 | Val Loss: 1.400236\n",
      "Epoch [500/500] | Train Loss: 0.807671 | Val Loss: 1.318739\n",
      "Epoch [100/500] | Train Loss: 1.028285 | Val Loss: 0.665931\n",
      "Epoch [200/500] | Train Loss: 0.899280 | Val Loss: 0.697414\n",
      "Epoch [300/500] | Train Loss: 0.828771 | Val Loss: 0.788924\n",
      "Epoch [400/500] | Train Loss: 0.779264 | Val Loss: 0.757535\n",
      "Epoch [500/500] | Train Loss: 0.799623 | Val Loss: 0.781537\n",
      "Epoch [100/500] | Train Loss: 0.935411 | Val Loss: 0.338838\n",
      "Epoch [200/500] | Train Loss: 0.799019 | Val Loss: 0.383658\n",
      "Epoch [300/500] | Train Loss: 0.819997 | Val Loss: 0.396465\n",
      "Epoch [400/500] | Train Loss: 0.757493 | Val Loss: 0.410616\n",
      "Epoch [500/500] | Train Loss: 0.768735 | Val Loss: 0.425260\n",
      "Epoch [100/500] | Train Loss: 0.791693 | Val Loss: 0.278137\n",
      "Epoch [200/500] | Train Loss: 0.702785 | Val Loss: 0.322797\n",
      "Epoch [300/500] | Train Loss: 0.677918 | Val Loss: 0.319288\n",
      "Epoch [400/500] | Train Loss: 0.660722 | Val Loss: 0.313923\n",
      "Epoch [500/500] | Train Loss: 0.630276 | Val Loss: 0.329395\n",
      "Epoch [100/500] | Train Loss: 0.689923 | Val Loss: 0.662088\n",
      "Epoch [200/500] | Train Loss: 0.622270 | Val Loss: 0.642298\n",
      "Epoch [300/500] | Train Loss: 0.598789 | Val Loss: 0.678820\n",
      "Epoch [400/500] | Train Loss: 0.574388 | Val Loss: 0.669946\n",
      "Epoch [500/500] | Train Loss: 0.576073 | Val Loss: 0.619564\n",
      "Epoch [100/500] | Train Loss: 1.373979 | Val Loss: 1.052773\n",
      "Epoch [200/500] | Train Loss: 1.068305 | Val Loss: 1.189724\n",
      "Epoch [300/500] | Train Loss: 0.883664 | Val Loss: 1.240607\n",
      "Epoch [400/500] | Train Loss: 0.849540 | Val Loss: 1.246434\n",
      "Epoch [500/500] | Train Loss: 0.716297 | Val Loss: 1.300185\n",
      "Epoch [100/500] | Train Loss: 1.223928 | Val Loss: 0.568730\n",
      "Epoch [200/500] | Train Loss: 1.066197 | Val Loss: 0.603289\n",
      "Epoch [300/500] | Train Loss: 0.910268 | Val Loss: 0.637345\n",
      "Epoch [400/500] | Train Loss: 0.795411 | Val Loss: 0.638350\n",
      "Epoch [500/500] | Train Loss: 0.797764 | Val Loss: 0.681225\n",
      "Epoch [100/500] | Train Loss: 1.011195 | Val Loss: 0.341523\n",
      "Epoch [200/500] | Train Loss: 0.917360 | Val Loss: 0.360818\n",
      "Epoch [300/500] | Train Loss: 0.843353 | Val Loss: 0.376191\n",
      "Epoch [400/500] | Train Loss: 0.661878 | Val Loss: 0.379812\n",
      "Epoch [500/500] | Train Loss: 0.701571 | Val Loss: 0.400844\n",
      "Epoch [100/500] | Train Loss: 0.851351 | Val Loss: 0.280116\n",
      "Epoch [200/500] | Train Loss: 0.823060 | Val Loss: 0.274874\n",
      "Epoch [300/500] | Train Loss: 0.745828 | Val Loss: 0.280122\n",
      "Epoch [400/500] | Train Loss: 0.683999 | Val Loss: 0.290670\n",
      "Epoch [500/500] | Train Loss: 0.647377 | Val Loss: 0.299118\n",
      "Epoch [100/500] | Train Loss: 0.749230 | Val Loss: 0.633445\n",
      "Epoch [200/500] | Train Loss: 0.690373 | Val Loss: 0.649572\n",
      "Epoch [300/500] | Train Loss: 0.644868 | Val Loss: 0.657432\n",
      "Epoch [400/500] | Train Loss: 0.603398 | Val Loss: 0.657276\n",
      "Epoch [500/500] | Train Loss: 0.576453 | Val Loss: 0.628051\n",
      "Epoch [100/500] | Train Loss: 0.923889 | Val Loss: 1.296246\n",
      "Epoch [200/500] | Train Loss: 0.559369 | Val Loss: 1.348783\n",
      "Epoch [300/500] | Train Loss: 0.337981 | Val Loss: 1.339599\n",
      "Epoch [400/500] | Train Loss: 0.355356 | Val Loss: 1.453268\n",
      "Epoch [500/500] | Train Loss: 0.329543 | Val Loss: 1.491841\n",
      "Epoch [100/500] | Train Loss: 0.759863 | Val Loss: 0.855802\n",
      "Epoch [200/500] | Train Loss: 0.560975 | Val Loss: 0.979616\n",
      "Epoch [300/500] | Train Loss: 0.487720 | Val Loss: 0.993657\n",
      "Epoch [400/500] | Train Loss: 0.445082 | Val Loss: 0.994449\n",
      "Epoch [500/500] | Train Loss: 0.423115 | Val Loss: 0.984704\n",
      "Epoch [100/500] | Train Loss: 0.656634 | Val Loss: 0.457543\n",
      "Epoch [200/500] | Train Loss: 0.505802 | Val Loss: 0.551619\n",
      "Epoch [300/500] | Train Loss: 0.484178 | Val Loss: 0.566485\n",
      "Epoch [400/500] | Train Loss: 0.418469 | Val Loss: 0.599390\n",
      "Epoch [500/500] | Train Loss: 0.349109 | Val Loss: 0.560691\n",
      "Epoch [100/500] | Train Loss: 0.622912 | Val Loss: 0.295735\n",
      "Epoch [200/500] | Train Loss: 0.564961 | Val Loss: 0.327547\n",
      "Epoch [300/500] | Train Loss: 0.470047 | Val Loss: 0.344794\n",
      "Epoch [400/500] | Train Loss: 0.420128 | Val Loss: 0.370886\n",
      "Epoch [500/500] | Train Loss: 0.427439 | Val Loss: 0.373888\n",
      "Epoch [100/500] | Train Loss: 0.574739 | Val Loss: 0.704966\n",
      "Epoch [200/500] | Train Loss: 0.476969 | Val Loss: 0.682533\n",
      "Epoch [300/500] | Train Loss: 0.423936 | Val Loss: 0.661604\n",
      "Epoch [400/500] | Train Loss: 0.402862 | Val Loss: 0.649302\n",
      "Epoch [500/500] | Train Loss: 0.349826 | Val Loss: 0.682603\n",
      "Epoch [100/500] | Train Loss: 1.477357 | Val Loss: 1.085277\n",
      "Epoch [200/500] | Train Loss: 1.285155 | Val Loss: 1.158478\n",
      "Epoch [300/500] | Train Loss: 1.216041 | Val Loss: 1.240596\n",
      "Epoch [400/500] | Train Loss: 0.991611 | Val Loss: 1.240232\n",
      "Epoch [500/500] | Train Loss: 0.990515 | Val Loss: 1.235994\n",
      "Epoch [100/500] | Train Loss: 1.253218 | Val Loss: 0.576136\n",
      "Epoch [200/500] | Train Loss: 1.167886 | Val Loss: 0.576684\n",
      "Epoch [300/500] | Train Loss: 1.144124 | Val Loss: 0.592341\n",
      "Epoch [400/500] | Train Loss: 1.065620 | Val Loss: 0.596014\n",
      "Epoch [500/500] | Train Loss: 0.981635 | Val Loss: 0.628397\n",
      "Epoch [100/500] | Train Loss: 1.058289 | Val Loss: 0.320580\n",
      "Epoch [200/500] | Train Loss: 0.961137 | Val Loss: 0.331939\n",
      "Epoch [300/500] | Train Loss: 0.936457 | Val Loss: 0.341376\n",
      "Epoch [400/500] | Train Loss: 0.854333 | Val Loss: 0.354904\n",
      "Epoch [500/500] | Train Loss: 0.848752 | Val Loss: 0.383654\n",
      "Epoch [100/500] | Train Loss: 0.858767 | Val Loss: 0.273899\n",
      "Epoch [200/500] | Train Loss: 0.827124 | Val Loss: 0.279515\n",
      "Epoch [300/500] | Train Loss: 0.778202 | Val Loss: 0.282765\n",
      "Epoch [400/500] | Train Loss: 0.747279 | Val Loss: 0.289384\n",
      "Epoch [500/500] | Train Loss: 0.703187 | Val Loss: 0.297635\n",
      "Epoch [100/500] | Train Loss: 0.743788 | Val Loss: 0.628006\n",
      "Epoch [200/500] | Train Loss: 0.722222 | Val Loss: 0.636605\n",
      "Epoch [300/500] | Train Loss: 0.683798 | Val Loss: 0.650715\n",
      "Epoch [400/500] | Train Loss: 0.700545 | Val Loss: 0.675122\n",
      "Epoch [500/500] | Train Loss: 0.655990 | Val Loss: 0.676001\n",
      "Epoch [100/500] | Train Loss: 1.095226 | Val Loss: 1.179752\n",
      "Epoch [200/500] | Train Loss: 0.803895 | Val Loss: 1.214698\n",
      "Epoch [300/500] | Train Loss: 0.670191 | Val Loss: 1.348752\n",
      "Epoch [400/500] | Train Loss: 0.701349 | Val Loss: 1.314890\n",
      "Epoch [500/500] | Train Loss: 0.765804 | Val Loss: 1.310870\n",
      "Epoch [100/500] | Train Loss: 0.974239 | Val Loss: 0.666049\n",
      "Epoch [200/500] | Train Loss: 0.844290 | Val Loss: 0.703830\n",
      "Epoch [300/500] | Train Loss: 0.731143 | Val Loss: 0.798650\n",
      "Epoch [400/500] | Train Loss: 0.667050 | Val Loss: 0.747002\n",
      "Epoch [500/500] | Train Loss: 0.702093 | Val Loss: 0.801473\n",
      "Epoch [100/500] | Train Loss: 0.903398 | Val Loss: 0.397981\n",
      "Epoch [200/500] | Train Loss: 0.668463 | Val Loss: 0.434565\n",
      "Epoch [300/500] | Train Loss: 0.701244 | Val Loss: 0.504419\n",
      "Epoch [400/500] | Train Loss: 0.600278 | Val Loss: 0.512474\n",
      "Epoch [500/500] | Train Loss: 0.649579 | Val Loss: 0.548970\n",
      "Epoch [100/500] | Train Loss: 0.759983 | Val Loss: 0.287903\n",
      "Epoch [200/500] | Train Loss: 0.693957 | Val Loss: 0.321011\n",
      "Epoch [300/500] | Train Loss: 0.623245 | Val Loss: 0.308579\n",
      "Epoch [400/500] | Train Loss: 0.596824 | Val Loss: 0.328497\n",
      "Epoch [500/500] | Train Loss: 0.549049 | Val Loss: 0.337856\n",
      "Epoch [100/500] | Train Loss: 0.662442 | Val Loss: 0.650078\n",
      "Epoch [200/500] | Train Loss: 0.583664 | Val Loss: 0.680239\n",
      "Epoch [300/500] | Train Loss: 0.570369 | Val Loss: 0.715854\n",
      "Epoch [400/500] | Train Loss: 0.499203 | Val Loss: 0.674218\n",
      "Epoch [500/500] | Train Loss: 0.489222 | Val Loss: 0.717314\n",
      "[Year=1979] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.638906 Test MSE=0.446484\n",
      "Year 1979 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.762865 | Val Loss: 0.466836\n",
      "Epoch [200/500] | Train Loss: 0.680552 | Val Loss: 0.535040\n",
      "Epoch [300/500] | Train Loss: 0.629636 | Val Loss: 0.596711\n",
      "Epoch [400/500] | Train Loss: 0.529717 | Val Loss: 0.637254\n",
      "Epoch [500/500] | Train Loss: 0.499945 | Val Loss: 0.753927\n",
      "Epoch [100/500] | Train Loss: 0.608837 | Val Loss: 0.341619\n",
      "Epoch [200/500] | Train Loss: 0.558435 | Val Loss: 0.389283\n",
      "Epoch [300/500] | Train Loss: 0.515283 | Val Loss: 0.420440\n",
      "Epoch [400/500] | Train Loss: 0.466674 | Val Loss: 0.454960\n",
      "Epoch [500/500] | Train Loss: 0.409342 | Val Loss: 0.476905\n",
      "Epoch [100/500] | Train Loss: 0.509809 | Val Loss: 0.305969\n",
      "Epoch [200/500] | Train Loss: 0.468343 | Val Loss: 0.306182\n",
      "Epoch [300/500] | Train Loss: 0.464723 | Val Loss: 0.304658\n",
      "Epoch [400/500] | Train Loss: 0.455496 | Val Loss: 0.304501\n",
      "Epoch [500/500] | Train Loss: 0.434088 | Val Loss: 0.307881\n",
      "Epoch [100/500] | Train Loss: 0.482745 | Val Loss: 0.659514\n",
      "Epoch [200/500] | Train Loss: 0.456354 | Val Loss: 0.687386\n",
      "Epoch [300/500] | Train Loss: 0.449023 | Val Loss: 0.701883\n",
      "Epoch [400/500] | Train Loss: 0.430711 | Val Loss: 0.735606\n",
      "Epoch [500/500] | Train Loss: 0.410676 | Val Loss: 0.774564\n",
      "Epoch [100/500] | Train Loss: 0.495321 | Val Loss: 0.442371\n",
      "Epoch [200/500] | Train Loss: 0.477090 | Val Loss: 0.455292\n",
      "Epoch [300/500] | Train Loss: 0.454622 | Val Loss: 0.468673\n",
      "Epoch [400/500] | Train Loss: 0.434942 | Val Loss: 0.477605\n",
      "Epoch [500/500] | Train Loss: 0.413672 | Val Loss: 0.478060\n",
      "Epoch [100/500] | Train Loss: 0.604027 | Val Loss: 0.706906\n",
      "Epoch [200/500] | Train Loss: 0.380718 | Val Loss: 0.764789\n",
      "Epoch [300/500] | Train Loss: 0.369552 | Val Loss: 0.827784\n",
      "Epoch [400/500] | Train Loss: 0.304192 | Val Loss: 0.865001\n",
      "Epoch [500/500] | Train Loss: 0.294503 | Val Loss: 0.754424\n",
      "Epoch [100/500] | Train Loss: 0.459998 | Val Loss: 0.428439\n",
      "Epoch [200/500] | Train Loss: 0.397719 | Val Loss: 0.483611\n",
      "Epoch [300/500] | Train Loss: 0.340632 | Val Loss: 0.541676\n",
      "Epoch [400/500] | Train Loss: 0.323922 | Val Loss: 0.522119\n",
      "Epoch [500/500] | Train Loss: 0.302117 | Val Loss: 0.534458\n",
      "Epoch [100/500] | Train Loss: 0.417432 | Val Loss: 0.323163\n",
      "Epoch [200/500] | Train Loss: 0.346093 | Val Loss: 0.367918\n",
      "Epoch [300/500] | Train Loss: 0.314530 | Val Loss: 0.385383\n",
      "Epoch [400/500] | Train Loss: 0.305640 | Val Loss: 0.395369\n",
      "Epoch [500/500] | Train Loss: 0.286782 | Val Loss: 0.438539\n",
      "Epoch [100/500] | Train Loss: 0.415301 | Val Loss: 0.755208\n",
      "Epoch [200/500] | Train Loss: 0.341408 | Val Loss: 0.856806\n",
      "Epoch [300/500] | Train Loss: 0.318832 | Val Loss: 0.870981\n",
      "Epoch [400/500] | Train Loss: 0.315805 | Val Loss: 0.944279\n",
      "Epoch [500/500] | Train Loss: 0.280161 | Val Loss: 0.884640\n",
      "Epoch [100/500] | Train Loss: 0.426634 | Val Loss: 0.471147\n",
      "Epoch [200/500] | Train Loss: 0.368421 | Val Loss: 0.512003\n",
      "Epoch [300/500] | Train Loss: 0.339020 | Val Loss: 0.519476\n",
      "Epoch [400/500] | Train Loss: 0.329591 | Val Loss: 0.536963\n",
      "Epoch [500/500] | Train Loss: 0.312237 | Val Loss: 0.552922\n",
      "Epoch [100/500] | Train Loss: 0.791809 | Val Loss: 0.459409\n",
      "Epoch [200/500] | Train Loss: 0.770019 | Val Loss: 0.494302\n",
      "Epoch [300/500] | Train Loss: 0.699123 | Val Loss: 0.513524\n",
      "Epoch [400/500] | Train Loss: 0.664895 | Val Loss: 0.529124\n",
      "Epoch [500/500] | Train Loss: 0.644328 | Val Loss: 0.542010\n",
      "Epoch [100/500] | Train Loss: 0.663775 | Val Loss: 0.305728\n",
      "Epoch [200/500] | Train Loss: 0.625106 | Val Loss: 0.319897\n",
      "Epoch [300/500] | Train Loss: 0.605688 | Val Loss: 0.322913\n",
      "Epoch [400/500] | Train Loss: 0.581931 | Val Loss: 0.329997\n",
      "Epoch [500/500] | Train Loss: 0.588677 | Val Loss: 0.333729\n",
      "Epoch [100/500] | Train Loss: 0.527141 | Val Loss: 0.308691\n",
      "Epoch [200/500] | Train Loss: 0.513045 | Val Loss: 0.304829\n",
      "Epoch [300/500] | Train Loss: 0.485830 | Val Loss: 0.304417\n",
      "Epoch [400/500] | Train Loss: 0.478089 | Val Loss: 0.305732\n",
      "Epoch [500/500] | Train Loss: 0.459120 | Val Loss: 0.305658\n",
      "Epoch [100/500] | Train Loss: 0.487547 | Val Loss: 0.611260\n",
      "Epoch [200/500] | Train Loss: 0.468410 | Val Loss: 0.629278\n",
      "Epoch [300/500] | Train Loss: 0.444136 | Val Loss: 0.653534\n",
      "Epoch [400/500] | Train Loss: 0.433683 | Val Loss: 0.672073\n",
      "Epoch [500/500] | Train Loss: 0.447512 | Val Loss: 0.680840\n",
      "Epoch [100/500] | Train Loss: 0.500015 | Val Loss: 0.451604\n",
      "Epoch [200/500] | Train Loss: 0.480097 | Val Loss: 0.447190\n",
      "Epoch [300/500] | Train Loss: 0.477084 | Val Loss: 0.449282\n",
      "Epoch [400/500] | Train Loss: 0.462182 | Val Loss: 0.455917\n",
      "Epoch [500/500] | Train Loss: 0.460456 | Val Loss: 0.456593\n",
      "Epoch [100/500] | Train Loss: 0.609947 | Val Loss: 0.589427\n",
      "Epoch [200/500] | Train Loss: 0.511202 | Val Loss: 0.717366\n",
      "Epoch [300/500] | Train Loss: 0.505112 | Val Loss: 0.688283\n",
      "Epoch [400/500] | Train Loss: 0.431682 | Val Loss: 0.644918\n",
      "Epoch [500/500] | Train Loss: 0.423715 | Val Loss: 0.667087\n",
      "Epoch [100/500] | Train Loss: 0.609877 | Val Loss: 0.339592\n",
      "Epoch [200/500] | Train Loss: 0.485042 | Val Loss: 0.386855\n",
      "Epoch [300/500] | Train Loss: 0.454169 | Val Loss: 0.428483\n",
      "Epoch [400/500] | Train Loss: 0.461365 | Val Loss: 0.438558\n",
      "Epoch [500/500] | Train Loss: 0.437410 | Val Loss: 0.446361\n",
      "Epoch [100/500] | Train Loss: 0.471044 | Val Loss: 0.314926\n",
      "Epoch [200/500] | Train Loss: 0.436339 | Val Loss: 0.329208\n",
      "Epoch [300/500] | Train Loss: 0.407571 | Val Loss: 0.328675\n",
      "Epoch [400/500] | Train Loss: 0.394189 | Val Loss: 0.337216\n",
      "Epoch [500/500] | Train Loss: 0.392418 | Val Loss: 0.334155\n",
      "Epoch [100/500] | Train Loss: 0.419659 | Val Loss: 0.703205\n",
      "Epoch [200/500] | Train Loss: 0.406136 | Val Loss: 0.803041\n",
      "Epoch [300/500] | Train Loss: 0.384255 | Val Loss: 0.839669\n",
      "Epoch [400/500] | Train Loss: 0.384519 | Val Loss: 0.810106\n",
      "Epoch [500/500] | Train Loss: 0.362299 | Val Loss: 0.833588\n",
      "Epoch [100/500] | Train Loss: 0.462413 | Val Loss: 0.469767\n",
      "Epoch [200/500] | Train Loss: 0.425075 | Val Loss: 0.473357\n",
      "Epoch [300/500] | Train Loss: 0.413033 | Val Loss: 0.485578\n",
      "Epoch [400/500] | Train Loss: 0.406313 | Val Loss: 0.491885\n",
      "Epoch [500/500] | Train Loss: 0.405698 | Val Loss: 0.495071\n",
      "Epoch [100/500] | Train Loss: 0.724114 | Val Loss: 0.483900\n",
      "Epoch [200/500] | Train Loss: 0.623133 | Val Loss: 0.556725\n",
      "Epoch [300/500] | Train Loss: 0.526280 | Val Loss: 0.619091\n",
      "Epoch [400/500] | Train Loss: 0.438322 | Val Loss: 0.706239\n",
      "Epoch [500/500] | Train Loss: 0.372787 | Val Loss: 0.783217\n",
      "Epoch [100/500] | Train Loss: 0.611382 | Val Loss: 0.333548\n",
      "Epoch [200/500] | Train Loss: 0.540845 | Val Loss: 0.342260\n",
      "Epoch [300/500] | Train Loss: 0.473056 | Val Loss: 0.359838\n",
      "Epoch [400/500] | Train Loss: 0.431453 | Val Loss: 0.378767\n",
      "Epoch [500/500] | Train Loss: 0.421602 | Val Loss: 0.415911\n",
      "Epoch [100/500] | Train Loss: 0.511035 | Val Loss: 0.309776\n",
      "Epoch [200/500] | Train Loss: 0.479947 | Val Loss: 0.309710\n",
      "Epoch [300/500] | Train Loss: 0.401125 | Val Loss: 0.320882\n",
      "Epoch [400/500] | Train Loss: 0.374272 | Val Loss: 0.327002\n",
      "Epoch [500/500] | Train Loss: 0.362174 | Val Loss: 0.322859\n",
      "Epoch [100/500] | Train Loss: 0.464267 | Val Loss: 0.630885\n",
      "Epoch [200/500] | Train Loss: 0.406804 | Val Loss: 0.672279\n",
      "Epoch [300/500] | Train Loss: 0.382910 | Val Loss: 0.700934\n",
      "Epoch [400/500] | Train Loss: 0.372648 | Val Loss: 0.752559\n",
      "Epoch [500/500] | Train Loss: 0.348623 | Val Loss: 0.785081\n",
      "Epoch [100/500] | Train Loss: 0.491413 | Val Loss: 0.445754\n",
      "Epoch [200/500] | Train Loss: 0.459459 | Val Loss: 0.468941\n",
      "Epoch [300/500] | Train Loss: 0.437180 | Val Loss: 0.493494\n",
      "Epoch [400/500] | Train Loss: 0.409911 | Val Loss: 0.494778\n",
      "Epoch [500/500] | Train Loss: 0.380740 | Val Loss: 0.509393\n",
      "Epoch [100/500] | Train Loss: 0.435290 | Val Loss: 0.797199\n",
      "Epoch [200/500] | Train Loss: 0.241613 | Val Loss: 0.762138\n",
      "Epoch [300/500] | Train Loss: 0.187323 | Val Loss: 0.887078\n",
      "Epoch [400/500] | Train Loss: 0.172455 | Val Loss: 0.913421\n",
      "Epoch [500/500] | Train Loss: 0.153081 | Val Loss: 0.996598\n",
      "Epoch [100/500] | Train Loss: 0.487053 | Val Loss: 0.430460\n",
      "Epoch [200/500] | Train Loss: 0.365817 | Val Loss: 0.494811\n",
      "Epoch [300/500] | Train Loss: 0.318364 | Val Loss: 0.557277\n",
      "Epoch [400/500] | Train Loss: 0.257230 | Val Loss: 0.601390\n",
      "Epoch [500/500] | Train Loss: 0.270822 | Val Loss: 0.557792\n",
      "Epoch [100/500] | Train Loss: 0.413877 | Val Loss: 0.327753\n",
      "Epoch [200/500] | Train Loss: 0.331367 | Val Loss: 0.385092\n",
      "Epoch [300/500] | Train Loss: 0.295284 | Val Loss: 0.414390\n",
      "Epoch [400/500] | Train Loss: 0.274383 | Val Loss: 0.434277\n",
      "Epoch [500/500] | Train Loss: 0.243502 | Val Loss: 0.437242\n",
      "Epoch [100/500] | Train Loss: 0.385667 | Val Loss: 0.759365\n",
      "Epoch [200/500] | Train Loss: 0.301694 | Val Loss: 0.813870\n",
      "Epoch [300/500] | Train Loss: 0.271005 | Val Loss: 0.790404\n",
      "Epoch [400/500] | Train Loss: 0.248188 | Val Loss: 0.812928\n",
      "Epoch [500/500] | Train Loss: 0.249322 | Val Loss: 0.840833\n",
      "Epoch [100/500] | Train Loss: 0.449635 | Val Loss: 0.472602\n",
      "Epoch [200/500] | Train Loss: 0.378458 | Val Loss: 0.530834\n",
      "Epoch [300/500] | Train Loss: 0.355971 | Val Loss: 0.579480\n",
      "Epoch [400/500] | Train Loss: 0.323578 | Val Loss: 0.588966\n",
      "Epoch [500/500] | Train Loss: 0.308624 | Val Loss: 0.609609\n",
      "Epoch [100/500] | Train Loss: 0.791100 | Val Loss: 0.483456\n",
      "Epoch [200/500] | Train Loss: 0.682311 | Val Loss: 0.528154\n",
      "Epoch [300/500] | Train Loss: 0.621468 | Val Loss: 0.546836\n",
      "Epoch [400/500] | Train Loss: 0.612264 | Val Loss: 0.620912\n",
      "Epoch [500/500] | Train Loss: 0.558463 | Val Loss: 0.650335\n",
      "Epoch [100/500] | Train Loss: 0.663753 | Val Loss: 0.324283\n",
      "Epoch [200/500] | Train Loss: 0.607594 | Val Loss: 0.339154\n",
      "Epoch [300/500] | Train Loss: 0.566710 | Val Loss: 0.350230\n",
      "Epoch [400/500] | Train Loss: 0.528867 | Val Loss: 0.369651\n",
      "Epoch [500/500] | Train Loss: 0.498897 | Val Loss: 0.382989\n",
      "Epoch [100/500] | Train Loss: 0.531825 | Val Loss: 0.310928\n",
      "Epoch [200/500] | Train Loss: 0.510918 | Val Loss: 0.305200\n",
      "Epoch [300/500] | Train Loss: 0.487461 | Val Loss: 0.302115\n",
      "Epoch [400/500] | Train Loss: 0.461276 | Val Loss: 0.301592\n",
      "Epoch [500/500] | Train Loss: 0.440211 | Val Loss: 0.305950\n",
      "Epoch [100/500] | Train Loss: 0.479182 | Val Loss: 0.618550\n",
      "Epoch [200/500] | Train Loss: 0.454845 | Val Loss: 0.641971\n",
      "Epoch [300/500] | Train Loss: 0.427649 | Val Loss: 0.676341\n",
      "Epoch [400/500] | Train Loss: 0.432799 | Val Loss: 0.683184\n",
      "Epoch [500/500] | Train Loss: 0.404501 | Val Loss: 0.690991\n",
      "Epoch [100/500] | Train Loss: 0.503701 | Val Loss: 0.453538\n",
      "Epoch [200/500] | Train Loss: 0.487935 | Val Loss: 0.457806\n",
      "Epoch [300/500] | Train Loss: 0.454918 | Val Loss: 0.466411\n",
      "Epoch [400/500] | Train Loss: 0.444581 | Val Loss: 0.467691\n",
      "Epoch [500/500] | Train Loss: 0.428872 | Val Loss: 0.485053\n",
      "Epoch [100/500] | Train Loss: 0.565502 | Val Loss: 0.659386\n",
      "Epoch [200/500] | Train Loss: 0.445967 | Val Loss: 0.733867\n",
      "Epoch [300/500] | Train Loss: 0.307964 | Val Loss: 0.823798\n",
      "Epoch [400/500] | Train Loss: 0.272432 | Val Loss: 0.813914\n",
      "Epoch [500/500] | Train Loss: 0.377187 | Val Loss: 0.839729\n",
      "Epoch [100/500] | Train Loss: 0.542184 | Val Loss: 0.359627\n",
      "Epoch [200/500] | Train Loss: 0.455685 | Val Loss: 0.407500\n",
      "Epoch [300/500] | Train Loss: 0.475089 | Val Loss: 0.482339\n",
      "Epoch [400/500] | Train Loss: 0.406592 | Val Loss: 0.457070\n",
      "Epoch [500/500] | Train Loss: 0.397639 | Val Loss: 0.470393\n",
      "Epoch [100/500] | Train Loss: 0.457688 | Val Loss: 0.315747\n",
      "Epoch [200/500] | Train Loss: 0.399332 | Val Loss: 0.338324\n",
      "Epoch [300/500] | Train Loss: 0.390569 | Val Loss: 0.336612\n",
      "Epoch [400/500] | Train Loss: 0.365427 | Val Loss: 0.327313\n",
      "Epoch [500/500] | Train Loss: 0.335815 | Val Loss: 0.336400\n",
      "Epoch [100/500] | Train Loss: 0.418299 | Val Loss: 0.706876\n",
      "Epoch [200/500] | Train Loss: 0.378340 | Val Loss: 0.817926\n",
      "Epoch [300/500] | Train Loss: 0.333861 | Val Loss: 0.797200\n",
      "Epoch [400/500] | Train Loss: 0.317195 | Val Loss: 0.845975\n",
      "Epoch [500/500] | Train Loss: 0.321662 | Val Loss: 0.814911\n",
      "Epoch [100/500] | Train Loss: 0.431929 | Val Loss: 0.485261\n",
      "Epoch [200/500] | Train Loss: 0.402312 | Val Loss: 0.488576\n",
      "Epoch [300/500] | Train Loss: 0.371807 | Val Loss: 0.498391\n",
      "Epoch [400/500] | Train Loss: 0.372328 | Val Loss: 0.544992\n",
      "Epoch [500/500] | Train Loss: 0.345275 | Val Loss: 0.542157\n",
      "[Year=1980] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.463766 Test MSE=1.004682\n",
      "Year 1980 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.424339 | Val Loss: 0.260091\n",
      "Epoch [200/500] | Train Loss: 0.360743 | Val Loss: 0.265980\n",
      "Epoch [300/500] | Train Loss: 0.324667 | Val Loss: 0.291829\n",
      "Epoch [400/500] | Train Loss: 0.273849 | Val Loss: 0.318782\n",
      "Epoch [500/500] | Train Loss: 0.266814 | Val Loss: 0.328445\n",
      "Epoch [100/500] | Train Loss: 0.322711 | Val Loss: 0.351526\n",
      "Epoch [200/500] | Train Loss: 0.293897 | Val Loss: 0.362616\n",
      "Epoch [300/500] | Train Loss: 0.268273 | Val Loss: 0.375513\n",
      "Epoch [400/500] | Train Loss: 0.254010 | Val Loss: 0.388700\n",
      "Epoch [500/500] | Train Loss: 0.230149 | Val Loss: 0.409795\n",
      "Epoch [100/500] | Train Loss: 0.323553 | Val Loss: 0.590462\n",
      "Epoch [200/500] | Train Loss: 0.304208 | Val Loss: 0.604358\n",
      "Epoch [300/500] | Train Loss: 0.277578 | Val Loss: 0.638131\n",
      "Epoch [400/500] | Train Loss: 0.257845 | Val Loss: 0.665178\n",
      "Epoch [500/500] | Train Loss: 0.253973 | Val Loss: 0.674613\n",
      "Epoch [100/500] | Train Loss: 0.397840 | Val Loss: 0.568571\n",
      "Epoch [200/500] | Train Loss: 0.369862 | Val Loss: 0.573150\n",
      "Epoch [300/500] | Train Loss: 0.349699 | Val Loss: 0.580805\n",
      "Epoch [400/500] | Train Loss: 0.346631 | Val Loss: 0.598023\n",
      "Epoch [500/500] | Train Loss: 0.325126 | Val Loss: 0.609778\n",
      "Epoch [100/500] | Train Loss: 0.432831 | Val Loss: 1.033770\n",
      "Epoch [200/500] | Train Loss: 0.411204 | Val Loss: 1.048048\n",
      "Epoch [300/500] | Train Loss: 0.377270 | Val Loss: 1.108100\n",
      "Epoch [400/500] | Train Loss: 0.354918 | Val Loss: 1.174058\n",
      "Epoch [500/500] | Train Loss: 0.368111 | Val Loss: 1.181020\n",
      "Epoch [100/500] | Train Loss: 0.242874 | Val Loss: 0.328098\n",
      "Epoch [200/500] | Train Loss: 0.156416 | Val Loss: 0.384424\n",
      "Epoch [300/500] | Train Loss: 0.135508 | Val Loss: 0.409889\n",
      "Epoch [400/500] | Train Loss: 0.125498 | Val Loss: 0.389803\n",
      "Epoch [500/500] | Train Loss: 0.128706 | Val Loss: 0.405708\n",
      "Epoch [100/500] | Train Loss: 0.263381 | Val Loss: 0.378433\n",
      "Epoch [200/500] | Train Loss: 0.195011 | Val Loss: 0.448213\n",
      "Epoch [300/500] | Train Loss: 0.157023 | Val Loss: 0.472830\n",
      "Epoch [400/500] | Train Loss: 0.147737 | Val Loss: 0.474952\n",
      "Epoch [500/500] | Train Loss: 0.153923 | Val Loss: 0.480528\n",
      "Epoch [100/500] | Train Loss: 0.306934 | Val Loss: 0.605541\n",
      "Epoch [200/500] | Train Loss: 0.263588 | Val Loss: 0.679006\n",
      "Epoch [300/500] | Train Loss: 0.225674 | Val Loss: 0.702645\n",
      "Epoch [400/500] | Train Loss: 0.225014 | Val Loss: 0.719993\n",
      "Epoch [500/500] | Train Loss: 0.210712 | Val Loss: 0.718485\n",
      "Epoch [100/500] | Train Loss: 0.328420 | Val Loss: 0.592333\n",
      "Epoch [200/500] | Train Loss: 0.282523 | Val Loss: 0.655853\n",
      "Epoch [300/500] | Train Loss: 0.266034 | Val Loss: 0.674034\n",
      "Epoch [400/500] | Train Loss: 0.261317 | Val Loss: 0.755555\n",
      "Epoch [500/500] | Train Loss: 0.240545 | Val Loss: 0.658644\n",
      "Epoch [100/500] | Train Loss: 0.383020 | Val Loss: 1.144037\n",
      "Epoch [200/500] | Train Loss: 0.331346 | Val Loss: 1.328595\n",
      "Epoch [300/500] | Train Loss: 0.309607 | Val Loss: 1.296232\n",
      "Epoch [400/500] | Train Loss: 0.293124 | Val Loss: 1.405957\n",
      "Epoch [500/500] | Train Loss: 0.284915 | Val Loss: 1.393402\n",
      "Epoch [100/500] | Train Loss: 0.434193 | Val Loss: 0.261358\n",
      "Epoch [200/500] | Train Loss: 0.394902 | Val Loss: 0.260220\n",
      "Epoch [300/500] | Train Loss: 0.362865 | Val Loss: 0.267199\n",
      "Epoch [400/500] | Train Loss: 0.325389 | Val Loss: 0.285743\n",
      "Epoch [500/500] | Train Loss: 0.314004 | Val Loss: 0.289042\n",
      "Epoch [100/500] | Train Loss: 0.356268 | Val Loss: 0.347163\n",
      "Epoch [200/500] | Train Loss: 0.315435 | Val Loss: 0.347674\n",
      "Epoch [300/500] | Train Loss: 0.300219 | Val Loss: 0.358562\n",
      "Epoch [400/500] | Train Loss: 0.296246 | Val Loss: 0.364831\n",
      "Epoch [500/500] | Train Loss: 0.276152 | Val Loss: 0.371417\n",
      "Epoch [100/500] | Train Loss: 0.341887 | Val Loss: 0.595938\n",
      "Epoch [200/500] | Train Loss: 0.340325 | Val Loss: 0.596479\n",
      "Epoch [300/500] | Train Loss: 0.326671 | Val Loss: 0.589091\n",
      "Epoch [400/500] | Train Loss: 0.321315 | Val Loss: 0.590059\n",
      "Epoch [500/500] | Train Loss: 0.314418 | Val Loss: 0.595986\n",
      "Epoch [100/500] | Train Loss: 0.402328 | Val Loss: 0.553308\n",
      "Epoch [200/500] | Train Loss: 0.388142 | Val Loss: 0.557866\n",
      "Epoch [300/500] | Train Loss: 0.389074 | Val Loss: 0.563059\n",
      "Epoch [400/500] | Train Loss: 0.382775 | Val Loss: 0.580155\n",
      "Epoch [500/500] | Train Loss: 0.372948 | Val Loss: 0.595633\n",
      "Epoch [100/500] | Train Loss: 0.434683 | Val Loss: 1.044118\n",
      "Epoch [200/500] | Train Loss: 0.419278 | Val Loss: 1.050800\n",
      "Epoch [300/500] | Train Loss: 0.417648 | Val Loss: 1.063199\n",
      "Epoch [400/500] | Train Loss: 0.396226 | Val Loss: 1.086164\n",
      "Epoch [500/500] | Train Loss: 0.377504 | Val Loss: 1.103607\n",
      "Epoch [100/500] | Train Loss: 0.349057 | Val Loss: 0.281870\n",
      "Epoch [200/500] | Train Loss: 0.283950 | Val Loss: 0.326882\n",
      "Epoch [300/500] | Train Loss: 0.259880 | Val Loss: 0.345091\n",
      "Epoch [400/500] | Train Loss: 0.247648 | Val Loss: 0.320107\n",
      "Epoch [500/500] | Train Loss: 0.215063 | Val Loss: 0.349188\n",
      "Epoch [100/500] | Train Loss: 0.288314 | Val Loss: 0.363354\n",
      "Epoch [200/500] | Train Loss: 0.256932 | Val Loss: 0.387209\n",
      "Epoch [300/500] | Train Loss: 0.244614 | Val Loss: 0.388128\n",
      "Epoch [400/500] | Train Loss: 0.223315 | Val Loss: 0.397668\n",
      "Epoch [500/500] | Train Loss: 0.234031 | Val Loss: 0.393023\n",
      "Epoch [100/500] | Train Loss: 0.314175 | Val Loss: 0.604705\n",
      "Epoch [200/500] | Train Loss: 0.278778 | Val Loss: 0.639052\n",
      "Epoch [300/500] | Train Loss: 0.263983 | Val Loss: 0.653359\n",
      "Epoch [400/500] | Train Loss: 0.251388 | Val Loss: 0.668610\n",
      "Epoch [500/500] | Train Loss: 0.240117 | Val Loss: 0.689912\n",
      "Epoch [100/500] | Train Loss: 0.367016 | Val Loss: 0.564937\n",
      "Epoch [200/500] | Train Loss: 0.342216 | Val Loss: 0.569987\n",
      "Epoch [300/500] | Train Loss: 0.333791 | Val Loss: 0.610675\n",
      "Epoch [400/500] | Train Loss: 0.292147 | Val Loss: 0.638936\n",
      "Epoch [500/500] | Train Loss: 0.285291 | Val Loss: 0.656066\n",
      "Epoch [100/500] | Train Loss: 0.386442 | Val Loss: 1.040639\n",
      "Epoch [200/500] | Train Loss: 0.362657 | Val Loss: 1.129466\n",
      "Epoch [300/500] | Train Loss: 0.365345 | Val Loss: 1.168660\n",
      "Epoch [400/500] | Train Loss: 0.341147 | Val Loss: 1.099363\n",
      "Epoch [500/500] | Train Loss: 0.343393 | Val Loss: 1.148806\n",
      "Epoch [100/500] | Train Loss: 0.380208 | Val Loss: 0.269742\n",
      "Epoch [200/500] | Train Loss: 0.313097 | Val Loss: 0.311491\n",
      "Epoch [300/500] | Train Loss: 0.237011 | Val Loss: 0.327722\n",
      "Epoch [400/500] | Train Loss: 0.190546 | Val Loss: 0.339711\n",
      "Epoch [500/500] | Train Loss: 0.172043 | Val Loss: 0.365713\n",
      "Epoch [100/500] | Train Loss: 0.316290 | Val Loss: 0.352306\n",
      "Epoch [200/500] | Train Loss: 0.267169 | Val Loss: 0.378099\n",
      "Epoch [300/500] | Train Loss: 0.235448 | Val Loss: 0.394624\n",
      "Epoch [400/500] | Train Loss: 0.210173 | Val Loss: 0.420446\n",
      "Epoch [500/500] | Train Loss: 0.200738 | Val Loss: 0.443240\n",
      "Epoch [100/500] | Train Loss: 0.318304 | Val Loss: 0.602040\n",
      "Epoch [200/500] | Train Loss: 0.299845 | Val Loss: 0.619419\n",
      "Epoch [300/500] | Train Loss: 0.275400 | Val Loss: 0.639504\n",
      "Epoch [400/500] | Train Loss: 0.254737 | Val Loss: 0.653338\n",
      "Epoch [500/500] | Train Loss: 0.236980 | Val Loss: 0.660918\n",
      "Epoch [100/500] | Train Loss: 0.402288 | Val Loss: 0.571244\n",
      "Epoch [200/500] | Train Loss: 0.365721 | Val Loss: 0.593711\n",
      "Epoch [300/500] | Train Loss: 0.344399 | Val Loss: 0.606287\n",
      "Epoch [400/500] | Train Loss: 0.321056 | Val Loss: 0.646928\n",
      "Epoch [500/500] | Train Loss: 0.295491 | Val Loss: 0.662193\n",
      "Epoch [100/500] | Train Loss: 0.415286 | Val Loss: 1.035234\n",
      "Epoch [200/500] | Train Loss: 0.388827 | Val Loss: 1.047784\n",
      "Epoch [300/500] | Train Loss: 0.364895 | Val Loss: 1.077175\n",
      "Epoch [400/500] | Train Loss: 0.332786 | Val Loss: 1.113637\n",
      "Epoch [500/500] | Train Loss: 0.308179 | Val Loss: 1.102615\n",
      "Epoch [100/500] | Train Loss: 0.169488 | Val Loss: 0.358705\n",
      "Epoch [200/500] | Train Loss: 0.134929 | Val Loss: 0.372673\n",
      "Epoch [300/500] | Train Loss: 0.124081 | Val Loss: 0.387242\n",
      "Epoch [400/500] | Train Loss: 0.101503 | Val Loss: 0.371795\n",
      "Epoch [500/500] | Train Loss: 0.100808 | Val Loss: 0.412972\n",
      "Epoch [100/500] | Train Loss: 0.232463 | Val Loss: 0.421871\n",
      "Epoch [200/500] | Train Loss: 0.176490 | Val Loss: 0.465511\n",
      "Epoch [300/500] | Train Loss: 0.132468 | Val Loss: 0.500538\n",
      "Epoch [400/500] | Train Loss: 0.130016 | Val Loss: 0.481858\n",
      "Epoch [500/500] | Train Loss: 0.119821 | Val Loss: 0.497714\n",
      "Epoch [100/500] | Train Loss: 0.251585 | Val Loss: 0.712797\n",
      "Epoch [200/500] | Train Loss: 0.210731 | Val Loss: 0.703697\n",
      "Epoch [300/500] | Train Loss: 0.183918 | Val Loss: 0.679881\n",
      "Epoch [400/500] | Train Loss: 0.171309 | Val Loss: 0.714043\n",
      "Epoch [500/500] | Train Loss: 0.149906 | Val Loss: 0.737391\n",
      "Epoch [100/500] | Train Loss: 0.307405 | Val Loss: 0.600824\n",
      "Epoch [200/500] | Train Loss: 0.261848 | Val Loss: 0.664204\n",
      "Epoch [300/500] | Train Loss: 0.243057 | Val Loss: 0.681490\n",
      "Epoch [400/500] | Train Loss: 0.217607 | Val Loss: 0.689121\n",
      "Epoch [500/500] | Train Loss: 0.222039 | Val Loss: 0.708737\n",
      "Epoch [100/500] | Train Loss: 0.358005 | Val Loss: 1.156590\n",
      "Epoch [200/500] | Train Loss: 0.327311 | Val Loss: 1.247149\n",
      "Epoch [300/500] | Train Loss: 0.309946 | Val Loss: 1.249750\n",
      "Epoch [400/500] | Train Loss: 0.265023 | Val Loss: 1.235016\n",
      "Epoch [500/500] | Train Loss: 0.263624 | Val Loss: 1.342530\n",
      "Epoch [100/500] | Train Loss: 0.414041 | Val Loss: 0.257925\n",
      "Epoch [200/500] | Train Loss: 0.371369 | Val Loss: 0.261258\n",
      "Epoch [300/500] | Train Loss: 0.328715 | Val Loss: 0.296824\n",
      "Epoch [400/500] | Train Loss: 0.275727 | Val Loss: 0.312922\n",
      "Epoch [500/500] | Train Loss: 0.268160 | Val Loss: 0.332171\n",
      "Epoch [100/500] | Train Loss: 0.333009 | Val Loss: 0.349156\n",
      "Epoch [200/500] | Train Loss: 0.314539 | Val Loss: 0.355817\n",
      "Epoch [300/500] | Train Loss: 0.301554 | Val Loss: 0.364363\n",
      "Epoch [400/500] | Train Loss: 0.263558 | Val Loss: 0.371776\n",
      "Epoch [500/500] | Train Loss: 0.256869 | Val Loss: 0.374192\n",
      "Epoch [100/500] | Train Loss: 0.343210 | Val Loss: 0.601764\n",
      "Epoch [200/500] | Train Loss: 0.326493 | Val Loss: 0.595304\n",
      "Epoch [300/500] | Train Loss: 0.306884 | Val Loss: 0.607633\n",
      "Epoch [400/500] | Train Loss: 0.294681 | Val Loss: 0.610569\n",
      "Epoch [500/500] | Train Loss: 0.286511 | Val Loss: 0.614892\n",
      "Epoch [100/500] | Train Loss: 0.396458 | Val Loss: 0.556254\n",
      "Epoch [200/500] | Train Loss: 0.366945 | Val Loss: 0.573050\n",
      "Epoch [300/500] | Train Loss: 0.353945 | Val Loss: 0.591763\n",
      "Epoch [400/500] | Train Loss: 0.349102 | Val Loss: 0.611672\n",
      "Epoch [500/500] | Train Loss: 0.319614 | Val Loss: 0.617127\n",
      "Epoch [100/500] | Train Loss: 0.440853 | Val Loss: 1.036728\n",
      "Epoch [200/500] | Train Loss: 0.420256 | Val Loss: 1.038780\n",
      "Epoch [300/500] | Train Loss: 0.398485 | Val Loss: 1.059573\n",
      "Epoch [400/500] | Train Loss: 0.382427 | Val Loss: 1.074409\n",
      "Epoch [500/500] | Train Loss: 0.376155 | Val Loss: 1.088619\n",
      "Epoch [100/500] | Train Loss: 0.272596 | Val Loss: 0.288844\n",
      "Epoch [200/500] | Train Loss: 0.241394 | Val Loss: 0.320193\n",
      "Epoch [300/500] | Train Loss: 0.178399 | Val Loss: 0.342080\n",
      "Epoch [400/500] | Train Loss: 0.147725 | Val Loss: 0.340718\n",
      "Epoch [500/500] | Train Loss: 0.170033 | Val Loss: 0.364249\n",
      "Epoch [100/500] | Train Loss: 0.307600 | Val Loss: 0.366869\n",
      "Epoch [200/500] | Train Loss: 0.233766 | Val Loss: 0.376927\n",
      "Epoch [300/500] | Train Loss: 0.214163 | Val Loss: 0.383151\n",
      "Epoch [400/500] | Train Loss: 0.209193 | Val Loss: 0.408446\n",
      "Epoch [500/500] | Train Loss: 0.216643 | Val Loss: 0.411115\n",
      "Epoch [100/500] | Train Loss: 0.315422 | Val Loss: 0.629610\n",
      "Epoch [200/500] | Train Loss: 0.277875 | Val Loss: 0.633024\n",
      "Epoch [300/500] | Train Loss: 0.262155 | Val Loss: 0.637758\n",
      "Epoch [400/500] | Train Loss: 0.254779 | Val Loss: 0.639408\n",
      "Epoch [500/500] | Train Loss: 0.261600 | Val Loss: 0.640545\n",
      "Epoch [100/500] | Train Loss: 0.343827 | Val Loss: 0.598513\n",
      "Epoch [200/500] | Train Loss: 0.297716 | Val Loss: 0.628276\n",
      "Epoch [300/500] | Train Loss: 0.275474 | Val Loss: 0.643168\n",
      "Epoch [400/500] | Train Loss: 0.270757 | Val Loss: 0.635825\n",
      "Epoch [500/500] | Train Loss: 0.260059 | Val Loss: 0.663931\n",
      "Epoch [100/500] | Train Loss: 0.365397 | Val Loss: 1.087421\n",
      "Epoch [200/500] | Train Loss: 0.338798 | Val Loss: 1.111105\n",
      "Epoch [300/500] | Train Loss: 0.327509 | Val Loss: 1.095312\n",
      "Epoch [400/500] | Train Loss: 0.303090 | Val Loss: 1.135872\n",
      "Epoch [500/500] | Train Loss: 0.319131 | Val Loss: 1.112193\n",
      "[Year=1981] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.591137 Test MSE=0.665228\n",
      "Year 1981 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.205125 | Val Loss: 0.403127\n",
      "Epoch [200/500] | Train Loss: 0.170051 | Val Loss: 0.448300\n",
      "Epoch [300/500] | Train Loss: 0.163954 | Val Loss: 0.499678\n",
      "Epoch [400/500] | Train Loss: 0.144432 | Val Loss: 0.541686\n",
      "Epoch [500/500] | Train Loss: 0.125970 | Val Loss: 0.583716\n",
      "Epoch [100/500] | Train Loss: 0.297418 | Val Loss: 0.591950\n",
      "Epoch [200/500] | Train Loss: 0.279301 | Val Loss: 0.596293\n",
      "Epoch [300/500] | Train Loss: 0.260773 | Val Loss: 0.620512\n",
      "Epoch [400/500] | Train Loss: 0.239092 | Val Loss: 0.647356\n",
      "Epoch [500/500] | Train Loss: 0.234635 | Val Loss: 0.655622\n",
      "Epoch [100/500] | Train Loss: 0.397328 | Val Loss: 0.847514\n",
      "Epoch [200/500] | Train Loss: 0.358282 | Val Loss: 0.863705\n",
      "Epoch [300/500] | Train Loss: 0.345999 | Val Loss: 0.901624\n",
      "Epoch [400/500] | Train Loss: 0.327742 | Val Loss: 0.947531\n",
      "Epoch [500/500] | Train Loss: 0.309126 | Val Loss: 0.953829\n",
      "Epoch [100/500] | Train Loss: 0.482547 | Val Loss: 0.843286\n",
      "Epoch [200/500] | Train Loss: 0.469389 | Val Loss: 0.837981\n",
      "Epoch [300/500] | Train Loss: 0.423040 | Val Loss: 0.845628\n",
      "Epoch [400/500] | Train Loss: 0.404821 | Val Loss: 0.869763\n",
      "Epoch [500/500] | Train Loss: 0.380847 | Val Loss: 0.903920\n",
      "Epoch [100/500] | Train Loss: 0.593303 | Val Loss: 0.623421\n",
      "Epoch [200/500] | Train Loss: 0.564464 | Val Loss: 0.631615\n",
      "Epoch [300/500] | Train Loss: 0.548320 | Val Loss: 0.645847\n",
      "Epoch [400/500] | Train Loss: 0.507683 | Val Loss: 0.651471\n",
      "Epoch [500/500] | Train Loss: 0.492556 | Val Loss: 0.664752\n",
      "Epoch [100/500] | Train Loss: 0.138049 | Val Loss: 0.502189\n",
      "Epoch [200/500] | Train Loss: 0.116925 | Val Loss: 0.518617\n",
      "Epoch [300/500] | Train Loss: 0.097487 | Val Loss: 0.550124\n",
      "Epoch [400/500] | Train Loss: 0.084202 | Val Loss: 0.536226\n",
      "Epoch [500/500] | Train Loss: 0.067731 | Val Loss: 0.533522\n",
      "Epoch [100/500] | Train Loss: 0.254499 | Val Loss: 0.627229\n",
      "Epoch [200/500] | Train Loss: 0.190555 | Val Loss: 0.675702\n",
      "Epoch [300/500] | Train Loss: 0.161712 | Val Loss: 0.708139\n",
      "Epoch [400/500] | Train Loss: 0.142176 | Val Loss: 0.723514\n",
      "Epoch [500/500] | Train Loss: 0.140702 | Val Loss: 0.699200\n",
      "Epoch [100/500] | Train Loss: 0.298300 | Val Loss: 0.972633\n",
      "Epoch [200/500] | Train Loss: 0.280151 | Val Loss: 0.988613\n",
      "Epoch [300/500] | Train Loss: 0.229721 | Val Loss: 1.104263\n",
      "Epoch [400/500] | Train Loss: 0.210351 | Val Loss: 1.050592\n",
      "Epoch [500/500] | Train Loss: 0.201245 | Val Loss: 1.006652\n",
      "Epoch [100/500] | Train Loss: 0.465563 | Val Loss: 0.860887\n",
      "Epoch [200/500] | Train Loss: 0.380487 | Val Loss: 0.966934\n",
      "Epoch [300/500] | Train Loss: 0.368954 | Val Loss: 0.959338\n",
      "Epoch [400/500] | Train Loss: 0.319947 | Val Loss: 0.979403\n",
      "Epoch [500/500] | Train Loss: 0.321806 | Val Loss: 0.998688\n",
      "Epoch [100/500] | Train Loss: 0.483387 | Val Loss: 0.637702\n",
      "Epoch [200/500] | Train Loss: 0.420409 | Val Loss: 0.667491\n",
      "Epoch [300/500] | Train Loss: 0.382187 | Val Loss: 0.688750\n",
      "Epoch [400/500] | Train Loss: 0.380776 | Val Loss: 0.713542\n",
      "Epoch [500/500] | Train Loss: 0.372244 | Val Loss: 0.741763\n",
      "Epoch [100/500] | Train Loss: 0.234590 | Val Loss: 0.394828\n",
      "Epoch [200/500] | Train Loss: 0.212648 | Val Loss: 0.406144\n",
      "Epoch [300/500] | Train Loss: 0.187347 | Val Loss: 0.430654\n",
      "Epoch [400/500] | Train Loss: 0.174042 | Val Loss: 0.443774\n",
      "Epoch [500/500] | Train Loss: 0.155512 | Val Loss: 0.455544\n",
      "Epoch [100/500] | Train Loss: 0.303678 | Val Loss: 0.595323\n",
      "Epoch [200/500] | Train Loss: 0.272107 | Val Loss: 0.596748\n",
      "Epoch [300/500] | Train Loss: 0.260332 | Val Loss: 0.601245\n",
      "Epoch [400/500] | Train Loss: 0.275283 | Val Loss: 0.605198\n",
      "Epoch [500/500] | Train Loss: 0.261769 | Val Loss: 0.624496\n",
      "Epoch [100/500] | Train Loss: 0.389875 | Val Loss: 0.848965\n",
      "Epoch [200/500] | Train Loss: 0.374010 | Val Loss: 0.844843\n",
      "Epoch [300/500] | Train Loss: 0.361289 | Val Loss: 0.864507\n",
      "Epoch [400/500] | Train Loss: 0.354010 | Val Loss: 0.882380\n",
      "Epoch [500/500] | Train Loss: 0.354144 | Val Loss: 0.928987\n",
      "Epoch [100/500] | Train Loss: 0.502457 | Val Loss: 0.833610\n",
      "Epoch [200/500] | Train Loss: 0.485004 | Val Loss: 0.851850\n",
      "Epoch [300/500] | Train Loss: 0.478744 | Val Loss: 0.867266\n",
      "Epoch [400/500] | Train Loss: 0.452716 | Val Loss: 0.885784\n",
      "Epoch [500/500] | Train Loss: 0.417141 | Val Loss: 0.886305\n",
      "Epoch [100/500] | Train Loss: 0.587319 | Val Loss: 0.626977\n",
      "Epoch [200/500] | Train Loss: 0.572295 | Val Loss: 0.632950\n",
      "Epoch [300/500] | Train Loss: 0.543394 | Val Loss: 0.630956\n",
      "Epoch [400/500] | Train Loss: 0.535317 | Val Loss: 0.621185\n",
      "Epoch [500/500] | Train Loss: 0.510154 | Val Loss: 0.622268\n",
      "Epoch [100/500] | Train Loss: 0.184890 | Val Loss: 0.453435\n",
      "Epoch [200/500] | Train Loss: 0.158695 | Val Loss: 0.455791\n",
      "Epoch [300/500] | Train Loss: 0.141462 | Val Loss: 0.476217\n",
      "Epoch [400/500] | Train Loss: 0.117615 | Val Loss: 0.483312\n",
      "Epoch [500/500] | Train Loss: 0.122187 | Val Loss: 0.494863\n",
      "Epoch [100/500] | Train Loss: 0.262943 | Val Loss: 0.638961\n",
      "Epoch [200/500] | Train Loss: 0.206137 | Val Loss: 0.675916\n",
      "Epoch [300/500] | Train Loss: 0.193388 | Val Loss: 0.686505\n",
      "Epoch [400/500] | Train Loss: 0.197554 | Val Loss: 0.672522\n",
      "Epoch [500/500] | Train Loss: 0.195285 | Val Loss: 0.693002\n",
      "Epoch [100/500] | Train Loss: 0.337140 | Val Loss: 0.890388\n",
      "Epoch [200/500] | Train Loss: 0.330832 | Val Loss: 0.946077\n",
      "Epoch [300/500] | Train Loss: 0.307689 | Val Loss: 1.001040\n",
      "Epoch [400/500] | Train Loss: 0.274388 | Val Loss: 0.984442\n",
      "Epoch [500/500] | Train Loss: 0.264305 | Val Loss: 1.005114\n",
      "Epoch [100/500] | Train Loss: 0.439022 | Val Loss: 0.833784\n",
      "Epoch [200/500] | Train Loss: 0.418897 | Val Loss: 0.852789\n",
      "Epoch [300/500] | Train Loss: 0.379947 | Val Loss: 0.933867\n",
      "Epoch [400/500] | Train Loss: 0.363342 | Val Loss: 0.903909\n",
      "Epoch [500/500] | Train Loss: 0.363085 | Val Loss: 0.916124\n",
      "Epoch [100/500] | Train Loss: 0.547596 | Val Loss: 0.641572\n",
      "Epoch [200/500] | Train Loss: 0.471688 | Val Loss: 0.652300\n",
      "Epoch [300/500] | Train Loss: 0.447862 | Val Loss: 0.644667\n",
      "Epoch [400/500] | Train Loss: 0.456063 | Val Loss: 0.643039\n",
      "Epoch [500/500] | Train Loss: 0.450272 | Val Loss: 0.646171\n",
      "Epoch [100/500] | Train Loss: 0.223975 | Val Loss: 0.401561\n",
      "Epoch [200/500] | Train Loss: 0.171331 | Val Loss: 0.426812\n",
      "Epoch [300/500] | Train Loss: 0.163043 | Val Loss: 0.443385\n",
      "Epoch [400/500] | Train Loss: 0.130375 | Val Loss: 0.454024\n",
      "Epoch [500/500] | Train Loss: 0.120652 | Val Loss: 0.490963\n",
      "Epoch [100/500] | Train Loss: 0.280374 | Val Loss: 0.607451\n",
      "Epoch [200/500] | Train Loss: 0.245342 | Val Loss: 0.637685\n",
      "Epoch [300/500] | Train Loss: 0.232153 | Val Loss: 0.655000\n",
      "Epoch [400/500] | Train Loss: 0.209998 | Val Loss: 0.670972\n",
      "Epoch [500/500] | Train Loss: 0.182684 | Val Loss: 0.676365\n",
      "Epoch [100/500] | Train Loss: 0.360900 | Val Loss: 0.835014\n",
      "Epoch [200/500] | Train Loss: 0.326767 | Val Loss: 0.877392\n",
      "Epoch [300/500] | Train Loss: 0.289724 | Val Loss: 0.936992\n",
      "Epoch [400/500] | Train Loss: 0.263453 | Val Loss: 1.000486\n",
      "Epoch [500/500] | Train Loss: 0.260723 | Val Loss: 0.996933\n",
      "Epoch [100/500] | Train Loss: 0.473976 | Val Loss: 0.831976\n",
      "Epoch [200/500] | Train Loss: 0.448287 | Val Loss: 0.877431\n",
      "Epoch [300/500] | Train Loss: 0.394155 | Val Loss: 0.926568\n",
      "Epoch [400/500] | Train Loss: 0.385952 | Val Loss: 0.927458\n",
      "Epoch [500/500] | Train Loss: 0.354364 | Val Loss: 0.949366\n",
      "Epoch [100/500] | Train Loss: 0.575805 | Val Loss: 0.621619\n",
      "Epoch [200/500] | Train Loss: 0.537491 | Val Loss: 0.634446\n",
      "Epoch [300/500] | Train Loss: 0.498887 | Val Loss: 0.647084\n",
      "Epoch [400/500] | Train Loss: 0.489989 | Val Loss: 0.644432\n",
      "Epoch [500/500] | Train Loss: 0.442134 | Val Loss: 0.642276\n",
      "Epoch [100/500] | Train Loss: 0.141435 | Val Loss: 0.542021\n",
      "Epoch [200/500] | Train Loss: 0.107028 | Val Loss: 0.595447\n",
      "Epoch [300/500] | Train Loss: 0.085501 | Val Loss: 0.619558\n",
      "Epoch [400/500] | Train Loss: 0.057740 | Val Loss: 0.611481\n",
      "Epoch [500/500] | Train Loss: 0.051752 | Val Loss: 0.595734\n",
      "Epoch [100/500] | Train Loss: 0.202344 | Val Loss: 0.690007\n",
      "Epoch [200/500] | Train Loss: 0.148605 | Val Loss: 0.823931\n",
      "Epoch [300/500] | Train Loss: 0.124001 | Val Loss: 0.781627\n",
      "Epoch [400/500] | Train Loss: 0.103517 | Val Loss: 0.736128\n",
      "Epoch [500/500] | Train Loss: 0.099103 | Val Loss: 0.744003\n",
      "Epoch [100/500] | Train Loss: 0.286436 | Val Loss: 0.988514\n",
      "Epoch [200/500] | Train Loss: 0.249705 | Val Loss: 1.088861\n",
      "Epoch [300/500] | Train Loss: 0.222482 | Val Loss: 1.117636\n",
      "Epoch [400/500] | Train Loss: 0.202701 | Val Loss: 1.074799\n",
      "Epoch [500/500] | Train Loss: 0.181330 | Val Loss: 1.132267\n",
      "Epoch [100/500] | Train Loss: 0.399907 | Val Loss: 0.949129\n",
      "Epoch [200/500] | Train Loss: 0.343632 | Val Loss: 1.060637\n",
      "Epoch [300/500] | Train Loss: 0.320813 | Val Loss: 1.013895\n",
      "Epoch [400/500] | Train Loss: 0.305789 | Val Loss: 1.073171\n",
      "Epoch [500/500] | Train Loss: 0.272734 | Val Loss: 1.058982\n",
      "Epoch [100/500] | Train Loss: 0.520623 | Val Loss: 0.672876\n",
      "Epoch [200/500] | Train Loss: 0.479838 | Val Loss: 0.674399\n",
      "Epoch [300/500] | Train Loss: 0.447802 | Val Loss: 0.789842\n",
      "Epoch [400/500] | Train Loss: 0.417156 | Val Loss: 0.789901\n",
      "Epoch [500/500] | Train Loss: 0.409582 | Val Loss: 0.785384\n",
      "Epoch [100/500] | Train Loss: 0.224724 | Val Loss: 0.402906\n",
      "Epoch [200/500] | Train Loss: 0.194018 | Val Loss: 0.419738\n",
      "Epoch [300/500] | Train Loss: 0.175484 | Val Loss: 0.447070\n",
      "Epoch [400/500] | Train Loss: 0.162446 | Val Loss: 0.472342\n",
      "Epoch [500/500] | Train Loss: 0.138873 | Val Loss: 0.494586\n",
      "Epoch [100/500] | Train Loss: 0.305419 | Val Loss: 0.609227\n",
      "Epoch [200/500] | Train Loss: 0.296499 | Val Loss: 0.607294\n",
      "Epoch [300/500] | Train Loss: 0.265254 | Val Loss: 0.611575\n",
      "Epoch [400/500] | Train Loss: 0.250539 | Val Loss: 0.617988\n",
      "Epoch [500/500] | Train Loss: 0.243684 | Val Loss: 0.629930\n",
      "Epoch [100/500] | Train Loss: 0.393183 | Val Loss: 0.863370\n",
      "Epoch [200/500] | Train Loss: 0.376747 | Val Loss: 0.855971\n",
      "Epoch [300/500] | Train Loss: 0.365741 | Val Loss: 0.880179\n",
      "Epoch [400/500] | Train Loss: 0.334775 | Val Loss: 0.885681\n",
      "Epoch [500/500] | Train Loss: 0.335174 | Val Loss: 0.911984\n",
      "Epoch [100/500] | Train Loss: 0.513465 | Val Loss: 0.827721\n",
      "Epoch [200/500] | Train Loss: 0.483983 | Val Loss: 0.836427\n",
      "Epoch [300/500] | Train Loss: 0.465996 | Val Loss: 0.842209\n",
      "Epoch [400/500] | Train Loss: 0.443405 | Val Loss: 0.862566\n",
      "Epoch [500/500] | Train Loss: 0.428121 | Val Loss: 0.886425\n",
      "Epoch [100/500] | Train Loss: 0.563523 | Val Loss: 0.630524\n",
      "Epoch [200/500] | Train Loss: 0.538510 | Val Loss: 0.651450\n",
      "Epoch [300/500] | Train Loss: 0.535212 | Val Loss: 0.652931\n",
      "Epoch [400/500] | Train Loss: 0.508478 | Val Loss: 0.648174\n",
      "Epoch [500/500] | Train Loss: 0.495740 | Val Loss: 0.658760\n",
      "Epoch [100/500] | Train Loss: 0.153922 | Val Loss: 0.477327\n",
      "Epoch [200/500] | Train Loss: 0.108250 | Val Loss: 0.524927\n",
      "Epoch [300/500] | Train Loss: 0.087621 | Val Loss: 0.551330\n",
      "Epoch [400/500] | Train Loss: 0.087089 | Val Loss: 0.491392\n",
      "Epoch [500/500] | Train Loss: 0.084516 | Val Loss: 0.519202\n",
      "Epoch [100/500] | Train Loss: 0.245937 | Val Loss: 0.635486\n",
      "Epoch [200/500] | Train Loss: 0.204377 | Val Loss: 0.677833\n",
      "Epoch [300/500] | Train Loss: 0.167610 | Val Loss: 0.685933\n",
      "Epoch [400/500] | Train Loss: 0.189137 | Val Loss: 0.677345\n",
      "Epoch [500/500] | Train Loss: 0.143888 | Val Loss: 0.694302\n",
      "Epoch [100/500] | Train Loss: 0.333348 | Val Loss: 0.971355\n",
      "Epoch [200/500] | Train Loss: 0.296467 | Val Loss: 1.078174\n",
      "Epoch [300/500] | Train Loss: 0.288316 | Val Loss: 1.093987\n",
      "Epoch [400/500] | Train Loss: 0.262178 | Val Loss: 1.146248\n",
      "Epoch [500/500] | Train Loss: 0.263859 | Val Loss: 1.132267\n",
      "Epoch [100/500] | Train Loss: 0.453409 | Val Loss: 0.882035\n",
      "Epoch [200/500] | Train Loss: 0.408094 | Val Loss: 0.874822\n",
      "Epoch [300/500] | Train Loss: 0.384209 | Val Loss: 0.892300\n",
      "Epoch [400/500] | Train Loss: 0.367434 | Val Loss: 0.885253\n",
      "Epoch [500/500] | Train Loss: 0.343959 | Val Loss: 0.915389\n",
      "Epoch [100/500] | Train Loss: 0.512547 | Val Loss: 0.654949\n",
      "Epoch [200/500] | Train Loss: 0.473305 | Val Loss: 0.705522\n",
      "Epoch [300/500] | Train Loss: 0.445325 | Val Loss: 0.701758\n",
      "Epoch [400/500] | Train Loss: 0.407892 | Val Loss: 0.716175\n",
      "Epoch [500/500] | Train Loss: 0.397283 | Val Loss: 0.699012\n",
      "[Year=1982] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.703520 Test MSE=1.058473\n",
      "Year 1982 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.513188 | Val Loss: 0.436956\n",
      "Epoch [200/500] | Train Loss: 0.395375 | Val Loss: 0.468706\n",
      "Epoch [300/500] | Train Loss: 0.364616 | Val Loss: 0.488139\n",
      "Epoch [400/500] | Train Loss: 0.293411 | Val Loss: 0.499766\n",
      "Epoch [500/500] | Train Loss: 0.231920 | Val Loss: 0.506382\n",
      "Epoch [100/500] | Train Loss: 0.453297 | Val Loss: 0.919482\n",
      "Epoch [200/500] | Train Loss: 0.428554 | Val Loss: 0.934661\n",
      "Epoch [300/500] | Train Loss: 0.373949 | Val Loss: 0.953178\n",
      "Epoch [400/500] | Train Loss: 0.352406 | Val Loss: 1.005397\n",
      "Epoch [500/500] | Train Loss: 0.328345 | Val Loss: 1.039883\n",
      "Epoch [100/500] | Train Loss: 0.578555 | Val Loss: 0.858818\n",
      "Epoch [200/500] | Train Loss: 0.524532 | Val Loss: 0.882146\n",
      "Epoch [300/500] | Train Loss: 0.510384 | Val Loss: 0.900437\n",
      "Epoch [400/500] | Train Loss: 0.454521 | Val Loss: 0.948219\n",
      "Epoch [500/500] | Train Loss: 0.449140 | Val Loss: 0.957122\n",
      "Epoch [100/500] | Train Loss: 0.641548 | Val Loss: 0.715106\n",
      "Epoch [200/500] | Train Loss: 0.613646 | Val Loss: 0.727529\n",
      "Epoch [300/500] | Train Loss: 0.583810 | Val Loss: 0.718733\n",
      "Epoch [400/500] | Train Loss: 0.543940 | Val Loss: 0.711361\n",
      "Epoch [500/500] | Train Loss: 0.519109 | Val Loss: 0.702285\n",
      "Epoch [100/500] | Train Loss: 0.653880 | Val Loss: 1.080050\n",
      "Epoch [200/500] | Train Loss: 0.617170 | Val Loss: 1.127232\n",
      "Epoch [300/500] | Train Loss: 0.576691 | Val Loss: 1.167803\n",
      "Epoch [400/500] | Train Loss: 0.559062 | Val Loss: 1.208272\n",
      "Epoch [500/500] | Train Loss: 0.535747 | Val Loss: 1.233108\n",
      "Epoch [100/500] | Train Loss: 0.272314 | Val Loss: 0.567435\n",
      "Epoch [200/500] | Train Loss: 0.190471 | Val Loss: 0.614010\n",
      "Epoch [300/500] | Train Loss: 0.149787 | Val Loss: 0.639855\n",
      "Epoch [400/500] | Train Loss: 0.147280 | Val Loss: 0.688913\n",
      "Epoch [500/500] | Train Loss: 0.219586 | Val Loss: 0.675531\n",
      "Epoch [100/500] | Train Loss: 0.339742 | Val Loss: 0.991423\n",
      "Epoch [200/500] | Train Loss: 0.261524 | Val Loss: 1.051975\n",
      "Epoch [300/500] | Train Loss: 0.239803 | Val Loss: 1.065573\n",
      "Epoch [400/500] | Train Loss: 0.178140 | Val Loss: 1.113426\n",
      "Epoch [500/500] | Train Loss: 0.178723 | Val Loss: 1.127684\n",
      "Epoch [100/500] | Train Loss: 0.474483 | Val Loss: 0.937659\n",
      "Epoch [200/500] | Train Loss: 0.418875 | Val Loss: 1.088233\n",
      "Epoch [300/500] | Train Loss: 0.334276 | Val Loss: 1.183364\n",
      "Epoch [400/500] | Train Loss: 0.321113 | Val Loss: 1.101116\n",
      "Epoch [500/500] | Train Loss: 0.327032 | Val Loss: 1.130012\n",
      "Epoch [100/500] | Train Loss: 0.579527 | Val Loss: 0.757897\n",
      "Epoch [200/500] | Train Loss: 0.532550 | Val Loss: 0.803421\n",
      "Epoch [300/500] | Train Loss: 0.496209 | Val Loss: 0.807599\n",
      "Epoch [400/500] | Train Loss: 0.476552 | Val Loss: 0.837365\n",
      "Epoch [500/500] | Train Loss: 0.485171 | Val Loss: 0.820272\n",
      "Epoch [100/500] | Train Loss: 0.578363 | Val Loss: 1.172860\n",
      "Epoch [200/500] | Train Loss: 0.536144 | Val Loss: 1.252316\n",
      "Epoch [300/500] | Train Loss: 0.466163 | Val Loss: 1.295668\n",
      "Epoch [400/500] | Train Loss: 0.436531 | Val Loss: 1.309746\n",
      "Epoch [500/500] | Train Loss: 0.461261 | Val Loss: 1.273927\n",
      "Epoch [100/500] | Train Loss: 0.492564 | Val Loss: 0.420452\n",
      "Epoch [200/500] | Train Loss: 0.436574 | Val Loss: 0.424229\n",
      "Epoch [300/500] | Train Loss: 0.410334 | Val Loss: 0.433093\n",
      "Epoch [400/500] | Train Loss: 0.347651 | Val Loss: 0.437387\n",
      "Epoch [500/500] | Train Loss: 0.389514 | Val Loss: 0.447288\n",
      "Epoch [100/500] | Train Loss: 0.431291 | Val Loss: 0.932227\n",
      "Epoch [200/500] | Train Loss: 0.431722 | Val Loss: 0.950019\n",
      "Epoch [300/500] | Train Loss: 0.408863 | Val Loss: 0.957611\n",
      "Epoch [400/500] | Train Loss: 0.387237 | Val Loss: 0.972690\n",
      "Epoch [500/500] | Train Loss: 0.375488 | Val Loss: 1.007739\n",
      "Epoch [100/500] | Train Loss: 0.602843 | Val Loss: 0.841081\n",
      "Epoch [200/500] | Train Loss: 0.580737 | Val Loss: 0.837067\n",
      "Epoch [300/500] | Train Loss: 0.580983 | Val Loss: 0.844129\n",
      "Epoch [400/500] | Train Loss: 0.522249 | Val Loss: 0.867116\n",
      "Epoch [500/500] | Train Loss: 0.527773 | Val Loss: 0.875025\n",
      "Epoch [100/500] | Train Loss: 0.665779 | Val Loss: 0.715913\n",
      "Epoch [200/500] | Train Loss: 0.633057 | Val Loss: 0.717583\n",
      "Epoch [300/500] | Train Loss: 0.612818 | Val Loss: 0.715127\n",
      "Epoch [400/500] | Train Loss: 0.597963 | Val Loss: 0.724032\n",
      "Epoch [500/500] | Train Loss: 0.605814 | Val Loss: 0.726958\n",
      "Epoch [100/500] | Train Loss: 0.697656 | Val Loss: 1.081629\n",
      "Epoch [200/500] | Train Loss: 0.666981 | Val Loss: 1.063240\n",
      "Epoch [300/500] | Train Loss: 0.655683 | Val Loss: 1.064849\n",
      "Epoch [400/500] | Train Loss: 0.638787 | Val Loss: 1.076755\n",
      "Epoch [500/500] | Train Loss: 0.636398 | Val Loss: 1.080761\n",
      "Epoch [100/500] | Train Loss: 0.349308 | Val Loss: 0.487469\n",
      "Epoch [200/500] | Train Loss: 0.303254 | Val Loss: 0.491149\n",
      "Epoch [300/500] | Train Loss: 0.264679 | Val Loss: 0.547636\n",
      "Epoch [400/500] | Train Loss: 0.259682 | Val Loss: 0.595278\n",
      "Epoch [500/500] | Train Loss: 0.224953 | Val Loss: 0.558411\n",
      "Epoch [100/500] | Train Loss: 0.399971 | Val Loss: 1.007167\n",
      "Epoch [200/500] | Train Loss: 0.334437 | Val Loss: 1.056232\n",
      "Epoch [300/500] | Train Loss: 0.335107 | Val Loss: 1.058497\n",
      "Epoch [400/500] | Train Loss: 0.276994 | Val Loss: 1.051927\n",
      "Epoch [500/500] | Train Loss: 0.301870 | Val Loss: 1.059212\n",
      "Epoch [100/500] | Train Loss: 0.571699 | Val Loss: 0.836185\n",
      "Epoch [200/500] | Train Loss: 0.531656 | Val Loss: 0.881108\n",
      "Epoch [300/500] | Train Loss: 0.484319 | Val Loss: 0.876591\n",
      "Epoch [400/500] | Train Loss: 0.485870 | Val Loss: 0.894969\n",
      "Epoch [500/500] | Train Loss: 0.422543 | Val Loss: 0.911660\n",
      "Epoch [100/500] | Train Loss: 0.592554 | Val Loss: 0.717027\n",
      "Epoch [200/500] | Train Loss: 0.533228 | Val Loss: 0.724855\n",
      "Epoch [300/500] | Train Loss: 0.534123 | Val Loss: 0.712893\n",
      "Epoch [400/500] | Train Loss: 0.528193 | Val Loss: 0.726167\n",
      "Epoch [500/500] | Train Loss: 0.466264 | Val Loss: 0.726630\n",
      "Epoch [100/500] | Train Loss: 0.622860 | Val Loss: 1.064422\n",
      "Epoch [200/500] | Train Loss: 0.567529 | Val Loss: 1.091996\n",
      "Epoch [300/500] | Train Loss: 0.540784 | Val Loss: 1.104726\n",
      "Epoch [400/500] | Train Loss: 0.496346 | Val Loss: 1.098883\n",
      "Epoch [500/500] | Train Loss: 0.536276 | Val Loss: 1.116208\n",
      "Epoch [100/500] | Train Loss: 0.441066 | Val Loss: 0.458773\n",
      "Epoch [200/500] | Train Loss: 0.337288 | Val Loss: 0.478334\n",
      "Epoch [300/500] | Train Loss: 0.290660 | Val Loss: 0.502026\n",
      "Epoch [400/500] | Train Loss: 0.234480 | Val Loss: 0.544333\n",
      "Epoch [500/500] | Train Loss: 0.218940 | Val Loss: 0.550920\n",
      "Epoch [100/500] | Train Loss: 0.416303 | Val Loss: 0.920606\n",
      "Epoch [200/500] | Train Loss: 0.363801 | Val Loss: 0.959444\n",
      "Epoch [300/500] | Train Loss: 0.319202 | Val Loss: 1.015520\n",
      "Epoch [400/500] | Train Loss: 0.273442 | Val Loss: 1.058620\n",
      "Epoch [500/500] | Train Loss: 0.250554 | Val Loss: 1.147224\n",
      "Epoch [100/500] | Train Loss: 0.578422 | Val Loss: 0.849060\n",
      "Epoch [200/500] | Train Loss: 0.515978 | Val Loss: 0.891658\n",
      "Epoch [300/500] | Train Loss: 0.487836 | Val Loss: 0.930014\n",
      "Epoch [400/500] | Train Loss: 0.435107 | Val Loss: 0.945063\n",
      "Epoch [500/500] | Train Loss: 0.425909 | Val Loss: 0.946440\n",
      "Epoch [100/500] | Train Loss: 0.647750 | Val Loss: 0.718677\n",
      "Epoch [200/500] | Train Loss: 0.584246 | Val Loss: 0.752542\n",
      "Epoch [300/500] | Train Loss: 0.546715 | Val Loss: 0.767750\n",
      "Epoch [400/500] | Train Loss: 0.493123 | Val Loss: 0.793795\n",
      "Epoch [500/500] | Train Loss: 0.482928 | Val Loss: 0.803288\n",
      "Epoch [100/500] | Train Loss: 0.655256 | Val Loss: 1.073067\n",
      "Epoch [200/500] | Train Loss: 0.608723 | Val Loss: 1.084168\n",
      "Epoch [300/500] | Train Loss: 0.546232 | Val Loss: 1.131588\n",
      "Epoch [400/500] | Train Loss: 0.530496 | Val Loss: 1.157781\n",
      "Epoch [500/500] | Train Loss: 0.497720 | Val Loss: 1.196304\n",
      "Epoch [100/500] | Train Loss: 0.266581 | Val Loss: 0.586211\n",
      "Epoch [200/500] | Train Loss: 0.166003 | Val Loss: 0.682479\n",
      "Epoch [300/500] | Train Loss: 0.117296 | Val Loss: 0.668027\n",
      "Epoch [400/500] | Train Loss: 0.136016 | Val Loss: 0.664314\n",
      "Epoch [500/500] | Train Loss: 0.095552 | Val Loss: 0.687802\n",
      "Epoch [100/500] | Train Loss: 0.280614 | Val Loss: 1.185169\n",
      "Epoch [200/500] | Train Loss: 0.224153 | Val Loss: 1.192185\n",
      "Epoch [300/500] | Train Loss: 0.171657 | Val Loss: 1.090547\n",
      "Epoch [400/500] | Train Loss: 0.185217 | Val Loss: 1.190170\n",
      "Epoch [500/500] | Train Loss: 0.149785 | Val Loss: 1.241389\n",
      "Epoch [100/500] | Train Loss: 0.475756 | Val Loss: 0.923630\n",
      "Epoch [200/500] | Train Loss: 0.336365 | Val Loss: 1.082496\n",
      "Epoch [300/500] | Train Loss: 0.275021 | Val Loss: 1.072236\n",
      "Epoch [400/500] | Train Loss: 0.287215 | Val Loss: 1.122392\n",
      "Epoch [500/500] | Train Loss: 0.272738 | Val Loss: 1.157798\n",
      "Epoch [100/500] | Train Loss: 0.539286 | Val Loss: 0.758825\n",
      "Epoch [200/500] | Train Loss: 0.406923 | Val Loss: 0.806754\n",
      "Epoch [300/500] | Train Loss: 0.389096 | Val Loss: 0.877992\n",
      "Epoch [400/500] | Train Loss: 0.339933 | Val Loss: 0.911887\n",
      "Epoch [500/500] | Train Loss: 0.345299 | Val Loss: 0.856414\n",
      "Epoch [100/500] | Train Loss: 0.540600 | Val Loss: 1.189920\n",
      "Epoch [200/500] | Train Loss: 0.443197 | Val Loss: 1.255829\n",
      "Epoch [300/500] | Train Loss: 0.415834 | Val Loss: 1.258299\n",
      "Epoch [400/500] | Train Loss: 0.370834 | Val Loss: 1.244521\n",
      "Epoch [500/500] | Train Loss: 0.378823 | Val Loss: 1.313307\n",
      "Epoch [100/500] | Train Loss: 0.496304 | Val Loss: 0.436318\n",
      "Epoch [200/500] | Train Loss: 0.440260 | Val Loss: 0.449146\n",
      "Epoch [300/500] | Train Loss: 0.379925 | Val Loss: 0.460020\n",
      "Epoch [400/500] | Train Loss: 0.344786 | Val Loss: 0.476583\n",
      "Epoch [500/500] | Train Loss: 0.267234 | Val Loss: 0.502644\n",
      "Epoch [100/500] | Train Loss: 0.465555 | Val Loss: 0.906046\n",
      "Epoch [200/500] | Train Loss: 0.425903 | Val Loss: 0.917971\n",
      "Epoch [300/500] | Train Loss: 0.406174 | Val Loss: 0.955859\n",
      "Epoch [400/500] | Train Loss: 0.389754 | Val Loss: 0.981510\n",
      "Epoch [500/500] | Train Loss: 0.351632 | Val Loss: 0.975426\n",
      "Epoch [100/500] | Train Loss: 0.613769 | Val Loss: 0.824827\n",
      "Epoch [200/500] | Train Loss: 0.575233 | Val Loss: 0.838339\n",
      "Epoch [300/500] | Train Loss: 0.546747 | Val Loss: 0.837624\n",
      "Epoch [400/500] | Train Loss: 0.539755 | Val Loss: 0.879033\n",
      "Epoch [500/500] | Train Loss: 0.487327 | Val Loss: 0.901247\n",
      "Epoch [100/500] | Train Loss: 0.645719 | Val Loss: 0.714259\n",
      "Epoch [200/500] | Train Loss: 0.613120 | Val Loss: 0.734049\n",
      "Epoch [300/500] | Train Loss: 0.579755 | Val Loss: 0.747311\n",
      "Epoch [400/500] | Train Loss: 0.534676 | Val Loss: 0.742984\n",
      "Epoch [500/500] | Train Loss: 0.518673 | Val Loss: 0.723570\n",
      "Epoch [100/500] | Train Loss: 0.681018 | Val Loss: 1.065294\n",
      "Epoch [200/500] | Train Loss: 0.650096 | Val Loss: 1.087153\n",
      "Epoch [300/500] | Train Loss: 0.632810 | Val Loss: 1.106830\n",
      "Epoch [400/500] | Train Loss: 0.603237 | Val Loss: 1.118450\n",
      "Epoch [500/500] | Train Loss: 0.563898 | Val Loss: 1.110839\n",
      "Epoch [100/500] | Train Loss: 0.279073 | Val Loss: 0.494308\n",
      "Epoch [200/500] | Train Loss: 0.233001 | Val Loss: 0.534039\n",
      "Epoch [300/500] | Train Loss: 0.208994 | Val Loss: 0.567410\n",
      "Epoch [400/500] | Train Loss: 0.178821 | Val Loss: 0.584690\n",
      "Epoch [500/500] | Train Loss: 0.161422 | Val Loss: 0.602053\n",
      "Epoch [100/500] | Train Loss: 0.358862 | Val Loss: 1.095819\n",
      "Epoch [200/500] | Train Loss: 0.302270 | Val Loss: 1.093428\n",
      "Epoch [300/500] | Train Loss: 0.284715 | Val Loss: 1.066264\n",
      "Epoch [400/500] | Train Loss: 0.268148 | Val Loss: 1.074928\n",
      "Epoch [500/500] | Train Loss: 0.251188 | Val Loss: 1.140973\n",
      "Epoch [100/500] | Train Loss: 0.501628 | Val Loss: 0.913213\n",
      "Epoch [200/500] | Train Loss: 0.460309 | Val Loss: 0.892561\n",
      "Epoch [300/500] | Train Loss: 0.403492 | Val Loss: 0.895981\n",
      "Epoch [400/500] | Train Loss: 0.425631 | Val Loss: 0.907685\n",
      "Epoch [500/500] | Train Loss: 0.382717 | Val Loss: 0.882080\n",
      "Epoch [100/500] | Train Loss: 0.616331 | Val Loss: 0.729326\n",
      "Epoch [200/500] | Train Loss: 0.598943 | Val Loss: 0.724701\n",
      "Epoch [300/500] | Train Loss: 0.548544 | Val Loss: 0.717409\n",
      "Epoch [400/500] | Train Loss: 0.528599 | Val Loss: 0.734769\n",
      "Epoch [500/500] | Train Loss: 0.498948 | Val Loss: 0.731713\n",
      "Epoch [100/500] | Train Loss: 0.612186 | Val Loss: 1.088990\n",
      "Epoch [200/500] | Train Loss: 0.532559 | Val Loss: 1.123308\n",
      "Epoch [300/500] | Train Loss: 0.507219 | Val Loss: 1.125687\n",
      "Epoch [400/500] | Train Loss: 0.494946 | Val Loss: 1.144323\n",
      "Epoch [500/500] | Train Loss: 0.465557 | Val Loss: 1.161641\n",
      "[Year=1983] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.827554 Test MSE=0.575675\n",
      "Year 1983 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.429576 | Val Loss: 0.922442\n",
      "Epoch [200/500] | Train Loss: 0.376976 | Val Loss: 0.992290\n",
      "Epoch [300/500] | Train Loss: 0.354480 | Val Loss: 0.988787\n",
      "Epoch [400/500] | Train Loss: 0.313579 | Val Loss: 1.006191\n",
      "Epoch [500/500] | Train Loss: 0.272607 | Val Loss: 0.991647\n",
      "Epoch [100/500] | Train Loss: 0.612393 | Val Loss: 0.813273\n",
      "Epoch [200/500] | Train Loss: 0.532634 | Val Loss: 0.916868\n",
      "Epoch [300/500] | Train Loss: 0.478398 | Val Loss: 0.997026\n",
      "Epoch [400/500] | Train Loss: 0.463495 | Val Loss: 1.007041\n",
      "Epoch [500/500] | Train Loss: 0.458673 | Val Loss: 1.047186\n",
      "Epoch [100/500] | Train Loss: 0.670778 | Val Loss: 0.727555\n",
      "Epoch [200/500] | Train Loss: 0.625013 | Val Loss: 0.729634\n",
      "Epoch [300/500] | Train Loss: 0.587702 | Val Loss: 0.761881\n",
      "Epoch [400/500] | Train Loss: 0.556943 | Val Loss: 0.790839\n",
      "Epoch [500/500] | Train Loss: 0.513670 | Val Loss: 0.793678\n",
      "Epoch [100/500] | Train Loss: 0.681418 | Val Loss: 1.218939\n",
      "Epoch [200/500] | Train Loss: 0.634320 | Val Loss: 1.244719\n",
      "Epoch [300/500] | Train Loss: 0.575451 | Val Loss: 1.265533\n",
      "Epoch [400/500] | Train Loss: 0.567569 | Val Loss: 1.251845\n",
      "Epoch [500/500] | Train Loss: 0.533258 | Val Loss: 1.242418\n",
      "Epoch [100/500] | Train Loss: 0.788740 | Val Loss: 0.465186\n",
      "Epoch [200/500] | Train Loss: 0.761602 | Val Loss: 0.474213\n",
      "Epoch [300/500] | Train Loss: 0.712030 | Val Loss: 0.475778\n",
      "Epoch [400/500] | Train Loss: 0.684530 | Val Loss: 0.491839\n",
      "Epoch [500/500] | Train Loss: 0.638025 | Val Loss: 0.502235\n",
      "Epoch [100/500] | Train Loss: 0.293379 | Val Loss: 0.856324\n",
      "Epoch [200/500] | Train Loss: 0.217379 | Val Loss: 0.902050\n",
      "Epoch [300/500] | Train Loss: 0.172762 | Val Loss: 0.914892\n",
      "Epoch [400/500] | Train Loss: 0.172018 | Val Loss: 0.941754\n",
      "Epoch [500/500] | Train Loss: 0.141226 | Val Loss: 0.931557\n",
      "Epoch [100/500] | Train Loss: 0.446654 | Val Loss: 0.901413\n",
      "Epoch [200/500] | Train Loss: 0.356879 | Val Loss: 0.919018\n",
      "Epoch [300/500] | Train Loss: 0.291121 | Val Loss: 0.994768\n",
      "Epoch [400/500] | Train Loss: 0.274266 | Val Loss: 1.026252\n",
      "Epoch [500/500] | Train Loss: 0.276529 | Val Loss: 0.980619\n",
      "Epoch [100/500] | Train Loss: 0.541305 | Val Loss: 0.735817\n",
      "Epoch [200/500] | Train Loss: 0.468775 | Val Loss: 0.810099\n",
      "Epoch [300/500] | Train Loss: 0.398753 | Val Loss: 0.845168\n",
      "Epoch [400/500] | Train Loss: 0.385987 | Val Loss: 0.843243\n",
      "Epoch [500/500] | Train Loss: 0.391980 | Val Loss: 0.845085\n",
      "Epoch [100/500] | Train Loss: 0.567342 | Val Loss: 1.269855\n",
      "Epoch [200/500] | Train Loss: 0.487722 | Val Loss: 1.255399\n",
      "Epoch [300/500] | Train Loss: 0.430726 | Val Loss: 1.338988\n",
      "Epoch [400/500] | Train Loss: 0.426430 | Val Loss: 1.329365\n",
      "Epoch [500/500] | Train Loss: 0.414750 | Val Loss: 1.344330\n",
      "Epoch [100/500] | Train Loss: 0.633646 | Val Loss: 0.476837\n",
      "Epoch [200/500] | Train Loss: 0.566913 | Val Loss: 0.535920\n",
      "Epoch [300/500] | Train Loss: 0.537522 | Val Loss: 0.579444\n",
      "Epoch [400/500] | Train Loss: 0.506618 | Val Loss: 0.569980\n",
      "Epoch [500/500] | Train Loss: 0.502821 | Val Loss: 0.559766\n",
      "Epoch [100/500] | Train Loss: 0.426084 | Val Loss: 0.925698\n",
      "Epoch [200/500] | Train Loss: 0.386805 | Val Loss: 0.963557\n",
      "Epoch [300/500] | Train Loss: 0.396043 | Val Loss: 0.949440\n",
      "Epoch [400/500] | Train Loss: 0.314111 | Val Loss: 0.966028\n",
      "Epoch [500/500] | Train Loss: 0.315291 | Val Loss: 0.940724\n",
      "Epoch [100/500] | Train Loss: 0.631380 | Val Loss: 0.809027\n",
      "Epoch [200/500] | Train Loss: 0.611799 | Val Loss: 0.824143\n",
      "Epoch [300/500] | Train Loss: 0.584630 | Val Loss: 0.827892\n",
      "Epoch [400/500] | Train Loss: 0.580121 | Val Loss: 0.837958\n",
      "Epoch [500/500] | Train Loss: 0.536941 | Val Loss: 0.853529\n",
      "Epoch [100/500] | Train Loss: 0.694107 | Val Loss: 0.725872\n",
      "Epoch [200/500] | Train Loss: 0.677312 | Val Loss: 0.716543\n",
      "Epoch [300/500] | Train Loss: 0.649912 | Val Loss: 0.718801\n",
      "Epoch [400/500] | Train Loss: 0.616603 | Val Loss: 0.723428\n",
      "Epoch [500/500] | Train Loss: 0.604494 | Val Loss: 0.723569\n",
      "Epoch [100/500] | Train Loss: 0.715613 | Val Loss: 1.255021\n",
      "Epoch [200/500] | Train Loss: 0.671034 | Val Loss: 1.240215\n",
      "Epoch [300/500] | Train Loss: 0.634703 | Val Loss: 1.283248\n",
      "Epoch [400/500] | Train Loss: 0.626872 | Val Loss: 1.309247\n",
      "Epoch [500/500] | Train Loss: 0.601735 | Val Loss: 1.313999\n",
      "Epoch [100/500] | Train Loss: 0.789670 | Val Loss: 0.463874\n",
      "Epoch [200/500] | Train Loss: 0.771291 | Val Loss: 0.459030\n",
      "Epoch [300/500] | Train Loss: 0.760728 | Val Loss: 0.458339\n",
      "Epoch [400/500] | Train Loss: 0.725391 | Val Loss: 0.460369\n",
      "Epoch [500/500] | Train Loss: 0.728422 | Val Loss: 0.461345\n",
      "Epoch [100/500] | Train Loss: 0.339678 | Val Loss: 0.923444\n",
      "Epoch [200/500] | Train Loss: 0.257717 | Val Loss: 0.908210\n",
      "Epoch [300/500] | Train Loss: 0.272054 | Val Loss: 0.951106\n",
      "Epoch [400/500] | Train Loss: 0.203807 | Val Loss: 0.930506\n",
      "Epoch [500/500] | Train Loss: 0.182838 | Val Loss: 0.939482\n",
      "Epoch [100/500] | Train Loss: 0.515971 | Val Loss: 0.818429\n",
      "Epoch [200/500] | Train Loss: 0.473256 | Val Loss: 0.917850\n",
      "Epoch [300/500] | Train Loss: 0.448636 | Val Loss: 0.973063\n",
      "Epoch [400/500] | Train Loss: 0.405455 | Val Loss: 0.952434\n",
      "Epoch [500/500] | Train Loss: 0.366740 | Val Loss: 1.051322\n",
      "Epoch [100/500] | Train Loss: 0.601540 | Val Loss: 0.752612\n",
      "Epoch [200/500] | Train Loss: 0.518173 | Val Loss: 0.734908\n",
      "Epoch [300/500] | Train Loss: 0.507884 | Val Loss: 0.718566\n",
      "Epoch [400/500] | Train Loss: 0.497275 | Val Loss: 0.787166\n",
      "Epoch [500/500] | Train Loss: 0.451656 | Val Loss: 0.743950\n",
      "Epoch [100/500] | Train Loss: 0.676252 | Val Loss: 1.239063\n",
      "Epoch [200/500] | Train Loss: 0.644196 | Val Loss: 1.260616\n",
      "Epoch [300/500] | Train Loss: 0.625218 | Val Loss: 1.238854\n",
      "Epoch [400/500] | Train Loss: 0.600947 | Val Loss: 1.272153\n",
      "Epoch [500/500] | Train Loss: 0.566972 | Val Loss: 1.281924\n",
      "Epoch [100/500] | Train Loss: 0.714083 | Val Loss: 0.459019\n",
      "Epoch [200/500] | Train Loss: 0.688223 | Val Loss: 0.463739\n",
      "Epoch [300/500] | Train Loss: 0.656429 | Val Loss: 0.472999\n",
      "Epoch [400/500] | Train Loss: 0.635777 | Val Loss: 0.477194\n",
      "Epoch [500/500] | Train Loss: 0.641430 | Val Loss: 0.492683\n",
      "Epoch [100/500] | Train Loss: 0.402623 | Val Loss: 0.931900\n",
      "Epoch [200/500] | Train Loss: 0.311933 | Val Loss: 1.028783\n",
      "Epoch [300/500] | Train Loss: 0.260563 | Val Loss: 1.013725\n",
      "Epoch [400/500] | Train Loss: 0.293106 | Val Loss: 1.025000\n",
      "Epoch [500/500] | Train Loss: 0.210974 | Val Loss: 1.028944\n",
      "Epoch [100/500] | Train Loss: 0.601534 | Val Loss: 0.817479\n",
      "Epoch [200/500] | Train Loss: 0.512428 | Val Loss: 0.860847\n",
      "Epoch [300/500] | Train Loss: 0.432494 | Val Loss: 0.927898\n",
      "Epoch [400/500] | Train Loss: 0.375572 | Val Loss: 0.952866\n",
      "Epoch [500/500] | Train Loss: 0.335789 | Val Loss: 0.968848\n",
      "Epoch [100/500] | Train Loss: 0.688917 | Val Loss: 0.707692\n",
      "Epoch [200/500] | Train Loss: 0.642705 | Val Loss: 0.718706\n",
      "Epoch [300/500] | Train Loss: 0.563460 | Val Loss: 0.753601\n",
      "Epoch [400/500] | Train Loss: 0.512144 | Val Loss: 0.779142\n",
      "Epoch [500/500] | Train Loss: 0.458688 | Val Loss: 0.802305\n",
      "Epoch [100/500] | Train Loss: 0.672730 | Val Loss: 1.203440\n",
      "Epoch [200/500] | Train Loss: 0.608330 | Val Loss: 1.265626\n",
      "Epoch [300/500] | Train Loss: 0.545988 | Val Loss: 1.353097\n",
      "Epoch [400/500] | Train Loss: 0.519052 | Val Loss: 1.406292\n",
      "Epoch [500/500] | Train Loss: 0.494238 | Val Loss: 1.441216\n",
      "Epoch [100/500] | Train Loss: 0.762833 | Val Loss: 0.463940\n",
      "Epoch [200/500] | Train Loss: 0.708782 | Val Loss: 0.457129\n",
      "Epoch [300/500] | Train Loss: 0.684232 | Val Loss: 0.455734\n",
      "Epoch [400/500] | Train Loss: 0.647648 | Val Loss: 0.472277\n",
      "Epoch [500/500] | Train Loss: 0.616806 | Val Loss: 0.502107\n",
      "Epoch [100/500] | Train Loss: 0.238543 | Val Loss: 0.990982\n",
      "Epoch [200/500] | Train Loss: 0.160878 | Val Loss: 1.016945\n",
      "Epoch [300/500] | Train Loss: 0.141141 | Val Loss: 0.976414\n",
      "Epoch [400/500] | Train Loss: 0.152997 | Val Loss: 0.977265\n",
      "Epoch [500/500] | Train Loss: 0.111547 | Val Loss: 1.037897\n",
      "Epoch [100/500] | Train Loss: 0.400167 | Val Loss: 0.960216\n",
      "Epoch [200/500] | Train Loss: 0.317904 | Val Loss: 1.018903\n",
      "Epoch [300/500] | Train Loss: 0.282240 | Val Loss: 0.985181\n",
      "Epoch [400/500] | Train Loss: 0.260138 | Val Loss: 1.001915\n",
      "Epoch [500/500] | Train Loss: 0.205745 | Val Loss: 0.940090\n",
      "Epoch [100/500] | Train Loss: 0.518430 | Val Loss: 0.770645\n",
      "Epoch [200/500] | Train Loss: 0.350394 | Val Loss: 0.824405\n",
      "Epoch [300/500] | Train Loss: 0.333206 | Val Loss: 0.867372\n",
      "Epoch [400/500] | Train Loss: 0.270928 | Val Loss: 0.882749\n",
      "Epoch [500/500] | Train Loss: 0.287655 | Val Loss: 0.902031\n",
      "Epoch [100/500] | Train Loss: 0.492504 | Val Loss: 1.351484\n",
      "Epoch [200/500] | Train Loss: 0.410960 | Val Loss: 1.415032\n",
      "Epoch [300/500] | Train Loss: 0.344521 | Val Loss: 1.377120\n",
      "Epoch [400/500] | Train Loss: 0.358080 | Val Loss: 1.402280\n",
      "Epoch [500/500] | Train Loss: 0.314036 | Val Loss: 1.387030\n",
      "Epoch [100/500] | Train Loss: 0.722990 | Val Loss: 0.443549\n",
      "Epoch [200/500] | Train Loss: 0.615874 | Val Loss: 0.478979\n",
      "Epoch [300/500] | Train Loss: 0.552039 | Val Loss: 0.540296\n",
      "Epoch [400/500] | Train Loss: 0.536372 | Val Loss: 0.573771\n",
      "Epoch [500/500] | Train Loss: 0.506986 | Val Loss: 0.590969\n",
      "Epoch [100/500] | Train Loss: 0.419916 | Val Loss: 0.896123\n",
      "Epoch [200/500] | Train Loss: 0.385538 | Val Loss: 0.949258\n",
      "Epoch [300/500] | Train Loss: 0.326411 | Val Loss: 0.974713\n",
      "Epoch [400/500] | Train Loss: 0.326157 | Val Loss: 0.967224\n",
      "Epoch [500/500] | Train Loss: 0.312645 | Val Loss: 0.949300\n",
      "Epoch [100/500] | Train Loss: 0.585835 | Val Loss: 0.825311\n",
      "Epoch [200/500] | Train Loss: 0.570076 | Val Loss: 0.866977\n",
      "Epoch [300/500] | Train Loss: 0.502917 | Val Loss: 0.892111\n",
      "Epoch [400/500] | Train Loss: 0.485940 | Val Loss: 0.907180\n",
      "Epoch [500/500] | Train Loss: 0.454323 | Val Loss: 0.921984\n",
      "Epoch [100/500] | Train Loss: 0.671419 | Val Loss: 0.709456\n",
      "Epoch [200/500] | Train Loss: 0.644236 | Val Loss: 0.711735\n",
      "Epoch [300/500] | Train Loss: 0.584013 | Val Loss: 0.706890\n",
      "Epoch [400/500] | Train Loss: 0.558762 | Val Loss: 0.709121\n",
      "Epoch [500/500] | Train Loss: 0.552328 | Val Loss: 0.692378\n",
      "Epoch [100/500] | Train Loss: 0.697103 | Val Loss: 1.214049\n",
      "Epoch [200/500] | Train Loss: 0.669375 | Val Loss: 1.198042\n",
      "Epoch [300/500] | Train Loss: 0.653734 | Val Loss: 1.194948\n",
      "Epoch [400/500] | Train Loss: 0.628490 | Val Loss: 1.210282\n",
      "Epoch [500/500] | Train Loss: 0.616630 | Val Loss: 1.223748\n",
      "Epoch [100/500] | Train Loss: 0.781890 | Val Loss: 0.476114\n",
      "Epoch [200/500] | Train Loss: 0.756237 | Val Loss: 0.464183\n",
      "Epoch [300/500] | Train Loss: 0.711585 | Val Loss: 0.459602\n",
      "Epoch [400/500] | Train Loss: 0.697937 | Val Loss: 0.463811\n",
      "Epoch [500/500] | Train Loss: 0.687943 | Val Loss: 0.465001\n",
      "Epoch [100/500] | Train Loss: 0.334298 | Val Loss: 0.945959\n",
      "Epoch [200/500] | Train Loss: 0.305948 | Val Loss: 0.915059\n",
      "Epoch [300/500] | Train Loss: 0.193802 | Val Loss: 0.946680\n",
      "Epoch [400/500] | Train Loss: 0.194239 | Val Loss: 0.961609\n",
      "Epoch [500/500] | Train Loss: 0.169590 | Val Loss: 0.956664\n",
      "Epoch [100/500] | Train Loss: 0.548618 | Val Loss: 0.823698\n",
      "Epoch [200/500] | Train Loss: 0.450605 | Val Loss: 0.881290\n",
      "Epoch [300/500] | Train Loss: 0.378519 | Val Loss: 0.889127\n",
      "Epoch [400/500] | Train Loss: 0.381899 | Val Loss: 0.891438\n",
      "Epoch [500/500] | Train Loss: 0.376379 | Val Loss: 0.965669\n",
      "Epoch [100/500] | Train Loss: 0.599248 | Val Loss: 0.692569\n",
      "Epoch [200/500] | Train Loss: 0.477977 | Val Loss: 0.732545\n",
      "Epoch [300/500] | Train Loss: 0.426624 | Val Loss: 0.741543\n",
      "Epoch [400/500] | Train Loss: 0.417266 | Val Loss: 0.743851\n",
      "Epoch [500/500] | Train Loss: 0.402689 | Val Loss: 0.751296\n",
      "Epoch [100/500] | Train Loss: 0.638841 | Val Loss: 1.228351\n",
      "Epoch [200/500] | Train Loss: 0.561121 | Val Loss: 1.272554\n",
      "Epoch [300/500] | Train Loss: 0.539705 | Val Loss: 1.275831\n",
      "Epoch [400/500] | Train Loss: 0.453164 | Val Loss: 1.298139\n",
      "Epoch [500/500] | Train Loss: 0.500372 | Val Loss: 1.283027\n",
      "Epoch [100/500] | Train Loss: 0.696894 | Val Loss: 0.459311\n",
      "Epoch [200/500] | Train Loss: 0.594230 | Val Loss: 0.489067\n",
      "Epoch [300/500] | Train Loss: 0.573359 | Val Loss: 0.497993\n",
      "Epoch [400/500] | Train Loss: 0.555982 | Val Loss: 0.517364\n",
      "Epoch [500/500] | Train Loss: 0.523174 | Val Loss: 0.524340\n",
      "[Year=1984] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.850482 Test MSE=0.524812\n",
      "Year 1984 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.852995 | Val Loss: 0.790075\n",
      "Epoch [200/500] | Train Loss: 0.672968 | Val Loss: 0.901092\n",
      "Epoch [300/500] | Train Loss: 0.600329 | Val Loss: 1.019344\n",
      "Epoch [400/500] | Train Loss: 0.484557 | Val Loss: 1.048789\n",
      "Epoch [500/500] | Train Loss: 0.451917 | Val Loss: 1.079441\n",
      "Epoch [100/500] | Train Loss: 0.823763 | Val Loss: 0.681631\n",
      "Epoch [200/500] | Train Loss: 0.768788 | Val Loss: 0.691561\n",
      "Epoch [300/500] | Train Loss: 0.684281 | Val Loss: 0.717508\n",
      "Epoch [400/500] | Train Loss: 0.656667 | Val Loss: 0.723447\n",
      "Epoch [500/500] | Train Loss: 0.619025 | Val Loss: 0.725412\n",
      "Epoch [100/500] | Train Loss: 0.764410 | Val Loss: 1.240222\n",
      "Epoch [200/500] | Train Loss: 0.722099 | Val Loss: 1.262200\n",
      "Epoch [300/500] | Train Loss: 0.680462 | Val Loss: 1.299776\n",
      "Epoch [400/500] | Train Loss: 0.647367 | Val Loss: 1.342036\n",
      "Epoch [500/500] | Train Loss: 0.596621 | Val Loss: 1.405118\n",
      "Epoch [100/500] | Train Loss: 0.887339 | Val Loss: 0.483579\n",
      "Epoch [200/500] | Train Loss: 0.821345 | Val Loss: 0.477106\n",
      "Epoch [300/500] | Train Loss: 0.785511 | Val Loss: 0.485579\n",
      "Epoch [400/500] | Train Loss: 0.734237 | Val Loss: 0.494197\n",
      "Epoch [500/500] | Train Loss: 0.729882 | Val Loss: 0.510675\n",
      "Epoch [100/500] | Train Loss: 0.794740 | Val Loss: 0.484679\n",
      "Epoch [200/500] | Train Loss: 0.755052 | Val Loss: 0.499942\n",
      "Epoch [300/500] | Train Loss: 0.700098 | Val Loss: 0.511322\n",
      "Epoch [400/500] | Train Loss: 0.669225 | Val Loss: 0.512520\n",
      "Epoch [500/500] | Train Loss: 0.668096 | Val Loss: 0.528196\n",
      "Epoch [100/500] | Train Loss: 0.545504 | Val Loss: 1.265301\n",
      "Epoch [200/500] | Train Loss: 0.332122 | Val Loss: 1.286252\n",
      "Epoch [300/500] | Train Loss: 0.300180 | Val Loss: 1.188623\n",
      "Epoch [400/500] | Train Loss: 0.272563 | Val Loss: 1.367869\n",
      "Epoch [500/500] | Train Loss: 0.310501 | Val Loss: 1.248291\n",
      "Epoch [100/500] | Train Loss: 0.626354 | Val Loss: 0.744974\n",
      "Epoch [200/500] | Train Loss: 0.501663 | Val Loss: 0.821306\n",
      "Epoch [300/500] | Train Loss: 0.413799 | Val Loss: 0.801030\n",
      "Epoch [400/500] | Train Loss: 0.428880 | Val Loss: 0.869787\n",
      "Epoch [500/500] | Train Loss: 0.353937 | Val Loss: 0.870136\n",
      "Epoch [100/500] | Train Loss: 0.614720 | Val Loss: 1.356220\n",
      "Epoch [200/500] | Train Loss: 0.528897 | Val Loss: 1.331174\n",
      "Epoch [300/500] | Train Loss: 0.462216 | Val Loss: 1.365438\n",
      "Epoch [400/500] | Train Loss: 0.447982 | Val Loss: 1.468615\n",
      "Epoch [500/500] | Train Loss: 0.393240 | Val Loss: 1.389959\n",
      "Epoch [100/500] | Train Loss: 0.711304 | Val Loss: 0.498174\n",
      "Epoch [200/500] | Train Loss: 0.591346 | Val Loss: 0.555505\n",
      "Epoch [300/500] | Train Loss: 0.533222 | Val Loss: 0.577853\n",
      "Epoch [400/500] | Train Loss: 0.517801 | Val Loss: 0.598275\n",
      "Epoch [500/500] | Train Loss: 0.497387 | Val Loss: 0.632081\n",
      "Epoch [100/500] | Train Loss: 0.682419 | Val Loss: 0.525283\n",
      "Epoch [200/500] | Train Loss: 0.578977 | Val Loss: 0.571699\n",
      "Epoch [300/500] | Train Loss: 0.574005 | Val Loss: 0.601049\n",
      "Epoch [400/500] | Train Loss: 0.511523 | Val Loss: 0.605095\n",
      "Epoch [500/500] | Train Loss: 0.496574 | Val Loss: 0.621513\n",
      "Epoch [100/500] | Train Loss: 0.947443 | Val Loss: 0.727543\n",
      "Epoch [200/500] | Train Loss: 0.828456 | Val Loss: 0.796314\n",
      "Epoch [300/500] | Train Loss: 0.749893 | Val Loss: 0.899827\n",
      "Epoch [400/500] | Train Loss: 0.714441 | Val Loss: 0.943608\n",
      "Epoch [500/500] | Train Loss: 0.585315 | Val Loss: 1.048231\n",
      "Epoch [100/500] | Train Loss: 0.853758 | Val Loss: 0.680301\n",
      "Epoch [200/500] | Train Loss: 0.774011 | Val Loss: 0.674426\n",
      "Epoch [300/500] | Train Loss: 0.765035 | Val Loss: 0.692385\n",
      "Epoch [400/500] | Train Loss: 0.713200 | Val Loss: 0.703477\n",
      "Epoch [500/500] | Train Loss: 0.673441 | Val Loss: 0.709589\n",
      "Epoch [100/500] | Train Loss: 0.783129 | Val Loss: 1.242180\n",
      "Epoch [200/500] | Train Loss: 0.755526 | Val Loss: 1.262404\n",
      "Epoch [300/500] | Train Loss: 0.715687 | Val Loss: 1.274571\n",
      "Epoch [400/500] | Train Loss: 0.697949 | Val Loss: 1.292648\n",
      "Epoch [500/500] | Train Loss: 0.692513 | Val Loss: 1.302696\n",
      "Epoch [100/500] | Train Loss: 0.878733 | Val Loss: 0.485975\n",
      "Epoch [200/500] | Train Loss: 0.859166 | Val Loss: 0.483946\n",
      "Epoch [300/500] | Train Loss: 0.827545 | Val Loss: 0.478602\n",
      "Epoch [400/500] | Train Loss: 0.797841 | Val Loss: 0.476485\n",
      "Epoch [500/500] | Train Loss: 0.804816 | Val Loss: 0.475350\n",
      "Epoch [100/500] | Train Loss: 0.806694 | Val Loss: 0.485642\n",
      "Epoch [200/500] | Train Loss: 0.791787 | Val Loss: 0.487186\n",
      "Epoch [300/500] | Train Loss: 0.772482 | Val Loss: 0.493018\n",
      "Epoch [400/500] | Train Loss: 0.757810 | Val Loss: 0.492884\n",
      "Epoch [500/500] | Train Loss: 0.757338 | Val Loss: 0.496672\n",
      "Epoch [100/500] | Train Loss: 0.760819 | Val Loss: 0.926899\n",
      "Epoch [200/500] | Train Loss: 0.670668 | Val Loss: 1.099572\n",
      "Epoch [300/500] | Train Loss: 0.511629 | Val Loss: 1.055108\n",
      "Epoch [400/500] | Train Loss: 0.516123 | Val Loss: 1.062075\n",
      "Epoch [500/500] | Train Loss: 0.461117 | Val Loss: 1.170565\n",
      "Epoch [100/500] | Train Loss: 0.725990 | Val Loss: 0.694946\n",
      "Epoch [200/500] | Train Loss: 0.620329 | Val Loss: 0.703301\n",
      "Epoch [300/500] | Train Loss: 0.543293 | Val Loss: 0.683207\n",
      "Epoch [400/500] | Train Loss: 0.557572 | Val Loss: 0.723441\n",
      "Epoch [500/500] | Train Loss: 0.553880 | Val Loss: 0.700995\n",
      "Epoch [100/500] | Train Loss: 0.703224 | Val Loss: 1.271957\n",
      "Epoch [200/500] | Train Loss: 0.662990 | Val Loss: 1.322500\n",
      "Epoch [300/500] | Train Loss: 0.553151 | Val Loss: 1.355304\n",
      "Epoch [400/500] | Train Loss: 0.586074 | Val Loss: 1.349888\n",
      "Epoch [500/500] | Train Loss: 0.545124 | Val Loss: 1.363979\n",
      "Epoch [100/500] | Train Loss: 0.828517 | Val Loss: 0.502599\n",
      "Epoch [200/500] | Train Loss: 0.748715 | Val Loss: 0.524022\n",
      "Epoch [300/500] | Train Loss: 0.676631 | Val Loss: 0.542053\n",
      "Epoch [400/500] | Train Loss: 0.693496 | Val Loss: 0.530151\n",
      "Epoch [500/500] | Train Loss: 0.682857 | Val Loss: 0.577411\n",
      "Epoch [100/500] | Train Loss: 0.760896 | Val Loss: 0.496910\n",
      "Epoch [200/500] | Train Loss: 0.703598 | Val Loss: 0.532690\n",
      "Epoch [300/500] | Train Loss: 0.657501 | Val Loss: 0.544160\n",
      "Epoch [400/500] | Train Loss: 0.631558 | Val Loss: 0.561509\n",
      "Epoch [500/500] | Train Loss: 0.646590 | Val Loss: 0.537536\n",
      "Epoch [100/500] | Train Loss: 0.844702 | Val Loss: 0.785836\n",
      "Epoch [200/500] | Train Loss: 0.637258 | Val Loss: 0.940975\n",
      "Epoch [300/500] | Train Loss: 0.555153 | Val Loss: 1.075412\n",
      "Epoch [400/500] | Train Loss: 0.443188 | Val Loss: 1.181936\n",
      "Epoch [500/500] | Train Loss: 0.393784 | Val Loss: 1.176777\n",
      "Epoch [100/500] | Train Loss: 0.779864 | Val Loss: 0.676860\n",
      "Epoch [200/500] | Train Loss: 0.662123 | Val Loss: 0.685060\n",
      "Epoch [300/500] | Train Loss: 0.567048 | Val Loss: 0.702435\n",
      "Epoch [400/500] | Train Loss: 0.503661 | Val Loss: 0.726771\n",
      "Epoch [500/500] | Train Loss: 0.453112 | Val Loss: 0.728972\n",
      "Epoch [100/500] | Train Loss: 0.731642 | Val Loss: 1.270841\n",
      "Epoch [200/500] | Train Loss: 0.670110 | Val Loss: 1.270226\n",
      "Epoch [300/500] | Train Loss: 0.599709 | Val Loss: 1.314658\n",
      "Epoch [400/500] | Train Loss: 0.544600 | Val Loss: 1.348691\n",
      "Epoch [500/500] | Train Loss: 0.490193 | Val Loss: 1.385349\n",
      "Epoch [100/500] | Train Loss: 0.874451 | Val Loss: 0.485926\n",
      "Epoch [200/500] | Train Loss: 0.843618 | Val Loss: 0.479172\n",
      "Epoch [300/500] | Train Loss: 0.777195 | Val Loss: 0.475064\n",
      "Epoch [400/500] | Train Loss: 0.741186 | Val Loss: 0.488734\n",
      "Epoch [500/500] | Train Loss: 0.689139 | Val Loss: 0.499277\n",
      "Epoch [100/500] | Train Loss: 0.792856 | Val Loss: 0.486405\n",
      "Epoch [200/500] | Train Loss: 0.731091 | Val Loss: 0.483811\n",
      "Epoch [300/500] | Train Loss: 0.695045 | Val Loss: 0.493155\n",
      "Epoch [400/500] | Train Loss: 0.665747 | Val Loss: 0.502490\n",
      "Epoch [500/500] | Train Loss: 0.633543 | Val Loss: 0.504869\n",
      "Epoch [100/500] | Train Loss: 0.476275 | Val Loss: 1.144353\n",
      "Epoch [200/500] | Train Loss: 0.257893 | Val Loss: 1.390979\n",
      "Epoch [300/500] | Train Loss: 0.250210 | Val Loss: 1.343408\n",
      "Epoch [400/500] | Train Loss: 0.224429 | Val Loss: 1.413317\n",
      "Epoch [500/500] | Train Loss: 0.214192 | Val Loss: 1.393917\n",
      "Epoch [100/500] | Train Loss: 0.557474 | Val Loss: 0.687093\n",
      "Epoch [200/500] | Train Loss: 0.436290 | Val Loss: 0.732493\n",
      "Epoch [300/500] | Train Loss: 0.350388 | Val Loss: 0.800722\n",
      "Epoch [400/500] | Train Loss: 0.297040 | Val Loss: 0.804098\n",
      "Epoch [500/500] | Train Loss: 0.268188 | Val Loss: 0.886816\n",
      "Epoch [100/500] | Train Loss: 0.599261 | Val Loss: 1.354484\n",
      "Epoch [200/500] | Train Loss: 0.473802 | Val Loss: 1.357083\n",
      "Epoch [300/500] | Train Loss: 0.430459 | Val Loss: 1.372697\n",
      "Epoch [400/500] | Train Loss: 0.369066 | Val Loss: 1.415193\n",
      "Epoch [500/500] | Train Loss: 0.360626 | Val Loss: 1.402350\n",
      "Epoch [100/500] | Train Loss: 0.694897 | Val Loss: 0.538833\n",
      "Epoch [200/500] | Train Loss: 0.519987 | Val Loss: 0.663571\n",
      "Epoch [300/500] | Train Loss: 0.479890 | Val Loss: 0.724356\n",
      "Epoch [400/500] | Train Loss: 0.455343 | Val Loss: 0.725276\n",
      "Epoch [500/500] | Train Loss: 0.454934 | Val Loss: 0.705048\n",
      "Epoch [100/500] | Train Loss: 0.670519 | Val Loss: 0.529451\n",
      "Epoch [200/500] | Train Loss: 0.577760 | Val Loss: 0.580280\n",
      "Epoch [300/500] | Train Loss: 0.529111 | Val Loss: 0.615742\n",
      "Epoch [400/500] | Train Loss: 0.484835 | Val Loss: 0.622055\n",
      "Epoch [500/500] | Train Loss: 0.457168 | Val Loss: 0.657722\n",
      "Epoch [100/500] | Train Loss: 0.982587 | Val Loss: 0.725330\n",
      "Epoch [200/500] | Train Loss: 0.857848 | Val Loss: 0.769009\n",
      "Epoch [300/500] | Train Loss: 0.723171 | Val Loss: 0.915977\n",
      "Epoch [400/500] | Train Loss: 0.623514 | Val Loss: 1.025648\n",
      "Epoch [500/500] | Train Loss: 0.605438 | Val Loss: 1.084670\n",
      "Epoch [100/500] | Train Loss: 0.802629 | Val Loss: 0.674424\n",
      "Epoch [200/500] | Train Loss: 0.761595 | Val Loss: 0.673584\n",
      "Epoch [300/500] | Train Loss: 0.690721 | Val Loss: 0.675162\n",
      "Epoch [400/500] | Train Loss: 0.675047 | Val Loss: 0.673729\n",
      "Epoch [500/500] | Train Loss: 0.605365 | Val Loss: 0.689275\n",
      "Epoch [100/500] | Train Loss: 0.763753 | Val Loss: 1.239018\n",
      "Epoch [200/500] | Train Loss: 0.708987 | Val Loss: 1.257245\n",
      "Epoch [300/500] | Train Loss: 0.669811 | Val Loss: 1.266959\n",
      "Epoch [400/500] | Train Loss: 0.628449 | Val Loss: 1.273058\n",
      "Epoch [500/500] | Train Loss: 0.597714 | Val Loss: 1.295803\n",
      "Epoch [100/500] | Train Loss: 0.894931 | Val Loss: 0.490379\n",
      "Epoch [200/500] | Train Loss: 0.861197 | Val Loss: 0.481037\n",
      "Epoch [300/500] | Train Loss: 0.825461 | Val Loss: 0.472334\n",
      "Epoch [400/500] | Train Loss: 0.798416 | Val Loss: 0.472464\n",
      "Epoch [500/500] | Train Loss: 0.758439 | Val Loss: 0.484843\n",
      "Epoch [100/500] | Train Loss: 0.823777 | Val Loss: 0.480089\n",
      "Epoch [200/500] | Train Loss: 0.790033 | Val Loss: 0.485555\n",
      "Epoch [300/500] | Train Loss: 0.758730 | Val Loss: 0.485998\n",
      "Epoch [400/500] | Train Loss: 0.736179 | Val Loss: 0.490280\n",
      "Epoch [500/500] | Train Loss: 0.728842 | Val Loss: 0.497324\n",
      "Epoch [100/500] | Train Loss: 0.670895 | Val Loss: 0.926667\n",
      "Epoch [200/500] | Train Loss: 0.552539 | Val Loss: 1.125285\n",
      "Epoch [300/500] | Train Loss: 0.469791 | Val Loss: 1.156869\n",
      "Epoch [400/500] | Train Loss: 0.436655 | Val Loss: 1.201110\n",
      "Epoch [500/500] | Train Loss: 0.365489 | Val Loss: 1.296508\n",
      "Epoch [100/500] | Train Loss: 0.641874 | Val Loss: 0.689009\n",
      "Epoch [200/500] | Train Loss: 0.621460 | Val Loss: 0.721399\n",
      "Epoch [300/500] | Train Loss: 0.474261 | Val Loss: 0.751468\n",
      "Epoch [400/500] | Train Loss: 0.458484 | Val Loss: 0.761655\n",
      "Epoch [500/500] | Train Loss: 0.470889 | Val Loss: 0.768584\n",
      "Epoch [100/500] | Train Loss: 0.656707 | Val Loss: 1.296860\n",
      "Epoch [200/500] | Train Loss: 0.569398 | Val Loss: 1.325285\n",
      "Epoch [300/500] | Train Loss: 0.546498 | Val Loss: 1.336924\n",
      "Epoch [400/500] | Train Loss: 0.478882 | Val Loss: 1.293126\n",
      "Epoch [500/500] | Train Loss: 0.491460 | Val Loss: 1.326251\n",
      "Epoch [100/500] | Train Loss: 0.798735 | Val Loss: 0.477339\n",
      "Epoch [200/500] | Train Loss: 0.771127 | Val Loss: 0.501633\n",
      "Epoch [300/500] | Train Loss: 0.655162 | Val Loss: 0.566547\n",
      "Epoch [400/500] | Train Loss: 0.601814 | Val Loss: 0.542154\n",
      "Epoch [500/500] | Train Loss: 0.614625 | Val Loss: 0.597440\n",
      "Epoch [100/500] | Train Loss: 0.729299 | Val Loss: 0.513768\n",
      "Epoch [200/500] | Train Loss: 0.696553 | Val Loss: 0.506800\n",
      "Epoch [300/500] | Train Loss: 0.630431 | Val Loss: 0.499332\n",
      "Epoch [400/500] | Train Loss: 0.572725 | Val Loss: 0.541839\n",
      "Epoch [500/500] | Train Loss: 0.617862 | Val Loss: 0.561326\n",
      "[Year=1985] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.806508 Test MSE=0.352678\n",
      "Year 1985 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.648045 | Val Loss: 0.730914\n",
      "Epoch [200/500] | Train Loss: 0.556436 | Val Loss: 0.752735\n",
      "Epoch [300/500] | Train Loss: 0.456209 | Val Loss: 0.788395\n",
      "Epoch [400/500] | Train Loss: 0.386173 | Val Loss: 0.805380\n",
      "Epoch [500/500] | Train Loss: 0.374803 | Val Loss: 0.818726\n",
      "Epoch [100/500] | Train Loss: 0.682546 | Val Loss: 1.067311\n",
      "Epoch [200/500] | Train Loss: 0.630329 | Val Loss: 1.174110\n",
      "Epoch [300/500] | Train Loss: 0.573792 | Val Loss: 1.224369\n",
      "Epoch [400/500] | Train Loss: 0.534360 | Val Loss: 1.247546\n",
      "Epoch [500/500] | Train Loss: 0.472326 | Val Loss: 1.283708\n",
      "Epoch [100/500] | Train Loss: 0.796340 | Val Loss: 0.489919\n",
      "Epoch [200/500] | Train Loss: 0.729991 | Val Loss: 0.508609\n",
      "Epoch [300/500] | Train Loss: 0.671595 | Val Loss: 0.526827\n",
      "Epoch [400/500] | Train Loss: 0.626611 | Val Loss: 0.546593\n",
      "Epoch [500/500] | Train Loss: 0.601408 | Val Loss: 0.574520\n",
      "Epoch [100/500] | Train Loss: 0.724133 | Val Loss: 0.486084\n",
      "Epoch [200/500] | Train Loss: 0.699746 | Val Loss: 0.493038\n",
      "Epoch [300/500] | Train Loss: 0.656611 | Val Loss: 0.481061\n",
      "Epoch [400/500] | Train Loss: 0.617316 | Val Loss: 0.488259\n",
      "Epoch [500/500] | Train Loss: 0.600569 | Val Loss: 0.493434\n",
      "Epoch [100/500] | Train Loss: 0.689270 | Val Loss: 0.292898\n",
      "Epoch [200/500] | Train Loss: 0.657307 | Val Loss: 0.307225\n",
      "Epoch [300/500] | Train Loss: 0.639954 | Val Loss: 0.314643\n",
      "Epoch [400/500] | Train Loss: 0.614552 | Val Loss: 0.316994\n",
      "Epoch [500/500] | Train Loss: 0.584708 | Val Loss: 0.321361\n",
      "Epoch [100/500] | Train Loss: 0.344737 | Val Loss: 0.809712\n",
      "Epoch [200/500] | Train Loss: 0.274348 | Val Loss: 0.823340\n",
      "Epoch [300/500] | Train Loss: 0.248134 | Val Loss: 0.820197\n",
      "Epoch [400/500] | Train Loss: 0.162730 | Val Loss: 0.858943\n",
      "Epoch [500/500] | Train Loss: 0.240690 | Val Loss: 0.861021\n",
      "Epoch [100/500] | Train Loss: 0.522149 | Val Loss: 1.209640\n",
      "Epoch [200/500] | Train Loss: 0.402674 | Val Loss: 1.304072\n",
      "Epoch [300/500] | Train Loss: 0.345400 | Val Loss: 1.406690\n",
      "Epoch [400/500] | Train Loss: 0.326172 | Val Loss: 1.314674\n",
      "Epoch [500/500] | Train Loss: 0.302834 | Val Loss: 1.382511\n",
      "Epoch [100/500] | Train Loss: 0.709207 | Val Loss: 0.488655\n",
      "Epoch [200/500] | Train Loss: 0.605961 | Val Loss: 0.531367\n",
      "Epoch [300/500] | Train Loss: 0.577695 | Val Loss: 0.554027\n",
      "Epoch [400/500] | Train Loss: 0.510640 | Val Loss: 0.570662\n",
      "Epoch [500/500] | Train Loss: 0.511762 | Val Loss: 0.607802\n",
      "Epoch [100/500] | Train Loss: 0.622352 | Val Loss: 0.541668\n",
      "Epoch [200/500] | Train Loss: 0.527483 | Val Loss: 0.625998\n",
      "Epoch [300/500] | Train Loss: 0.472215 | Val Loss: 0.643003\n",
      "Epoch [400/500] | Train Loss: 0.439512 | Val Loss: 0.591711\n",
      "Epoch [500/500] | Train Loss: 0.434905 | Val Loss: 0.605487\n",
      "Epoch [100/500] | Train Loss: 0.570484 | Val Loss: 0.316532\n",
      "Epoch [200/500] | Train Loss: 0.474474 | Val Loss: 0.367615\n",
      "Epoch [300/500] | Train Loss: 0.467192 | Val Loss: 0.382532\n",
      "Epoch [400/500] | Train Loss: 0.461110 | Val Loss: 0.377958\n",
      "Epoch [500/500] | Train Loss: 0.422811 | Val Loss: 0.417344\n",
      "Epoch [100/500] | Train Loss: 0.678933 | Val Loss: 0.751784\n",
      "Epoch [200/500] | Train Loss: 0.608828 | Val Loss: 0.732033\n",
      "Epoch [300/500] | Train Loss: 0.541808 | Val Loss: 0.746630\n",
      "Epoch [400/500] | Train Loss: 0.511797 | Val Loss: 0.741845\n",
      "Epoch [500/500] | Train Loss: 0.552844 | Val Loss: 0.762831\n",
      "Epoch [100/500] | Train Loss: 0.685024 | Val Loss: 1.079616\n",
      "Epoch [200/500] | Train Loss: 0.646216 | Val Loss: 1.119697\n",
      "Epoch [300/500] | Train Loss: 0.619088 | Val Loss: 1.137210\n",
      "Epoch [400/500] | Train Loss: 0.613260 | Val Loss: 1.156250\n",
      "Epoch [500/500] | Train Loss: 0.597672 | Val Loss: 1.192219\n",
      "Epoch [100/500] | Train Loss: 0.794917 | Val Loss: 0.479518\n",
      "Epoch [200/500] | Train Loss: 0.777083 | Val Loss: 0.489501\n",
      "Epoch [300/500] | Train Loss: 0.769357 | Val Loss: 0.488636\n",
      "Epoch [400/500] | Train Loss: 0.735130 | Val Loss: 0.494558\n",
      "Epoch [500/500] | Train Loss: 0.722824 | Val Loss: 0.499300\n",
      "Epoch [100/500] | Train Loss: 0.722596 | Val Loss: 0.489723\n",
      "Epoch [200/500] | Train Loss: 0.700468 | Val Loss: 0.496547\n",
      "Epoch [300/500] | Train Loss: 0.689401 | Val Loss: 0.501911\n",
      "Epoch [400/500] | Train Loss: 0.672323 | Val Loss: 0.506491\n",
      "Epoch [500/500] | Train Loss: 0.658361 | Val Loss: 0.507943\n",
      "Epoch [100/500] | Train Loss: 0.687756 | Val Loss: 0.303602\n",
      "Epoch [200/500] | Train Loss: 0.671493 | Val Loss: 0.306184\n",
      "Epoch [300/500] | Train Loss: 0.668222 | Val Loss: 0.315477\n",
      "Epoch [400/500] | Train Loss: 0.632229 | Val Loss: 0.316777\n",
      "Epoch [500/500] | Train Loss: 0.635215 | Val Loss: 0.314906\n",
      "Epoch [100/500] | Train Loss: 0.584549 | Val Loss: 0.725635\n",
      "Epoch [200/500] | Train Loss: 0.461350 | Val Loss: 0.782559\n",
      "Epoch [300/500] | Train Loss: 0.389518 | Val Loss: 0.790692\n",
      "Epoch [400/500] | Train Loss: 0.324643 | Val Loss: 0.810680\n",
      "Epoch [500/500] | Train Loss: 0.304133 | Val Loss: 0.829361\n",
      "Epoch [100/500] | Train Loss: 0.613289 | Val Loss: 1.143186\n",
      "Epoch [200/500] | Train Loss: 0.515733 | Val Loss: 1.210924\n",
      "Epoch [300/500] | Train Loss: 0.498718 | Val Loss: 1.296936\n",
      "Epoch [400/500] | Train Loss: 0.465110 | Val Loss: 1.230306\n",
      "Epoch [500/500] | Train Loss: 0.438777 | Val Loss: 1.232727\n",
      "Epoch [100/500] | Train Loss: 0.728438 | Val Loss: 0.486081\n",
      "Epoch [200/500] | Train Loss: 0.656716 | Val Loss: 0.538289\n",
      "Epoch [300/500] | Train Loss: 0.577945 | Val Loss: 0.555636\n",
      "Epoch [400/500] | Train Loss: 0.603327 | Val Loss: 0.583205\n",
      "Epoch [500/500] | Train Loss: 0.581865 | Val Loss: 0.552270\n",
      "Epoch [100/500] | Train Loss: 0.667949 | Val Loss: 0.504986\n",
      "Epoch [200/500] | Train Loss: 0.611112 | Val Loss: 0.509563\n",
      "Epoch [300/500] | Train Loss: 0.571856 | Val Loss: 0.532072\n",
      "Epoch [400/500] | Train Loss: 0.576416 | Val Loss: 0.522910\n",
      "Epoch [500/500] | Train Loss: 0.565259 | Val Loss: 0.525888\n",
      "Epoch [100/500] | Train Loss: 0.677283 | Val Loss: 0.312761\n",
      "Epoch [200/500] | Train Loss: 0.630291 | Val Loss: 0.314072\n",
      "Epoch [300/500] | Train Loss: 0.593045 | Val Loss: 0.321167\n",
      "Epoch [400/500] | Train Loss: 0.571091 | Val Loss: 0.320341\n",
      "Epoch [500/500] | Train Loss: 0.551896 | Val Loss: 0.324895\n",
      "Epoch [100/500] | Train Loss: 0.644364 | Val Loss: 0.732195\n",
      "Epoch [200/500] | Train Loss: 0.472275 | Val Loss: 0.722374\n",
      "Epoch [300/500] | Train Loss: 0.366223 | Val Loss: 0.755583\n",
      "Epoch [400/500] | Train Loss: 0.323100 | Val Loss: 0.776980\n",
      "Epoch [500/500] | Train Loss: 0.261637 | Val Loss: 0.802790\n",
      "Epoch [100/500] | Train Loss: 0.638471 | Val Loss: 1.138619\n",
      "Epoch [200/500] | Train Loss: 0.562172 | Val Loss: 1.178762\n",
      "Epoch [300/500] | Train Loss: 0.526662 | Val Loss: 1.247535\n",
      "Epoch [400/500] | Train Loss: 0.455291 | Val Loss: 1.283136\n",
      "Epoch [500/500] | Train Loss: 0.414371 | Val Loss: 1.330852\n",
      "Epoch [100/500] | Train Loss: 0.779974 | Val Loss: 0.493661\n",
      "Epoch [200/500] | Train Loss: 0.702280 | Val Loss: 0.510226\n",
      "Epoch [300/500] | Train Loss: 0.635021 | Val Loss: 0.544087\n",
      "Epoch [400/500] | Train Loss: 0.564280 | Val Loss: 0.571426\n",
      "Epoch [500/500] | Train Loss: 0.533815 | Val Loss: 0.605286\n",
      "Epoch [100/500] | Train Loss: 0.697505 | Val Loss: 0.485885\n",
      "Epoch [200/500] | Train Loss: 0.652155 | Val Loss: 0.486114\n",
      "Epoch [300/500] | Train Loss: 0.614707 | Val Loss: 0.510184\n",
      "Epoch [400/500] | Train Loss: 0.609314 | Val Loss: 0.529473\n",
      "Epoch [500/500] | Train Loss: 0.559639 | Val Loss: 0.534891\n",
      "Epoch [100/500] | Train Loss: 0.670507 | Val Loss: 0.296689\n",
      "Epoch [200/500] | Train Loss: 0.632944 | Val Loss: 0.309276\n",
      "Epoch [300/500] | Train Loss: 0.614219 | Val Loss: 0.313826\n",
      "Epoch [400/500] | Train Loss: 0.572140 | Val Loss: 0.326884\n",
      "Epoch [500/500] | Train Loss: 0.560224 | Val Loss: 0.342541\n",
      "Epoch [100/500] | Train Loss: 0.389070 | Val Loss: 0.851994\n",
      "Epoch [200/500] | Train Loss: 0.230670 | Val Loss: 0.859317\n",
      "Epoch [300/500] | Train Loss: 0.130055 | Val Loss: 1.011802\n",
      "Epoch [400/500] | Train Loss: 0.142785 | Val Loss: 0.985345\n",
      "Epoch [500/500] | Train Loss: 0.197936 | Val Loss: 0.981229\n",
      "Epoch [100/500] | Train Loss: 0.446022 | Val Loss: 1.256511\n",
      "Epoch [200/500] | Train Loss: 0.329260 | Val Loss: 1.346245\n",
      "Epoch [300/500] | Train Loss: 0.235691 | Val Loss: 1.333609\n",
      "Epoch [400/500] | Train Loss: 0.242404 | Val Loss: 1.491943\n",
      "Epoch [500/500] | Train Loss: 0.266412 | Val Loss: 1.461446\n",
      "Epoch [100/500] | Train Loss: 0.602792 | Val Loss: 0.646066\n",
      "Epoch [200/500] | Train Loss: 0.499791 | Val Loss: 0.688702\n",
      "Epoch [300/500] | Train Loss: 0.455089 | Val Loss: 0.669353\n",
      "Epoch [400/500] | Train Loss: 0.389997 | Val Loss: 0.723906\n",
      "Epoch [500/500] | Train Loss: 0.411359 | Val Loss: 0.709053\n",
      "Epoch [100/500] | Train Loss: 0.529120 | Val Loss: 0.565137\n",
      "Epoch [200/500] | Train Loss: 0.466363 | Val Loss: 0.551552\n",
      "Epoch [300/500] | Train Loss: 0.374055 | Val Loss: 0.585405\n",
      "Epoch [400/500] | Train Loss: 0.365931 | Val Loss: 0.597196\n",
      "Epoch [500/500] | Train Loss: 0.339925 | Val Loss: 0.590450\n",
      "Epoch [100/500] | Train Loss: 0.560380 | Val Loss: 0.320955\n",
      "Epoch [200/500] | Train Loss: 0.463228 | Val Loss: 0.339971\n",
      "Epoch [300/500] | Train Loss: 0.436990 | Val Loss: 0.361040\n",
      "Epoch [400/500] | Train Loss: 0.461355 | Val Loss: 0.406233\n",
      "Epoch [500/500] | Train Loss: 0.418998 | Val Loss: 0.386651\n",
      "Epoch [100/500] | Train Loss: 0.727733 | Val Loss: 0.770398\n",
      "Epoch [200/500] | Train Loss: 0.637485 | Val Loss: 0.738107\n",
      "Epoch [300/500] | Train Loss: 0.599057 | Val Loss: 0.746314\n",
      "Epoch [400/500] | Train Loss: 0.553869 | Val Loss: 0.754909\n",
      "Epoch [500/500] | Train Loss: 0.525047 | Val Loss: 0.773090\n",
      "Epoch [100/500] | Train Loss: 0.686411 | Val Loss: 1.114934\n",
      "Epoch [200/500] | Train Loss: 0.639774 | Val Loss: 1.166568\n",
      "Epoch [300/500] | Train Loss: 0.602028 | Val Loss: 1.162154\n",
      "Epoch [400/500] | Train Loss: 0.564183 | Val Loss: 1.210662\n",
      "Epoch [500/500] | Train Loss: 0.561942 | Val Loss: 1.216030\n",
      "Epoch [100/500] | Train Loss: 0.788051 | Val Loss: 0.480581\n",
      "Epoch [200/500] | Train Loss: 0.727529 | Val Loss: 0.479783\n",
      "Epoch [300/500] | Train Loss: 0.694321 | Val Loss: 0.493856\n",
      "Epoch [400/500] | Train Loss: 0.634941 | Val Loss: 0.513875\n",
      "Epoch [500/500] | Train Loss: 0.626503 | Val Loss: 0.535056\n",
      "Epoch [100/500] | Train Loss: 0.722566 | Val Loss: 0.490436\n",
      "Epoch [200/500] | Train Loss: 0.685941 | Val Loss: 0.501744\n",
      "Epoch [300/500] | Train Loss: 0.676268 | Val Loss: 0.502833\n",
      "Epoch [400/500] | Train Loss: 0.670963 | Val Loss: 0.503348\n",
      "Epoch [500/500] | Train Loss: 0.614341 | Val Loss: 0.509298\n",
      "Epoch [100/500] | Train Loss: 0.704962 | Val Loss: 0.297117\n",
      "Epoch [200/500] | Train Loss: 0.663582 | Val Loss: 0.298046\n",
      "Epoch [300/500] | Train Loss: 0.644297 | Val Loss: 0.306926\n",
      "Epoch [400/500] | Train Loss: 0.619659 | Val Loss: 0.318566\n",
      "Epoch [500/500] | Train Loss: 0.592617 | Val Loss: 0.321900\n",
      "Epoch [100/500] | Train Loss: 0.507236 | Val Loss: 0.787475\n",
      "Epoch [200/500] | Train Loss: 0.435788 | Val Loss: 0.788721\n",
      "Epoch [300/500] | Train Loss: 0.351668 | Val Loss: 0.871881\n",
      "Epoch [400/500] | Train Loss: 0.292039 | Val Loss: 0.894827\n",
      "Epoch [500/500] | Train Loss: 0.251340 | Val Loss: 0.878025\n",
      "Epoch [100/500] | Train Loss: 0.597616 | Val Loss: 1.203471\n",
      "Epoch [200/500] | Train Loss: 0.499598 | Val Loss: 1.213841\n",
      "Epoch [300/500] | Train Loss: 0.469311 | Val Loss: 1.223733\n",
      "Epoch [400/500] | Train Loss: 0.433099 | Val Loss: 1.185309\n",
      "Epoch [500/500] | Train Loss: 0.391048 | Val Loss: 1.190948\n",
      "Epoch [100/500] | Train Loss: 0.633587 | Val Loss: 0.514647\n",
      "Epoch [200/500] | Train Loss: 0.561040 | Val Loss: 0.588673\n",
      "Epoch [300/500] | Train Loss: 0.543696 | Val Loss: 0.603862\n",
      "Epoch [400/500] | Train Loss: 0.442790 | Val Loss: 0.633542\n",
      "Epoch [500/500] | Train Loss: 0.461949 | Val Loss: 0.581407\n",
      "Epoch [100/500] | Train Loss: 0.645619 | Val Loss: 0.512473\n",
      "Epoch [200/500] | Train Loss: 0.582963 | Val Loss: 0.522688\n",
      "Epoch [300/500] | Train Loss: 0.540930 | Val Loss: 0.527399\n",
      "Epoch [400/500] | Train Loss: 0.536155 | Val Loss: 0.541604\n",
      "Epoch [500/500] | Train Loss: 0.500736 | Val Loss: 0.526191\n",
      "Epoch [100/500] | Train Loss: 0.600572 | Val Loss: 0.306900\n",
      "Epoch [200/500] | Train Loss: 0.567707 | Val Loss: 0.319573\n",
      "Epoch [300/500] | Train Loss: 0.503971 | Val Loss: 0.352005\n",
      "Epoch [400/500] | Train Loss: 0.450578 | Val Loss: 0.350250\n",
      "Epoch [500/500] | Train Loss: 0.489444 | Val Loss: 0.341315\n",
      "[Year=1986] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.655440 Test MSE=0.647792\n",
      "Year 1986 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.922831 | Val Loss: 0.865888\n",
      "Epoch [200/500] | Train Loss: 0.755996 | Val Loss: 0.927769\n",
      "Epoch [300/500] | Train Loss: 0.660877 | Val Loss: 0.979728\n",
      "Epoch [400/500] | Train Loss: 0.553936 | Val Loss: 1.050612\n",
      "Epoch [500/500] | Train Loss: 0.482065 | Val Loss: 1.095068\n",
      "Epoch [100/500] | Train Loss: 0.899557 | Val Loss: 0.437607\n",
      "Epoch [200/500] | Train Loss: 0.855775 | Val Loss: 0.432649\n",
      "Epoch [300/500] | Train Loss: 0.738316 | Val Loss: 0.445947\n",
      "Epoch [400/500] | Train Loss: 0.696473 | Val Loss: 0.467693\n",
      "Epoch [500/500] | Train Loss: 0.676277 | Val Loss: 0.488623\n",
      "Epoch [100/500] | Train Loss: 0.725989 | Val Loss: 0.440956\n",
      "Epoch [200/500] | Train Loss: 0.650203 | Val Loss: 0.457628\n",
      "Epoch [300/500] | Train Loss: 0.643853 | Val Loss: 0.468638\n",
      "Epoch [400/500] | Train Loss: 0.614977 | Val Loss: 0.465920\n",
      "Epoch [500/500] | Train Loss: 0.570966 | Val Loss: 0.462697\n",
      "Epoch [100/500] | Train Loss: 0.656983 | Val Loss: 0.359025\n",
      "Epoch [200/500] | Train Loss: 0.614717 | Val Loss: 0.374391\n",
      "Epoch [300/500] | Train Loss: 0.585147 | Val Loss: 0.391918\n",
      "Epoch [400/500] | Train Loss: 0.567226 | Val Loss: 0.403960\n",
      "Epoch [500/500] | Train Loss: 0.521712 | Val Loss: 0.414811\n",
      "Epoch [100/500] | Train Loss: 0.579406 | Val Loss: 0.669265\n",
      "Epoch [200/500] | Train Loss: 0.544368 | Val Loss: 0.681332\n",
      "Epoch [300/500] | Train Loss: 0.514675 | Val Loss: 0.707249\n",
      "Epoch [400/500] | Train Loss: 0.496201 | Val Loss: 0.722065\n",
      "Epoch [500/500] | Train Loss: 0.483557 | Val Loss: 0.738608\n",
      "Epoch [100/500] | Train Loss: 0.726718 | Val Loss: 0.905329\n",
      "Epoch [200/500] | Train Loss: 0.598200 | Val Loss: 0.956885\n",
      "Epoch [300/500] | Train Loss: 0.576473 | Val Loss: 0.977295\n",
      "Epoch [400/500] | Train Loss: 0.553109 | Val Loss: 0.963095\n",
      "Epoch [500/500] | Train Loss: 0.554792 | Val Loss: 0.985457\n",
      "Epoch [100/500] | Train Loss: 0.663137 | Val Loss: 0.529132\n",
      "Epoch [200/500] | Train Loss: 0.515341 | Val Loss: 0.603782\n",
      "Epoch [300/500] | Train Loss: 0.486234 | Val Loss: 0.639455\n",
      "Epoch [400/500] | Train Loss: 0.430807 | Val Loss: 0.659922\n",
      "Epoch [500/500] | Train Loss: 0.375037 | Val Loss: 0.607282\n",
      "Epoch [100/500] | Train Loss: 0.582037 | Val Loss: 0.493235\n",
      "Epoch [200/500] | Train Loss: 0.523562 | Val Loss: 0.541761\n",
      "Epoch [300/500] | Train Loss: 0.450540 | Val Loss: 0.534376\n",
      "Epoch [400/500] | Train Loss: 0.414012 | Val Loss: 0.534020\n",
      "Epoch [500/500] | Train Loss: 0.367397 | Val Loss: 0.496733\n",
      "Epoch [100/500] | Train Loss: 0.516931 | Val Loss: 0.383787\n",
      "Epoch [200/500] | Train Loss: 0.476856 | Val Loss: 0.449717\n",
      "Epoch [300/500] | Train Loss: 0.434816 | Val Loss: 0.467590\n",
      "Epoch [400/500] | Train Loss: 0.377273 | Val Loss: 0.458844\n",
      "Epoch [500/500] | Train Loss: 0.402463 | Val Loss: 0.497418\n",
      "Epoch [100/500] | Train Loss: 0.520534 | Val Loss: 0.717142\n",
      "Epoch [200/500] | Train Loss: 0.496021 | Val Loss: 0.703312\n",
      "Epoch [300/500] | Train Loss: 0.432608 | Val Loss: 0.741401\n",
      "Epoch [400/500] | Train Loss: 0.399684 | Val Loss: 0.772793\n",
      "Epoch [500/500] | Train Loss: 0.410919 | Val Loss: 0.792672\n",
      "Epoch [100/500] | Train Loss: 0.947880 | Val Loss: 0.832134\n",
      "Epoch [200/500] | Train Loss: 0.849537 | Val Loss: 0.866522\n",
      "Epoch [300/500] | Train Loss: 0.805808 | Val Loss: 0.921057\n",
      "Epoch [400/500] | Train Loss: 0.730925 | Val Loss: 0.933975\n",
      "Epoch [500/500] | Train Loss: 0.665252 | Val Loss: 0.959649\n",
      "Epoch [100/500] | Train Loss: 0.895355 | Val Loss: 0.443385\n",
      "Epoch [200/500] | Train Loss: 0.881680 | Val Loss: 0.437777\n",
      "Epoch [300/500] | Train Loss: 0.810402 | Val Loss: 0.436790\n",
      "Epoch [400/500] | Train Loss: 0.781223 | Val Loss: 0.443626\n",
      "Epoch [500/500] | Train Loss: 0.758204 | Val Loss: 0.452134\n",
      "Epoch [100/500] | Train Loss: 0.737690 | Val Loss: 0.441540\n",
      "Epoch [200/500] | Train Loss: 0.723940 | Val Loss: 0.451843\n",
      "Epoch [300/500] | Train Loss: 0.694267 | Val Loss: 0.451389\n",
      "Epoch [400/500] | Train Loss: 0.680492 | Val Loss: 0.455152\n",
      "Epoch [500/500] | Train Loss: 0.650171 | Val Loss: 0.449769\n",
      "Epoch [100/500] | Train Loss: 0.670835 | Val Loss: 0.357006\n",
      "Epoch [200/500] | Train Loss: 0.659226 | Val Loss: 0.375606\n",
      "Epoch [300/500] | Train Loss: 0.635907 | Val Loss: 0.392751\n",
      "Epoch [400/500] | Train Loss: 0.611902 | Val Loss: 0.396134\n",
      "Epoch [500/500] | Train Loss: 0.590107 | Val Loss: 0.384732\n",
      "Epoch [100/500] | Train Loss: 0.593684 | Val Loss: 0.658573\n",
      "Epoch [200/500] | Train Loss: 0.581254 | Val Loss: 0.662759\n",
      "Epoch [300/500] | Train Loss: 0.569403 | Val Loss: 0.668683\n",
      "Epoch [400/500] | Train Loss: 0.559630 | Val Loss: 0.683557\n",
      "Epoch [500/500] | Train Loss: 0.536454 | Val Loss: 0.688946\n",
      "Epoch [100/500] | Train Loss: 0.741681 | Val Loss: 0.957786\n",
      "Epoch [200/500] | Train Loss: 0.555111 | Val Loss: 1.076783\n",
      "Epoch [300/500] | Train Loss: 0.495936 | Val Loss: 1.008775\n",
      "Epoch [400/500] | Train Loss: 0.470944 | Val Loss: 1.072406\n",
      "Epoch [500/500] | Train Loss: 0.456234 | Val Loss: 1.049638\n",
      "Epoch [100/500] | Train Loss: 0.797517 | Val Loss: 0.439426\n",
      "Epoch [200/500] | Train Loss: 0.717168 | Val Loss: 0.490267\n",
      "Epoch [300/500] | Train Loss: 0.618385 | Val Loss: 0.526267\n",
      "Epoch [400/500] | Train Loss: 0.639947 | Val Loss: 0.526231\n",
      "Epoch [500/500] | Train Loss: 0.562032 | Val Loss: 0.508340\n",
      "Epoch [100/500] | Train Loss: 0.663854 | Val Loss: 0.437876\n",
      "Epoch [200/500] | Train Loss: 0.632303 | Val Loss: 0.450773\n",
      "Epoch [300/500] | Train Loss: 0.576968 | Val Loss: 0.458950\n",
      "Epoch [400/500] | Train Loss: 0.523309 | Val Loss: 0.465923\n",
      "Epoch [500/500] | Train Loss: 0.524840 | Val Loss: 0.482764\n",
      "Epoch [100/500] | Train Loss: 0.605731 | Val Loss: 0.405411\n",
      "Epoch [200/500] | Train Loss: 0.549262 | Val Loss: 0.415654\n",
      "Epoch [300/500] | Train Loss: 0.510779 | Val Loss: 0.419372\n",
      "Epoch [400/500] | Train Loss: 0.517721 | Val Loss: 0.418076\n",
      "Epoch [500/500] | Train Loss: 0.523709 | Val Loss: 0.421580\n",
      "Epoch [100/500] | Train Loss: 0.560181 | Val Loss: 0.671280\n",
      "Epoch [200/500] | Train Loss: 0.512549 | Val Loss: 0.697816\n",
      "Epoch [300/500] | Train Loss: 0.483977 | Val Loss: 0.714507\n",
      "Epoch [400/500] | Train Loss: 0.468670 | Val Loss: 0.716756\n",
      "Epoch [500/500] | Train Loss: 0.456986 | Val Loss: 0.744713\n",
      "Epoch [100/500] | Train Loss: 0.938798 | Val Loss: 0.875557\n",
      "Epoch [200/500] | Train Loss: 0.766983 | Val Loss: 0.953185\n",
      "Epoch [300/500] | Train Loss: 0.614025 | Val Loss: 1.059725\n",
      "Epoch [400/500] | Train Loss: 0.483992 | Val Loss: 1.173733\n",
      "Epoch [500/500] | Train Loss: 0.426151 | Val Loss: 1.220923\n",
      "Epoch [100/500] | Train Loss: 0.824346 | Val Loss: 0.450250\n",
      "Epoch [200/500] | Train Loss: 0.653569 | Val Loss: 0.507300\n",
      "Epoch [300/500] | Train Loss: 0.611808 | Val Loss: 0.559280\n",
      "Epoch [400/500] | Train Loss: 0.538239 | Val Loss: 0.604163\n",
      "Epoch [500/500] | Train Loss: 0.465539 | Val Loss: 0.654468\n",
      "Epoch [100/500] | Train Loss: 0.714805 | Val Loss: 0.441083\n",
      "Epoch [200/500] | Train Loss: 0.613628 | Val Loss: 0.442643\n",
      "Epoch [300/500] | Train Loss: 0.590463 | Val Loss: 0.465396\n",
      "Epoch [400/500] | Train Loss: 0.545905 | Val Loss: 0.456702\n",
      "Epoch [500/500] | Train Loss: 0.550247 | Val Loss: 0.460116\n",
      "Epoch [100/500] | Train Loss: 0.660739 | Val Loss: 0.361321\n",
      "Epoch [200/500] | Train Loss: 0.592493 | Val Loss: 0.400716\n",
      "Epoch [300/500] | Train Loss: 0.544010 | Val Loss: 0.400995\n",
      "Epoch [400/500] | Train Loss: 0.496628 | Val Loss: 0.391195\n",
      "Epoch [500/500] | Train Loss: 0.498449 | Val Loss: 0.405476\n",
      "Epoch [100/500] | Train Loss: 0.583432 | Val Loss: 0.677889\n",
      "Epoch [200/500] | Train Loss: 0.528488 | Val Loss: 0.704563\n",
      "Epoch [300/500] | Train Loss: 0.479192 | Val Loss: 0.722456\n",
      "Epoch [400/500] | Train Loss: 0.467040 | Val Loss: 0.735378\n",
      "Epoch [500/500] | Train Loss: 0.451931 | Val Loss: 0.747971\n",
      "Epoch [100/500] | Train Loss: 0.492145 | Val Loss: 1.061903\n",
      "Epoch [200/500] | Train Loss: 0.336819 | Val Loss: 1.134022\n",
      "Epoch [300/500] | Train Loss: 0.339849 | Val Loss: 1.084479\n",
      "Epoch [400/500] | Train Loss: 0.227871 | Val Loss: 1.073904\n",
      "Epoch [500/500] | Train Loss: 0.247565 | Val Loss: 1.059679\n",
      "Epoch [100/500] | Train Loss: 0.614919 | Val Loss: 0.521973\n",
      "Epoch [200/500] | Train Loss: 0.543989 | Val Loss: 0.667656\n",
      "Epoch [300/500] | Train Loss: 0.373589 | Val Loss: 0.724946\n",
      "Epoch [400/500] | Train Loss: 0.372590 | Val Loss: 0.670774\n",
      "Epoch [500/500] | Train Loss: 0.371696 | Val Loss: 0.712118\n",
      "Epoch [100/500] | Train Loss: 0.583844 | Val Loss: 0.482796\n",
      "Epoch [200/500] | Train Loss: 0.488805 | Val Loss: 0.541805\n",
      "Epoch [300/500] | Train Loss: 0.402351 | Val Loss: 0.587827\n",
      "Epoch [400/500] | Train Loss: 0.392568 | Val Loss: 0.577907\n",
      "Epoch [500/500] | Train Loss: 0.330713 | Val Loss: 0.581449\n",
      "Epoch [100/500] | Train Loss: 0.494126 | Val Loss: 0.394999\n",
      "Epoch [200/500] | Train Loss: 0.419705 | Val Loss: 0.428148\n",
      "Epoch [300/500] | Train Loss: 0.353621 | Val Loss: 0.446846\n",
      "Epoch [400/500] | Train Loss: 0.342772 | Val Loss: 0.455097\n",
      "Epoch [500/500] | Train Loss: 0.337000 | Val Loss: 0.494046\n",
      "Epoch [100/500] | Train Loss: 0.444380 | Val Loss: 0.727048\n",
      "Epoch [200/500] | Train Loss: 0.382339 | Val Loss: 0.729418\n",
      "Epoch [300/500] | Train Loss: 0.361652 | Val Loss: 0.756643\n",
      "Epoch [400/500] | Train Loss: 0.319102 | Val Loss: 0.743415\n",
      "Epoch [500/500] | Train Loss: 0.307032 | Val Loss: 0.752049\n",
      "Epoch [100/500] | Train Loss: 0.942581 | Val Loss: 0.861180\n",
      "Epoch [200/500] | Train Loss: 0.803381 | Val Loss: 0.898641\n",
      "Epoch [300/500] | Train Loss: 0.714029 | Val Loss: 0.956260\n",
      "Epoch [400/500] | Train Loss: 0.718361 | Val Loss: 0.989121\n",
      "Epoch [500/500] | Train Loss: 0.582838 | Val Loss: 1.017355\n",
      "Epoch [100/500] | Train Loss: 0.890201 | Val Loss: 0.443822\n",
      "Epoch [200/500] | Train Loss: 0.803606 | Val Loss: 0.456350\n",
      "Epoch [300/500] | Train Loss: 0.722202 | Val Loss: 0.471512\n",
      "Epoch [400/500] | Train Loss: 0.693151 | Val Loss: 0.506092\n",
      "Epoch [500/500] | Train Loss: 0.615455 | Val Loss: 0.521407\n",
      "Epoch [100/500] | Train Loss: 0.743076 | Val Loss: 0.443511\n",
      "Epoch [200/500] | Train Loss: 0.696277 | Val Loss: 0.450203\n",
      "Epoch [300/500] | Train Loss: 0.645342 | Val Loss: 0.463598\n",
      "Epoch [400/500] | Train Loss: 0.635957 | Val Loss: 0.471372\n",
      "Epoch [500/500] | Train Loss: 0.585115 | Val Loss: 0.472615\n",
      "Epoch [100/500] | Train Loss: 0.677849 | Val Loss: 0.365563\n",
      "Epoch [200/500] | Train Loss: 0.625330 | Val Loss: 0.379120\n",
      "Epoch [300/500] | Train Loss: 0.590074 | Val Loss: 0.375965\n",
      "Epoch [400/500] | Train Loss: 0.577684 | Val Loss: 0.372319\n",
      "Epoch [500/500] | Train Loss: 0.564907 | Val Loss: 0.375941\n",
      "Epoch [100/500] | Train Loss: 0.597159 | Val Loss: 0.654366\n",
      "Epoch [200/500] | Train Loss: 0.573034 | Val Loss: 0.668018\n",
      "Epoch [300/500] | Train Loss: 0.540665 | Val Loss: 0.686322\n",
      "Epoch [400/500] | Train Loss: 0.537526 | Val Loss: 0.712085\n",
      "Epoch [500/500] | Train Loss: 0.541308 | Val Loss: 0.709964\n",
      "Epoch [100/500] | Train Loss: 0.721532 | Val Loss: 0.904866\n",
      "Epoch [200/500] | Train Loss: 0.635822 | Val Loss: 0.957036\n",
      "Epoch [300/500] | Train Loss: 0.520867 | Val Loss: 0.981219\n",
      "Epoch [400/500] | Train Loss: 0.519782 | Val Loss: 0.971890\n",
      "Epoch [500/500] | Train Loss: 0.449737 | Val Loss: 0.923920\n",
      "Epoch [100/500] | Train Loss: 0.691026 | Val Loss: 0.473921\n",
      "Epoch [200/500] | Train Loss: 0.587050 | Val Loss: 0.542354\n",
      "Epoch [300/500] | Train Loss: 0.531138 | Val Loss: 0.616423\n",
      "Epoch [400/500] | Train Loss: 0.517195 | Val Loss: 0.645960\n",
      "Epoch [500/500] | Train Loss: 0.468331 | Val Loss: 0.653760\n",
      "Epoch [100/500] | Train Loss: 0.610361 | Val Loss: 0.485739\n",
      "Epoch [200/500] | Train Loss: 0.572278 | Val Loss: 0.478683\n",
      "Epoch [300/500] | Train Loss: 0.495928 | Val Loss: 0.478513\n",
      "Epoch [400/500] | Train Loss: 0.437678 | Val Loss: 0.505100\n",
      "Epoch [500/500] | Train Loss: 0.445102 | Val Loss: 0.507792\n",
      "Epoch [100/500] | Train Loss: 0.524947 | Val Loss: 0.385306\n",
      "Epoch [200/500] | Train Loss: 0.513647 | Val Loss: 0.417236\n",
      "Epoch [300/500] | Train Loss: 0.455523 | Val Loss: 0.398454\n",
      "Epoch [400/500] | Train Loss: 0.422760 | Val Loss: 0.435071\n",
      "Epoch [500/500] | Train Loss: 0.443929 | Val Loss: 0.449249\n",
      "Epoch [100/500] | Train Loss: 0.552891 | Val Loss: 0.708920\n",
      "Epoch [200/500] | Train Loss: 0.521153 | Val Loss: 0.710810\n",
      "Epoch [300/500] | Train Loss: 0.481619 | Val Loss: 0.689605\n",
      "Epoch [400/500] | Train Loss: 0.467325 | Val Loss: 0.694115\n",
      "Epoch [500/500] | Train Loss: 0.456644 | Val Loss: 0.693573\n",
      "[Year=1987] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.587046 Test MSE=3.797427\n",
      "Year 1987 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.577786 | Val Loss: 0.528047\n",
      "Epoch [200/500] | Train Loss: 0.527495 | Val Loss: 0.540672\n",
      "Epoch [300/500] | Train Loss: 0.481250 | Val Loss: 0.573201\n",
      "Epoch [400/500] | Train Loss: 0.431783 | Val Loss: 0.604504\n",
      "Epoch [500/500] | Train Loss: 0.401572 | Val Loss: 0.642956\n",
      "Epoch [100/500] | Train Loss: 0.592084 | Val Loss: 0.352499\n",
      "Epoch [200/500] | Train Loss: 0.518459 | Val Loss: 0.356261\n",
      "Epoch [300/500] | Train Loss: 0.501694 | Val Loss: 0.370720\n",
      "Epoch [400/500] | Train Loss: 0.459557 | Val Loss: 0.379807\n",
      "Epoch [500/500] | Train Loss: 0.425129 | Val Loss: 0.412745\n",
      "Epoch [100/500] | Train Loss: 0.463397 | Val Loss: 0.456490\n",
      "Epoch [200/500] | Train Loss: 0.434958 | Val Loss: 0.480118\n",
      "Epoch [300/500] | Train Loss: 0.403420 | Val Loss: 0.489301\n",
      "Epoch [400/500] | Train Loss: 0.397436 | Val Loss: 0.502328\n",
      "Epoch [500/500] | Train Loss: 0.376594 | Val Loss: 0.501688\n",
      "Epoch [100/500] | Train Loss: 0.460818 | Val Loss: 0.698328\n",
      "Epoch [200/500] | Train Loss: 0.436723 | Val Loss: 0.718176\n",
      "Epoch [300/500] | Train Loss: 0.417491 | Val Loss: 0.736487\n",
      "Epoch [400/500] | Train Loss: 0.394285 | Val Loss: 0.741190\n",
      "Epoch [500/500] | Train Loss: 0.384975 | Val Loss: 0.788517\n",
      "Epoch [100/500] | Train Loss: 0.533564 | Val Loss: 3.802355\n",
      "Epoch [200/500] | Train Loss: 0.515081 | Val Loss: 3.705049\n",
      "Epoch [300/500] | Train Loss: 0.493910 | Val Loss: 3.693775\n",
      "Epoch [400/500] | Train Loss: 0.484959 | Val Loss: 3.742616\n",
      "Epoch [500/500] | Train Loss: 0.459979 | Val Loss: 3.683792\n",
      "Epoch [100/500] | Train Loss: 0.317863 | Val Loss: 0.646976\n",
      "Epoch [200/500] | Train Loss: 0.221784 | Val Loss: 0.714553\n",
      "Epoch [300/500] | Train Loss: 0.209269 | Val Loss: 0.722581\n",
      "Epoch [400/500] | Train Loss: 0.188706 | Val Loss: 0.698088\n",
      "Epoch [500/500] | Train Loss: 0.129814 | Val Loss: 0.651988\n",
      "Epoch [100/500] | Train Loss: 0.399667 | Val Loss: 0.449250\n",
      "Epoch [200/500] | Train Loss: 0.292554 | Val Loss: 0.498633\n",
      "Epoch [300/500] | Train Loss: 0.304998 | Val Loss: 0.573378\n",
      "Epoch [400/500] | Train Loss: 0.257472 | Val Loss: 0.594891\n",
      "Epoch [500/500] | Train Loss: 0.223251 | Val Loss: 0.559662\n",
      "Epoch [100/500] | Train Loss: 0.381494 | Val Loss: 0.520776\n",
      "Epoch [200/500] | Train Loss: 0.320831 | Val Loss: 0.545246\n",
      "Epoch [300/500] | Train Loss: 0.307127 | Val Loss: 0.500917\n",
      "Epoch [400/500] | Train Loss: 0.298547 | Val Loss: 0.540203\n",
      "Epoch [500/500] | Train Loss: 0.274444 | Val Loss: 0.546423\n",
      "Epoch [100/500] | Train Loss: 0.399993 | Val Loss: 0.839804\n",
      "Epoch [200/500] | Train Loss: 0.361914 | Val Loss: 0.941888\n",
      "Epoch [300/500] | Train Loss: 0.349517 | Val Loss: 0.832566\n",
      "Epoch [400/500] | Train Loss: 0.327358 | Val Loss: 0.858784\n",
      "Epoch [500/500] | Train Loss: 0.290809 | Val Loss: 0.910154\n",
      "Epoch [100/500] | Train Loss: 0.458216 | Val Loss: 4.507886\n",
      "Epoch [200/500] | Train Loss: 0.407256 | Val Loss: 3.864182\n",
      "Epoch [300/500] | Train Loss: 0.358018 | Val Loss: 3.963334\n",
      "Epoch [400/500] | Train Loss: 0.363073 | Val Loss: 3.916329\n",
      "Epoch [500/500] | Train Loss: 0.350922 | Val Loss: 4.238353\n",
      "Epoch [100/500] | Train Loss: 0.609259 | Val Loss: 0.535598\n",
      "Epoch [200/500] | Train Loss: 0.537248 | Val Loss: 0.533280\n",
      "Epoch [300/500] | Train Loss: 0.529409 | Val Loss: 0.548789\n",
      "Epoch [400/500] | Train Loss: 0.454946 | Val Loss: 0.577121\n",
      "Epoch [500/500] | Train Loss: 0.420848 | Val Loss: 0.587693\n",
      "Epoch [100/500] | Train Loss: 0.601027 | Val Loss: 0.336033\n",
      "Epoch [200/500] | Train Loss: 0.567042 | Val Loss: 0.335961\n",
      "Epoch [300/500] | Train Loss: 0.534000 | Val Loss: 0.354413\n",
      "Epoch [400/500] | Train Loss: 0.525981 | Val Loss: 0.361123\n",
      "Epoch [500/500] | Train Loss: 0.463995 | Val Loss: 0.367328\n",
      "Epoch [100/500] | Train Loss: 0.477839 | Val Loss: 0.446165\n",
      "Epoch [200/500] | Train Loss: 0.468539 | Val Loss: 0.459024\n",
      "Epoch [300/500] | Train Loss: 0.450417 | Val Loss: 0.465248\n",
      "Epoch [400/500] | Train Loss: 0.441680 | Val Loss: 0.467222\n",
      "Epoch [500/500] | Train Loss: 0.427818 | Val Loss: 0.473825\n",
      "Epoch [100/500] | Train Loss: 0.477325 | Val Loss: 0.688527\n",
      "Epoch [200/500] | Train Loss: 0.469270 | Val Loss: 0.687258\n",
      "Epoch [300/500] | Train Loss: 0.454841 | Val Loss: 0.696799\n",
      "Epoch [400/500] | Train Loss: 0.436280 | Val Loss: 0.697262\n",
      "Epoch [500/500] | Train Loss: 0.436709 | Val Loss: 0.704003\n",
      "Epoch [100/500] | Train Loss: 0.523981 | Val Loss: 3.668124\n",
      "Epoch [200/500] | Train Loss: 0.520057 | Val Loss: 3.736242\n",
      "Epoch [300/500] | Train Loss: 0.508226 | Val Loss: 3.859311\n",
      "Epoch [400/500] | Train Loss: 0.511819 | Val Loss: 3.901443\n",
      "Epoch [500/500] | Train Loss: 0.493435 | Val Loss: 3.965218\n",
      "Epoch [100/500] | Train Loss: 0.447473 | Val Loss: 0.587666\n",
      "Epoch [200/500] | Train Loss: 0.398401 | Val Loss: 0.602349\n",
      "Epoch [300/500] | Train Loss: 0.323860 | Val Loss: 0.616955\n",
      "Epoch [400/500] | Train Loss: 0.342968 | Val Loss: 0.638687\n",
      "Epoch [500/500] | Train Loss: 0.335016 | Val Loss: 0.676719\n",
      "Epoch [100/500] | Train Loss: 0.500658 | Val Loss: 0.382344\n",
      "Epoch [200/500] | Train Loss: 0.428922 | Val Loss: 0.458114\n",
      "Epoch [300/500] | Train Loss: 0.424785 | Val Loss: 0.460814\n",
      "Epoch [400/500] | Train Loss: 0.388996 | Val Loss: 0.444674\n",
      "Epoch [500/500] | Train Loss: 0.327013 | Val Loss: 0.475487\n",
      "Epoch [100/500] | Train Loss: 0.467576 | Val Loss: 0.442869\n",
      "Epoch [200/500] | Train Loss: 0.439262 | Val Loss: 0.439008\n",
      "Epoch [300/500] | Train Loss: 0.407261 | Val Loss: 0.432424\n",
      "Epoch [400/500] | Train Loss: 0.408273 | Val Loss: 0.467522\n",
      "Epoch [500/500] | Train Loss: 0.381767 | Val Loss: 0.457556\n",
      "Epoch [100/500] | Train Loss: 0.467101 | Val Loss: 0.694272\n",
      "Epoch [200/500] | Train Loss: 0.412531 | Val Loss: 0.729692\n",
      "Epoch [300/500] | Train Loss: 0.393575 | Val Loss: 0.742100\n",
      "Epoch [400/500] | Train Loss: 0.377421 | Val Loss: 0.747729\n",
      "Epoch [500/500] | Train Loss: 0.389779 | Val Loss: 0.727150\n",
      "Epoch [100/500] | Train Loss: 0.467690 | Val Loss: 4.010737\n",
      "Epoch [200/500] | Train Loss: 0.453333 | Val Loss: 3.618891\n",
      "Epoch [300/500] | Train Loss: 0.430299 | Val Loss: 3.695486\n",
      "Epoch [400/500] | Train Loss: 0.425366 | Val Loss: 4.178349\n",
      "Epoch [500/500] | Train Loss: 0.403349 | Val Loss: 4.218316\n",
      "Epoch [100/500] | Train Loss: 0.543503 | Val Loss: 0.540600\n",
      "Epoch [200/500] | Train Loss: 0.398717 | Val Loss: 0.592719\n",
      "Epoch [300/500] | Train Loss: 0.361620 | Val Loss: 0.643939\n",
      "Epoch [400/500] | Train Loss: 0.273031 | Val Loss: 0.683747\n",
      "Epoch [500/500] | Train Loss: 0.229032 | Val Loss: 0.718826\n",
      "Epoch [100/500] | Train Loss: 0.535237 | Val Loss: 0.354428\n",
      "Epoch [200/500] | Train Loss: 0.481364 | Val Loss: 0.390421\n",
      "Epoch [300/500] | Train Loss: 0.450421 | Val Loss: 0.411341\n",
      "Epoch [400/500] | Train Loss: 0.404634 | Val Loss: 0.449097\n",
      "Epoch [500/500] | Train Loss: 0.358580 | Val Loss: 0.462642\n",
      "Epoch [100/500] | Train Loss: 0.488674 | Val Loss: 0.449838\n",
      "Epoch [200/500] | Train Loss: 0.458520 | Val Loss: 0.452047\n",
      "Epoch [300/500] | Train Loss: 0.430608 | Val Loss: 0.485634\n",
      "Epoch [400/500] | Train Loss: 0.383238 | Val Loss: 0.508507\n",
      "Epoch [500/500] | Train Loss: 0.353373 | Val Loss: 0.514059\n",
      "Epoch [100/500] | Train Loss: 0.464898 | Val Loss: 0.696620\n",
      "Epoch [200/500] | Train Loss: 0.436768 | Val Loss: 0.715487\n",
      "Epoch [300/500] | Train Loss: 0.404636 | Val Loss: 0.765465\n",
      "Epoch [400/500] | Train Loss: 0.360772 | Val Loss: 0.810062\n",
      "Epoch [500/500] | Train Loss: 0.336224 | Val Loss: 0.831905\n",
      "Epoch [100/500] | Train Loss: 0.526671 | Val Loss: 3.646305\n",
      "Epoch [200/500] | Train Loss: 0.509508 | Val Loss: 3.665064\n",
      "Epoch [300/500] | Train Loss: 0.478103 | Val Loss: 3.767575\n",
      "Epoch [400/500] | Train Loss: 0.464719 | Val Loss: 3.785433\n",
      "Epoch [500/500] | Train Loss: 0.451562 | Val Loss: 3.764147\n",
      "Epoch [100/500] | Train Loss: 0.268806 | Val Loss: 0.703835\n",
      "Epoch [200/500] | Train Loss: 0.157729 | Val Loss: 0.859104\n",
      "Epoch [300/500] | Train Loss: 0.141411 | Val Loss: 0.793926\n",
      "Epoch [400/500] | Train Loss: 0.123069 | Val Loss: 0.812053\n",
      "Epoch [500/500] | Train Loss: 0.100763 | Val Loss: 0.776052\n",
      "Epoch [100/500] | Train Loss: 0.417606 | Val Loss: 0.391099\n",
      "Epoch [200/500] | Train Loss: 0.323265 | Val Loss: 0.473210\n",
      "Epoch [300/500] | Train Loss: 0.235742 | Val Loss: 0.554551\n",
      "Epoch [400/500] | Train Loss: 0.213795 | Val Loss: 0.534107\n",
      "Epoch [500/500] | Train Loss: 0.207597 | Val Loss: 0.554630\n",
      "Epoch [100/500] | Train Loss: 0.403058 | Val Loss: 0.515267\n",
      "Epoch [200/500] | Train Loss: 0.337033 | Val Loss: 0.518876\n",
      "Epoch [300/500] | Train Loss: 0.300425 | Val Loss: 0.579568\n",
      "Epoch [400/500] | Train Loss: 0.281573 | Val Loss: 0.568979\n",
      "Epoch [500/500] | Train Loss: 0.253887 | Val Loss: 0.599811\n",
      "Epoch [100/500] | Train Loss: 0.408357 | Val Loss: 0.762152\n",
      "Epoch [200/500] | Train Loss: 0.361125 | Val Loss: 0.812859\n",
      "Epoch [300/500] | Train Loss: 0.342377 | Val Loss: 0.849993\n",
      "Epoch [400/500] | Train Loss: 0.297610 | Val Loss: 0.906374\n",
      "Epoch [500/500] | Train Loss: 0.273851 | Val Loss: 0.934089\n",
      "Epoch [100/500] | Train Loss: 0.508260 | Val Loss: 4.043054\n",
      "Epoch [200/500] | Train Loss: 0.454122 | Val Loss: 4.162943\n",
      "Epoch [300/500] | Train Loss: 0.384249 | Val Loss: 4.262305\n",
      "Epoch [400/500] | Train Loss: 0.342689 | Val Loss: 4.142019\n",
      "Epoch [500/500] | Train Loss: 0.337411 | Val Loss: 3.847212\n",
      "Epoch [100/500] | Train Loss: 0.585221 | Val Loss: 0.512371\n",
      "Epoch [200/500] | Train Loss: 0.551982 | Val Loss: 0.514344\n",
      "Epoch [300/500] | Train Loss: 0.503250 | Val Loss: 0.535103\n",
      "Epoch [400/500] | Train Loss: 0.440744 | Val Loss: 0.569930\n",
      "Epoch [500/500] | Train Loss: 0.432665 | Val Loss: 0.600131\n",
      "Epoch [100/500] | Train Loss: 0.571711 | Val Loss: 0.331088\n",
      "Epoch [200/500] | Train Loss: 0.541356 | Val Loss: 0.352429\n",
      "Epoch [300/500] | Train Loss: 0.497542 | Val Loss: 0.377365\n",
      "Epoch [400/500] | Train Loss: 0.445473 | Val Loss: 0.389582\n",
      "Epoch [500/500] | Train Loss: 0.442201 | Val Loss: 0.400881\n",
      "Epoch [100/500] | Train Loss: 0.506036 | Val Loss: 0.451022\n",
      "Epoch [200/500] | Train Loss: 0.458635 | Val Loss: 0.448854\n",
      "Epoch [300/500] | Train Loss: 0.460470 | Val Loss: 0.460577\n",
      "Epoch [400/500] | Train Loss: 0.450509 | Val Loss: 0.464341\n",
      "Epoch [500/500] | Train Loss: 0.432751 | Val Loss: 0.466257\n",
      "Epoch [100/500] | Train Loss: 0.465112 | Val Loss: 0.699440\n",
      "Epoch [200/500] | Train Loss: 0.445850 | Val Loss: 0.702238\n",
      "Epoch [300/500] | Train Loss: 0.428208 | Val Loss: 0.729890\n",
      "Epoch [400/500] | Train Loss: 0.423795 | Val Loss: 0.761276\n",
      "Epoch [500/500] | Train Loss: 0.396898 | Val Loss: 0.772332\n",
      "Epoch [100/500] | Train Loss: 0.510110 | Val Loss: 3.568544\n",
      "Epoch [200/500] | Train Loss: 0.496271 | Val Loss: 3.584794\n",
      "Epoch [300/500] | Train Loss: 0.474018 | Val Loss: 3.642444\n",
      "Epoch [400/500] | Train Loss: 0.474799 | Val Loss: 3.692097\n",
      "Epoch [500/500] | Train Loss: 0.470160 | Val Loss: 3.636312\n",
      "Epoch [100/500] | Train Loss: 0.412890 | Val Loss: 0.618253\n",
      "Epoch [200/500] | Train Loss: 0.295793 | Val Loss: 0.664057\n",
      "Epoch [300/500] | Train Loss: 0.232246 | Val Loss: 0.700478\n",
      "Epoch [400/500] | Train Loss: 0.211737 | Val Loss: 0.722139\n",
      "Epoch [500/500] | Train Loss: 0.238850 | Val Loss: 0.695267\n",
      "Epoch [100/500] | Train Loss: 0.446706 | Val Loss: 0.402603\n",
      "Epoch [200/500] | Train Loss: 0.391045 | Val Loss: 0.444110\n",
      "Epoch [300/500] | Train Loss: 0.366476 | Val Loss: 0.468827\n",
      "Epoch [400/500] | Train Loss: 0.315510 | Val Loss: 0.446615\n",
      "Epoch [500/500] | Train Loss: 0.297316 | Val Loss: 0.461920\n",
      "Epoch [100/500] | Train Loss: 0.426078 | Val Loss: 0.467562\n",
      "Epoch [200/500] | Train Loss: 0.396517 | Val Loss: 0.476325\n",
      "Epoch [300/500] | Train Loss: 0.360098 | Val Loss: 0.499115\n",
      "Epoch [400/500] | Train Loss: 0.347108 | Val Loss: 0.499851\n",
      "Epoch [500/500] | Train Loss: 0.320932 | Val Loss: 0.491739\n",
      "Epoch [100/500] | Train Loss: 0.453112 | Val Loss: 0.725624\n",
      "Epoch [200/500] | Train Loss: 0.415017 | Val Loss: 0.811412\n",
      "Epoch [300/500] | Train Loss: 0.352132 | Val Loss: 0.870916\n",
      "Epoch [400/500] | Train Loss: 0.346843 | Val Loss: 0.830386\n",
      "Epoch [500/500] | Train Loss: 0.346262 | Val Loss: 0.838988\n",
      "Epoch [100/500] | Train Loss: 0.502985 | Val Loss: 3.650292\n",
      "Epoch [200/500] | Train Loss: 0.460888 | Val Loss: 4.228155\n",
      "Epoch [300/500] | Train Loss: 0.431971 | Val Loss: 3.968270\n",
      "Epoch [400/500] | Train Loss: 0.428596 | Val Loss: 3.853521\n",
      "Epoch [500/500] | Train Loss: 0.410462 | Val Loss: 3.736823\n",
      "[Year=1988] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.175183 Test MSE=0.828354\n",
      "Year 1988 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.479532 | Val Loss: 0.339748\n",
      "Epoch [200/500] | Train Loss: 0.400324 | Val Loss: 0.389288\n",
      "Epoch [300/500] | Train Loss: 0.368818 | Val Loss: 0.413506\n",
      "Epoch [400/500] | Train Loss: 0.348715 | Val Loss: 0.424417\n",
      "Epoch [500/500] | Train Loss: 0.292322 | Val Loss: 0.432999\n",
      "Epoch [100/500] | Train Loss: 0.419469 | Val Loss: 0.512688\n",
      "Epoch [200/500] | Train Loss: 0.386006 | Val Loss: 0.525045\n",
      "Epoch [300/500] | Train Loss: 0.373811 | Val Loss: 0.536273\n",
      "Epoch [400/500] | Train Loss: 0.342659 | Val Loss: 0.547647\n",
      "Epoch [500/500] | Train Loss: 0.330854 | Val Loss: 0.551072\n",
      "Epoch [100/500] | Train Loss: 0.440253 | Val Loss: 0.782448\n",
      "Epoch [200/500] | Train Loss: 0.422704 | Val Loss: 0.777723\n",
      "Epoch [300/500] | Train Loss: 0.400745 | Val Loss: 0.807864\n",
      "Epoch [400/500] | Train Loss: 0.381767 | Val Loss: 0.855664\n",
      "Epoch [500/500] | Train Loss: 0.363468 | Val Loss: 0.898283\n",
      "Epoch [100/500] | Train Loss: 0.515610 | Val Loss: 3.709996\n",
      "Epoch [200/500] | Train Loss: 0.487645 | Val Loss: 3.698203\n",
      "Epoch [300/500] | Train Loss: 0.474313 | Val Loss: 3.580285\n",
      "Epoch [400/500] | Train Loss: 0.441220 | Val Loss: 3.504992\n",
      "Epoch [500/500] | Train Loss: 0.433222 | Val Loss: 3.498757\n",
      "Epoch [100/500] | Train Loss: 1.064122 | Val Loss: 0.613176\n",
      "Epoch [200/500] | Train Loss: 0.882884 | Val Loss: 0.621531\n",
      "Epoch [300/500] | Train Loss: 0.804043 | Val Loss: 0.627433\n",
      "Epoch [400/500] | Train Loss: 0.704218 | Val Loss: 0.635481\n",
      "Epoch [500/500] | Train Loss: 0.719275 | Val Loss: 0.638022\n",
      "Epoch [100/500] | Train Loss: 0.328361 | Val Loss: 0.412001\n",
      "Epoch [200/500] | Train Loss: 0.239213 | Val Loss: 0.529873\n",
      "Epoch [300/500] | Train Loss: 0.211409 | Val Loss: 0.536007\n",
      "Epoch [400/500] | Train Loss: 0.203634 | Val Loss: 0.524900\n",
      "Epoch [500/500] | Train Loss: 0.209208 | Val Loss: 0.533332\n",
      "Epoch [100/500] | Train Loss: 0.361685 | Val Loss: 0.602803\n",
      "Epoch [200/500] | Train Loss: 0.271376 | Val Loss: 0.617606\n",
      "Epoch [300/500] | Train Loss: 0.225956 | Val Loss: 0.618621\n",
      "Epoch [400/500] | Train Loss: 0.215958 | Val Loss: 0.666512\n",
      "Epoch [500/500] | Train Loss: 0.185016 | Val Loss: 0.670150\n",
      "Epoch [100/500] | Train Loss: 0.383187 | Val Loss: 1.027984\n",
      "Epoch [200/500] | Train Loss: 0.316976 | Val Loss: 0.904078\n",
      "Epoch [300/500] | Train Loss: 0.310154 | Val Loss: 0.933039\n",
      "Epoch [400/500] | Train Loss: 0.281279 | Val Loss: 0.913890\n",
      "Epoch [500/500] | Train Loss: 0.248701 | Val Loss: 0.927053\n",
      "Epoch [100/500] | Train Loss: 0.461649 | Val Loss: 3.206230\n",
      "Epoch [200/500] | Train Loss: 0.423768 | Val Loss: 3.344859\n",
      "Epoch [300/500] | Train Loss: 0.406231 | Val Loss: 3.719710\n",
      "Epoch [400/500] | Train Loss: 0.375047 | Val Loss: 3.508911\n",
      "Epoch [500/500] | Train Loss: 0.372188 | Val Loss: 3.419008\n",
      "Epoch [100/500] | Train Loss: 0.677001 | Val Loss: 0.609736\n",
      "Epoch [200/500] | Train Loss: 0.664618 | Val Loss: 0.627238\n",
      "Epoch [300/500] | Train Loss: 0.542647 | Val Loss: 0.634998\n",
      "Epoch [400/500] | Train Loss: 0.577669 | Val Loss: 0.635987\n",
      "Epoch [500/500] | Train Loss: 0.546646 | Val Loss: 0.657786\n",
      "Epoch [100/500] | Train Loss: 0.515476 | Val Loss: 0.333511\n",
      "Epoch [200/500] | Train Loss: 0.451980 | Val Loss: 0.359780\n",
      "Epoch [300/500] | Train Loss: 0.423024 | Val Loss: 0.375202\n",
      "Epoch [400/500] | Train Loss: 0.408408 | Val Loss: 0.384247\n",
      "Epoch [500/500] | Train Loss: 0.370266 | Val Loss: 0.397968\n",
      "Epoch [100/500] | Train Loss: 0.419901 | Val Loss: 0.507444\n",
      "Epoch [200/500] | Train Loss: 0.403462 | Val Loss: 0.514774\n",
      "Epoch [300/500] | Train Loss: 0.371282 | Val Loss: 0.530759\n",
      "Epoch [400/500] | Train Loss: 0.387476 | Val Loss: 0.550814\n",
      "Epoch [500/500] | Train Loss: 0.354711 | Val Loss: 0.566108\n",
      "Epoch [100/500] | Train Loss: 0.445204 | Val Loss: 0.790675\n",
      "Epoch [200/500] | Train Loss: 0.432254 | Val Loss: 0.792464\n",
      "Epoch [300/500] | Train Loss: 0.440294 | Val Loss: 0.790261\n",
      "Epoch [400/500] | Train Loss: 0.422081 | Val Loss: 0.804587\n",
      "Epoch [500/500] | Train Loss: 0.410665 | Val Loss: 0.848300\n",
      "Epoch [100/500] | Train Loss: 0.522071 | Val Loss: 3.728497\n",
      "Epoch [200/500] | Train Loss: 0.499212 | Val Loss: 3.635439\n",
      "Epoch [300/500] | Train Loss: 0.491225 | Val Loss: 3.546418\n",
      "Epoch [400/500] | Train Loss: 0.484165 | Val Loss: 3.450555\n",
      "Epoch [500/500] | Train Loss: 0.477258 | Val Loss: 3.383664\n",
      "Epoch [100/500] | Train Loss: 1.151952 | Val Loss: 0.604022\n",
      "Epoch [200/500] | Train Loss: 1.064492 | Val Loss: 0.598931\n",
      "Epoch [300/500] | Train Loss: 0.870263 | Val Loss: 0.603880\n",
      "Epoch [400/500] | Train Loss: 0.793091 | Val Loss: 0.617689\n",
      "Epoch [500/500] | Train Loss: 0.859193 | Val Loss: 0.614734\n",
      "Epoch [100/500] | Train Loss: 0.411049 | Val Loss: 0.362870\n",
      "Epoch [200/500] | Train Loss: 0.308759 | Val Loss: 0.392700\n",
      "Epoch [300/500] | Train Loss: 0.285887 | Val Loss: 0.422201\n",
      "Epoch [400/500] | Train Loss: 0.275206 | Val Loss: 0.413482\n",
      "Epoch [500/500] | Train Loss: 0.255185 | Val Loss: 0.429912\n",
      "Epoch [100/500] | Train Loss: 0.345214 | Val Loss: 0.578947\n",
      "Epoch [200/500] | Train Loss: 0.316390 | Val Loss: 0.602927\n",
      "Epoch [300/500] | Train Loss: 0.310273 | Val Loss: 0.612579\n",
      "Epoch [400/500] | Train Loss: 0.289030 | Val Loss: 0.639476\n",
      "Epoch [500/500] | Train Loss: 0.268365 | Val Loss: 0.644009\n",
      "Epoch [100/500] | Train Loss: 0.414301 | Val Loss: 0.764878\n",
      "Epoch [200/500] | Train Loss: 0.367520 | Val Loss: 0.811792\n",
      "Epoch [300/500] | Train Loss: 0.350482 | Val Loss: 0.845913\n",
      "Epoch [400/500] | Train Loss: 0.339141 | Val Loss: 0.864355\n",
      "Epoch [500/500] | Train Loss: 0.337696 | Val Loss: 0.855165\n",
      "Epoch [100/500] | Train Loss: 0.471110 | Val Loss: 3.855279\n",
      "Epoch [200/500] | Train Loss: 0.446780 | Val Loss: 3.665626\n",
      "Epoch [300/500] | Train Loss: 0.439994 | Val Loss: 3.746676\n",
      "Epoch [400/500] | Train Loss: 0.435516 | Val Loss: 3.631388\n",
      "Epoch [500/500] | Train Loss: 0.440281 | Val Loss: 3.644949\n",
      "Epoch [100/500] | Train Loss: 1.018795 | Val Loss: 0.613796\n",
      "Epoch [200/500] | Train Loss: 0.806943 | Val Loss: 0.612210\n",
      "Epoch [300/500] | Train Loss: 0.724103 | Val Loss: 0.618205\n",
      "Epoch [400/500] | Train Loss: 0.783464 | Val Loss: 0.622328\n",
      "Epoch [500/500] | Train Loss: 0.647665 | Val Loss: 0.612392\n",
      "Epoch [100/500] | Train Loss: 0.447995 | Val Loss: 0.357301\n",
      "Epoch [200/500] | Train Loss: 0.372204 | Val Loss: 0.398179\n",
      "Epoch [300/500] | Train Loss: 0.322585 | Val Loss: 0.431813\n",
      "Epoch [400/500] | Train Loss: 0.267403 | Val Loss: 0.441733\n",
      "Epoch [500/500] | Train Loss: 0.264755 | Val Loss: 0.443995\n",
      "Epoch [100/500] | Train Loss: 0.384384 | Val Loss: 0.545100\n",
      "Epoch [200/500] | Train Loss: 0.337911 | Val Loss: 0.615936\n",
      "Epoch [300/500] | Train Loss: 0.315584 | Val Loss: 0.637073\n",
      "Epoch [400/500] | Train Loss: 0.258368 | Val Loss: 0.666158\n",
      "Epoch [500/500] | Train Loss: 0.264629 | Val Loss: 0.680619\n",
      "Epoch [100/500] | Train Loss: 0.437656 | Val Loss: 0.779062\n",
      "Epoch [200/500] | Train Loss: 0.407233 | Val Loss: 0.798559\n",
      "Epoch [300/500] | Train Loss: 0.381317 | Val Loss: 0.929033\n",
      "Epoch [400/500] | Train Loss: 0.338912 | Val Loss: 1.079792\n",
      "Epoch [500/500] | Train Loss: 0.300518 | Val Loss: 1.123736\n",
      "Epoch [100/500] | Train Loss: 0.525804 | Val Loss: 3.715502\n",
      "Epoch [200/500] | Train Loss: 0.488796 | Val Loss: 3.854106\n",
      "Epoch [300/500] | Train Loss: 0.437218 | Val Loss: 4.109270\n",
      "Epoch [400/500] | Train Loss: 0.415737 | Val Loss: 4.200663\n",
      "Epoch [500/500] | Train Loss: 0.377386 | Val Loss: 4.409051\n",
      "Epoch [100/500] | Train Loss: 1.089585 | Val Loss: 0.625147\n",
      "Epoch [200/500] | Train Loss: 0.958040 | Val Loss: 0.644172\n",
      "Epoch [300/500] | Train Loss: 0.809648 | Val Loss: 0.658838\n",
      "Epoch [400/500] | Train Loss: 0.620677 | Val Loss: 0.638985\n",
      "Epoch [500/500] | Train Loss: 0.645339 | Val Loss: 0.653780\n",
      "Epoch [100/500] | Train Loss: 0.373291 | Val Loss: 0.397345\n",
      "Epoch [200/500] | Train Loss: 0.345677 | Val Loss: 0.403556\n",
      "Epoch [300/500] | Train Loss: 0.307466 | Val Loss: 0.428036\n",
      "Epoch [400/500] | Train Loss: 0.290315 | Val Loss: 0.478154\n",
      "Epoch [500/500] | Train Loss: 0.276218 | Val Loss: 0.474106\n",
      "Epoch [100/500] | Train Loss: 0.314524 | Val Loss: 0.618458\n",
      "Epoch [200/500] | Train Loss: 0.239795 | Val Loss: 0.630400\n",
      "Epoch [300/500] | Train Loss: 0.208113 | Val Loss: 0.698840\n",
      "Epoch [400/500] | Train Loss: 0.148485 | Val Loss: 0.717799\n",
      "Epoch [500/500] | Train Loss: 0.157702 | Val Loss: 0.730616\n",
      "Epoch [100/500] | Train Loss: 0.378540 | Val Loss: 1.087044\n",
      "Epoch [200/500] | Train Loss: 0.290659 | Val Loss: 1.264119\n",
      "Epoch [300/500] | Train Loss: 0.241931 | Val Loss: 1.020040\n",
      "Epoch [400/500] | Train Loss: 0.232447 | Val Loss: 0.981270\n",
      "Epoch [500/500] | Train Loss: 0.218471 | Val Loss: 1.054033\n",
      "Epoch [100/500] | Train Loss: 0.465127 | Val Loss: 3.460526\n",
      "Epoch [200/500] | Train Loss: 0.404507 | Val Loss: 3.649106\n",
      "Epoch [300/500] | Train Loss: 0.369709 | Val Loss: 3.769258\n",
      "Epoch [400/500] | Train Loss: 0.328783 | Val Loss: 4.037222\n",
      "Epoch [500/500] | Train Loss: 0.306608 | Val Loss: 4.057991\n",
      "Epoch [100/500] | Train Loss: 0.669228 | Val Loss: 0.605849\n",
      "Epoch [200/500] | Train Loss: 0.630883 | Val Loss: 0.617332\n",
      "Epoch [300/500] | Train Loss: 0.599903 | Val Loss: 0.633405\n",
      "Epoch [400/500] | Train Loss: 0.610297 | Val Loss: 0.625258\n",
      "Epoch [500/500] | Train Loss: 0.590254 | Val Loss: 0.625471\n",
      "Epoch [100/500] | Train Loss: 0.514777 | Val Loss: 0.323137\n",
      "Epoch [200/500] | Train Loss: 0.475706 | Val Loss: 0.334304\n",
      "Epoch [300/500] | Train Loss: 0.460040 | Val Loss: 0.354915\n",
      "Epoch [400/500] | Train Loss: 0.363729 | Val Loss: 0.362629\n",
      "Epoch [500/500] | Train Loss: 0.316422 | Val Loss: 0.378270\n",
      "Epoch [100/500] | Train Loss: 0.414806 | Val Loss: 0.519567\n",
      "Epoch [200/500] | Train Loss: 0.381348 | Val Loss: 0.542517\n",
      "Epoch [300/500] | Train Loss: 0.360223 | Val Loss: 0.560956\n",
      "Epoch [400/500] | Train Loss: 0.356423 | Val Loss: 0.568910\n",
      "Epoch [500/500] | Train Loss: 0.314228 | Val Loss: 0.579184\n",
      "Epoch [100/500] | Train Loss: 0.443013 | Val Loss: 0.789270\n",
      "Epoch [200/500] | Train Loss: 0.425073 | Val Loss: 0.788310\n",
      "Epoch [300/500] | Train Loss: 0.407002 | Val Loss: 0.806042\n",
      "Epoch [400/500] | Train Loss: 0.391816 | Val Loss: 0.837008\n",
      "Epoch [500/500] | Train Loss: 0.367856 | Val Loss: 0.865230\n",
      "Epoch [100/500] | Train Loss: 0.506372 | Val Loss: 3.790557\n",
      "Epoch [200/500] | Train Loss: 0.492281 | Val Loss: 3.826253\n",
      "Epoch [300/500] | Train Loss: 0.472173 | Val Loss: 3.800737\n",
      "Epoch [400/500] | Train Loss: 0.456820 | Val Loss: 3.755737\n",
      "Epoch [500/500] | Train Loss: 0.451036 | Val Loss: 3.841839\n",
      "Epoch [100/500] | Train Loss: 1.102413 | Val Loss: 0.601831\n",
      "Epoch [200/500] | Train Loss: 1.024375 | Val Loss: 0.613503\n",
      "Epoch [300/500] | Train Loss: 0.897168 | Val Loss: 0.615163\n",
      "Epoch [400/500] | Train Loss: 0.879453 | Val Loss: 0.619241\n",
      "Epoch [500/500] | Train Loss: 0.907365 | Val Loss: 0.616212\n",
      "Epoch [100/500] | Train Loss: 0.403082 | Val Loss: 0.420959\n",
      "Epoch [200/500] | Train Loss: 0.308474 | Val Loss: 0.435888\n",
      "Epoch [300/500] | Train Loss: 0.267739 | Val Loss: 0.499341\n",
      "Epoch [400/500] | Train Loss: 0.241269 | Val Loss: 0.506806\n",
      "Epoch [500/500] | Train Loss: 0.225320 | Val Loss: 0.495998\n",
      "Epoch [100/500] | Train Loss: 0.305931 | Val Loss: 0.615784\n",
      "Epoch [200/500] | Train Loss: 0.271917 | Val Loss: 0.646821\n",
      "Epoch [300/500] | Train Loss: 0.249630 | Val Loss: 0.635701\n",
      "Epoch [400/500] | Train Loss: 0.241085 | Val Loss: 0.634063\n",
      "Epoch [500/500] | Train Loss: 0.259141 | Val Loss: 0.653390\n",
      "Epoch [100/500] | Train Loss: 0.394487 | Val Loss: 0.854358\n",
      "Epoch [200/500] | Train Loss: 0.327024 | Val Loss: 0.849661\n",
      "Epoch [300/500] | Train Loss: 0.298943 | Val Loss: 0.814050\n",
      "Epoch [400/500] | Train Loss: 0.247167 | Val Loss: 0.872580\n",
      "Epoch [500/500] | Train Loss: 0.272253 | Val Loss: 0.874435\n",
      "Epoch [100/500] | Train Loss: 0.470563 | Val Loss: 4.062426\n",
      "Epoch [200/500] | Train Loss: 0.432944 | Val Loss: 4.224609\n",
      "Epoch [300/500] | Train Loss: 0.359324 | Val Loss: 4.701302\n",
      "Epoch [400/500] | Train Loss: 0.360251 | Val Loss: 5.170763\n",
      "Epoch [500/500] | Train Loss: 0.355435 | Val Loss: 5.139027\n",
      "Epoch [100/500] | Train Loss: 0.851846 | Val Loss: 0.630413\n",
      "Epoch [200/500] | Train Loss: 0.725766 | Val Loss: 0.650516\n",
      "Epoch [300/500] | Train Loss: 0.836939 | Val Loss: 0.624608\n",
      "Epoch [400/500] | Train Loss: 0.722311 | Val Loss: 0.622988\n",
      "Epoch [500/500] | Train Loss: 0.603534 | Val Loss: 0.647202\n",
      "[Year=1989] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.162155 Test MSE=0.504876\n",
      "Year 1989 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.304200 | Val Loss: 0.555607\n",
      "Epoch [200/500] | Train Loss: 0.265903 | Val Loss: 0.578482\n",
      "Epoch [300/500] | Train Loss: 0.232739 | Val Loss: 0.604911\n",
      "Epoch [400/500] | Train Loss: 0.205346 | Val Loss: 0.629949\n",
      "Epoch [500/500] | Train Loss: 0.195666 | Val Loss: 0.641468\n",
      "Epoch [100/500] | Train Loss: 0.413177 | Val Loss: 0.786999\n",
      "Epoch [200/500] | Train Loss: 0.381291 | Val Loss: 0.798201\n",
      "Epoch [300/500] | Train Loss: 0.351327 | Val Loss: 0.807582\n",
      "Epoch [400/500] | Train Loss: 0.343051 | Val Loss: 0.833838\n",
      "Epoch [500/500] | Train Loss: 0.285649 | Val Loss: 0.870718\n",
      "Epoch [100/500] | Train Loss: 0.521465 | Val Loss: 3.653543\n",
      "Epoch [200/500] | Train Loss: 0.475712 | Val Loss: 3.844665\n",
      "Epoch [300/500] | Train Loss: 0.426861 | Val Loss: 4.044769\n",
      "Epoch [400/500] | Train Loss: 0.411095 | Val Loss: 4.147632\n",
      "Epoch [500/500] | Train Loss: 0.375915 | Val Loss: 4.175153\n",
      "Epoch [100/500] | Train Loss: 1.272915 | Val Loss: 0.523146\n",
      "Epoch [200/500] | Train Loss: 1.059795 | Val Loss: 0.539511\n",
      "Epoch [300/500] | Train Loss: 0.976686 | Val Loss: 0.558747\n",
      "Epoch [400/500] | Train Loss: 0.822313 | Val Loss: 0.572472\n",
      "Epoch [500/500] | Train Loss: 0.783988 | Val Loss: 0.558604\n",
      "Epoch [100/500] | Train Loss: 1.077226 | Val Loss: 0.531855\n",
      "Epoch [200/500] | Train Loss: 0.997990 | Val Loss: 0.561080\n",
      "Epoch [300/500] | Train Loss: 0.802186 | Val Loss: 0.566079\n",
      "Epoch [400/500] | Train Loss: 0.860066 | Val Loss: 0.562381\n",
      "Epoch [500/500] | Train Loss: 0.815029 | Val Loss: 0.542317\n",
      "Epoch [100/500] | Train Loss: 0.184495 | Val Loss: 0.635338\n",
      "Epoch [200/500] | Train Loss: 0.156840 | Val Loss: 0.684295\n",
      "Epoch [300/500] | Train Loss: 0.124779 | Val Loss: 0.733207\n",
      "Epoch [400/500] | Train Loss: 0.119760 | Val Loss: 0.676909\n",
      "Epoch [500/500] | Train Loss: 0.101981 | Val Loss: 0.720974\n",
      "Epoch [100/500] | Train Loss: 0.309865 | Val Loss: 0.894969\n",
      "Epoch [200/500] | Train Loss: 0.245051 | Val Loss: 0.964097\n",
      "Epoch [300/500] | Train Loss: 0.221126 | Val Loss: 0.907169\n",
      "Epoch [400/500] | Train Loss: 0.226478 | Val Loss: 0.905975\n",
      "Epoch [500/500] | Train Loss: 0.197232 | Val Loss: 0.884445\n",
      "Epoch [100/500] | Train Loss: 0.405686 | Val Loss: 4.069545\n",
      "Epoch [200/500] | Train Loss: 0.337152 | Val Loss: 4.302703\n",
      "Epoch [300/500] | Train Loss: 0.295737 | Val Loss: 4.527611\n",
      "Epoch [400/500] | Train Loss: 0.289383 | Val Loss: 4.768257\n",
      "Epoch [500/500] | Train Loss: 0.270232 | Val Loss: 4.126417\n",
      "Epoch [100/500] | Train Loss: 0.776947 | Val Loss: 0.531910\n",
      "Epoch [200/500] | Train Loss: 0.694335 | Val Loss: 0.556280\n",
      "Epoch [300/500] | Train Loss: 0.641305 | Val Loss: 0.553167\n",
      "Epoch [400/500] | Train Loss: 0.610748 | Val Loss: 0.557215\n",
      "Epoch [500/500] | Train Loss: 0.598451 | Val Loss: 0.549611\n",
      "Epoch [100/500] | Train Loss: 0.993073 | Val Loss: 0.537753\n",
      "Epoch [200/500] | Train Loss: 0.624819 | Val Loss: 0.526236\n",
      "Epoch [300/500] | Train Loss: 0.656307 | Val Loss: 0.541697\n",
      "Epoch [400/500] | Train Loss: 0.557550 | Val Loss: 0.544192\n",
      "Epoch [500/500] | Train Loss: 0.835266 | Val Loss: 0.561737\n",
      "Epoch [100/500] | Train Loss: 0.308344 | Val Loss: 0.561363\n",
      "Epoch [200/500] | Train Loss: 0.286787 | Val Loss: 0.571459\n",
      "Epoch [300/500] | Train Loss: 0.273355 | Val Loss: 0.585436\n",
      "Epoch [400/500] | Train Loss: 0.251512 | Val Loss: 0.607344\n",
      "Epoch [500/500] | Train Loss: 0.236696 | Val Loss: 0.626139\n",
      "Epoch [100/500] | Train Loss: 0.461922 | Val Loss: 0.764609\n",
      "Epoch [200/500] | Train Loss: 0.434748 | Val Loss: 0.748867\n",
      "Epoch [300/500] | Train Loss: 0.411812 | Val Loss: 0.741467\n",
      "Epoch [400/500] | Train Loss: 0.412421 | Val Loss: 0.738797\n",
      "Epoch [500/500] | Train Loss: 0.401073 | Val Loss: 0.747550\n",
      "Epoch [100/500] | Train Loss: 0.518779 | Val Loss: 3.768538\n",
      "Epoch [200/500] | Train Loss: 0.502463 | Val Loss: 3.790899\n",
      "Epoch [300/500] | Train Loss: 0.472250 | Val Loss: 3.918862\n",
      "Epoch [400/500] | Train Loss: 0.467569 | Val Loss: 3.934857\n",
      "Epoch [500/500] | Train Loss: 0.447414 | Val Loss: 3.954444\n",
      "Epoch [100/500] | Train Loss: 1.315908 | Val Loss: 0.512014\n",
      "Epoch [200/500] | Train Loss: 1.274077 | Val Loss: 0.515999\n",
      "Epoch [300/500] | Train Loss: 1.072526 | Val Loss: 0.523021\n",
      "Epoch [400/500] | Train Loss: 1.171310 | Val Loss: 0.525371\n",
      "Epoch [500/500] | Train Loss: 0.899242 | Val Loss: 0.516441\n",
      "Epoch [100/500] | Train Loss: 1.131911 | Val Loss: 0.523510\n",
      "Epoch [200/500] | Train Loss: 1.102706 | Val Loss: 0.528257\n",
      "Epoch [300/500] | Train Loss: 0.999568 | Val Loss: 0.538657\n",
      "Epoch [400/500] | Train Loss: 0.954500 | Val Loss: 0.555076\n",
      "Epoch [500/500] | Train Loss: 0.884947 | Val Loss: 0.554788\n",
      "Epoch [100/500] | Train Loss: 0.255124 | Val Loss: 0.631734\n",
      "Epoch [200/500] | Train Loss: 0.210708 | Val Loss: 0.626034\n",
      "Epoch [300/500] | Train Loss: 0.177062 | Val Loss: 0.636634\n",
      "Epoch [400/500] | Train Loss: 0.166979 | Val Loss: 0.621685\n",
      "Epoch [500/500] | Train Loss: 0.178925 | Val Loss: 0.627355\n",
      "Epoch [100/500] | Train Loss: 0.379616 | Val Loss: 0.789303\n",
      "Epoch [200/500] | Train Loss: 0.340577 | Val Loss: 0.819121\n",
      "Epoch [300/500] | Train Loss: 0.319302 | Val Loss: 0.860657\n",
      "Epoch [400/500] | Train Loss: 0.313578 | Val Loss: 0.859667\n",
      "Epoch [500/500] | Train Loss: 0.282924 | Val Loss: 0.839694\n",
      "Epoch [100/500] | Train Loss: 0.471694 | Val Loss: 3.846042\n",
      "Epoch [200/500] | Train Loss: 0.423891 | Val Loss: 3.761892\n",
      "Epoch [300/500] | Train Loss: 0.437120 | Val Loss: 3.550586\n",
      "Epoch [400/500] | Train Loss: 0.429020 | Val Loss: 3.969394\n",
      "Epoch [500/500] | Train Loss: 0.417845 | Val Loss: 3.914737\n",
      "Epoch [100/500] | Train Loss: 1.206683 | Val Loss: 0.515607\n",
      "Epoch [200/500] | Train Loss: 0.753685 | Val Loss: 0.532104\n",
      "Epoch [300/500] | Train Loss: 0.884328 | Val Loss: 0.547236\n",
      "Epoch [400/500] | Train Loss: 0.777595 | Val Loss: 0.543717\n",
      "Epoch [500/500] | Train Loss: 0.833736 | Val Loss: 0.587070\n",
      "Epoch [100/500] | Train Loss: 1.064801 | Val Loss: 0.576849\n",
      "Epoch [200/500] | Train Loss: 0.698204 | Val Loss: 0.538653\n",
      "Epoch [300/500] | Train Loss: 0.725914 | Val Loss: 0.560730\n",
      "Epoch [400/500] | Train Loss: 0.807680 | Val Loss: 0.551961\n",
      "Epoch [500/500] | Train Loss: 0.689430 | Val Loss: 0.545810\n",
      "Epoch [100/500] | Train Loss: 0.300004 | Val Loss: 0.558766\n",
      "Epoch [200/500] | Train Loss: 0.230331 | Val Loss: 0.613035\n",
      "Epoch [300/500] | Train Loss: 0.216562 | Val Loss: 0.660682\n",
      "Epoch [400/500] | Train Loss: 0.170489 | Val Loss: 0.672175\n",
      "Epoch [500/500] | Train Loss: 0.143452 | Val Loss: 0.672224\n",
      "Epoch [100/500] | Train Loss: 0.395582 | Val Loss: 0.766983\n",
      "Epoch [200/500] | Train Loss: 0.372683 | Val Loss: 0.784270\n",
      "Epoch [300/500] | Train Loss: 0.317088 | Val Loss: 0.820885\n",
      "Epoch [400/500] | Train Loss: 0.289469 | Val Loss: 0.836246\n",
      "Epoch [500/500] | Train Loss: 0.245893 | Val Loss: 0.866229\n",
      "Epoch [100/500] | Train Loss: 0.495031 | Val Loss: 3.668705\n",
      "Epoch [200/500] | Train Loss: 0.440923 | Val Loss: 4.051406\n",
      "Epoch [300/500] | Train Loss: 0.409589 | Val Loss: 3.882406\n",
      "Epoch [400/500] | Train Loss: 0.376808 | Val Loss: 3.756211\n",
      "Epoch [500/500] | Train Loss: 0.357248 | Val Loss: 3.658537\n",
      "Epoch [100/500] | Train Loss: 1.231511 | Val Loss: 0.536771\n",
      "Epoch [200/500] | Train Loss: 1.097537 | Val Loss: 0.523851\n",
      "Epoch [300/500] | Train Loss: 1.197426 | Val Loss: 0.557802\n",
      "Epoch [400/500] | Train Loss: 0.764273 | Val Loss: 0.543128\n",
      "Epoch [500/500] | Train Loss: 0.731300 | Val Loss: 0.547319\n",
      "Epoch [100/500] | Train Loss: 1.017869 | Val Loss: 0.534204\n",
      "Epoch [200/500] | Train Loss: 0.758656 | Val Loss: 0.564345\n",
      "Epoch [300/500] | Train Loss: 0.710967 | Val Loss: 0.547096\n",
      "Epoch [400/500] | Train Loss: 0.720484 | Val Loss: 0.537435\n",
      "Epoch [500/500] | Train Loss: 0.675523 | Val Loss: 0.540607\n",
      "Epoch [100/500] | Train Loss: 0.158659 | Val Loss: 0.699299\n",
      "Epoch [200/500] | Train Loss: 0.105403 | Val Loss: 0.696882\n",
      "Epoch [300/500] | Train Loss: 0.087813 | Val Loss: 0.664826\n",
      "Epoch [400/500] | Train Loss: 0.073836 | Val Loss: 0.713957\n",
      "Epoch [500/500] | Train Loss: 0.080352 | Val Loss: 0.737853\n",
      "Epoch [100/500] | Train Loss: 0.264795 | Val Loss: 0.899643\n",
      "Epoch [200/500] | Train Loss: 0.200368 | Val Loss: 0.960024\n",
      "Epoch [300/500] | Train Loss: 0.153968 | Val Loss: 0.988324\n",
      "Epoch [400/500] | Train Loss: 0.143695 | Val Loss: 0.967975\n",
      "Epoch [500/500] | Train Loss: 0.168442 | Val Loss: 0.987536\n",
      "Epoch [100/500] | Train Loss: 0.397386 | Val Loss: 5.045282\n",
      "Epoch [200/500] | Train Loss: 0.314833 | Val Loss: 5.419966\n",
      "Epoch [300/500] | Train Loss: 0.283785 | Val Loss: 5.895872\n",
      "Epoch [400/500] | Train Loss: 0.259823 | Val Loss: 5.708876\n",
      "Epoch [500/500] | Train Loss: 0.252235 | Val Loss: 5.036415\n",
      "Epoch [100/500] | Train Loss: 0.782489 | Val Loss: 0.524140\n",
      "Epoch [200/500] | Train Loss: 0.641644 | Val Loss: 0.541851\n",
      "Epoch [300/500] | Train Loss: 0.635625 | Val Loss: 0.571174\n",
      "Epoch [400/500] | Train Loss: 0.604600 | Val Loss: 0.605712\n",
      "Epoch [500/500] | Train Loss: 0.691890 | Val Loss: 0.612432\n",
      "Epoch [100/500] | Train Loss: 0.677041 | Val Loss: 0.542404\n",
      "Epoch [200/500] | Train Loss: 0.649044 | Val Loss: 0.562940\n",
      "Epoch [300/500] | Train Loss: 0.637929 | Val Loss: 0.574043\n",
      "Epoch [400/500] | Train Loss: 0.551614 | Val Loss: 0.573050\n",
      "Epoch [500/500] | Train Loss: 0.546331 | Val Loss: 0.566686\n",
      "Epoch [100/500] | Train Loss: 0.277942 | Val Loss: 0.552775\n",
      "Epoch [200/500] | Train Loss: 0.266597 | Val Loss: 0.583241\n",
      "Epoch [300/500] | Train Loss: 0.229387 | Val Loss: 0.630297\n",
      "Epoch [400/500] | Train Loss: 0.195850 | Val Loss: 0.661617\n",
      "Epoch [500/500] | Train Loss: 0.179275 | Val Loss: 0.657911\n",
      "Epoch [100/500] | Train Loss: 0.406628 | Val Loss: 0.777683\n",
      "Epoch [200/500] | Train Loss: 0.380142 | Val Loss: 0.777146\n",
      "Epoch [300/500] | Train Loss: 0.358746 | Val Loss: 0.792589\n",
      "Epoch [400/500] | Train Loss: 0.354569 | Val Loss: 0.825672\n",
      "Epoch [500/500] | Train Loss: 0.335259 | Val Loss: 0.850935\n",
      "Epoch [100/500] | Train Loss: 0.536917 | Val Loss: 3.800108\n",
      "Epoch [200/500] | Train Loss: 0.500010 | Val Loss: 3.779877\n",
      "Epoch [300/500] | Train Loss: 0.466892 | Val Loss: 3.904660\n",
      "Epoch [400/500] | Train Loss: 0.469441 | Val Loss: 4.025223\n",
      "Epoch [500/500] | Train Loss: 0.454024 | Val Loss: 4.070163\n",
      "Epoch [100/500] | Train Loss: 1.240758 | Val Loss: 0.493406\n",
      "Epoch [200/500] | Train Loss: 1.210600 | Val Loss: 0.498088\n",
      "Epoch [300/500] | Train Loss: 0.907605 | Val Loss: 0.500967\n",
      "Epoch [400/500] | Train Loss: 0.931094 | Val Loss: 0.502487\n",
      "Epoch [500/500] | Train Loss: 0.878967 | Val Loss: 0.503798\n",
      "Epoch [100/500] | Train Loss: 1.130702 | Val Loss: 0.532260\n",
      "Epoch [200/500] | Train Loss: 0.962779 | Val Loss: 0.543534\n",
      "Epoch [300/500] | Train Loss: 0.974816 | Val Loss: 0.540061\n",
      "Epoch [400/500] | Train Loss: 0.761226 | Val Loss: 0.523450\n",
      "Epoch [500/500] | Train Loss: 0.783945 | Val Loss: 0.515737\n",
      "Epoch [100/500] | Train Loss: 0.255706 | Val Loss: 0.602590\n",
      "Epoch [200/500] | Train Loss: 0.199602 | Val Loss: 0.662525\n",
      "Epoch [300/500] | Train Loss: 0.138796 | Val Loss: 0.687203\n",
      "Epoch [400/500] | Train Loss: 0.147664 | Val Loss: 0.658787\n",
      "Epoch [500/500] | Train Loss: 0.136858 | Val Loss: 0.657845\n",
      "Epoch [100/500] | Train Loss: 0.351895 | Val Loss: 0.823753\n",
      "Epoch [200/500] | Train Loss: 0.296560 | Val Loss: 0.891913\n",
      "Epoch [300/500] | Train Loss: 0.264990 | Val Loss: 0.838513\n",
      "Epoch [400/500] | Train Loss: 0.268701 | Val Loss: 0.855274\n",
      "Epoch [500/500] | Train Loss: 0.272128 | Val Loss: 0.861438\n",
      "Epoch [100/500] | Train Loss: 0.437464 | Val Loss: 4.179451\n",
      "Epoch [200/500] | Train Loss: 0.412435 | Val Loss: 4.120995\n",
      "Epoch [300/500] | Train Loss: 0.389245 | Val Loss: 4.175207\n",
      "Epoch [400/500] | Train Loss: 0.353059 | Val Loss: 4.133049\n",
      "Epoch [500/500] | Train Loss: 0.344590 | Val Loss: 4.359638\n",
      "Epoch [100/500] | Train Loss: 0.765781 | Val Loss: 0.510083\n",
      "Epoch [200/500] | Train Loss: 0.754834 | Val Loss: 0.534170\n",
      "Epoch [300/500] | Train Loss: 0.754635 | Val Loss: 0.541685\n",
      "Epoch [400/500] | Train Loss: 0.627408 | Val Loss: 0.533933\n",
      "Epoch [500/500] | Train Loss: 0.603510 | Val Loss: 0.556620\n",
      "Epoch [100/500] | Train Loss: 0.970095 | Val Loss: 0.527371\n",
      "Epoch [200/500] | Train Loss: 0.779843 | Val Loss: 0.520959\n",
      "Epoch [300/500] | Train Loss: 0.722731 | Val Loss: 0.540235\n",
      "Epoch [400/500] | Train Loss: 0.785302 | Val Loss: 0.533813\n",
      "Epoch [500/500] | Train Loss: 0.654476 | Val Loss: 0.543549\n",
      "[Year=1990] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.1, 'learning_rate': 0.001} CV-MSE=1.256983 Test MSE=1.304220\n",
      "Year 1990 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.606437 | Val Loss: 0.692063\n",
      "Epoch [200/500] | Train Loss: 0.572705 | Val Loss: 0.713501\n",
      "Epoch [300/500] | Train Loss: 0.462227 | Val Loss: 0.795119\n",
      "Epoch [400/500] | Train Loss: 0.447194 | Val Loss: 0.823240\n",
      "Epoch [500/500] | Train Loss: 0.409942 | Val Loss: 0.847954\n",
      "Epoch [100/500] | Train Loss: 0.635409 | Val Loss: 3.957374\n",
      "Epoch [200/500] | Train Loss: 0.573928 | Val Loss: 4.052905\n",
      "Epoch [300/500] | Train Loss: 0.573463 | Val Loss: 4.236373\n",
      "Epoch [400/500] | Train Loss: 0.539935 | Val Loss: 4.514399\n",
      "Epoch [500/500] | Train Loss: 0.476974 | Val Loss: 4.731562\n",
      "Epoch [100/500] | Train Loss: 1.496334 | Val Loss: 0.437371\n",
      "Epoch [200/500] | Train Loss: 1.373903 | Val Loss: 0.429502\n",
      "Epoch [300/500] | Train Loss: 1.001851 | Val Loss: 0.413280\n",
      "Epoch [400/500] | Train Loss: 0.901771 | Val Loss: 0.409854\n",
      "Epoch [500/500] | Train Loss: 0.895123 | Val Loss: 0.410500\n",
      "Epoch [100/500] | Train Loss: 1.270457 | Val Loss: 0.634475\n",
      "Epoch [200/500] | Train Loss: 1.096612 | Val Loss: 0.655140\n",
      "Epoch [300/500] | Train Loss: 1.053604 | Val Loss: 0.653622\n",
      "Epoch [400/500] | Train Loss: 1.010471 | Val Loss: 0.671226\n",
      "Epoch [500/500] | Train Loss: 0.781680 | Val Loss: 0.673444\n",
      "Epoch [100/500] | Train Loss: 1.115020 | Val Loss: 0.931416\n",
      "Epoch [200/500] | Train Loss: 1.059546 | Val Loss: 1.032227\n",
      "Epoch [300/500] | Train Loss: 0.839319 | Val Loss: 1.147972\n",
      "Epoch [400/500] | Train Loss: 0.765036 | Val Loss: 1.205416\n",
      "Epoch [500/500] | Train Loss: 0.788146 | Val Loss: 1.225329\n",
      "Epoch [100/500] | Train Loss: 0.330813 | Val Loss: 0.790679\n",
      "Epoch [200/500] | Train Loss: 0.240773 | Val Loss: 0.859998\n",
      "Epoch [300/500] | Train Loss: 0.222868 | Val Loss: 0.820745\n",
      "Epoch [400/500] | Train Loss: 0.180956 | Val Loss: 0.874459\n",
      "Epoch [500/500] | Train Loss: 0.148496 | Val Loss: 0.820577\n",
      "Epoch [100/500] | Train Loss: 0.452345 | Val Loss: 4.165219\n",
      "Epoch [200/500] | Train Loss: 0.322610 | Val Loss: 4.175007\n",
      "Epoch [300/500] | Train Loss: 0.323701 | Val Loss: 4.076628\n",
      "Epoch [400/500] | Train Loss: 0.246504 | Val Loss: 4.130554\n",
      "Epoch [500/500] | Train Loss: 0.285254 | Val Loss: 4.139038\n",
      "Epoch [100/500] | Train Loss: 0.974889 | Val Loss: 0.419265\n",
      "Epoch [200/500] | Train Loss: 0.974731 | Val Loss: 0.429769\n",
      "Epoch [300/500] | Train Loss: 0.758376 | Val Loss: 0.447776\n",
      "Epoch [400/500] | Train Loss: 0.843804 | Val Loss: 0.429376\n",
      "Epoch [500/500] | Train Loss: 0.730897 | Val Loss: 0.451895\n",
      "Epoch [100/500] | Train Loss: 0.845494 | Val Loss: 0.635175\n",
      "Epoch [200/500] | Train Loss: 0.765644 | Val Loss: 0.621738\n",
      "Epoch [300/500] | Train Loss: 0.648967 | Val Loss: 0.657928\n",
      "Epoch [400/500] | Train Loss: 0.664319 | Val Loss: 0.668410\n",
      "Epoch [500/500] | Train Loss: 0.915956 | Val Loss: 0.705679\n",
      "Epoch [100/500] | Train Loss: 0.755985 | Val Loss: 1.254507\n",
      "Epoch [200/500] | Train Loss: 0.658818 | Val Loss: 1.137398\n",
      "Epoch [300/500] | Train Loss: 0.634000 | Val Loss: 1.070331\n",
      "Epoch [400/500] | Train Loss: 0.659778 | Val Loss: 1.200343\n",
      "Epoch [500/500] | Train Loss: 0.565793 | Val Loss: 1.178109\n",
      "Epoch [100/500] | Train Loss: 0.614188 | Val Loss: 0.684557\n",
      "Epoch [200/500] | Train Loss: 0.574778 | Val Loss: 0.676367\n",
      "Epoch [300/500] | Train Loss: 0.533185 | Val Loss: 0.685447\n",
      "Epoch [400/500] | Train Loss: 0.468672 | Val Loss: 0.699282\n",
      "Epoch [500/500] | Train Loss: 0.439698 | Val Loss: 0.716698\n",
      "Epoch [100/500] | Train Loss: 0.682146 | Val Loss: 4.015152\n",
      "Epoch [200/500] | Train Loss: 0.621023 | Val Loss: 3.928705\n",
      "Epoch [300/500] | Train Loss: 0.599901 | Val Loss: 3.959558\n",
      "Epoch [400/500] | Train Loss: 0.599135 | Val Loss: 3.783725\n",
      "Epoch [500/500] | Train Loss: 0.578761 | Val Loss: 3.799003\n",
      "Epoch [100/500] | Train Loss: 1.696138 | Val Loss: 0.406772\n",
      "Epoch [200/500] | Train Loss: 1.572090 | Val Loss: 0.422001\n",
      "Epoch [300/500] | Train Loss: 1.339462 | Val Loss: 0.416243\n",
      "Epoch [400/500] | Train Loss: 1.439762 | Val Loss: 0.417529\n",
      "Epoch [500/500] | Train Loss: 1.285905 | Val Loss: 0.418675\n",
      "Epoch [100/500] | Train Loss: 1.324592 | Val Loss: 0.619226\n",
      "Epoch [200/500] | Train Loss: 1.182672 | Val Loss: 0.657498\n",
      "Epoch [300/500] | Train Loss: 1.089921 | Val Loss: 0.626841\n",
      "Epoch [400/500] | Train Loss: 1.032511 | Val Loss: 0.625091\n",
      "Epoch [500/500] | Train Loss: 0.874397 | Val Loss: 0.609847\n",
      "Epoch [100/500] | Train Loss: 1.191412 | Val Loss: 0.905901\n",
      "Epoch [200/500] | Train Loss: 1.186228 | Val Loss: 0.905847\n",
      "Epoch [300/500] | Train Loss: 1.130429 | Val Loss: 0.931767\n",
      "Epoch [400/500] | Train Loss: 1.015832 | Val Loss: 0.991406\n",
      "Epoch [500/500] | Train Loss: 1.058189 | Val Loss: 1.141690\n",
      "Epoch [100/500] | Train Loss: 0.480448 | Val Loss: 0.712953\n",
      "Epoch [200/500] | Train Loss: 0.461202 | Val Loss: 0.723988\n",
      "Epoch [300/500] | Train Loss: 0.381716 | Val Loss: 0.726412\n",
      "Epoch [400/500] | Train Loss: 0.459000 | Val Loss: 0.758997\n",
      "Epoch [500/500] | Train Loss: 0.298191 | Val Loss: 0.785013\n",
      "Epoch [100/500] | Train Loss: 0.588739 | Val Loss: 4.043342\n",
      "Epoch [200/500] | Train Loss: 0.486061 | Val Loss: 3.950356\n",
      "Epoch [300/500] | Train Loss: 0.470022 | Val Loss: 4.049147\n",
      "Epoch [400/500] | Train Loss: 0.448519 | Val Loss: 4.102335\n",
      "Epoch [500/500] | Train Loss: 0.436589 | Val Loss: 4.125516\n",
      "Epoch [100/500] | Train Loss: 1.212617 | Val Loss: 0.410841\n",
      "Epoch [200/500] | Train Loss: 1.026020 | Val Loss: 0.408374\n",
      "Epoch [300/500] | Train Loss: 0.973662 | Val Loss: 0.413268\n",
      "Epoch [400/500] | Train Loss: 0.882070 | Val Loss: 0.414397\n",
      "Epoch [500/500] | Train Loss: 1.102642 | Val Loss: 0.412071\n",
      "Epoch [100/500] | Train Loss: 1.103922 | Val Loss: 0.608087\n",
      "Epoch [200/500] | Train Loss: 0.901910 | Val Loss: 0.613991\n",
      "Epoch [300/500] | Train Loss: 0.844075 | Val Loss: 0.607342\n",
      "Epoch [400/500] | Train Loss: 0.823934 | Val Loss: 0.615524\n",
      "Epoch [500/500] | Train Loss: 1.042605 | Val Loss: 0.607840\n",
      "Epoch [100/500] | Train Loss: 1.103742 | Val Loss: 0.916404\n",
      "Epoch [200/500] | Train Loss: 1.086209 | Val Loss: 1.235969\n",
      "Epoch [300/500] | Train Loss: 0.888778 | Val Loss: 1.083621\n",
      "Epoch [400/500] | Train Loss: 0.800474 | Val Loss: 1.198855\n",
      "Epoch [500/500] | Train Loss: 0.769509 | Val Loss: 1.206503\n",
      "Epoch [100/500] | Train Loss: 0.610461 | Val Loss: 0.689937\n",
      "Epoch [200/500] | Train Loss: 0.477733 | Val Loss: 0.755148\n",
      "Epoch [300/500] | Train Loss: 0.406967 | Val Loss: 0.833163\n",
      "Epoch [400/500] | Train Loss: 0.274520 | Val Loss: 0.879709\n",
      "Epoch [500/500] | Train Loss: 0.271746 | Val Loss: 0.923199\n",
      "Epoch [100/500] | Train Loss: 0.615240 | Val Loss: 3.937181\n",
      "Epoch [200/500] | Train Loss: 0.578964 | Val Loss: 4.064662\n",
      "Epoch [300/500] | Train Loss: 0.495239 | Val Loss: 4.272991\n",
      "Epoch [400/500] | Train Loss: 0.449054 | Val Loss: 4.253679\n",
      "Epoch [500/500] | Train Loss: 0.395676 | Val Loss: 4.378372\n",
      "Epoch [100/500] | Train Loss: 1.492658 | Val Loss: 0.430438\n",
      "Epoch [200/500] | Train Loss: 1.219584 | Val Loss: 0.433778\n",
      "Epoch [300/500] | Train Loss: 1.109914 | Val Loss: 0.434000\n",
      "Epoch [400/500] | Train Loss: 1.039313 | Val Loss: 0.424643\n",
      "Epoch [500/500] | Train Loss: 0.928231 | Val Loss: 0.428487\n",
      "Epoch [100/500] | Train Loss: 1.206939 | Val Loss: 0.635980\n",
      "Epoch [200/500] | Train Loss: 0.935993 | Val Loss: 0.643297\n",
      "Epoch [300/500] | Train Loss: 0.807027 | Val Loss: 0.634426\n",
      "Epoch [400/500] | Train Loss: 0.822217 | Val Loss: 0.635052\n",
      "Epoch [500/500] | Train Loss: 0.702299 | Val Loss: 0.634577\n",
      "Epoch [100/500] | Train Loss: 1.051295 | Val Loss: 0.911581\n",
      "Epoch [200/500] | Train Loss: 1.047556 | Val Loss: 0.973550\n",
      "Epoch [300/500] | Train Loss: 0.764889 | Val Loss: 1.236663\n",
      "Epoch [400/500] | Train Loss: 0.780624 | Val Loss: 1.316028\n",
      "Epoch [500/500] | Train Loss: 0.720314 | Val Loss: 1.282969\n",
      "Epoch [100/500] | Train Loss: 0.386387 | Val Loss: 0.718040\n",
      "Epoch [200/500] | Train Loss: 0.262021 | Val Loss: 0.847615\n",
      "Epoch [300/500] | Train Loss: 0.198804 | Val Loss: 0.867873\n",
      "Epoch [400/500] | Train Loss: 0.185321 | Val Loss: 0.901312\n",
      "Epoch [500/500] | Train Loss: 0.227305 | Val Loss: 0.875882\n",
      "Epoch [100/500] | Train Loss: 0.469702 | Val Loss: 4.473271\n",
      "Epoch [200/500] | Train Loss: 0.337858 | Val Loss: 4.415728\n",
      "Epoch [300/500] | Train Loss: 0.333105 | Val Loss: 4.399013\n",
      "Epoch [400/500] | Train Loss: 0.285407 | Val Loss: 4.260452\n",
      "Epoch [500/500] | Train Loss: 0.291376 | Val Loss: 4.298364\n",
      "Epoch [100/500] | Train Loss: 0.808054 | Val Loss: 0.426595\n",
      "Epoch [200/500] | Train Loss: 0.756334 | Val Loss: 0.430694\n",
      "Epoch [300/500] | Train Loss: 0.738073 | Val Loss: 0.432387\n",
      "Epoch [400/500] | Train Loss: 0.869887 | Val Loss: 0.435107\n",
      "Epoch [500/500] | Train Loss: 0.720699 | Val Loss: 0.472262\n",
      "Epoch [100/500] | Train Loss: 0.772300 | Val Loss: 0.636203\n",
      "Epoch [200/500] | Train Loss: 0.629749 | Val Loss: 0.630356\n",
      "Epoch [300/500] | Train Loss: 0.644312 | Val Loss: 0.655628\n",
      "Epoch [400/500] | Train Loss: 0.587551 | Val Loss: 0.695856\n",
      "Epoch [500/500] | Train Loss: 0.622610 | Val Loss: 0.700671\n",
      "Epoch [100/500] | Train Loss: 0.740368 | Val Loss: 1.572937\n",
      "Epoch [200/500] | Train Loss: 0.670183 | Val Loss: 1.552716\n",
      "Epoch [300/500] | Train Loss: 0.662747 | Val Loss: 1.701883\n",
      "Epoch [400/500] | Train Loss: 0.631618 | Val Loss: 1.403073\n",
      "Epoch [500/500] | Train Loss: 0.628659 | Val Loss: 1.404993\n",
      "Epoch [100/500] | Train Loss: 0.601565 | Val Loss: 0.681176\n",
      "Epoch [200/500] | Train Loss: 0.564019 | Val Loss: 0.682019\n",
      "Epoch [300/500] | Train Loss: 0.483914 | Val Loss: 0.718373\n",
      "Epoch [400/500] | Train Loss: 0.467639 | Val Loss: 0.750454\n",
      "Epoch [500/500] | Train Loss: 0.433204 | Val Loss: 0.765296\n",
      "Epoch [100/500] | Train Loss: 0.655790 | Val Loss: 3.873987\n",
      "Epoch [200/500] | Train Loss: 0.577689 | Val Loss: 3.862024\n",
      "Epoch [300/500] | Train Loss: 0.548020 | Val Loss: 3.907858\n",
      "Epoch [400/500] | Train Loss: 0.532835 | Val Loss: 3.959032\n",
      "Epoch [500/500] | Train Loss: 0.554086 | Val Loss: 3.948743\n",
      "Epoch [100/500] | Train Loss: 1.678554 | Val Loss: 0.413689\n",
      "Epoch [200/500] | Train Loss: 1.434502 | Val Loss: 0.417854\n",
      "Epoch [300/500] | Train Loss: 1.480369 | Val Loss: 0.414823\n",
      "Epoch [400/500] | Train Loss: 1.103982 | Val Loss: 0.417409\n",
      "Epoch [500/500] | Train Loss: 1.408953 | Val Loss: 0.410152\n",
      "Epoch [100/500] | Train Loss: 1.308784 | Val Loss: 0.616513\n",
      "Epoch [200/500] | Train Loss: 1.166793 | Val Loss: 0.645616\n",
      "Epoch [300/500] | Train Loss: 0.963523 | Val Loss: 0.639077\n",
      "Epoch [400/500] | Train Loss: 0.871852 | Val Loss: 0.627827\n",
      "Epoch [500/500] | Train Loss: 0.839604 | Val Loss: 0.619579\n",
      "Epoch [100/500] | Train Loss: 1.159511 | Val Loss: 0.916724\n",
      "Epoch [200/500] | Train Loss: 1.070411 | Val Loss: 0.961861\n",
      "Epoch [300/500] | Train Loss: 0.901571 | Val Loss: 1.142612\n",
      "Epoch [400/500] | Train Loss: 0.878060 | Val Loss: 1.171336\n",
      "Epoch [500/500] | Train Loss: 0.810863 | Val Loss: 1.157583\n",
      "Epoch [100/500] | Train Loss: 0.523021 | Val Loss: 0.694362\n",
      "Epoch [200/500] | Train Loss: 0.506733 | Val Loss: 0.717352\n",
      "Epoch [300/500] | Train Loss: 0.410668 | Val Loss: 0.738653\n",
      "Epoch [400/500] | Train Loss: 0.458799 | Val Loss: 0.739888\n",
      "Epoch [500/500] | Train Loss: 0.413478 | Val Loss: 0.796717\n",
      "Epoch [100/500] | Train Loss: 0.508167 | Val Loss: 3.948620\n",
      "Epoch [200/500] | Train Loss: 0.451341 | Val Loss: 3.881174\n",
      "Epoch [300/500] | Train Loss: 0.396355 | Val Loss: 4.005284\n",
      "Epoch [400/500] | Train Loss: 0.416048 | Val Loss: 3.859093\n",
      "Epoch [500/500] | Train Loss: 0.391569 | Val Loss: 4.037104\n",
      "Epoch [100/500] | Train Loss: 1.019093 | Val Loss: 0.409962\n",
      "Epoch [200/500] | Train Loss: 0.922701 | Val Loss: 0.431410\n",
      "Epoch [300/500] | Train Loss: 0.945001 | Val Loss: 0.418944\n",
      "Epoch [400/500] | Train Loss: 0.842256 | Val Loss: 0.443437\n",
      "Epoch [500/500] | Train Loss: 0.815771 | Val Loss: 0.477914\n",
      "Epoch [100/500] | Train Loss: 0.837723 | Val Loss: 0.621611\n",
      "Epoch [200/500] | Train Loss: 0.864532 | Val Loss: 0.599728\n",
      "Epoch [300/500] | Train Loss: 0.922892 | Val Loss: 0.609831\n",
      "Epoch [400/500] | Train Loss: 0.933755 | Val Loss: 0.626183\n",
      "Epoch [500/500] | Train Loss: 0.669754 | Val Loss: 0.632117\n",
      "Epoch [100/500] | Train Loss: 0.774166 | Val Loss: 1.751618\n",
      "Epoch [200/500] | Train Loss: 0.788223 | Val Loss: 1.109899\n",
      "Epoch [300/500] | Train Loss: 0.702852 | Val Loss: 1.175853\n",
      "Epoch [400/500] | Train Loss: 0.749381 | Val Loss: 1.226630\n",
      "Epoch [500/500] | Train Loss: 0.669388 | Val Loss: 1.487808\n",
      "[Year=1991] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.337183 Test MSE=0.708454\n",
      "Year 1991 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 2.725742 | Val Loss: 1.354229\n",
      "Epoch [200/500] | Train Loss: 2.480043 | Val Loss: 1.448077\n",
      "Epoch [300/500] | Train Loss: 1.990329 | Val Loss: 1.555391\n",
      "Epoch [400/500] | Train Loss: 1.448490 | Val Loss: 1.620718\n",
      "Epoch [500/500] | Train Loss: 1.263558 | Val Loss: 1.785424\n",
      "Epoch [100/500] | Train Loss: 2.050548 | Val Loss: 0.383653\n",
      "Epoch [200/500] | Train Loss: 1.608063 | Val Loss: 0.398453\n",
      "Epoch [300/500] | Train Loss: 1.908174 | Val Loss: 0.403503\n",
      "Epoch [400/500] | Train Loss: 1.207261 | Val Loss: 0.397547\n",
      "Epoch [500/500] | Train Loss: 1.187904 | Val Loss: 0.390187\n",
      "Epoch [100/500] | Train Loss: 1.448918 | Val Loss: 0.612332\n",
      "Epoch [200/500] | Train Loss: 1.318623 | Val Loss: 0.628590\n",
      "Epoch [300/500] | Train Loss: 0.999737 | Val Loss: 0.632089\n",
      "Epoch [400/500] | Train Loss: 0.934996 | Val Loss: 0.628592\n",
      "Epoch [500/500] | Train Loss: 0.976823 | Val Loss: 0.633096\n",
      "Epoch [100/500] | Train Loss: 1.300339 | Val Loss: 1.047815\n",
      "Epoch [200/500] | Train Loss: 1.107457 | Val Loss: 1.086650\n",
      "Epoch [300/500] | Train Loss: 1.011683 | Val Loss: 1.142775\n",
      "Epoch [400/500] | Train Loss: 0.884448 | Val Loss: 1.261709\n",
      "Epoch [500/500] | Train Loss: 0.779082 | Val Loss: 1.454278\n",
      "Epoch [100/500] | Train Loss: 1.203726 | Val Loss: 0.613902\n",
      "Epoch [200/500] | Train Loss: 1.086849 | Val Loss: 0.604597\n",
      "Epoch [300/500] | Train Loss: 1.059752 | Val Loss: 0.600560\n",
      "Epoch [400/500] | Train Loss: 0.996752 | Val Loss: 0.604283\n",
      "Epoch [500/500] | Train Loss: 0.902406 | Val Loss: 0.609411\n",
      "Epoch [100/500] | Train Loss: 1.623576 | Val Loss: 1.490295\n",
      "Epoch [200/500] | Train Loss: 1.144893 | Val Loss: 1.633789\n",
      "Epoch [300/500] | Train Loss: 0.595651 | Val Loss: 1.775353\n",
      "Epoch [400/500] | Train Loss: 0.869956 | Val Loss: 1.640444\n",
      "Epoch [500/500] | Train Loss: 0.536366 | Val Loss: 1.787935\n",
      "Epoch [100/500] | Train Loss: 1.197768 | Val Loss: 0.407712\n",
      "Epoch [200/500] | Train Loss: 0.860783 | Val Loss: 0.403911\n",
      "Epoch [300/500] | Train Loss: 0.856789 | Val Loss: 0.410288\n",
      "Epoch [400/500] | Train Loss: 0.981164 | Val Loss: 0.436003\n",
      "Epoch [500/500] | Train Loss: 0.773501 | Val Loss: 0.468405\n",
      "Epoch [100/500] | Train Loss: 0.865616 | Val Loss: 0.629730\n",
      "Epoch [200/500] | Train Loss: 0.718944 | Val Loss: 0.637850\n",
      "Epoch [300/500] | Train Loss: 0.655919 | Val Loss: 0.648877\n",
      "Epoch [400/500] | Train Loss: 0.737681 | Val Loss: 0.686995\n",
      "Epoch [500/500] | Train Loss: 0.594971 | Val Loss: 0.675342\n",
      "Epoch [100/500] | Train Loss: 0.831924 | Val Loss: 1.615877\n",
      "Epoch [200/500] | Train Loss: 0.700079 | Val Loss: 1.343313\n",
      "Epoch [300/500] | Train Loss: 0.729511 | Val Loss: 1.321941\n",
      "Epoch [400/500] | Train Loss: 0.663781 | Val Loss: 1.355669\n",
      "Epoch [500/500] | Train Loss: 0.645415 | Val Loss: 1.597881\n",
      "Epoch [100/500] | Train Loss: 0.952421 | Val Loss: 0.600127\n",
      "Epoch [200/500] | Train Loss: 0.825540 | Val Loss: 0.615092\n",
      "Epoch [300/500] | Train Loss: 0.793231 | Val Loss: 0.630184\n",
      "Epoch [400/500] | Train Loss: 0.826812 | Val Loss: 0.646928\n",
      "Epoch [500/500] | Train Loss: 0.769958 | Val Loss: 0.644244\n",
      "Epoch [100/500] | Train Loss: 3.019227 | Val Loss: 1.339310\n",
      "Epoch [200/500] | Train Loss: 2.946886 | Val Loss: 1.475709\n",
      "Epoch [300/500] | Train Loss: 2.250606 | Val Loss: 1.487134\n",
      "Epoch [400/500] | Train Loss: 2.674330 | Val Loss: 1.495226\n",
      "Epoch [500/500] | Train Loss: 1.957321 | Val Loss: 1.480904\n",
      "Epoch [100/500] | Train Loss: 2.078012 | Val Loss: 0.376028\n",
      "Epoch [200/500] | Train Loss: 1.817360 | Val Loss: 0.384079\n",
      "Epoch [300/500] | Train Loss: 1.799156 | Val Loss: 0.381764\n",
      "Epoch [400/500] | Train Loss: 1.792120 | Val Loss: 0.373712\n",
      "Epoch [500/500] | Train Loss: 1.320485 | Val Loss: 0.368840\n",
      "Epoch [100/500] | Train Loss: 1.602103 | Val Loss: 0.604837\n",
      "Epoch [200/500] | Train Loss: 1.506831 | Val Loss: 0.598892\n",
      "Epoch [300/500] | Train Loss: 1.240803 | Val Loss: 0.612503\n",
      "Epoch [400/500] | Train Loss: 1.225273 | Val Loss: 0.627258\n",
      "Epoch [500/500] | Train Loss: 1.015725 | Val Loss: 0.623072\n",
      "Epoch [100/500] | Train Loss: 1.359840 | Val Loss: 1.058540\n",
      "Epoch [200/500] | Train Loss: 1.217901 | Val Loss: 1.052995\n",
      "Epoch [300/500] | Train Loss: 1.184117 | Val Loss: 1.072343\n",
      "Epoch [400/500] | Train Loss: 1.107902 | Val Loss: 1.138614\n",
      "Epoch [500/500] | Train Loss: 1.051424 | Val Loss: 1.221708\n",
      "Epoch [100/500] | Train Loss: 1.273863 | Val Loss: 0.604759\n",
      "Epoch [200/500] | Train Loss: 1.242845 | Val Loss: 0.599164\n",
      "Epoch [300/500] | Train Loss: 1.169999 | Val Loss: 0.600901\n",
      "Epoch [400/500] | Train Loss: 1.098767 | Val Loss: 0.607809\n",
      "Epoch [500/500] | Train Loss: 1.031768 | Val Loss: 0.615228\n",
      "Epoch [100/500] | Train Loss: 1.728971 | Val Loss: 1.477631\n",
      "Epoch [200/500] | Train Loss: 1.151490 | Val Loss: 1.441520\n",
      "Epoch [300/500] | Train Loss: 1.456037 | Val Loss: 1.421746\n",
      "Epoch [400/500] | Train Loss: 1.150643 | Val Loss: 1.495442\n",
      "Epoch [500/500] | Train Loss: 1.163505 | Val Loss: 1.561676\n",
      "Epoch [100/500] | Train Loss: 2.495408 | Val Loss: 0.377395\n",
      "Epoch [200/500] | Train Loss: 1.171797 | Val Loss: 0.380909\n",
      "Epoch [300/500] | Train Loss: 1.067071 | Val Loss: 0.391932\n",
      "Epoch [400/500] | Train Loss: 1.874975 | Val Loss: 0.379926\n",
      "Epoch [500/500] | Train Loss: 1.029442 | Val Loss: 0.383370\n",
      "Epoch [100/500] | Train Loss: 1.019624 | Val Loss: 0.604899\n",
      "Epoch [200/500] | Train Loss: 0.981547 | Val Loss: 0.598332\n",
      "Epoch [300/500] | Train Loss: 0.844654 | Val Loss: 0.587799\n",
      "Epoch [400/500] | Train Loss: 0.924026 | Val Loss: 0.585415\n",
      "Epoch [500/500] | Train Loss: 1.064957 | Val Loss: 0.633982\n",
      "Epoch [100/500] | Train Loss: 0.928659 | Val Loss: 1.218845\n",
      "Epoch [200/500] | Train Loss: 0.875361 | Val Loss: 1.190687\n",
      "Epoch [300/500] | Train Loss: 0.828577 | Val Loss: 1.275241\n",
      "Epoch [400/500] | Train Loss: 1.061126 | Val Loss: 1.104254\n",
      "Epoch [500/500] | Train Loss: 0.808247 | Val Loss: 1.315539\n",
      "Epoch [100/500] | Train Loss: 0.967160 | Val Loss: 0.608681\n",
      "Epoch [200/500] | Train Loss: 0.813467 | Val Loss: 0.622898\n",
      "Epoch [300/500] | Train Loss: 0.814123 | Val Loss: 0.615697\n",
      "Epoch [400/500] | Train Loss: 0.875176 | Val Loss: 0.622229\n",
      "Epoch [500/500] | Train Loss: 0.804567 | Val Loss: 0.623709\n",
      "Epoch [100/500] | Train Loss: 2.531217 | Val Loss: 1.432587\n",
      "Epoch [200/500] | Train Loss: 1.077816 | Val Loss: 1.561986\n",
      "Epoch [300/500] | Train Loss: 0.935115 | Val Loss: 1.637110\n",
      "Epoch [400/500] | Train Loss: 0.783256 | Val Loss: 1.497749\n",
      "Epoch [500/500] | Train Loss: 0.739896 | Val Loss: 1.498459\n",
      "Epoch [100/500] | Train Loss: 1.870690 | Val Loss: 0.397996\n",
      "Epoch [200/500] | Train Loss: 1.410692 | Val Loss: 0.422560\n",
      "Epoch [300/500] | Train Loss: 1.453045 | Val Loss: 0.425984\n",
      "Epoch [400/500] | Train Loss: 0.954461 | Val Loss: 0.420931\n",
      "Epoch [500/500] | Train Loss: 0.910777 | Val Loss: 0.420125\n",
      "Epoch [100/500] | Train Loss: 1.415411 | Val Loss: 0.615329\n",
      "Epoch [200/500] | Train Loss: 1.102372 | Val Loss: 0.638917\n",
      "Epoch [300/500] | Train Loss: 0.786979 | Val Loss: 0.640660\n",
      "Epoch [400/500] | Train Loss: 0.898788 | Val Loss: 0.643448\n",
      "Epoch [500/500] | Train Loss: 0.738455 | Val Loss: 0.636142\n",
      "Epoch [100/500] | Train Loss: 1.236282 | Val Loss: 1.116612\n",
      "Epoch [200/500] | Train Loss: 0.951570 | Val Loss: 1.194002\n",
      "Epoch [300/500] | Train Loss: 0.901303 | Val Loss: 1.402288\n",
      "Epoch [400/500] | Train Loss: 0.745741 | Val Loss: 1.512579\n",
      "Epoch [500/500] | Train Loss: 0.741456 | Val Loss: 1.627447\n",
      "Epoch [100/500] | Train Loss: 1.154673 | Val Loss: 0.602058\n",
      "Epoch [200/500] | Train Loss: 1.025020 | Val Loss: 0.616607\n",
      "Epoch [300/500] | Train Loss: 0.863842 | Val Loss: 0.618553\n",
      "Epoch [400/500] | Train Loss: 0.813198 | Val Loss: 0.624204\n",
      "Epoch [500/500] | Train Loss: 0.760430 | Val Loss: 0.636381\n",
      "Epoch [100/500] | Train Loss: 0.793848 | Val Loss: 1.800177\n",
      "Epoch [200/500] | Train Loss: 0.761215 | Val Loss: 1.520140\n",
      "Epoch [300/500] | Train Loss: 0.689900 | Val Loss: 1.669682\n",
      "Epoch [400/500] | Train Loss: 0.586633 | Val Loss: 1.733749\n",
      "Epoch [500/500] | Train Loss: 0.464316 | Val Loss: 1.965372\n",
      "Epoch [100/500] | Train Loss: 1.000931 | Val Loss: 0.396611\n",
      "Epoch [200/500] | Train Loss: 0.888353 | Val Loss: 0.405511\n",
      "Epoch [300/500] | Train Loss: 1.029925 | Val Loss: 0.431872\n",
      "Epoch [400/500] | Train Loss: 0.922298 | Val Loss: 0.456906\n",
      "Epoch [500/500] | Train Loss: 0.665887 | Val Loss: 0.487458\n",
      "Epoch [100/500] | Train Loss: 0.853521 | Val Loss: 0.609041\n",
      "Epoch [200/500] | Train Loss: 0.722020 | Val Loss: 0.608175\n",
      "Epoch [300/500] | Train Loss: 0.557652 | Val Loss: 0.671186\n",
      "Epoch [400/500] | Train Loss: 0.532802 | Val Loss: 0.708965\n",
      "Epoch [500/500] | Train Loss: 0.490041 | Val Loss: 0.747264\n",
      "Epoch [100/500] | Train Loss: 0.814082 | Val Loss: 1.412414\n",
      "Epoch [200/500] | Train Loss: 0.778425 | Val Loss: 1.574913\n",
      "Epoch [300/500] | Train Loss: 0.694153 | Val Loss: 1.591788\n",
      "Epoch [400/500] | Train Loss: 0.663104 | Val Loss: 1.453949\n",
      "Epoch [500/500] | Train Loss: 0.580377 | Val Loss: 1.587053\n",
      "Epoch [100/500] | Train Loss: 0.942072 | Val Loss: 0.614351\n",
      "Epoch [200/500] | Train Loss: 0.742449 | Val Loss: 0.635356\n",
      "Epoch [300/500] | Train Loss: 0.699656 | Val Loss: 0.666349\n",
      "Epoch [400/500] | Train Loss: 0.644958 | Val Loss: 0.668287\n",
      "Epoch [500/500] | Train Loss: 0.595950 | Val Loss: 0.691842\n",
      "Epoch [100/500] | Train Loss: 2.738656 | Val Loss: 1.374479\n",
      "Epoch [200/500] | Train Loss: 2.265630 | Val Loss: 1.419385\n",
      "Epoch [300/500] | Train Loss: 2.465134 | Val Loss: 1.441950\n",
      "Epoch [400/500] | Train Loss: 1.613972 | Val Loss: 1.545067\n",
      "Epoch [500/500] | Train Loss: 1.436359 | Val Loss: 1.591963\n",
      "Epoch [100/500] | Train Loss: 2.176511 | Val Loss: 0.371299\n",
      "Epoch [200/500] | Train Loss: 1.875337 | Val Loss: 0.389407\n",
      "Epoch [300/500] | Train Loss: 1.489475 | Val Loss: 0.396040\n",
      "Epoch [400/500] | Train Loss: 1.461683 | Val Loss: 0.390646\n",
      "Epoch [500/500] | Train Loss: 1.352075 | Val Loss: 0.382065\n",
      "Epoch [100/500] | Train Loss: 1.617090 | Val Loss: 0.597642\n",
      "Epoch [200/500] | Train Loss: 1.381840 | Val Loss: 0.615905\n",
      "Epoch [300/500] | Train Loss: 1.391990 | Val Loss: 0.609568\n",
      "Epoch [400/500] | Train Loss: 0.924294 | Val Loss: 0.605871\n",
      "Epoch [500/500] | Train Loss: 1.190804 | Val Loss: 0.603025\n",
      "Epoch [100/500] | Train Loss: 1.302077 | Val Loss: 1.047187\n",
      "Epoch [200/500] | Train Loss: 1.051435 | Val Loss: 1.106233\n",
      "Epoch [300/500] | Train Loss: 0.978606 | Val Loss: 1.177659\n",
      "Epoch [400/500] | Train Loss: 1.057736 | Val Loss: 1.324479\n",
      "Epoch [500/500] | Train Loss: 0.901942 | Val Loss: 1.295177\n",
      "Epoch [100/500] | Train Loss: 1.292017 | Val Loss: 0.607025\n",
      "Epoch [200/500] | Train Loss: 1.167286 | Val Loss: 0.613852\n",
      "Epoch [300/500] | Train Loss: 1.106236 | Val Loss: 0.619010\n",
      "Epoch [400/500] | Train Loss: 1.104416 | Val Loss: 0.621444\n",
      "Epoch [500/500] | Train Loss: 1.165774 | Val Loss: 0.617719\n",
      "Epoch [100/500] | Train Loss: 0.825391 | Val Loss: 1.649287\n",
      "Epoch [200/500] | Train Loss: 2.637921 | Val Loss: 1.670530\n",
      "Epoch [300/500] | Train Loss: 1.917660 | Val Loss: 2.137873\n",
      "Epoch [400/500] | Train Loss: 0.813654 | Val Loss: 1.976519\n",
      "Epoch [500/500] | Train Loss: 0.855052 | Val Loss: 1.747494\n",
      "Epoch [100/500] | Train Loss: 1.608631 | Val Loss: 0.396974\n",
      "Epoch [200/500] | Train Loss: 1.020899 | Val Loss: 0.406804\n",
      "Epoch [300/500] | Train Loss: 1.228336 | Val Loss: 0.407183\n",
      "Epoch [400/500] | Train Loss: 1.121609 | Val Loss: 0.421865\n",
      "Epoch [500/500] | Train Loss: 0.781775 | Val Loss: 0.439651\n",
      "Epoch [100/500] | Train Loss: 1.079449 | Val Loss: 0.604011\n",
      "Epoch [200/500] | Train Loss: 1.118845 | Val Loss: 0.623664\n",
      "Epoch [300/500] | Train Loss: 0.980899 | Val Loss: 0.647892\n",
      "Epoch [400/500] | Train Loss: 0.778506 | Val Loss: 0.647480\n",
      "Epoch [500/500] | Train Loss: 1.067519 | Val Loss: 0.652592\n",
      "Epoch [100/500] | Train Loss: 0.794733 | Val Loss: 1.347437\n",
      "Epoch [200/500] | Train Loss: 1.193625 | Val Loss: 1.446039\n",
      "Epoch [300/500] | Train Loss: 0.853617 | Val Loss: 1.297811\n",
      "Epoch [400/500] | Train Loss: 0.813990 | Val Loss: 1.429040\n",
      "Epoch [500/500] | Train Loss: 0.716490 | Val Loss: 1.592097\n",
      "Epoch [100/500] | Train Loss: 1.071387 | Val Loss: 0.613211\n",
      "Epoch [200/500] | Train Loss: 0.826911 | Val Loss: 0.622419\n",
      "Epoch [300/500] | Train Loss: 0.788154 | Val Loss: 0.622231\n",
      "Epoch [400/500] | Train Loss: 0.812887 | Val Loss: 0.630561\n",
      "Epoch [500/500] | Train Loss: 0.940246 | Val Loss: 0.626914\n",
      "[Year=1992] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.861950 Test MSE=0.355419\n",
      "Year 1992 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.848671 | Val Loss: 0.379121\n",
      "Epoch [200/500] | Train Loss: 0.769777 | Val Loss: 0.405952\n",
      "Epoch [300/500] | Train Loss: 0.655495 | Val Loss: 0.436427\n",
      "Epoch [400/500] | Train Loss: 0.650102 | Val Loss: 0.464290\n",
      "Epoch [500/500] | Train Loss: 0.494306 | Val Loss: 0.490878\n",
      "Epoch [100/500] | Train Loss: 0.617296 | Val Loss: 0.627513\n",
      "Epoch [200/500] | Train Loss: 0.556215 | Val Loss: 0.641275\n",
      "Epoch [300/500] | Train Loss: 0.534647 | Val Loss: 0.691005\n",
      "Epoch [400/500] | Train Loss: 0.460509 | Val Loss: 0.725079\n",
      "Epoch [500/500] | Train Loss: 0.434445 | Val Loss: 0.754100\n",
      "Epoch [100/500] | Train Loss: 0.607477 | Val Loss: 1.106627\n",
      "Epoch [200/500] | Train Loss: 0.580778 | Val Loss: 1.141267\n",
      "Epoch [300/500] | Train Loss: 0.543897 | Val Loss: 1.149301\n",
      "Epoch [400/500] | Train Loss: 0.493104 | Val Loss: 1.156224\n",
      "Epoch [500/500] | Train Loss: 0.495211 | Val Loss: 1.133959\n",
      "Epoch [100/500] | Train Loss: 0.738228 | Val Loss: 0.551997\n",
      "Epoch [200/500] | Train Loss: 0.702297 | Val Loss: 0.562374\n",
      "Epoch [300/500] | Train Loss: 0.662137 | Val Loss: 0.586958\n",
      "Epoch [400/500] | Train Loss: 0.648153 | Val Loss: 0.608759\n",
      "Epoch [500/500] | Train Loss: 0.618772 | Val Loss: 0.619541\n",
      "Epoch [100/500] | Train Loss: 0.673250 | Val Loss: 0.326194\n",
      "Epoch [200/500] | Train Loss: 0.640956 | Val Loss: 0.329394\n",
      "Epoch [300/500] | Train Loss: 0.619093 | Val Loss: 0.343214\n",
      "Epoch [400/500] | Train Loss: 0.577714 | Val Loss: 0.359820\n",
      "Epoch [500/500] | Train Loss: 0.562758 | Val Loss: 0.366977\n",
      "Epoch [100/500] | Train Loss: 0.445504 | Val Loss: 0.477133\n",
      "Epoch [200/500] | Train Loss: 0.354856 | Val Loss: 0.602302\n",
      "Epoch [300/500] | Train Loss: 0.253894 | Val Loss: 0.602696\n",
      "Epoch [400/500] | Train Loss: 0.246490 | Val Loss: 0.593439\n",
      "Epoch [500/500] | Train Loss: 0.255988 | Val Loss: 0.573007\n",
      "Epoch [100/500] | Train Loss: 0.408280 | Val Loss: 0.707615\n",
      "Epoch [200/500] | Train Loss: 0.314788 | Val Loss: 0.802603\n",
      "Epoch [300/500] | Train Loss: 0.256885 | Val Loss: 0.706586\n",
      "Epoch [400/500] | Train Loss: 0.277097 | Val Loss: 0.776644\n",
      "Epoch [500/500] | Train Loss: 0.247684 | Val Loss: 0.758487\n",
      "Epoch [100/500] | Train Loss: 0.461508 | Val Loss: 1.206587\n",
      "Epoch [200/500] | Train Loss: 0.364797 | Val Loss: 1.276508\n",
      "Epoch [300/500] | Train Loss: 0.365973 | Val Loss: 1.190954\n",
      "Epoch [400/500] | Train Loss: 0.316261 | Val Loss: 1.166882\n",
      "Epoch [500/500] | Train Loss: 0.293624 | Val Loss: 1.218352\n",
      "Epoch [100/500] | Train Loss: 0.570202 | Val Loss: 0.596756\n",
      "Epoch [200/500] | Train Loss: 0.494289 | Val Loss: 0.675873\n",
      "Epoch [300/500] | Train Loss: 0.466098 | Val Loss: 0.707350\n",
      "Epoch [400/500] | Train Loss: 0.418398 | Val Loss: 0.678415\n",
      "Epoch [500/500] | Train Loss: 0.416016 | Val Loss: 0.713247\n",
      "Epoch [100/500] | Train Loss: 0.598838 | Val Loss: 0.363303\n",
      "Epoch [200/500] | Train Loss: 0.491389 | Val Loss: 0.391863\n",
      "Epoch [300/500] | Train Loss: 0.475085 | Val Loss: 0.398063\n",
      "Epoch [400/500] | Train Loss: 0.465460 | Val Loss: 0.422538\n",
      "Epoch [500/500] | Train Loss: 0.413111 | Val Loss: 0.492358\n",
      "Epoch [100/500] | Train Loss: 0.873018 | Val Loss: 0.379156\n",
      "Epoch [200/500] | Train Loss: 0.752707 | Val Loss: 0.402246\n",
      "Epoch [300/500] | Train Loss: 0.745670 | Val Loss: 0.444952\n",
      "Epoch [400/500] | Train Loss: 0.613912 | Val Loss: 0.463928\n",
      "Epoch [500/500] | Train Loss: 0.603629 | Val Loss: 0.472037\n",
      "Epoch [100/500] | Train Loss: 0.624267 | Val Loss: 0.627731\n",
      "Epoch [200/500] | Train Loss: 0.621315 | Val Loss: 0.652746\n",
      "Epoch [300/500] | Train Loss: 0.571361 | Val Loss: 0.677950\n",
      "Epoch [400/500] | Train Loss: 0.494679 | Val Loss: 0.682424\n",
      "Epoch [500/500] | Train Loss: 0.467330 | Val Loss: 0.690616\n",
      "Epoch [100/500] | Train Loss: 0.620858 | Val Loss: 1.116351\n",
      "Epoch [200/500] | Train Loss: 0.608817 | Val Loss: 1.129829\n",
      "Epoch [300/500] | Train Loss: 0.593661 | Val Loss: 1.143397\n",
      "Epoch [400/500] | Train Loss: 0.583669 | Val Loss: 1.140401\n",
      "Epoch [500/500] | Train Loss: 0.539760 | Val Loss: 1.149265\n",
      "Epoch [100/500] | Train Loss: 0.722647 | Val Loss: 0.552520\n",
      "Epoch [200/500] | Train Loss: 0.699316 | Val Loss: 0.562723\n",
      "Epoch [300/500] | Train Loss: 0.690367 | Val Loss: 0.573886\n",
      "Epoch [400/500] | Train Loss: 0.670346 | Val Loss: 0.580744\n",
      "Epoch [500/500] | Train Loss: 0.656472 | Val Loss: 0.589369\n",
      "Epoch [100/500] | Train Loss: 0.701956 | Val Loss: 0.325127\n",
      "Epoch [200/500] | Train Loss: 0.691397 | Val Loss: 0.329307\n",
      "Epoch [300/500] | Train Loss: 0.679101 | Val Loss: 0.331241\n",
      "Epoch [400/500] | Train Loss: 0.659667 | Val Loss: 0.333231\n",
      "Epoch [500/500] | Train Loss: 0.626487 | Val Loss: 0.334724\n",
      "Epoch [100/500] | Train Loss: 0.630859 | Val Loss: 0.514214\n",
      "Epoch [200/500] | Train Loss: 0.461564 | Val Loss: 0.475431\n",
      "Epoch [300/500] | Train Loss: 0.494591 | Val Loss: 0.568501\n",
      "Epoch [400/500] | Train Loss: 0.462766 | Val Loss: 0.612581\n",
      "Epoch [500/500] | Train Loss: 0.428071 | Val Loss: 0.643272\n",
      "Epoch [100/500] | Train Loss: 0.492888 | Val Loss: 0.656187\n",
      "Epoch [200/500] | Train Loss: 0.426765 | Val Loss: 0.685191\n",
      "Epoch [300/500] | Train Loss: 0.410426 | Val Loss: 0.657642\n",
      "Epoch [400/500] | Train Loss: 0.377072 | Val Loss: 0.631092\n",
      "Epoch [500/500] | Train Loss: 0.368173 | Val Loss: 0.650882\n",
      "Epoch [100/500] | Train Loss: 0.562079 | Val Loss: 1.127956\n",
      "Epoch [200/500] | Train Loss: 0.467463 | Val Loss: 1.186399\n",
      "Epoch [300/500] | Train Loss: 0.497472 | Val Loss: 1.188250\n",
      "Epoch [400/500] | Train Loss: 0.442459 | Val Loss: 1.227608\n",
      "Epoch [500/500] | Train Loss: 0.426836 | Val Loss: 1.194853\n",
      "Epoch [100/500] | Train Loss: 0.680440 | Val Loss: 0.562950\n",
      "Epoch [200/500] | Train Loss: 0.547894 | Val Loss: 0.614730\n",
      "Epoch [300/500] | Train Loss: 0.547462 | Val Loss: 0.637317\n",
      "Epoch [400/500] | Train Loss: 0.545345 | Val Loss: 0.618832\n",
      "Epoch [500/500] | Train Loss: 0.539180 | Val Loss: 0.638519\n",
      "Epoch [100/500] | Train Loss: 0.629241 | Val Loss: 0.357005\n",
      "Epoch [200/500] | Train Loss: 0.602247 | Val Loss: 0.379173\n",
      "Epoch [300/500] | Train Loss: 0.602861 | Val Loss: 0.375539\n",
      "Epoch [400/500] | Train Loss: 0.569375 | Val Loss: 0.378136\n",
      "Epoch [500/500] | Train Loss: 0.553562 | Val Loss: 0.398935\n",
      "Epoch [100/500] | Train Loss: 0.787505 | Val Loss: 0.420231\n",
      "Epoch [200/500] | Train Loss: 0.582802 | Val Loss: 0.476939\n",
      "Epoch [300/500] | Train Loss: 0.415632 | Val Loss: 0.503933\n",
      "Epoch [400/500] | Train Loss: 0.366083 | Val Loss: 0.519057\n",
      "Epoch [500/500] | Train Loss: 0.349693 | Val Loss: 0.516443\n",
      "Epoch [100/500] | Train Loss: 0.593241 | Val Loss: 0.638971\n",
      "Epoch [200/500] | Train Loss: 0.521586 | Val Loss: 0.703621\n",
      "Epoch [300/500] | Train Loss: 0.410557 | Val Loss: 0.720531\n",
      "Epoch [400/500] | Train Loss: 0.395380 | Val Loss: 0.713686\n",
      "Epoch [500/500] | Train Loss: 0.362713 | Val Loss: 0.720956\n",
      "Epoch [100/500] | Train Loss: 0.610646 | Val Loss: 1.103743\n",
      "Epoch [200/500] | Train Loss: 0.551659 | Val Loss: 1.182849\n",
      "Epoch [300/500] | Train Loss: 0.502833 | Val Loss: 1.211269\n",
      "Epoch [400/500] | Train Loss: 0.437313 | Val Loss: 1.217098\n",
      "Epoch [500/500] | Train Loss: 0.425344 | Val Loss: 1.205088\n",
      "Epoch [100/500] | Train Loss: 0.712321 | Val Loss: 0.562650\n",
      "Epoch [200/500] | Train Loss: 0.645641 | Val Loss: 0.588728\n",
      "Epoch [300/500] | Train Loss: 0.600930 | Val Loss: 0.613133\n",
      "Epoch [400/500] | Train Loss: 0.578432 | Val Loss: 0.639547\n",
      "Epoch [500/500] | Train Loss: 0.522557 | Val Loss: 0.636163\n",
      "Epoch [100/500] | Train Loss: 0.676208 | Val Loss: 0.327444\n",
      "Epoch [200/500] | Train Loss: 0.627293 | Val Loss: 0.347767\n",
      "Epoch [300/500] | Train Loss: 0.583113 | Val Loss: 0.367329\n",
      "Epoch [400/500] | Train Loss: 0.541899 | Val Loss: 0.379439\n",
      "Epoch [500/500] | Train Loss: 0.507147 | Val Loss: 0.393840\n",
      "Epoch [100/500] | Train Loss: 0.441085 | Val Loss: 0.499683\n",
      "Epoch [200/500] | Train Loss: 0.313211 | Val Loss: 0.555598\n",
      "Epoch [300/500] | Train Loss: 0.247752 | Val Loss: 0.555071\n",
      "Epoch [400/500] | Train Loss: 0.205025 | Val Loss: 0.559235\n",
      "Epoch [500/500] | Train Loss: 0.206181 | Val Loss: 0.648360\n",
      "Epoch [100/500] | Train Loss: 0.350095 | Val Loss: 0.774150\n",
      "Epoch [200/500] | Train Loss: 0.320391 | Val Loss: 0.754929\n",
      "Epoch [300/500] | Train Loss: 0.256578 | Val Loss: 0.791545\n",
      "Epoch [400/500] | Train Loss: 0.232886 | Val Loss: 0.835703\n",
      "Epoch [500/500] | Train Loss: 0.201337 | Val Loss: 0.817974\n",
      "Epoch [100/500] | Train Loss: 0.449858 | Val Loss: 1.181166\n",
      "Epoch [200/500] | Train Loss: 0.402532 | Val Loss: 1.258130\n",
      "Epoch [300/500] | Train Loss: 0.349225 | Val Loss: 1.339939\n",
      "Epoch [400/500] | Train Loss: 0.306064 | Val Loss: 1.353398\n",
      "Epoch [500/500] | Train Loss: 0.286106 | Val Loss: 1.373624\n",
      "Epoch [100/500] | Train Loss: 0.601337 | Val Loss: 0.588526\n",
      "Epoch [200/500] | Train Loss: 0.484462 | Val Loss: 0.695521\n",
      "Epoch [300/500] | Train Loss: 0.413289 | Val Loss: 0.775860\n",
      "Epoch [400/500] | Train Loss: 0.399825 | Val Loss: 0.777324\n",
      "Epoch [500/500] | Train Loss: 0.390503 | Val Loss: 0.792459\n",
      "Epoch [100/500] | Train Loss: 0.603713 | Val Loss: 0.346963\n",
      "Epoch [200/500] | Train Loss: 0.510886 | Val Loss: 0.404206\n",
      "Epoch [300/500] | Train Loss: 0.468358 | Val Loss: 0.407418\n",
      "Epoch [400/500] | Train Loss: 0.446292 | Val Loss: 0.438628\n",
      "Epoch [500/500] | Train Loss: 0.421391 | Val Loss: 0.455991\n",
      "Epoch [100/500] | Train Loss: 0.838580 | Val Loss: 0.384522\n",
      "Epoch [200/500] | Train Loss: 0.771295 | Val Loss: 0.448765\n",
      "Epoch [300/500] | Train Loss: 0.661929 | Val Loss: 0.482094\n",
      "Epoch [400/500] | Train Loss: 0.582575 | Val Loss: 0.475132\n",
      "Epoch [500/500] | Train Loss: 0.508422 | Val Loss: 0.487555\n",
      "Epoch [100/500] | Train Loss: 0.606261 | Val Loss: 0.638254\n",
      "Epoch [200/500] | Train Loss: 0.537252 | Val Loss: 0.679496\n",
      "Epoch [300/500] | Train Loss: 0.506013 | Val Loss: 0.683099\n",
      "Epoch [400/500] | Train Loss: 0.478987 | Val Loss: 0.689039\n",
      "Epoch [500/500] | Train Loss: 0.420297 | Val Loss: 0.696222\n",
      "Epoch [100/500] | Train Loss: 0.621984 | Val Loss: 1.097459\n",
      "Epoch [200/500] | Train Loss: 0.596158 | Val Loss: 1.106181\n",
      "Epoch [300/500] | Train Loss: 0.576193 | Val Loss: 1.142461\n",
      "Epoch [400/500] | Train Loss: 0.560666 | Val Loss: 1.163268\n",
      "Epoch [500/500] | Train Loss: 0.503240 | Val Loss: 1.208143\n",
      "Epoch [100/500] | Train Loss: 0.746566 | Val Loss: 0.554041\n",
      "Epoch [200/500] | Train Loss: 0.716715 | Val Loss: 0.563175\n",
      "Epoch [300/500] | Train Loss: 0.699520 | Val Loss: 0.580226\n",
      "Epoch [400/500] | Train Loss: 0.662437 | Val Loss: 0.606989\n",
      "Epoch [500/500] | Train Loss: 0.631741 | Val Loss: 0.612536\n",
      "Epoch [100/500] | Train Loss: 0.692947 | Val Loss: 0.324077\n",
      "Epoch [200/500] | Train Loss: 0.659164 | Val Loss: 0.330500\n",
      "Epoch [300/500] | Train Loss: 0.636439 | Val Loss: 0.334522\n",
      "Epoch [400/500] | Train Loss: 0.610881 | Val Loss: 0.342613\n",
      "Epoch [500/500] | Train Loss: 0.580436 | Val Loss: 0.343102\n",
      "Epoch [100/500] | Train Loss: 0.629575 | Val Loss: 0.448042\n",
      "Epoch [200/500] | Train Loss: 0.442859 | Val Loss: 0.501306\n",
      "Epoch [300/500] | Train Loss: 0.359484 | Val Loss: 0.498657\n",
      "Epoch [400/500] | Train Loss: 0.402504 | Val Loss: 0.474171\n",
      "Epoch [500/500] | Train Loss: 0.293050 | Val Loss: 0.598130\n",
      "Epoch [100/500] | Train Loss: 0.482568 | Val Loss: 0.653103\n",
      "Epoch [200/500] | Train Loss: 0.384077 | Val Loss: 0.718829\n",
      "Epoch [300/500] | Train Loss: 0.347231 | Val Loss: 0.710245\n",
      "Epoch [400/500] | Train Loss: 0.351484 | Val Loss: 0.712667\n",
      "Epoch [500/500] | Train Loss: 0.298441 | Val Loss: 0.796485\n",
      "Epoch [100/500] | Train Loss: 0.517644 | Val Loss: 1.144245\n",
      "Epoch [200/500] | Train Loss: 0.469082 | Val Loss: 1.156401\n",
      "Epoch [300/500] | Train Loss: 0.434834 | Val Loss: 1.141215\n",
      "Epoch [400/500] | Train Loss: 0.404014 | Val Loss: 1.141094\n",
      "Epoch [500/500] | Train Loss: 0.399504 | Val Loss: 1.138379\n",
      "Epoch [100/500] | Train Loss: 0.656823 | Val Loss: 0.606061\n",
      "Epoch [200/500] | Train Loss: 0.581349 | Val Loss: 0.606434\n",
      "Epoch [300/500] | Train Loss: 0.561705 | Val Loss: 0.656639\n",
      "Epoch [400/500] | Train Loss: 0.496125 | Val Loss: 0.676015\n",
      "Epoch [500/500] | Train Loss: 0.516151 | Val Loss: 0.683842\n",
      "Epoch [100/500] | Train Loss: 0.603348 | Val Loss: 0.340485\n",
      "Epoch [200/500] | Train Loss: 0.520227 | Val Loss: 0.390516\n",
      "Epoch [300/500] | Train Loss: 0.517454 | Val Loss: 0.420148\n",
      "Epoch [400/500] | Train Loss: 0.484400 | Val Loss: 0.434543\n",
      "Epoch [500/500] | Train Loss: 0.478390 | Val Loss: 0.414318\n",
      "[Year=1993] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.647202 Test MSE=0.280249\n",
      "Year 1993 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.499300 | Val Loss: 0.771329\n",
      "Epoch [200/500] | Train Loss: 0.440086 | Val Loss: 0.799143\n",
      "Epoch [300/500] | Train Loss: 0.377647 | Val Loss: 0.832649\n",
      "Epoch [400/500] | Train Loss: 0.325213 | Val Loss: 0.921071\n",
      "Epoch [500/500] | Train Loss: 0.320844 | Val Loss: 0.935539\n",
      "Epoch [100/500] | Train Loss: 0.605319 | Val Loss: 0.884960\n",
      "Epoch [200/500] | Train Loss: 0.550753 | Val Loss: 0.936521\n",
      "Epoch [300/500] | Train Loss: 0.487174 | Val Loss: 0.977962\n",
      "Epoch [400/500] | Train Loss: 0.457635 | Val Loss: 1.005242\n",
      "Epoch [500/500] | Train Loss: 0.444764 | Val Loss: 1.024470\n",
      "Epoch [100/500] | Train Loss: 0.681727 | Val Loss: 0.539245\n",
      "Epoch [200/500] | Train Loss: 0.615195 | Val Loss: 0.574039\n",
      "Epoch [300/500] | Train Loss: 0.575281 | Val Loss: 0.592117\n",
      "Epoch [400/500] | Train Loss: 0.545644 | Val Loss: 0.596093\n",
      "Epoch [500/500] | Train Loss: 0.567514 | Val Loss: 0.610301\n",
      "Epoch [100/500] | Train Loss: 0.645140 | Val Loss: 0.304124\n",
      "Epoch [200/500] | Train Loss: 0.614793 | Val Loss: 0.316367\n",
      "Epoch [300/500] | Train Loss: 0.586162 | Val Loss: 0.316912\n",
      "Epoch [400/500] | Train Loss: 0.551996 | Val Loss: 0.319865\n",
      "Epoch [500/500] | Train Loss: 0.524984 | Val Loss: 0.323914\n",
      "Epoch [100/500] | Train Loss: 0.579458 | Val Loss: 0.239779\n",
      "Epoch [200/500] | Train Loss: 0.549229 | Val Loss: 0.249869\n",
      "Epoch [300/500] | Train Loss: 0.511156 | Val Loss: 0.258303\n",
      "Epoch [400/500] | Train Loss: 0.502005 | Val Loss: 0.261479\n",
      "Epoch [500/500] | Train Loss: 0.499681 | Val Loss: 0.259914\n",
      "Epoch [100/500] | Train Loss: 0.235301 | Val Loss: 1.098907\n",
      "Epoch [200/500] | Train Loss: 0.200743 | Val Loss: 0.925055\n",
      "Epoch [300/500] | Train Loss: 0.249480 | Val Loss: 0.891449\n",
      "Epoch [400/500] | Train Loss: 0.129154 | Val Loss: 0.941983\n",
      "Epoch [500/500] | Train Loss: 0.129023 | Val Loss: 1.007692\n",
      "Epoch [100/500] | Train Loss: 0.414014 | Val Loss: 0.986577\n",
      "Epoch [200/500] | Train Loss: 0.296801 | Val Loss: 1.063734\n",
      "Epoch [300/500] | Train Loss: 0.269251 | Val Loss: 1.076035\n",
      "Epoch [400/500] | Train Loss: 0.242290 | Val Loss: 1.134291\n",
      "Epoch [500/500] | Train Loss: 0.255822 | Val Loss: 1.171895\n",
      "Epoch [100/500] | Train Loss: 0.540324 | Val Loss: 0.652644\n",
      "Epoch [200/500] | Train Loss: 0.449656 | Val Loss: 0.685341\n",
      "Epoch [300/500] | Train Loss: 0.400802 | Val Loss: 0.686433\n",
      "Epoch [400/500] | Train Loss: 0.367927 | Val Loss: 0.721216\n",
      "Epoch [500/500] | Train Loss: 0.375041 | Val Loss: 0.753289\n",
      "Epoch [100/500] | Train Loss: 0.565198 | Val Loss: 0.329992\n",
      "Epoch [200/500] | Train Loss: 0.489334 | Val Loss: 0.354457\n",
      "Epoch [300/500] | Train Loss: 0.427631 | Val Loss: 0.379145\n",
      "Epoch [400/500] | Train Loss: 0.437174 | Val Loss: 0.389296\n",
      "Epoch [500/500] | Train Loss: 0.414713 | Val Loss: 0.428573\n",
      "Epoch [100/500] | Train Loss: 0.518724 | Val Loss: 0.253631\n",
      "Epoch [200/500] | Train Loss: 0.452964 | Val Loss: 0.256389\n",
      "Epoch [300/500] | Train Loss: 0.424376 | Val Loss: 0.297535\n",
      "Epoch [400/500] | Train Loss: 0.391723 | Val Loss: 0.275452\n",
      "Epoch [500/500] | Train Loss: 0.372219 | Val Loss: 0.307708\n",
      "Epoch [100/500] | Train Loss: 0.508435 | Val Loss: 0.747972\n",
      "Epoch [200/500] | Train Loss: 0.454747 | Val Loss: 0.758430\n",
      "Epoch [300/500] | Train Loss: 0.444393 | Val Loss: 0.756226\n",
      "Epoch [400/500] | Train Loss: 0.446297 | Val Loss: 0.764309\n",
      "Epoch [500/500] | Train Loss: 0.410234 | Val Loss: 0.772942\n",
      "Epoch [100/500] | Train Loss: 0.621781 | Val Loss: 0.887504\n",
      "Epoch [200/500] | Train Loss: 0.592066 | Val Loss: 0.897144\n",
      "Epoch [300/500] | Train Loss: 0.553767 | Val Loss: 0.922669\n",
      "Epoch [400/500] | Train Loss: 0.522175 | Val Loss: 0.942083\n",
      "Epoch [500/500] | Train Loss: 0.517251 | Val Loss: 0.930954\n",
      "Epoch [100/500] | Train Loss: 0.705009 | Val Loss: 0.538018\n",
      "Epoch [200/500] | Train Loss: 0.696376 | Val Loss: 0.535706\n",
      "Epoch [300/500] | Train Loss: 0.668019 | Val Loss: 0.533912\n",
      "Epoch [400/500] | Train Loss: 0.640469 | Val Loss: 0.541813\n",
      "Epoch [500/500] | Train Loss: 0.638088 | Val Loss: 0.551917\n",
      "Epoch [100/500] | Train Loss: 0.664938 | Val Loss: 0.302964\n",
      "Epoch [200/500] | Train Loss: 0.650500 | Val Loss: 0.304940\n",
      "Epoch [300/500] | Train Loss: 0.619358 | Val Loss: 0.308556\n",
      "Epoch [400/500] | Train Loss: 0.608688 | Val Loss: 0.305758\n",
      "Epoch [500/500] | Train Loss: 0.599712 | Val Loss: 0.307876\n",
      "Epoch [100/500] | Train Loss: 0.573389 | Val Loss: 0.239003\n",
      "Epoch [200/500] | Train Loss: 0.569602 | Val Loss: 0.243089\n",
      "Epoch [300/500] | Train Loss: 0.556294 | Val Loss: 0.249124\n",
      "Epoch [400/500] | Train Loss: 0.535701 | Val Loss: 0.254565\n",
      "Epoch [500/500] | Train Loss: 0.510688 | Val Loss: 0.258521\n",
      "Epoch [100/500] | Train Loss: 0.406214 | Val Loss: 0.801792\n",
      "Epoch [200/500] | Train Loss: 0.377226 | Val Loss: 0.885405\n",
      "Epoch [300/500] | Train Loss: 0.333950 | Val Loss: 0.864876\n",
      "Epoch [400/500] | Train Loss: 0.325264 | Val Loss: 0.874984\n",
      "Epoch [500/500] | Train Loss: 0.289338 | Val Loss: 0.903444\n",
      "Epoch [100/500] | Train Loss: 0.497594 | Val Loss: 0.984477\n",
      "Epoch [200/500] | Train Loss: 0.456394 | Val Loss: 0.989436\n",
      "Epoch [300/500] | Train Loss: 0.412343 | Val Loss: 0.956581\n",
      "Epoch [400/500] | Train Loss: 0.366687 | Val Loss: 0.992901\n",
      "Epoch [500/500] | Train Loss: 0.385401 | Val Loss: 0.995693\n",
      "Epoch [100/500] | Train Loss: 0.596744 | Val Loss: 0.543948\n",
      "Epoch [200/500] | Train Loss: 0.574340 | Val Loss: 0.556951\n",
      "Epoch [300/500] | Train Loss: 0.527951 | Val Loss: 0.605637\n",
      "Epoch [400/500] | Train Loss: 0.539181 | Val Loss: 0.596656\n",
      "Epoch [500/500] | Train Loss: 0.489514 | Val Loss: 0.619028\n",
      "Epoch [100/500] | Train Loss: 0.594321 | Val Loss: 0.311365\n",
      "Epoch [200/500] | Train Loss: 0.544255 | Val Loss: 0.327435\n",
      "Epoch [300/500] | Train Loss: 0.525579 | Val Loss: 0.337803\n",
      "Epoch [400/500] | Train Loss: 0.484219 | Val Loss: 0.356024\n",
      "Epoch [500/500] | Train Loss: 0.504230 | Val Loss: 0.347792\n",
      "Epoch [100/500] | Train Loss: 0.555843 | Val Loss: 0.242453\n",
      "Epoch [200/500] | Train Loss: 0.529394 | Val Loss: 0.257108\n",
      "Epoch [300/500] | Train Loss: 0.504854 | Val Loss: 0.266145\n",
      "Epoch [400/500] | Train Loss: 0.493286 | Val Loss: 0.262755\n",
      "Epoch [500/500] | Train Loss: 0.477496 | Val Loss: 0.274326\n",
      "Epoch [100/500] | Train Loss: 0.499663 | Val Loss: 0.764686\n",
      "Epoch [200/500] | Train Loss: 0.431611 | Val Loss: 0.812685\n",
      "Epoch [300/500] | Train Loss: 0.375358 | Val Loss: 0.914596\n",
      "Epoch [400/500] | Train Loss: 0.240269 | Val Loss: 1.046941\n",
      "Epoch [500/500] | Train Loss: 0.256990 | Val Loss: 1.196114\n",
      "Epoch [100/500] | Train Loss: 0.546134 | Val Loss: 0.918389\n",
      "Epoch [200/500] | Train Loss: 0.496472 | Val Loss: 0.972660\n",
      "Epoch [300/500] | Train Loss: 0.439569 | Val Loss: 0.975409\n",
      "Epoch [400/500] | Train Loss: 0.410249 | Val Loss: 0.999758\n",
      "Epoch [500/500] | Train Loss: 0.383677 | Val Loss: 1.006353\n",
      "Epoch [100/500] | Train Loss: 0.690937 | Val Loss: 0.533025\n",
      "Epoch [200/500] | Train Loss: 0.650758 | Val Loss: 0.558254\n",
      "Epoch [300/500] | Train Loss: 0.580297 | Val Loss: 0.595525\n",
      "Epoch [400/500] | Train Loss: 0.484507 | Val Loss: 0.635151\n",
      "Epoch [500/500] | Train Loss: 0.454141 | Val Loss: 0.664176\n",
      "Epoch [100/500] | Train Loss: 0.633187 | Val Loss: 0.305987\n",
      "Epoch [200/500] | Train Loss: 0.565799 | Val Loss: 0.321280\n",
      "Epoch [300/500] | Train Loss: 0.519998 | Val Loss: 0.332260\n",
      "Epoch [400/500] | Train Loss: 0.490379 | Val Loss: 0.352380\n",
      "Epoch [500/500] | Train Loss: 0.461089 | Val Loss: 0.350096\n",
      "Epoch [100/500] | Train Loss: 0.576740 | Val Loss: 0.240809\n",
      "Epoch [200/500] | Train Loss: 0.541314 | Val Loss: 0.246098\n",
      "Epoch [300/500] | Train Loss: 0.505090 | Val Loss: 0.252498\n",
      "Epoch [400/500] | Train Loss: 0.485932 | Val Loss: 0.257520\n",
      "Epoch [500/500] | Train Loss: 0.469821 | Val Loss: 0.265887\n",
      "Epoch [100/500] | Train Loss: 0.309834 | Val Loss: 1.413195\n",
      "Epoch [200/500] | Train Loss: 0.220034 | Val Loss: 1.096877\n",
      "Epoch [300/500] | Train Loss: 0.161963 | Val Loss: 1.333955\n",
      "Epoch [400/500] | Train Loss: 0.154722 | Val Loss: 1.256910\n",
      "Epoch [500/500] | Train Loss: 0.115738 | Val Loss: 1.172691\n",
      "Epoch [100/500] | Train Loss: 0.385579 | Val Loss: 1.018998\n",
      "Epoch [200/500] | Train Loss: 0.274607 | Val Loss: 0.995276\n",
      "Epoch [300/500] | Train Loss: 0.222061 | Val Loss: 1.045002\n",
      "Epoch [400/500] | Train Loss: 0.236741 | Val Loss: 1.055310\n",
      "Epoch [500/500] | Train Loss: 0.203263 | Val Loss: 1.092889\n",
      "Epoch [100/500] | Train Loss: 0.451274 | Val Loss: 0.647305\n",
      "Epoch [200/500] | Train Loss: 0.359026 | Val Loss: 0.711581\n",
      "Epoch [300/500] | Train Loss: 0.296198 | Val Loss: 0.750530\n",
      "Epoch [400/500] | Train Loss: 0.284217 | Val Loss: 0.764181\n",
      "Epoch [500/500] | Train Loss: 0.278419 | Val Loss: 0.755312\n",
      "Epoch [100/500] | Train Loss: 0.493843 | Val Loss: 0.339158\n",
      "Epoch [200/500] | Train Loss: 0.415155 | Val Loss: 0.412720\n",
      "Epoch [300/500] | Train Loss: 0.383908 | Val Loss: 0.391193\n",
      "Epoch [400/500] | Train Loss: 0.408495 | Val Loss: 0.406987\n",
      "Epoch [500/500] | Train Loss: 0.324077 | Val Loss: 0.427445\n",
      "Epoch [100/500] | Train Loss: 0.512028 | Val Loss: 0.265274\n",
      "Epoch [200/500] | Train Loss: 0.447102 | Val Loss: 0.313936\n",
      "Epoch [300/500] | Train Loss: 0.395780 | Val Loss: 0.325553\n",
      "Epoch [400/500] | Train Loss: 0.374971 | Val Loss: 0.381525\n",
      "Epoch [500/500] | Train Loss: 0.353625 | Val Loss: 0.387101\n",
      "Epoch [100/500] | Train Loss: 0.498427 | Val Loss: 0.765531\n",
      "Epoch [200/500] | Train Loss: 0.464528 | Val Loss: 0.777231\n",
      "Epoch [300/500] | Train Loss: 0.402568 | Val Loss: 0.809411\n",
      "Epoch [400/500] | Train Loss: 0.363179 | Val Loss: 0.868445\n",
      "Epoch [500/500] | Train Loss: 0.288676 | Val Loss: 0.890912\n",
      "Epoch [100/500] | Train Loss: 0.585006 | Val Loss: 0.903923\n",
      "Epoch [200/500] | Train Loss: 0.542054 | Val Loss: 0.937537\n",
      "Epoch [300/500] | Train Loss: 0.494879 | Val Loss: 0.964401\n",
      "Epoch [400/500] | Train Loss: 0.448718 | Val Loss: 0.961591\n",
      "Epoch [500/500] | Train Loss: 0.433216 | Val Loss: 0.963727\n",
      "Epoch [100/500] | Train Loss: 0.688342 | Val Loss: 0.530902\n",
      "Epoch [200/500] | Train Loss: 0.645069 | Val Loss: 0.538072\n",
      "Epoch [300/500] | Train Loss: 0.618474 | Val Loss: 0.563033\n",
      "Epoch [400/500] | Train Loss: 0.594060 | Val Loss: 0.582815\n",
      "Epoch [500/500] | Train Loss: 0.558434 | Val Loss: 0.589348\n",
      "Epoch [100/500] | Train Loss: 0.667413 | Val Loss: 0.304103\n",
      "Epoch [200/500] | Train Loss: 0.647856 | Val Loss: 0.303707\n",
      "Epoch [300/500] | Train Loss: 0.625405 | Val Loss: 0.309193\n",
      "Epoch [400/500] | Train Loss: 0.591007 | Val Loss: 0.320295\n",
      "Epoch [500/500] | Train Loss: 0.555760 | Val Loss: 0.323135\n",
      "Epoch [100/500] | Train Loss: 0.601244 | Val Loss: 0.241630\n",
      "Epoch [200/500] | Train Loss: 0.582377 | Val Loss: 0.242192\n",
      "Epoch [300/500] | Train Loss: 0.557403 | Val Loss: 0.249747\n",
      "Epoch [400/500] | Train Loss: 0.524659 | Val Loss: 0.252591\n",
      "Epoch [500/500] | Train Loss: 0.503426 | Val Loss: 0.258106\n",
      "Epoch [100/500] | Train Loss: 0.401520 | Val Loss: 0.818522\n",
      "Epoch [200/500] | Train Loss: 0.364557 | Val Loss: 0.901335\n",
      "Epoch [300/500] | Train Loss: 0.341760 | Val Loss: 0.817840\n",
      "Epoch [400/500] | Train Loss: 0.205430 | Val Loss: 0.792999\n",
      "Epoch [500/500] | Train Loss: 0.320248 | Val Loss: 0.791349\n",
      "Epoch [100/500] | Train Loss: 0.506530 | Val Loss: 0.953197\n",
      "Epoch [200/500] | Train Loss: 0.428585 | Val Loss: 1.027551\n",
      "Epoch [300/500] | Train Loss: 0.417473 | Val Loss: 1.067109\n",
      "Epoch [400/500] | Train Loss: 0.383719 | Val Loss: 1.077345\n",
      "Epoch [500/500] | Train Loss: 0.306063 | Val Loss: 1.106013\n",
      "Epoch [100/500] | Train Loss: 0.576479 | Val Loss: 0.562092\n",
      "Epoch [200/500] | Train Loss: 0.463593 | Val Loss: 0.583261\n",
      "Epoch [300/500] | Train Loss: 0.420694 | Val Loss: 0.619775\n",
      "Epoch [400/500] | Train Loss: 0.437261 | Val Loss: 0.677328\n",
      "Epoch [500/500] | Train Loss: 0.403914 | Val Loss: 0.677027\n",
      "Epoch [100/500] | Train Loss: 0.570336 | Val Loss: 0.307878\n",
      "Epoch [200/500] | Train Loss: 0.494824 | Val Loss: 0.326366\n",
      "Epoch [300/500] | Train Loss: 0.496709 | Val Loss: 0.348997\n",
      "Epoch [400/500] | Train Loss: 0.438346 | Val Loss: 0.353630\n",
      "Epoch [500/500] | Train Loss: 0.445343 | Val Loss: 0.376706\n",
      "Epoch [100/500] | Train Loss: 0.552642 | Val Loss: 0.254920\n",
      "Epoch [200/500] | Train Loss: 0.494454 | Val Loss: 0.273556\n",
      "Epoch [300/500] | Train Loss: 0.467842 | Val Loss: 0.286087\n",
      "Epoch [400/500] | Train Loss: 0.449355 | Val Loss: 0.276076\n",
      "Epoch [500/500] | Train Loss: 0.442084 | Val Loss: 0.285973\n",
      "[Year=1994] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.564442 Test MSE=0.368758\n",
      "Year 1994 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.838989 | Val Loss: 0.735271\n",
      "Epoch [200/500] | Train Loss: 0.755224 | Val Loss: 0.757039\n",
      "Epoch [300/500] | Train Loss: 0.634785 | Val Loss: 0.803410\n",
      "Epoch [400/500] | Train Loss: 0.487632 | Val Loss: 0.849303\n",
      "Epoch [500/500] | Train Loss: 0.414427 | Val Loss: 0.906302\n",
      "Epoch [100/500] | Train Loss: 0.797593 | Val Loss: 0.488295\n",
      "Epoch [200/500] | Train Loss: 0.713909 | Val Loss: 0.522193\n",
      "Epoch [300/500] | Train Loss: 0.654680 | Val Loss: 0.579843\n",
      "Epoch [400/500] | Train Loss: 0.574915 | Val Loss: 0.614851\n",
      "Epoch [500/500] | Train Loss: 0.562928 | Val Loss: 0.626258\n",
      "Epoch [100/500] | Train Loss: 0.689012 | Val Loss: 0.316461\n",
      "Epoch [200/500] | Train Loss: 0.652471 | Val Loss: 0.323501\n",
      "Epoch [300/500] | Train Loss: 0.591542 | Val Loss: 0.340843\n",
      "Epoch [400/500] | Train Loss: 0.555824 | Val Loss: 0.342440\n",
      "Epoch [500/500] | Train Loss: 0.541246 | Val Loss: 0.346023\n",
      "Epoch [100/500] | Train Loss: 0.591099 | Val Loss: 0.225725\n",
      "Epoch [200/500] | Train Loss: 0.547910 | Val Loss: 0.229892\n",
      "Epoch [300/500] | Train Loss: 0.526787 | Val Loss: 0.233663\n",
      "Epoch [400/500] | Train Loss: 0.502188 | Val Loss: 0.239655\n",
      "Epoch [500/500] | Train Loss: 0.484007 | Val Loss: 0.241136\n",
      "Epoch [100/500] | Train Loss: 0.527702 | Val Loss: 0.356737\n",
      "Epoch [200/500] | Train Loss: 0.502375 | Val Loss: 0.369731\n",
      "Epoch [300/500] | Train Loss: 0.477844 | Val Loss: 0.381066\n",
      "Epoch [400/500] | Train Loss: 0.458831 | Val Loss: 0.389205\n",
      "Epoch [500/500] | Train Loss: 0.426494 | Val Loss: 0.396495\n",
      "Epoch [100/500] | Train Loss: 0.499188 | Val Loss: 0.866224\n",
      "Epoch [200/500] | Train Loss: 0.381444 | Val Loss: 0.964323\n",
      "Epoch [300/500] | Train Loss: 0.277595 | Val Loss: 1.040453\n",
      "Epoch [400/500] | Train Loss: 0.214052 | Val Loss: 1.054271\n",
      "Epoch [500/500] | Train Loss: 0.202931 | Val Loss: 1.091288\n",
      "Epoch [100/500] | Train Loss: 0.590296 | Val Loss: 0.615431\n",
      "Epoch [200/500] | Train Loss: 0.457375 | Val Loss: 0.604823\n",
      "Epoch [300/500] | Train Loss: 0.361185 | Val Loss: 0.623587\n",
      "Epoch [400/500] | Train Loss: 0.367735 | Val Loss: 0.647355\n",
      "Epoch [500/500] | Train Loss: 0.328283 | Val Loss: 0.675240\n",
      "Epoch [100/500] | Train Loss: 0.515437 | Val Loss: 0.352945\n",
      "Epoch [200/500] | Train Loss: 0.414450 | Val Loss: 0.409819\n",
      "Epoch [300/500] | Train Loss: 0.406198 | Val Loss: 0.428053\n",
      "Epoch [400/500] | Train Loss: 0.375092 | Val Loss: 0.427007\n",
      "Epoch [500/500] | Train Loss: 0.361773 | Val Loss: 0.489946\n",
      "Epoch [100/500] | Train Loss: 0.473880 | Val Loss: 0.240878\n",
      "Epoch [200/500] | Train Loss: 0.402649 | Val Loss: 0.262345\n",
      "Epoch [300/500] | Train Loss: 0.384776 | Val Loss: 0.275473\n",
      "Epoch [400/500] | Train Loss: 0.354851 | Val Loss: 0.283741\n",
      "Epoch [500/500] | Train Loss: 0.340132 | Val Loss: 0.332613\n",
      "Epoch [100/500] | Train Loss: 0.486586 | Val Loss: 0.371875\n",
      "Epoch [200/500] | Train Loss: 0.411886 | Val Loss: 0.419522\n",
      "Epoch [300/500] | Train Loss: 0.382386 | Val Loss: 0.445518\n",
      "Epoch [400/500] | Train Loss: 0.371241 | Val Loss: 0.442645\n",
      "Epoch [500/500] | Train Loss: 0.322844 | Val Loss: 0.499577\n",
      "Epoch [100/500] | Train Loss: 0.849235 | Val Loss: 0.731232\n",
      "Epoch [200/500] | Train Loss: 0.791133 | Val Loss: 0.748907\n",
      "Epoch [300/500] | Train Loss: 0.705050 | Val Loss: 0.751296\n",
      "Epoch [400/500] | Train Loss: 0.630362 | Val Loss: 0.758409\n",
      "Epoch [500/500] | Train Loss: 0.578695 | Val Loss: 0.771153\n",
      "Epoch [100/500] | Train Loss: 0.786946 | Val Loss: 0.490766\n",
      "Epoch [200/500] | Train Loss: 0.722976 | Val Loss: 0.513441\n",
      "Epoch [300/500] | Train Loss: 0.697177 | Val Loss: 0.536314\n",
      "Epoch [400/500] | Train Loss: 0.728066 | Val Loss: 0.543580\n",
      "Epoch [500/500] | Train Loss: 0.663186 | Val Loss: 0.553184\n",
      "Epoch [100/500] | Train Loss: 0.699972 | Val Loss: 0.323154\n",
      "Epoch [200/500] | Train Loss: 0.657159 | Val Loss: 0.330015\n",
      "Epoch [300/500] | Train Loss: 0.652526 | Val Loss: 0.332187\n",
      "Epoch [400/500] | Train Loss: 0.641060 | Val Loss: 0.333733\n",
      "Epoch [500/500] | Train Loss: 0.607059 | Val Loss: 0.347558\n",
      "Epoch [100/500] | Train Loss: 0.593551 | Val Loss: 0.229269\n",
      "Epoch [200/500] | Train Loss: 0.576678 | Val Loss: 0.225969\n",
      "Epoch [300/500] | Train Loss: 0.558149 | Val Loss: 0.230138\n",
      "Epoch [400/500] | Train Loss: 0.535643 | Val Loss: 0.229826\n",
      "Epoch [500/500] | Train Loss: 0.527806 | Val Loss: 0.231904\n",
      "Epoch [100/500] | Train Loss: 0.529552 | Val Loss: 0.358347\n",
      "Epoch [200/500] | Train Loss: 0.510646 | Val Loss: 0.363580\n",
      "Epoch [300/500] | Train Loss: 0.479331 | Val Loss: 0.373975\n",
      "Epoch [400/500] | Train Loss: 0.474663 | Val Loss: 0.384296\n",
      "Epoch [500/500] | Train Loss: 0.467699 | Val Loss: 0.380005\n",
      "Epoch [100/500] | Train Loss: 0.641600 | Val Loss: 0.743504\n",
      "Epoch [200/500] | Train Loss: 0.580290 | Val Loss: 0.772567\n",
      "Epoch [300/500] | Train Loss: 0.459947 | Val Loss: 0.826508\n",
      "Epoch [400/500] | Train Loss: 0.454840 | Val Loss: 0.827044\n",
      "Epoch [500/500] | Train Loss: 0.472119 | Val Loss: 0.838706\n",
      "Epoch [100/500] | Train Loss: 0.679170 | Val Loss: 0.530007\n",
      "Epoch [200/500] | Train Loss: 0.603083 | Val Loss: 0.584184\n",
      "Epoch [300/500] | Train Loss: 0.604197 | Val Loss: 0.610033\n",
      "Epoch [400/500] | Train Loss: 0.534005 | Val Loss: 0.638928\n",
      "Epoch [500/500] | Train Loss: 0.555118 | Val Loss: 0.625911\n",
      "Epoch [100/500] | Train Loss: 0.634513 | Val Loss: 0.322354\n",
      "Epoch [200/500] | Train Loss: 0.575287 | Val Loss: 0.330755\n",
      "Epoch [300/500] | Train Loss: 0.537996 | Val Loss: 0.355718\n",
      "Epoch [400/500] | Train Loss: 0.502425 | Val Loss: 0.350513\n",
      "Epoch [500/500] | Train Loss: 0.480452 | Val Loss: 0.359594\n",
      "Epoch [100/500] | Train Loss: 0.539291 | Val Loss: 0.224183\n",
      "Epoch [200/500] | Train Loss: 0.490376 | Val Loss: 0.233417\n",
      "Epoch [300/500] | Train Loss: 0.499155 | Val Loss: 0.256901\n",
      "Epoch [400/500] | Train Loss: 0.445328 | Val Loss: 0.256619\n",
      "Epoch [500/500] | Train Loss: 0.449954 | Val Loss: 0.269688\n",
      "Epoch [100/500] | Train Loss: 0.513454 | Val Loss: 0.358434\n",
      "Epoch [200/500] | Train Loss: 0.483583 | Val Loss: 0.367732\n",
      "Epoch [300/500] | Train Loss: 0.467890 | Val Loss: 0.376923\n",
      "Epoch [400/500] | Train Loss: 0.440567 | Val Loss: 0.375860\n",
      "Epoch [500/500] | Train Loss: 0.422917 | Val Loss: 0.404663\n",
      "Epoch [100/500] | Train Loss: 0.817131 | Val Loss: 0.765180\n",
      "Epoch [200/500] | Train Loss: 0.531954 | Val Loss: 0.827511\n",
      "Epoch [300/500] | Train Loss: 0.403103 | Val Loss: 0.902302\n",
      "Epoch [400/500] | Train Loss: 0.354379 | Val Loss: 0.922568\n",
      "Epoch [500/500] | Train Loss: 0.359841 | Val Loss: 0.964343\n",
      "Epoch [100/500] | Train Loss: 0.734823 | Val Loss: 0.514299\n",
      "Epoch [200/500] | Train Loss: 0.624614 | Val Loss: 0.574633\n",
      "Epoch [300/500] | Train Loss: 0.545218 | Val Loss: 0.611860\n",
      "Epoch [400/500] | Train Loss: 0.481593 | Val Loss: 0.653511\n",
      "Epoch [500/500] | Train Loss: 0.447494 | Val Loss: 0.658694\n",
      "Epoch [100/500] | Train Loss: 0.683019 | Val Loss: 0.320927\n",
      "Epoch [200/500] | Train Loss: 0.636619 | Val Loss: 0.334786\n",
      "Epoch [300/500] | Train Loss: 0.569386 | Val Loss: 0.345500\n",
      "Epoch [400/500] | Train Loss: 0.536518 | Val Loss: 0.352566\n",
      "Epoch [500/500] | Train Loss: 0.484163 | Val Loss: 0.375530\n",
      "Epoch [100/500] | Train Loss: 0.586448 | Val Loss: 0.230021\n",
      "Epoch [200/500] | Train Loss: 0.520933 | Val Loss: 0.236232\n",
      "Epoch [300/500] | Train Loss: 0.486898 | Val Loss: 0.240003\n",
      "Epoch [400/500] | Train Loss: 0.449000 | Val Loss: 0.244090\n",
      "Epoch [500/500] | Train Loss: 0.425251 | Val Loss: 0.255630\n",
      "Epoch [100/500] | Train Loss: 0.504347 | Val Loss: 0.369209\n",
      "Epoch [200/500] | Train Loss: 0.470740 | Val Loss: 0.384603\n",
      "Epoch [300/500] | Train Loss: 0.432950 | Val Loss: 0.399977\n",
      "Epoch [400/500] | Train Loss: 0.400993 | Val Loss: 0.413084\n",
      "Epoch [500/500] | Train Loss: 0.378936 | Val Loss: 0.433526\n",
      "Epoch [100/500] | Train Loss: 0.388770 | Val Loss: 0.877624\n",
      "Epoch [200/500] | Train Loss: 0.261154 | Val Loss: 0.978688\n",
      "Epoch [300/500] | Train Loss: 0.232153 | Val Loss: 0.985536\n",
      "Epoch [400/500] | Train Loss: 0.187899 | Val Loss: 1.045751\n",
      "Epoch [500/500] | Train Loss: 0.170964 | Val Loss: 1.008038\n",
      "Epoch [100/500] | Train Loss: 0.503952 | Val Loss: 0.648681\n",
      "Epoch [200/500] | Train Loss: 0.383745 | Val Loss: 0.704468\n",
      "Epoch [300/500] | Train Loss: 0.290152 | Val Loss: 0.750870\n",
      "Epoch [400/500] | Train Loss: 0.256858 | Val Loss: 0.856589\n",
      "Epoch [500/500] | Train Loss: 0.282345 | Val Loss: 0.861752\n",
      "Epoch [100/500] | Train Loss: 0.487173 | Val Loss: 0.383923\n",
      "Epoch [200/500] | Train Loss: 0.358917 | Val Loss: 0.428446\n",
      "Epoch [300/500] | Train Loss: 0.310123 | Val Loss: 0.450613\n",
      "Epoch [400/500] | Train Loss: 0.290565 | Val Loss: 0.487547\n",
      "Epoch [500/500] | Train Loss: 0.288675 | Val Loss: 0.455294\n",
      "Epoch [100/500] | Train Loss: 0.475585 | Val Loss: 0.248484\n",
      "Epoch [200/500] | Train Loss: 0.386842 | Val Loss: 0.286757\n",
      "Epoch [300/500] | Train Loss: 0.331194 | Val Loss: 0.326670\n",
      "Epoch [400/500] | Train Loss: 0.340027 | Val Loss: 0.358196\n",
      "Epoch [500/500] | Train Loss: 0.291967 | Val Loss: 0.344100\n",
      "Epoch [100/500] | Train Loss: 0.377120 | Val Loss: 0.423000\n",
      "Epoch [200/500] | Train Loss: 0.346312 | Val Loss: 0.469979\n",
      "Epoch [300/500] | Train Loss: 0.292573 | Val Loss: 0.470477\n",
      "Epoch [400/500] | Train Loss: 0.282630 | Val Loss: 0.470837\n",
      "Epoch [500/500] | Train Loss: 0.259129 | Val Loss: 0.490756\n",
      "Epoch [100/500] | Train Loss: 0.842626 | Val Loss: 0.735231\n",
      "Epoch [200/500] | Train Loss: 0.743286 | Val Loss: 0.740228\n",
      "Epoch [300/500] | Train Loss: 0.645254 | Val Loss: 0.757286\n",
      "Epoch [400/500] | Train Loss: 0.557220 | Val Loss: 0.781561\n",
      "Epoch [500/500] | Train Loss: 0.477327 | Val Loss: 0.773834\n",
      "Epoch [100/500] | Train Loss: 0.777436 | Val Loss: 0.501477\n",
      "Epoch [200/500] | Train Loss: 0.710515 | Val Loss: 0.550561\n",
      "Epoch [300/500] | Train Loss: 0.661243 | Val Loss: 0.587563\n",
      "Epoch [400/500] | Train Loss: 0.584198 | Val Loss: 0.605214\n",
      "Epoch [500/500] | Train Loss: 0.583175 | Val Loss: 0.616874\n",
      "Epoch [100/500] | Train Loss: 0.683624 | Val Loss: 0.321668\n",
      "Epoch [200/500] | Train Loss: 0.659217 | Val Loss: 0.327152\n",
      "Epoch [300/500] | Train Loss: 0.627489 | Val Loss: 0.339032\n",
      "Epoch [400/500] | Train Loss: 0.584579 | Val Loss: 0.346223\n",
      "Epoch [500/500] | Train Loss: 0.557173 | Val Loss: 0.353130\n",
      "Epoch [100/500] | Train Loss: 0.608839 | Val Loss: 0.234801\n",
      "Epoch [200/500] | Train Loss: 0.600231 | Val Loss: 0.231527\n",
      "Epoch [300/500] | Train Loss: 0.596777 | Val Loss: 0.228443\n",
      "Epoch [400/500] | Train Loss: 0.574844 | Val Loss: 0.232799\n",
      "Epoch [500/500] | Train Loss: 0.549938 | Val Loss: 0.239366\n",
      "Epoch [100/500] | Train Loss: 0.533721 | Val Loss: 0.358527\n",
      "Epoch [200/500] | Train Loss: 0.522461 | Val Loss: 0.363163\n",
      "Epoch [300/500] | Train Loss: 0.491145 | Val Loss: 0.371991\n",
      "Epoch [400/500] | Train Loss: 0.487086 | Val Loss: 0.377773\n",
      "Epoch [500/500] | Train Loss: 0.472692 | Val Loss: 0.378099\n",
      "Epoch [100/500] | Train Loss: 0.617870 | Val Loss: 0.744379\n",
      "Epoch [200/500] | Train Loss: 0.382246 | Val Loss: 0.835477\n",
      "Epoch [300/500] | Train Loss: 0.323110 | Val Loss: 0.913464\n",
      "Epoch [400/500] | Train Loss: 0.361302 | Val Loss: 0.848196\n",
      "Epoch [500/500] | Train Loss: 0.321907 | Val Loss: 0.844965\n",
      "Epoch [100/500] | Train Loss: 0.549908 | Val Loss: 0.583316\n",
      "Epoch [200/500] | Train Loss: 0.463300 | Val Loss: 0.621764\n",
      "Epoch [300/500] | Train Loss: 0.457668 | Val Loss: 0.621155\n",
      "Epoch [400/500] | Train Loss: 0.397582 | Val Loss: 0.694484\n",
      "Epoch [500/500] | Train Loss: 0.432669 | Val Loss: 0.720664\n",
      "Epoch [100/500] | Train Loss: 0.605475 | Val Loss: 0.338445\n",
      "Epoch [200/500] | Train Loss: 0.542822 | Val Loss: 0.371972\n",
      "Epoch [300/500] | Train Loss: 0.538066 | Val Loss: 0.383169\n",
      "Epoch [400/500] | Train Loss: 0.484999 | Val Loss: 0.414861\n",
      "Epoch [500/500] | Train Loss: 0.490014 | Val Loss: 0.426268\n",
      "Epoch [100/500] | Train Loss: 0.502087 | Val Loss: 0.251240\n",
      "Epoch [200/500] | Train Loss: 0.436417 | Val Loss: 0.264531\n",
      "Epoch [300/500] | Train Loss: 0.414465 | Val Loss: 0.286911\n",
      "Epoch [400/500] | Train Loss: 0.390294 | Val Loss: 0.298396\n",
      "Epoch [500/500] | Train Loss: 0.405723 | Val Loss: 0.304308\n",
      "Epoch [100/500] | Train Loss: 0.480331 | Val Loss: 0.385226\n",
      "Epoch [200/500] | Train Loss: 0.436263 | Val Loss: 0.375203\n",
      "Epoch [300/500] | Train Loss: 0.420169 | Val Loss: 0.428517\n",
      "Epoch [400/500] | Train Loss: 0.369059 | Val Loss: 0.434837\n",
      "Epoch [500/500] | Train Loss: 0.341047 | Val Loss: 0.435048\n",
      "[Year=1995] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.456761 Test MSE=0.258630\n",
      "Year 1995 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.628780 | Val Loss: 0.466975\n",
      "Epoch [200/500] | Train Loss: 0.568037 | Val Loss: 0.479597\n",
      "Epoch [300/500] | Train Loss: 0.514637 | Val Loss: 0.519447\n",
      "Epoch [400/500] | Train Loss: 0.427799 | Val Loss: 0.557718\n",
      "Epoch [500/500] | Train Loss: 0.432311 | Val Loss: 0.594776\n",
      "Epoch [100/500] | Train Loss: 0.554454 | Val Loss: 0.328110\n",
      "Epoch [200/500] | Train Loss: 0.501988 | Val Loss: 0.347535\n",
      "Epoch [300/500] | Train Loss: 0.456303 | Val Loss: 0.363851\n",
      "Epoch [400/500] | Train Loss: 0.432615 | Val Loss: 0.368665\n",
      "Epoch [500/500] | Train Loss: 0.381449 | Val Loss: 0.373516\n",
      "Epoch [100/500] | Train Loss: 0.484975 | Val Loss: 0.287541\n",
      "Epoch [200/500] | Train Loss: 0.460039 | Val Loss: 0.285955\n",
      "Epoch [300/500] | Train Loss: 0.435431 | Val Loss: 0.283784\n",
      "Epoch [400/500] | Train Loss: 0.398963 | Val Loss: 0.269917\n",
      "Epoch [500/500] | Train Loss: 0.380741 | Val Loss: 0.271469\n",
      "Epoch [100/500] | Train Loss: 0.426200 | Val Loss: 0.276724\n",
      "Epoch [200/500] | Train Loss: 0.387550 | Val Loss: 0.289701\n",
      "Epoch [300/500] | Train Loss: 0.378558 | Val Loss: 0.311549\n",
      "Epoch [400/500] | Train Loss: 0.355916 | Val Loss: 0.320774\n",
      "Epoch [500/500] | Train Loss: 0.335134 | Val Loss: 0.325331\n",
      "Epoch [100/500] | Train Loss: 0.402415 | Val Loss: 0.255156\n",
      "Epoch [200/500] | Train Loss: 0.390752 | Val Loss: 0.259106\n",
      "Epoch [300/500] | Train Loss: 0.370538 | Val Loss: 0.275410\n",
      "Epoch [400/500] | Train Loss: 0.361785 | Val Loss: 0.283818\n",
      "Epoch [500/500] | Train Loss: 0.350704 | Val Loss: 0.292183\n",
      "Epoch [100/500] | Train Loss: 0.393056 | Val Loss: 0.545866\n",
      "Epoch [200/500] | Train Loss: 0.323007 | Val Loss: 0.568281\n",
      "Epoch [300/500] | Train Loss: 0.224983 | Val Loss: 0.634480\n",
      "Epoch [400/500] | Train Loss: 0.209473 | Val Loss: 0.667819\n",
      "Epoch [500/500] | Train Loss: 0.203391 | Val Loss: 0.643095\n",
      "Epoch [100/500] | Train Loss: 0.566628 | Val Loss: 0.327887\n",
      "Epoch [200/500] | Train Loss: 0.566627 | Val Loss: 0.327912\n",
      "Epoch [300/500] | Train Loss: 0.566627 | Val Loss: 0.327912\n",
      "Epoch [400/500] | Train Loss: 0.566627 | Val Loss: 0.327912\n",
      "Epoch [500/500] | Train Loss: 0.566627 | Val Loss: 0.327912\n",
      "Epoch [100/500] | Train Loss: 0.388674 | Val Loss: 0.266822\n",
      "Epoch [200/500] | Train Loss: 0.329937 | Val Loss: 0.292718\n",
      "Epoch [300/500] | Train Loss: 0.280201 | Val Loss: 0.298001\n",
      "Epoch [400/500] | Train Loss: 0.272746 | Val Loss: 0.299831\n",
      "Epoch [500/500] | Train Loss: 0.227531 | Val Loss: 0.280138\n",
      "Epoch [100/500] | Train Loss: 0.354598 | Val Loss: 0.313870\n",
      "Epoch [200/500] | Train Loss: 0.313373 | Val Loss: 0.334564\n",
      "Epoch [300/500] | Train Loss: 0.301899 | Val Loss: 0.360601\n",
      "Epoch [400/500] | Train Loss: 0.270859 | Val Loss: 0.366612\n",
      "Epoch [500/500] | Train Loss: 0.263181 | Val Loss: 0.376348\n",
      "Epoch [100/500] | Train Loss: 0.349471 | Val Loss: 0.269334\n",
      "Epoch [200/500] | Train Loss: 0.318317 | Val Loss: 0.275885\n",
      "Epoch [300/500] | Train Loss: 0.277964 | Val Loss: 0.299670\n",
      "Epoch [400/500] | Train Loss: 0.262594 | Val Loss: 0.303148\n",
      "Epoch [500/500] | Train Loss: 0.246445 | Val Loss: 0.287406\n",
      "Epoch [100/500] | Train Loss: 0.632812 | Val Loss: 0.472287\n",
      "Epoch [200/500] | Train Loss: 0.578437 | Val Loss: 0.492638\n",
      "Epoch [300/500] | Train Loss: 0.582166 | Val Loss: 0.522578\n",
      "Epoch [400/500] | Train Loss: 0.523742 | Val Loss: 0.547666\n",
      "Epoch [500/500] | Train Loss: 0.531690 | Val Loss: 0.558794\n",
      "Epoch [100/500] | Train Loss: 0.551100 | Val Loss: 0.326026\n",
      "Epoch [200/500] | Train Loss: 0.520179 | Val Loss: 0.338889\n",
      "Epoch [300/500] | Train Loss: 0.518552 | Val Loss: 0.351785\n",
      "Epoch [400/500] | Train Loss: 0.466131 | Val Loss: 0.358324\n",
      "Epoch [500/500] | Train Loss: 0.455260 | Val Loss: 0.354615\n",
      "Epoch [100/500] | Train Loss: 0.486878 | Val Loss: 0.283851\n",
      "Epoch [200/500] | Train Loss: 0.471961 | Val Loss: 0.282619\n",
      "Epoch [300/500] | Train Loss: 0.443806 | Val Loss: 0.280219\n",
      "Epoch [400/500] | Train Loss: 0.441801 | Val Loss: 0.277714\n",
      "Epoch [500/500] | Train Loss: 0.429849 | Val Loss: 0.282787\n",
      "Epoch [100/500] | Train Loss: 0.424803 | Val Loss: 0.275005\n",
      "Epoch [200/500] | Train Loss: 0.422168 | Val Loss: 0.279013\n",
      "Epoch [300/500] | Train Loss: 0.394170 | Val Loss: 0.291449\n",
      "Epoch [400/500] | Train Loss: 0.384660 | Val Loss: 0.301118\n",
      "Epoch [500/500] | Train Loss: 0.371474 | Val Loss: 0.306385\n",
      "Epoch [100/500] | Train Loss: 0.397192 | Val Loss: 0.248246\n",
      "Epoch [200/500] | Train Loss: 0.387370 | Val Loss: 0.253513\n",
      "Epoch [300/500] | Train Loss: 0.382936 | Val Loss: 0.260988\n",
      "Epoch [400/500] | Train Loss: 0.369296 | Val Loss: 0.264918\n",
      "Epoch [500/500] | Train Loss: 0.367104 | Val Loss: 0.268057\n",
      "Epoch [100/500] | Train Loss: 0.557626 | Val Loss: 0.555379\n",
      "Epoch [200/500] | Train Loss: 0.415747 | Val Loss: 0.554809\n",
      "Epoch [300/500] | Train Loss: 0.329593 | Val Loss: 0.638172\n",
      "Epoch [400/500] | Train Loss: 0.312552 | Val Loss: 0.561112\n",
      "Epoch [500/500] | Train Loss: 0.320357 | Val Loss: 0.548273\n",
      "Epoch [100/500] | Train Loss: 0.444098 | Val Loss: 0.380444\n",
      "Epoch [200/500] | Train Loss: 0.395756 | Val Loss: 0.390715\n",
      "Epoch [300/500] | Train Loss: 0.368734 | Val Loss: 0.419296\n",
      "Epoch [400/500] | Train Loss: 0.355830 | Val Loss: 0.405754\n",
      "Epoch [500/500] | Train Loss: 0.312385 | Val Loss: 0.399451\n",
      "Epoch [100/500] | Train Loss: 0.434112 | Val Loss: 0.286298\n",
      "Epoch [200/500] | Train Loss: 0.403138 | Val Loss: 0.286043\n",
      "Epoch [300/500] | Train Loss: 0.377230 | Val Loss: 0.311734\n",
      "Epoch [400/500] | Train Loss: 0.350865 | Val Loss: 0.327458\n",
      "Epoch [500/500] | Train Loss: 0.349257 | Val Loss: 0.323264\n",
      "Epoch [100/500] | Train Loss: 0.421379 | Val Loss: 0.281455\n",
      "Epoch [200/500] | Train Loss: 0.371739 | Val Loss: 0.313414\n",
      "Epoch [300/500] | Train Loss: 0.351359 | Val Loss: 0.318088\n",
      "Epoch [400/500] | Train Loss: 0.334887 | Val Loss: 0.329773\n",
      "Epoch [500/500] | Train Loss: 0.324504 | Val Loss: 0.318476\n",
      "Epoch [100/500] | Train Loss: 0.395359 | Val Loss: 0.245948\n",
      "Epoch [200/500] | Train Loss: 0.348642 | Val Loss: 0.259953\n",
      "Epoch [300/500] | Train Loss: 0.317807 | Val Loss: 0.268948\n",
      "Epoch [400/500] | Train Loss: 0.309601 | Val Loss: 0.269192\n",
      "Epoch [500/500] | Train Loss: 0.301037 | Val Loss: 0.270649\n",
      "Epoch [100/500] | Train Loss: 0.531085 | Val Loss: 0.485953\n",
      "Epoch [200/500] | Train Loss: 0.419563 | Val Loss: 0.574574\n",
      "Epoch [300/500] | Train Loss: 0.310948 | Val Loss: 0.587077\n",
      "Epoch [400/500] | Train Loss: 0.274143 | Val Loss: 0.618613\n",
      "Epoch [500/500] | Train Loss: 0.246714 | Val Loss: 0.649841\n",
      "Epoch [100/500] | Train Loss: 0.543740 | Val Loss: 0.327925\n",
      "Epoch [200/500] | Train Loss: 0.502918 | Val Loss: 0.343441\n",
      "Epoch [300/500] | Train Loss: 0.445567 | Val Loss: 0.370021\n",
      "Epoch [400/500] | Train Loss: 0.401883 | Val Loss: 0.389943\n",
      "Epoch [500/500] | Train Loss: 0.375366 | Val Loss: 0.423577\n",
      "Epoch [100/500] | Train Loss: 0.451412 | Val Loss: 0.286590\n",
      "Epoch [200/500] | Train Loss: 0.401404 | Val Loss: 0.293596\n",
      "Epoch [300/500] | Train Loss: 0.357060 | Val Loss: 0.302007\n",
      "Epoch [400/500] | Train Loss: 0.337217 | Val Loss: 0.317822\n",
      "Epoch [500/500] | Train Loss: 0.314638 | Val Loss: 0.323994\n",
      "Epoch [100/500] | Train Loss: 0.425079 | Val Loss: 0.279600\n",
      "Epoch [200/500] | Train Loss: 0.385366 | Val Loss: 0.288770\n",
      "Epoch [300/500] | Train Loss: 0.350827 | Val Loss: 0.306552\n",
      "Epoch [400/500] | Train Loss: 0.315819 | Val Loss: 0.323016\n",
      "Epoch [500/500] | Train Loss: 0.296171 | Val Loss: 0.339581\n",
      "Epoch [100/500] | Train Loss: 0.403859 | Val Loss: 0.248625\n",
      "Epoch [200/500] | Train Loss: 0.379752 | Val Loss: 0.252088\n",
      "Epoch [300/500] | Train Loss: 0.356699 | Val Loss: 0.266141\n",
      "Epoch [400/500] | Train Loss: 0.338543 | Val Loss: 0.281403\n",
      "Epoch [500/500] | Train Loss: 0.317200 | Val Loss: 0.288019\n",
      "Epoch [100/500] | Train Loss: 0.342897 | Val Loss: 0.617117\n",
      "Epoch [200/500] | Train Loss: 0.232203 | Val Loss: 0.622400\n",
      "Epoch [300/500] | Train Loss: 0.211071 | Val Loss: 0.772311\n",
      "Epoch [400/500] | Train Loss: 0.174776 | Val Loss: 0.730710\n",
      "Epoch [500/500] | Train Loss: 0.153689 | Val Loss: 0.722764\n",
      "Epoch [100/500] | Train Loss: 0.366333 | Val Loss: 0.406950\n",
      "Epoch [200/500] | Train Loss: 0.239558 | Val Loss: 0.415379\n",
      "Epoch [300/500] | Train Loss: 0.199338 | Val Loss: 0.486271\n",
      "Epoch [400/500] | Train Loss: 0.200830 | Val Loss: 0.507628\n",
      "Epoch [500/500] | Train Loss: 0.169191 | Val Loss: 0.542366\n",
      "Epoch [100/500] | Train Loss: 0.376757 | Val Loss: 0.304011\n",
      "Epoch [200/500] | Train Loss: 0.307692 | Val Loss: 0.336228\n",
      "Epoch [300/500] | Train Loss: 0.238203 | Val Loss: 0.347831\n",
      "Epoch [400/500] | Train Loss: 0.228710 | Val Loss: 0.352582\n",
      "Epoch [500/500] | Train Loss: 0.209088 | Val Loss: 0.344351\n",
      "Epoch [100/500] | Train Loss: 0.329773 | Val Loss: 0.361670\n",
      "Epoch [200/500] | Train Loss: 0.270624 | Val Loss: 0.358369\n",
      "Epoch [300/500] | Train Loss: 0.252837 | Val Loss: 0.361065\n",
      "Epoch [400/500] | Train Loss: 0.225271 | Val Loss: 0.378794\n",
      "Epoch [500/500] | Train Loss: 0.220947 | Val Loss: 0.374480\n",
      "Epoch [100/500] | Train Loss: 0.322408 | Val Loss: 0.273538\n",
      "Epoch [200/500] | Train Loss: 0.256794 | Val Loss: 0.314170\n",
      "Epoch [300/500] | Train Loss: 0.244452 | Val Loss: 0.329544\n",
      "Epoch [400/500] | Train Loss: 0.238812 | Val Loss: 0.334737\n",
      "Epoch [500/500] | Train Loss: 0.221785 | Val Loss: 0.338621\n",
      "Epoch [100/500] | Train Loss: 0.591451 | Val Loss: 0.474134\n",
      "Epoch [200/500] | Train Loss: 0.552145 | Val Loss: 0.495230\n",
      "Epoch [300/500] | Train Loss: 0.513420 | Val Loss: 0.513357\n",
      "Epoch [400/500] | Train Loss: 0.449779 | Val Loss: 0.544173\n",
      "Epoch [500/500] | Train Loss: 0.451003 | Val Loss: 0.576361\n",
      "Epoch [100/500] | Train Loss: 0.538949 | Val Loss: 0.328682\n",
      "Epoch [200/500] | Train Loss: 0.505583 | Val Loss: 0.339550\n",
      "Epoch [300/500] | Train Loss: 0.475777 | Val Loss: 0.345305\n",
      "Epoch [400/500] | Train Loss: 0.460005 | Val Loss: 0.354743\n",
      "Epoch [500/500] | Train Loss: 0.438542 | Val Loss: 0.363307\n",
      "Epoch [100/500] | Train Loss: 0.473215 | Val Loss: 0.285178\n",
      "Epoch [200/500] | Train Loss: 0.447004 | Val Loss: 0.280442\n",
      "Epoch [300/500] | Train Loss: 0.442727 | Val Loss: 0.276071\n",
      "Epoch [400/500] | Train Loss: 0.405783 | Val Loss: 0.272067\n",
      "Epoch [500/500] | Train Loss: 0.391510 | Val Loss: 0.278002\n",
      "Epoch [100/500] | Train Loss: 0.429921 | Val Loss: 0.278079\n",
      "Epoch [200/500] | Train Loss: 0.401446 | Val Loss: 0.287340\n",
      "Epoch [300/500] | Train Loss: 0.392407 | Val Loss: 0.298107\n",
      "Epoch [400/500] | Train Loss: 0.383251 | Val Loss: 0.300740\n",
      "Epoch [500/500] | Train Loss: 0.362304 | Val Loss: 0.311105\n",
      "Epoch [100/500] | Train Loss: 0.389597 | Val Loss: 0.247454\n",
      "Epoch [200/500] | Train Loss: 0.381170 | Val Loss: 0.253205\n",
      "Epoch [300/500] | Train Loss: 0.361725 | Val Loss: 0.256922\n",
      "Epoch [400/500] | Train Loss: 0.349708 | Val Loss: 0.262005\n",
      "Epoch [500/500] | Train Loss: 0.337194 | Val Loss: 0.269756\n",
      "Epoch [100/500] | Train Loss: 0.554031 | Val Loss: 0.503361\n",
      "Epoch [200/500] | Train Loss: 0.417800 | Val Loss: 0.631012\n",
      "Epoch [300/500] | Train Loss: 0.341259 | Val Loss: 0.615486\n",
      "Epoch [400/500] | Train Loss: 0.321328 | Val Loss: 0.600420\n",
      "Epoch [500/500] | Train Loss: 0.268767 | Val Loss: 0.547682\n",
      "Epoch [100/500] | Train Loss: 0.513096 | Val Loss: 0.336259\n",
      "Epoch [200/500] | Train Loss: 0.451576 | Val Loss: 0.370698\n",
      "Epoch [300/500] | Train Loss: 0.344497 | Val Loss: 0.410365\n",
      "Epoch [400/500] | Train Loss: 0.330924 | Val Loss: 0.402106\n",
      "Epoch [500/500] | Train Loss: 0.296001 | Val Loss: 0.411353\n",
      "Epoch [100/500] | Train Loss: 0.416214 | Val Loss: 0.289896\n",
      "Epoch [200/500] | Train Loss: 0.332783 | Val Loss: 0.301776\n",
      "Epoch [300/500] | Train Loss: 0.311971 | Val Loss: 0.313615\n",
      "Epoch [400/500] | Train Loss: 0.294977 | Val Loss: 0.318606\n",
      "Epoch [500/500] | Train Loss: 0.262825 | Val Loss: 0.320885\n",
      "Epoch [100/500] | Train Loss: 0.388927 | Val Loss: 0.286226\n",
      "Epoch [200/500] | Train Loss: 0.355166 | Val Loss: 0.313922\n",
      "Epoch [300/500] | Train Loss: 0.328482 | Val Loss: 0.316232\n",
      "Epoch [400/500] | Train Loss: 0.312952 | Val Loss: 0.318446\n",
      "Epoch [500/500] | Train Loss: 0.310344 | Val Loss: 0.304235\n",
      "Epoch [100/500] | Train Loss: 0.376182 | Val Loss: 0.255252\n",
      "Epoch [200/500] | Train Loss: 0.356732 | Val Loss: 0.287324\n",
      "Epoch [300/500] | Train Loss: 0.321665 | Val Loss: 0.285384\n",
      "Epoch [400/500] | Train Loss: 0.287647 | Val Loss: 0.294722\n",
      "Epoch [500/500] | Train Loss: 0.297921 | Val Loss: 0.298885\n",
      "[Year=1996] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.354128 Test MSE=0.499538\n",
      "Year 1996 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.330112 | Val Loss: 0.288784\n",
      "Epoch [200/500] | Train Loss: 0.296940 | Val Loss: 0.322010\n",
      "Epoch [300/500] | Train Loss: 0.240558 | Val Loss: 0.352433\n",
      "Epoch [400/500] | Train Loss: 0.211593 | Val Loss: 0.350972\n",
      "Epoch [500/500] | Train Loss: 0.214437 | Val Loss: 0.369657\n",
      "Epoch [100/500] | Train Loss: 0.328388 | Val Loss: 0.324775\n",
      "Epoch [200/500] | Train Loss: 0.326473 | Val Loss: 0.323193\n",
      "Epoch [300/500] | Train Loss: 0.306249 | Val Loss: 0.325314\n",
      "Epoch [400/500] | Train Loss: 0.294225 | Val Loss: 0.324600\n",
      "Epoch [500/500] | Train Loss: 0.272875 | Val Loss: 0.331341\n",
      "Epoch [100/500] | Train Loss: 0.321859 | Val Loss: 0.238920\n",
      "Epoch [200/500] | Train Loss: 0.294809 | Val Loss: 0.248895\n",
      "Epoch [300/500] | Train Loss: 0.272803 | Val Loss: 0.258145\n",
      "Epoch [400/500] | Train Loss: 0.264231 | Val Loss: 0.262752\n",
      "Epoch [500/500] | Train Loss: 0.248553 | Val Loss: 0.268081\n",
      "Epoch [100/500] | Train Loss: 0.291110 | Val Loss: 0.326177\n",
      "Epoch [200/500] | Train Loss: 0.279694 | Val Loss: 0.343938\n",
      "Epoch [300/500] | Train Loss: 0.263351 | Val Loss: 0.347732\n",
      "Epoch [400/500] | Train Loss: 0.254753 | Val Loss: 0.348481\n",
      "Epoch [500/500] | Train Loss: 0.236869 | Val Loss: 0.357487\n",
      "Epoch [100/500] | Train Loss: 0.314374 | Val Loss: 0.478943\n",
      "Epoch [200/500] | Train Loss: 0.302444 | Val Loss: 0.485046\n",
      "Epoch [300/500] | Train Loss: 0.285415 | Val Loss: 0.494680\n",
      "Epoch [400/500] | Train Loss: 0.281743 | Val Loss: 0.501226\n",
      "Epoch [500/500] | Train Loss: 0.275924 | Val Loss: 0.500823\n",
      "Epoch [100/500] | Train Loss: 0.288868 | Val Loss: 0.348109\n",
      "Epoch [200/500] | Train Loss: 0.180248 | Val Loss: 0.376684\n",
      "Epoch [300/500] | Train Loss: 0.164646 | Val Loss: 0.389291\n",
      "Epoch [400/500] | Train Loss: 0.121894 | Val Loss: 0.394940\n",
      "Epoch [500/500] | Train Loss: 0.113082 | Val Loss: 0.380510\n",
      "Epoch [100/500] | Train Loss: 0.268575 | Val Loss: 0.341103\n",
      "Epoch [200/500] | Train Loss: 0.230054 | Val Loss: 0.360060\n",
      "Epoch [300/500] | Train Loss: 0.164945 | Val Loss: 0.398044\n",
      "Epoch [400/500] | Train Loss: 0.146440 | Val Loss: 0.408361\n",
      "Epoch [500/500] | Train Loss: 0.155279 | Val Loss: 0.419286\n",
      "Epoch [100/500] | Train Loss: 0.261880 | Val Loss: 0.280072\n",
      "Epoch [200/500] | Train Loss: 0.220587 | Val Loss: 0.292632\n",
      "Epoch [300/500] | Train Loss: 0.200761 | Val Loss: 0.296910\n",
      "Epoch [400/500] | Train Loss: 0.203404 | Val Loss: 0.317385\n",
      "Epoch [500/500] | Train Loss: 0.172157 | Val Loss: 0.300850\n",
      "Epoch [100/500] | Train Loss: 0.253849 | Val Loss: 0.348774\n",
      "Epoch [200/500] | Train Loss: 0.221551 | Val Loss: 0.390164\n",
      "Epoch [300/500] | Train Loss: 0.195541 | Val Loss: 0.429122\n",
      "Epoch [400/500] | Train Loss: 0.189397 | Val Loss: 0.434420\n",
      "Epoch [500/500] | Train Loss: 0.160072 | Val Loss: 0.416629\n",
      "Epoch [100/500] | Train Loss: 0.268806 | Val Loss: 0.515576\n",
      "Epoch [200/500] | Train Loss: 0.236402 | Val Loss: 0.517382\n",
      "Epoch [300/500] | Train Loss: 0.207751 | Val Loss: 0.538267\n",
      "Epoch [400/500] | Train Loss: 0.219154 | Val Loss: 0.544558\n",
      "Epoch [500/500] | Train Loss: 0.200408 | Val Loss: 0.584301\n",
      "Epoch [100/500] | Train Loss: 0.359984 | Val Loss: 0.280401\n",
      "Epoch [200/500] | Train Loss: 0.325460 | Val Loss: 0.298058\n",
      "Epoch [300/500] | Train Loss: 0.312439 | Val Loss: 0.308426\n",
      "Epoch [400/500] | Train Loss: 0.307689 | Val Loss: 0.303455\n",
      "Epoch [500/500] | Train Loss: 0.272014 | Val Loss: 0.309283\n",
      "Epoch [100/500] | Train Loss: 0.329555 | Val Loss: 0.329598\n",
      "Epoch [200/500] | Train Loss: 0.326584 | Val Loss: 0.321795\n",
      "Epoch [300/500] | Train Loss: 0.309923 | Val Loss: 0.313824\n",
      "Epoch [400/500] | Train Loss: 0.294527 | Val Loss: 0.320160\n",
      "Epoch [500/500] | Train Loss: 0.278124 | Val Loss: 0.321483\n",
      "Epoch [100/500] | Train Loss: 0.321779 | Val Loss: 0.234443\n",
      "Epoch [200/500] | Train Loss: 0.319090 | Val Loss: 0.236100\n",
      "Epoch [300/500] | Train Loss: 0.302759 | Val Loss: 0.241112\n",
      "Epoch [400/500] | Train Loss: 0.294394 | Val Loss: 0.243616\n",
      "Epoch [500/500] | Train Loss: 0.284499 | Val Loss: 0.245512\n",
      "Epoch [100/500] | Train Loss: 0.302299 | Val Loss: 0.323142\n",
      "Epoch [200/500] | Train Loss: 0.298521 | Val Loss: 0.322350\n",
      "Epoch [300/500] | Train Loss: 0.293603 | Val Loss: 0.327117\n",
      "Epoch [400/500] | Train Loss: 0.279813 | Val Loss: 0.330840\n",
      "Epoch [500/500] | Train Loss: 0.273037 | Val Loss: 0.331206\n",
      "Epoch [100/500] | Train Loss: 0.307218 | Val Loss: 0.477902\n",
      "Epoch [200/500] | Train Loss: 0.299473 | Val Loss: 0.480617\n",
      "Epoch [300/500] | Train Loss: 0.293222 | Val Loss: 0.480749\n",
      "Epoch [400/500] | Train Loss: 0.291080 | Val Loss: 0.476614\n",
      "Epoch [500/500] | Train Loss: 0.275418 | Val Loss: 0.476082\n",
      "Epoch [100/500] | Train Loss: 0.305898 | Val Loss: 0.310764\n",
      "Epoch [200/500] | Train Loss: 0.239850 | Val Loss: 0.342914\n",
      "Epoch [300/500] | Train Loss: 0.201999 | Val Loss: 0.363052\n",
      "Epoch [400/500] | Train Loss: 0.173878 | Val Loss: 0.406392\n",
      "Epoch [500/500] | Train Loss: 0.178616 | Val Loss: 0.414379\n",
      "Epoch [100/500] | Train Loss: 0.281493 | Val Loss: 0.325916\n",
      "Epoch [200/500] | Train Loss: 0.226323 | Val Loss: 0.357845\n",
      "Epoch [300/500] | Train Loss: 0.224969 | Val Loss: 0.356028\n",
      "Epoch [400/500] | Train Loss: 0.219041 | Val Loss: 0.374167\n",
      "Epoch [500/500] | Train Loss: 0.219518 | Val Loss: 0.374050\n",
      "Epoch [100/500] | Train Loss: 0.296136 | Val Loss: 0.252023\n",
      "Epoch [200/500] | Train Loss: 0.270558 | Val Loss: 0.253173\n",
      "Epoch [300/500] | Train Loss: 0.263845 | Val Loss: 0.260564\n",
      "Epoch [400/500] | Train Loss: 0.264902 | Val Loss: 0.289131\n",
      "Epoch [500/500] | Train Loss: 0.232385 | Val Loss: 0.289972\n",
      "Epoch [100/500] | Train Loss: 0.285469 | Val Loss: 0.353986\n",
      "Epoch [200/500] | Train Loss: 0.262182 | Val Loss: 0.364235\n",
      "Epoch [300/500] | Train Loss: 0.250560 | Val Loss: 0.365332\n",
      "Epoch [400/500] | Train Loss: 0.250921 | Val Loss: 0.362293\n",
      "Epoch [500/500] | Train Loss: 0.226061 | Val Loss: 0.359542\n",
      "Epoch [100/500] | Train Loss: 0.281804 | Val Loss: 0.499078\n",
      "Epoch [200/500] | Train Loss: 0.269212 | Val Loss: 0.512641\n",
      "Epoch [300/500] | Train Loss: 0.252784 | Val Loss: 0.541030\n",
      "Epoch [400/500] | Train Loss: 0.239460 | Val Loss: 0.528824\n",
      "Epoch [500/500] | Train Loss: 0.229362 | Val Loss: 0.514407\n",
      "Epoch [100/500] | Train Loss: 0.349120 | Val Loss: 0.296577\n",
      "Epoch [200/500] | Train Loss: 0.290617 | Val Loss: 0.332921\n",
      "Epoch [300/500] | Train Loss: 0.247767 | Val Loss: 0.334719\n",
      "Epoch [400/500] | Train Loss: 0.200033 | Val Loss: 0.352610\n",
      "Epoch [500/500] | Train Loss: 0.182768 | Val Loss: 0.367065\n",
      "Epoch [100/500] | Train Loss: 0.312230 | Val Loss: 0.316133\n",
      "Epoch [200/500] | Train Loss: 0.252273 | Val Loss: 0.325741\n",
      "Epoch [300/500] | Train Loss: 0.253969 | Val Loss: 0.340027\n",
      "Epoch [400/500] | Train Loss: 0.200931 | Val Loss: 0.357699\n",
      "Epoch [500/500] | Train Loss: 0.183151 | Val Loss: 0.370813\n",
      "Epoch [100/500] | Train Loss: 0.305083 | Val Loss: 0.242857\n",
      "Epoch [200/500] | Train Loss: 0.266722 | Val Loss: 0.271497\n",
      "Epoch [300/500] | Train Loss: 0.244019 | Val Loss: 0.284493\n",
      "Epoch [400/500] | Train Loss: 0.238107 | Val Loss: 0.294949\n",
      "Epoch [500/500] | Train Loss: 0.215117 | Val Loss: 0.297496\n",
      "Epoch [100/500] | Train Loss: 0.302718 | Val Loss: 0.322875\n",
      "Epoch [200/500] | Train Loss: 0.278758 | Val Loss: 0.321813\n",
      "Epoch [300/500] | Train Loss: 0.269827 | Val Loss: 0.335021\n",
      "Epoch [400/500] | Train Loss: 0.257055 | Val Loss: 0.346757\n",
      "Epoch [500/500] | Train Loss: 0.236222 | Val Loss: 0.362886\n",
      "Epoch [100/500] | Train Loss: 0.294715 | Val Loss: 0.493931\n",
      "Epoch [200/500] | Train Loss: 0.274324 | Val Loss: 0.531114\n",
      "Epoch [300/500] | Train Loss: 0.257697 | Val Loss: 0.542886\n",
      "Epoch [400/500] | Train Loss: 0.247173 | Val Loss: 0.553592\n",
      "Epoch [500/500] | Train Loss: 0.233090 | Val Loss: 0.551335\n",
      "Epoch [100/500] | Train Loss: 0.213282 | Val Loss: 0.352715\n",
      "Epoch [200/500] | Train Loss: 0.160731 | Val Loss: 0.365009\n",
      "Epoch [300/500] | Train Loss: 0.137787 | Val Loss: 0.377349\n",
      "Epoch [400/500] | Train Loss: 0.104326 | Val Loss: 0.395706\n",
      "Epoch [500/500] | Train Loss: 0.122306 | Val Loss: 0.403798\n",
      "Epoch [100/500] | Train Loss: 0.244586 | Val Loss: 0.373268\n",
      "Epoch [200/500] | Train Loss: 0.171956 | Val Loss: 0.395732\n",
      "Epoch [300/500] | Train Loss: 0.134192 | Val Loss: 0.414102\n",
      "Epoch [400/500] | Train Loss: 0.143666 | Val Loss: 0.424841\n",
      "Epoch [500/500] | Train Loss: 0.128686 | Val Loss: 0.421986\n",
      "Epoch [100/500] | Train Loss: 0.261421 | Val Loss: 0.249885\n",
      "Epoch [200/500] | Train Loss: 0.221887 | Val Loss: 0.302704\n",
      "Epoch [300/500] | Train Loss: 0.204360 | Val Loss: 0.292655\n",
      "Epoch [400/500] | Train Loss: 0.173908 | Val Loss: 0.287389\n",
      "Epoch [500/500] | Train Loss: 0.170534 | Val Loss: 0.349827\n",
      "Epoch [100/500] | Train Loss: 0.222752 | Val Loss: 0.378249\n",
      "Epoch [200/500] | Train Loss: 0.192167 | Val Loss: 0.391849\n",
      "Epoch [300/500] | Train Loss: 0.162059 | Val Loss: 0.380704\n",
      "Epoch [400/500] | Train Loss: 0.165619 | Val Loss: 0.387814\n",
      "Epoch [500/500] | Train Loss: 0.171240 | Val Loss: 0.394604\n",
      "Epoch [100/500] | Train Loss: 0.292152 | Val Loss: 0.490472\n",
      "Epoch [200/500] | Train Loss: 0.263369 | Val Loss: 0.522492\n",
      "Epoch [300/500] | Train Loss: 0.227298 | Val Loss: 0.532045\n",
      "Epoch [400/500] | Train Loss: 0.201227 | Val Loss: 0.548709\n",
      "Epoch [500/500] | Train Loss: 0.188331 | Val Loss: 0.549303\n",
      "Epoch [100/500] | Train Loss: 0.366282 | Val Loss: 0.280022\n",
      "Epoch [200/500] | Train Loss: 0.326694 | Val Loss: 0.304760\n",
      "Epoch [300/500] | Train Loss: 0.289789 | Val Loss: 0.316732\n",
      "Epoch [400/500] | Train Loss: 0.283411 | Val Loss: 0.323031\n",
      "Epoch [500/500] | Train Loss: 0.233254 | Val Loss: 0.330872\n",
      "Epoch [100/500] | Train Loss: 0.327067 | Val Loss: 0.325799\n",
      "Epoch [200/500] | Train Loss: 0.300530 | Val Loss: 0.323109\n",
      "Epoch [300/500] | Train Loss: 0.288065 | Val Loss: 0.327531\n",
      "Epoch [400/500] | Train Loss: 0.274969 | Val Loss: 0.331344\n",
      "Epoch [500/500] | Train Loss: 0.245907 | Val Loss: 0.335461\n",
      "Epoch [100/500] | Train Loss: 0.323103 | Val Loss: 0.233341\n",
      "Epoch [200/500] | Train Loss: 0.309740 | Val Loss: 0.237910\n",
      "Epoch [300/500] | Train Loss: 0.297360 | Val Loss: 0.249796\n",
      "Epoch [400/500] | Train Loss: 0.288002 | Val Loss: 0.257887\n",
      "Epoch [500/500] | Train Loss: 0.266531 | Val Loss: 0.265604\n",
      "Epoch [100/500] | Train Loss: 0.294340 | Val Loss: 0.324968\n",
      "Epoch [200/500] | Train Loss: 0.278029 | Val Loss: 0.334834\n",
      "Epoch [300/500] | Train Loss: 0.271891 | Val Loss: 0.345961\n",
      "Epoch [400/500] | Train Loss: 0.257104 | Val Loss: 0.352326\n",
      "Epoch [500/500] | Train Loss: 0.245260 | Val Loss: 0.358815\n",
      "Epoch [100/500] | Train Loss: 0.306026 | Val Loss: 0.482137\n",
      "Epoch [200/500] | Train Loss: 0.297228 | Val Loss: 0.486707\n",
      "Epoch [300/500] | Train Loss: 0.286793 | Val Loss: 0.499050\n",
      "Epoch [400/500] | Train Loss: 0.282423 | Val Loss: 0.511522\n",
      "Epoch [500/500] | Train Loss: 0.274146 | Val Loss: 0.520141\n",
      "Epoch [100/500] | Train Loss: 0.310338 | Val Loss: 0.315398\n",
      "Epoch [200/500] | Train Loss: 0.271387 | Val Loss: 0.334899\n",
      "Epoch [300/500] | Train Loss: 0.188718 | Val Loss: 0.359985\n",
      "Epoch [400/500] | Train Loss: 0.174423 | Val Loss: 0.365636\n",
      "Epoch [500/500] | Train Loss: 0.164440 | Val Loss: 0.353172\n",
      "Epoch [100/500] | Train Loss: 0.282196 | Val Loss: 0.321791\n",
      "Epoch [200/500] | Train Loss: 0.250558 | Val Loss: 0.362034\n",
      "Epoch [300/500] | Train Loss: 0.226767 | Val Loss: 0.369050\n",
      "Epoch [400/500] | Train Loss: 0.208965 | Val Loss: 0.367926\n",
      "Epoch [500/500] | Train Loss: 0.195794 | Val Loss: 0.358066\n",
      "Epoch [100/500] | Train Loss: 0.292496 | Val Loss: 0.243165\n",
      "Epoch [200/500] | Train Loss: 0.251743 | Val Loss: 0.282200\n",
      "Epoch [300/500] | Train Loss: 0.220047 | Val Loss: 0.273675\n",
      "Epoch [400/500] | Train Loss: 0.215749 | Val Loss: 0.294343\n",
      "Epoch [500/500] | Train Loss: 0.212397 | Val Loss: 0.291074\n",
      "Epoch [100/500] | Train Loss: 0.262360 | Val Loss: 0.357047\n",
      "Epoch [200/500] | Train Loss: 0.255312 | Val Loss: 0.359103\n",
      "Epoch [300/500] | Train Loss: 0.223906 | Val Loss: 0.367248\n",
      "Epoch [400/500] | Train Loss: 0.218033 | Val Loss: 0.391625\n",
      "Epoch [500/500] | Train Loss: 0.215548 | Val Loss: 0.397606\n",
      "Epoch [100/500] | Train Loss: 0.288432 | Val Loss: 0.500943\n",
      "Epoch [200/500] | Train Loss: 0.257142 | Val Loss: 0.511081\n",
      "Epoch [300/500] | Train Loss: 0.244457 | Val Loss: 0.515537\n",
      "Epoch [400/500] | Train Loss: 0.232415 | Val Loss: 0.524817\n",
      "Epoch [500/500] | Train Loss: 0.244667 | Val Loss: 0.526299\n",
      "[Year=1997] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.336713 Test MSE=0.993729\n",
      "Year 1997 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.295941 | Val Loss: 0.307436\n",
      "Epoch [200/500] | Train Loss: 0.271021 | Val Loss: 0.317825\n",
      "Epoch [300/500] | Train Loss: 0.257949 | Val Loss: 0.328426\n",
      "Epoch [400/500] | Train Loss: 0.232418 | Val Loss: 0.344271\n",
      "Epoch [500/500] | Train Loss: 0.201467 | Val Loss: 0.353793\n",
      "Epoch [100/500] | Train Loss: 0.288660 | Val Loss: 0.262654\n",
      "Epoch [200/500] | Train Loss: 0.273521 | Val Loss: 0.269989\n",
      "Epoch [300/500] | Train Loss: 0.271454 | Val Loss: 0.278293\n",
      "Epoch [400/500] | Train Loss: 0.232136 | Val Loss: 0.299770\n",
      "Epoch [500/500] | Train Loss: 0.212475 | Val Loss: 0.310455\n",
      "Epoch [100/500] | Train Loss: 0.280867 | Val Loss: 0.373559\n",
      "Epoch [200/500] | Train Loss: 0.270221 | Val Loss: 0.388597\n",
      "Epoch [300/500] | Train Loss: 0.260441 | Val Loss: 0.396349\n",
      "Epoch [400/500] | Train Loss: 0.251319 | Val Loss: 0.410486\n",
      "Epoch [500/500] | Train Loss: 0.230839 | Val Loss: 0.429675\n",
      "Epoch [100/500] | Train Loss: 0.301844 | Val Loss: 0.468025\n",
      "Epoch [200/500] | Train Loss: 0.286828 | Val Loss: 0.486187\n",
      "Epoch [300/500] | Train Loss: 0.267149 | Val Loss: 0.491040\n",
      "Epoch [400/500] | Train Loss: 0.268942 | Val Loss: 0.507201\n",
      "Epoch [500/500] | Train Loss: 0.261583 | Val Loss: 0.501640\n",
      "Epoch [100/500] | Train Loss: 0.341845 | Val Loss: 1.121697\n",
      "Epoch [200/500] | Train Loss: 0.320995 | Val Loss: 1.152521\n",
      "Epoch [300/500] | Train Loss: 0.308555 | Val Loss: 1.180915\n",
      "Epoch [400/500] | Train Loss: 0.292502 | Val Loss: 1.167135\n",
      "Epoch [500/500] | Train Loss: 0.287659 | Val Loss: 1.180128\n",
      "Epoch [100/500] | Train Loss: 0.263956 | Val Loss: 0.316388\n",
      "Epoch [200/500] | Train Loss: 0.185120 | Val Loss: 0.336746\n",
      "Epoch [300/500] | Train Loss: 0.196703 | Val Loss: 0.340532\n",
      "Epoch [400/500] | Train Loss: 0.200176 | Val Loss: 0.376505\n",
      "Epoch [500/500] | Train Loss: 0.133974 | Val Loss: 0.390134\n",
      "Epoch [100/500] | Train Loss: 0.260384 | Val Loss: 0.272370\n",
      "Epoch [200/500] | Train Loss: 0.211440 | Val Loss: 0.308528\n",
      "Epoch [300/500] | Train Loss: 0.169350 | Val Loss: 0.330497\n",
      "Epoch [400/500] | Train Loss: 0.149710 | Val Loss: 0.353072\n",
      "Epoch [500/500] | Train Loss: 0.164671 | Val Loss: 0.341685\n",
      "Epoch [100/500] | Train Loss: 0.253467 | Val Loss: 0.396173\n",
      "Epoch [200/500] | Train Loss: 0.223560 | Val Loss: 0.412053\n",
      "Epoch [300/500] | Train Loss: 0.193812 | Val Loss: 0.426885\n",
      "Epoch [400/500] | Train Loss: 0.183911 | Val Loss: 0.422251\n",
      "Epoch [500/500] | Train Loss: 0.174421 | Val Loss: 0.421312\n",
      "Epoch [100/500] | Train Loss: 0.270108 | Val Loss: 0.479027\n",
      "Epoch [200/500] | Train Loss: 0.238704 | Val Loss: 0.520444\n",
      "Epoch [300/500] | Train Loss: 0.221681 | Val Loss: 0.507477\n",
      "Epoch [400/500] | Train Loss: 0.216802 | Val Loss: 0.528951\n",
      "Epoch [500/500] | Train Loss: 0.187501 | Val Loss: 0.534659\n",
      "Epoch [100/500] | Train Loss: 0.341370 | Val Loss: 1.160385\n",
      "Epoch [200/500] | Train Loss: 0.283303 | Val Loss: 1.361470\n",
      "Epoch [300/500] | Train Loss: 0.275944 | Val Loss: 1.354769\n",
      "Epoch [400/500] | Train Loss: 0.250004 | Val Loss: 1.274875\n",
      "Epoch [500/500] | Train Loss: 0.241984 | Val Loss: 1.267475\n",
      "Epoch [100/500] | Train Loss: 0.297194 | Val Loss: 0.307261\n",
      "Epoch [200/500] | Train Loss: 0.282965 | Val Loss: 0.312147\n",
      "Epoch [300/500] | Train Loss: 0.267910 | Val Loss: 0.311650\n",
      "Epoch [400/500] | Train Loss: 0.240104 | Val Loss: 0.317752\n",
      "Epoch [500/500] | Train Loss: 0.255701 | Val Loss: 0.320190\n",
      "Epoch [100/500] | Train Loss: 0.310702 | Val Loss: 0.270077\n",
      "Epoch [200/500] | Train Loss: 0.291752 | Val Loss: 0.265700\n",
      "Epoch [300/500] | Train Loss: 0.284635 | Val Loss: 0.267587\n",
      "Epoch [400/500] | Train Loss: 0.282389 | Val Loss: 0.270883\n",
      "Epoch [500/500] | Train Loss: 0.272202 | Val Loss: 0.276553\n",
      "Epoch [100/500] | Train Loss: 0.284432 | Val Loss: 0.374256\n",
      "Epoch [200/500] | Train Loss: 0.278917 | Val Loss: 0.377502\n",
      "Epoch [300/500] | Train Loss: 0.268987 | Val Loss: 0.382823\n",
      "Epoch [400/500] | Train Loss: 0.262203 | Val Loss: 0.387407\n",
      "Epoch [500/500] | Train Loss: 0.265114 | Val Loss: 0.387024\n",
      "Epoch [100/500] | Train Loss: 0.308981 | Val Loss: 0.466275\n",
      "Epoch [200/500] | Train Loss: 0.300143 | Val Loss: 0.464018\n",
      "Epoch [300/500] | Train Loss: 0.297958 | Val Loss: 0.466969\n",
      "Epoch [400/500] | Train Loss: 0.295019 | Val Loss: 0.467535\n",
      "Epoch [500/500] | Train Loss: 0.294243 | Val Loss: 0.472179\n",
      "Epoch [100/500] | Train Loss: 0.358856 | Val Loss: 1.110837\n",
      "Epoch [200/500] | Train Loss: 0.342008 | Val Loss: 1.110765\n",
      "Epoch [300/500] | Train Loss: 0.340067 | Val Loss: 1.111027\n",
      "Epoch [400/500] | Train Loss: 0.335206 | Val Loss: 1.121074\n",
      "Epoch [500/500] | Train Loss: 0.325431 | Val Loss: 1.145725\n",
      "Epoch [100/500] | Train Loss: 0.272200 | Val Loss: 0.299994\n",
      "Epoch [200/500] | Train Loss: 0.232285 | Val Loss: 0.310285\n",
      "Epoch [300/500] | Train Loss: 0.210523 | Val Loss: 0.310812\n",
      "Epoch [400/500] | Train Loss: 0.178813 | Val Loss: 0.333309\n",
      "Epoch [500/500] | Train Loss: 0.155247 | Val Loss: 0.333723\n",
      "Epoch [100/500] | Train Loss: 0.255749 | Val Loss: 0.276826\n",
      "Epoch [200/500] | Train Loss: 0.258275 | Val Loss: 0.292402\n",
      "Epoch [300/500] | Train Loss: 0.200099 | Val Loss: 0.301930\n",
      "Epoch [400/500] | Train Loss: 0.199472 | Val Loss: 0.309179\n",
      "Epoch [500/500] | Train Loss: 0.179889 | Val Loss: 0.326390\n",
      "Epoch [100/500] | Train Loss: 0.272109 | Val Loss: 0.399890\n",
      "Epoch [200/500] | Train Loss: 0.246430 | Val Loss: 0.391491\n",
      "Epoch [300/500] | Train Loss: 0.233447 | Val Loss: 0.399449\n",
      "Epoch [400/500] | Train Loss: 0.233557 | Val Loss: 0.411917\n",
      "Epoch [500/500] | Train Loss: 0.240994 | Val Loss: 0.419665\n",
      "Epoch [100/500] | Train Loss: 0.282557 | Val Loss: 0.485541\n",
      "Epoch [200/500] | Train Loss: 0.266845 | Val Loss: 0.502915\n",
      "Epoch [300/500] | Train Loss: 0.266905 | Val Loss: 0.493830\n",
      "Epoch [400/500] | Train Loss: 0.244034 | Val Loss: 0.522941\n",
      "Epoch [500/500] | Train Loss: 0.229117 | Val Loss: 0.497573\n",
      "Epoch [100/500] | Train Loss: 0.308547 | Val Loss: 1.191088\n",
      "Epoch [200/500] | Train Loss: 0.279023 | Val Loss: 1.278910\n",
      "Epoch [300/500] | Train Loss: 0.284519 | Val Loss: 1.291166\n",
      "Epoch [400/500] | Train Loss: 0.280079 | Val Loss: 1.246681\n",
      "Epoch [500/500] | Train Loss: 0.280495 | Val Loss: 1.277324\n",
      "Epoch [100/500] | Train Loss: 0.268515 | Val Loss: 0.312263\n",
      "Epoch [200/500] | Train Loss: 0.229311 | Val Loss: 0.330507\n",
      "Epoch [300/500] | Train Loss: 0.192890 | Val Loss: 0.338744\n",
      "Epoch [400/500] | Train Loss: 0.164239 | Val Loss: 0.361786\n",
      "Epoch [500/500] | Train Loss: 0.143265 | Val Loss: 0.367558\n",
      "Epoch [100/500] | Train Loss: 0.280709 | Val Loss: 0.267183\n",
      "Epoch [200/500] | Train Loss: 0.266809 | Val Loss: 0.281707\n",
      "Epoch [300/500] | Train Loss: 0.223772 | Val Loss: 0.297617\n",
      "Epoch [400/500] | Train Loss: 0.218022 | Val Loss: 0.311516\n",
      "Epoch [500/500] | Train Loss: 0.178518 | Val Loss: 0.325308\n",
      "Epoch [100/500] | Train Loss: 0.275735 | Val Loss: 0.385091\n",
      "Epoch [200/500] | Train Loss: 0.246565 | Val Loss: 0.420054\n",
      "Epoch [300/500] | Train Loss: 0.228538 | Val Loss: 0.417718\n",
      "Epoch [400/500] | Train Loss: 0.215852 | Val Loss: 0.416680\n",
      "Epoch [500/500] | Train Loss: 0.201542 | Val Loss: 0.421467\n",
      "Epoch [100/500] | Train Loss: 0.291378 | Val Loss: 0.469351\n",
      "Epoch [200/500] | Train Loss: 0.273076 | Val Loss: 0.480485\n",
      "Epoch [300/500] | Train Loss: 0.258523 | Val Loss: 0.492552\n",
      "Epoch [400/500] | Train Loss: 0.246578 | Val Loss: 0.506831\n",
      "Epoch [500/500] | Train Loss: 0.239246 | Val Loss: 0.512499\n",
      "Epoch [100/500] | Train Loss: 0.322670 | Val Loss: 1.142467\n",
      "Epoch [200/500] | Train Loss: 0.304943 | Val Loss: 1.271911\n",
      "Epoch [300/500] | Train Loss: 0.289196 | Val Loss: 1.322415\n",
      "Epoch [400/500] | Train Loss: 0.268708 | Val Loss: 1.348373\n",
      "Epoch [500/500] | Train Loss: 0.263128 | Val Loss: 1.395049\n",
      "Epoch [100/500] | Train Loss: 0.193487 | Val Loss: 0.321780\n",
      "Epoch [200/500] | Train Loss: 0.103739 | Val Loss: 0.378878\n",
      "Epoch [300/500] | Train Loss: 0.095610 | Val Loss: 0.409338\n",
      "Epoch [400/500] | Train Loss: 0.074825 | Val Loss: 0.377929\n",
      "Epoch [500/500] | Train Loss: 0.067413 | Val Loss: 0.408429\n",
      "Epoch [100/500] | Train Loss: 0.261529 | Val Loss: 0.287139\n",
      "Epoch [200/500] | Train Loss: 0.205302 | Val Loss: 0.325981\n",
      "Epoch [300/500] | Train Loss: 0.155612 | Val Loss: 0.354731\n",
      "Epoch [400/500] | Train Loss: 0.140255 | Val Loss: 0.370786\n",
      "Epoch [500/500] | Train Loss: 0.140770 | Val Loss: 0.402956\n",
      "Epoch [100/500] | Train Loss: 0.218520 | Val Loss: 0.419004\n",
      "Epoch [200/500] | Train Loss: 0.180844 | Val Loss: 0.416593\n",
      "Epoch [300/500] | Train Loss: 0.151565 | Val Loss: 0.464292\n",
      "Epoch [400/500] | Train Loss: 0.147172 | Val Loss: 0.458057\n",
      "Epoch [500/500] | Train Loss: 0.131684 | Val Loss: 0.453108\n",
      "Epoch [100/500] | Train Loss: 0.252701 | Val Loss: 0.525948\n",
      "Epoch [200/500] | Train Loss: 0.234473 | Val Loss: 0.552018\n",
      "Epoch [300/500] | Train Loss: 0.207630 | Val Loss: 0.545704\n",
      "Epoch [400/500] | Train Loss: 0.188946 | Val Loss: 0.551568\n",
      "Epoch [500/500] | Train Loss: 0.189452 | Val Loss: 0.567834\n",
      "Epoch [100/500] | Train Loss: 0.291667 | Val Loss: 1.215894\n",
      "Epoch [200/500] | Train Loss: 0.241224 | Val Loss: 1.271788\n",
      "Epoch [300/500] | Train Loss: 0.203969 | Val Loss: 1.216597\n",
      "Epoch [400/500] | Train Loss: 0.198636 | Val Loss: 1.269941\n",
      "Epoch [500/500] | Train Loss: 0.197608 | Val Loss: 1.302489\n",
      "Epoch [100/500] | Train Loss: 0.290039 | Val Loss: 0.308706\n",
      "Epoch [200/500] | Train Loss: 0.274186 | Val Loss: 0.308826\n",
      "Epoch [300/500] | Train Loss: 0.270681 | Val Loss: 0.310203\n",
      "Epoch [400/500] | Train Loss: 0.233412 | Val Loss: 0.320551\n",
      "Epoch [500/500] | Train Loss: 0.228626 | Val Loss: 0.319533\n",
      "Epoch [100/500] | Train Loss: 0.296040 | Val Loss: 0.262222\n",
      "Epoch [200/500] | Train Loss: 0.277567 | Val Loss: 0.264953\n",
      "Epoch [300/500] | Train Loss: 0.261425 | Val Loss: 0.274114\n",
      "Epoch [400/500] | Train Loss: 0.259155 | Val Loss: 0.286582\n",
      "Epoch [500/500] | Train Loss: 0.231668 | Val Loss: 0.292315\n",
      "Epoch [100/500] | Train Loss: 0.280672 | Val Loss: 0.377705\n",
      "Epoch [200/500] | Train Loss: 0.274230 | Val Loss: 0.389528\n",
      "Epoch [300/500] | Train Loss: 0.259585 | Val Loss: 0.396145\n",
      "Epoch [400/500] | Train Loss: 0.246808 | Val Loss: 0.399917\n",
      "Epoch [500/500] | Train Loss: 0.239502 | Val Loss: 0.406515\n",
      "Epoch [100/500] | Train Loss: 0.304997 | Val Loss: 0.464939\n",
      "Epoch [200/500] | Train Loss: 0.296772 | Val Loss: 0.472882\n",
      "Epoch [300/500] | Train Loss: 0.289581 | Val Loss: 0.473784\n",
      "Epoch [400/500] | Train Loss: 0.271027 | Val Loss: 0.482540\n",
      "Epoch [500/500] | Train Loss: 0.265313 | Val Loss: 0.498733\n",
      "Epoch [100/500] | Train Loss: 0.333674 | Val Loss: 1.119671\n",
      "Epoch [200/500] | Train Loss: 0.326023 | Val Loss: 1.137069\n",
      "Epoch [300/500] | Train Loss: 0.314093 | Val Loss: 1.156444\n",
      "Epoch [400/500] | Train Loss: 0.310414 | Val Loss: 1.156353\n",
      "Epoch [500/500] | Train Loss: 0.296495 | Val Loss: 1.171728\n",
      "Epoch [100/500] | Train Loss: 0.212647 | Val Loss: 0.330154\n",
      "Epoch [200/500] | Train Loss: 0.168748 | Val Loss: 0.323835\n",
      "Epoch [300/500] | Train Loss: 0.122653 | Val Loss: 0.349741\n",
      "Epoch [400/500] | Train Loss: 0.113421 | Val Loss: 0.358487\n",
      "Epoch [500/500] | Train Loss: 0.103527 | Val Loss: 0.362229\n",
      "Epoch [100/500] | Train Loss: 0.247264 | Val Loss: 0.288507\n",
      "Epoch [200/500] | Train Loss: 0.210033 | Val Loss: 0.299457\n",
      "Epoch [300/500] | Train Loss: 0.194495 | Val Loss: 0.311991\n",
      "Epoch [400/500] | Train Loss: 0.191527 | Val Loss: 0.321404\n",
      "Epoch [500/500] | Train Loss: 0.153124 | Val Loss: 0.316596\n",
      "Epoch [100/500] | Train Loss: 0.245138 | Val Loss: 0.411748\n",
      "Epoch [200/500] | Train Loss: 0.206977 | Val Loss: 0.429521\n",
      "Epoch [300/500] | Train Loss: 0.209571 | Val Loss: 0.409808\n",
      "Epoch [400/500] | Train Loss: 0.200891 | Val Loss: 0.427516\n",
      "Epoch [500/500] | Train Loss: 0.173197 | Val Loss: 0.440619\n",
      "Epoch [100/500] | Train Loss: 0.286564 | Val Loss: 0.467523\n",
      "Epoch [200/500] | Train Loss: 0.268435 | Val Loss: 0.498405\n",
      "Epoch [300/500] | Train Loss: 0.255611 | Val Loss: 0.504007\n",
      "Epoch [400/500] | Train Loss: 0.233673 | Val Loss: 0.523834\n",
      "Epoch [500/500] | Train Loss: 0.240306 | Val Loss: 0.518456\n",
      "Epoch [100/500] | Train Loss: 0.313083 | Val Loss: 1.179663\n",
      "Epoch [200/500] | Train Loss: 0.265099 | Val Loss: 1.232874\n",
      "Epoch [300/500] | Train Loss: 0.262792 | Val Loss: 1.204225\n",
      "Epoch [400/500] | Train Loss: 0.243254 | Val Loss: 1.176815\n",
      "Epoch [500/500] | Train Loss: 0.227034 | Val Loss: 1.185208\n",
      "[Year=1998] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.520334 Test MSE=1.457224\n",
      "Year 1998 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.317624 | Val Loss: 0.242680\n",
      "Epoch [200/500] | Train Loss: 0.251562 | Val Loss: 0.245005\n",
      "Epoch [300/500] | Train Loss: 0.225194 | Val Loss: 0.254131\n",
      "Epoch [400/500] | Train Loss: 0.222992 | Val Loss: 0.259726\n",
      "Epoch [500/500] | Train Loss: 0.184296 | Val Loss: 0.264738\n",
      "Epoch [100/500] | Train Loss: 0.282620 | Val Loss: 0.392278\n",
      "Epoch [200/500] | Train Loss: 0.254686 | Val Loss: 0.413346\n",
      "Epoch [300/500] | Train Loss: 0.225730 | Val Loss: 0.434983\n",
      "Epoch [400/500] | Train Loss: 0.225300 | Val Loss: 0.440476\n",
      "Epoch [500/500] | Train Loss: 0.211572 | Val Loss: 0.446613\n",
      "Epoch [100/500] | Train Loss: 0.320129 | Val Loss: 0.614649\n",
      "Epoch [200/500] | Train Loss: 0.296325 | Val Loss: 0.649173\n",
      "Epoch [300/500] | Train Loss: 0.282569 | Val Loss: 0.673534\n",
      "Epoch [400/500] | Train Loss: 0.280277 | Val Loss: 0.684366\n",
      "Epoch [500/500] | Train Loss: 0.261662 | Val Loss: 0.677168\n",
      "Epoch [100/500] | Train Loss: 0.383444 | Val Loss: 1.061270\n",
      "Epoch [200/500] | Train Loss: 0.359432 | Val Loss: 1.058876\n",
      "Epoch [300/500] | Train Loss: 0.339527 | Val Loss: 1.154467\n",
      "Epoch [400/500] | Train Loss: 0.340281 | Val Loss: 1.234467\n",
      "Epoch [500/500] | Train Loss: 0.305055 | Val Loss: 1.233336\n",
      "Epoch [100/500] | Train Loss: 0.520009 | Val Loss: 1.680877\n",
      "Epoch [200/500] | Train Loss: 0.490986 | Val Loss: 1.626663\n",
      "Epoch [300/500] | Train Loss: 0.478559 | Val Loss: 1.618802\n",
      "Epoch [400/500] | Train Loss: 0.453215 | Val Loss: 1.611073\n",
      "Epoch [500/500] | Train Loss: 0.451311 | Val Loss: 1.662292\n",
      "Epoch [100/500] | Train Loss: 0.215780 | Val Loss: 0.282004\n",
      "Epoch [200/500] | Train Loss: 0.129704 | Val Loss: 0.324933\n",
      "Epoch [300/500] | Train Loss: 0.119671 | Val Loss: 0.343044\n",
      "Epoch [400/500] | Train Loss: 0.098948 | Val Loss: 0.324649\n",
      "Epoch [500/500] | Train Loss: 0.112597 | Val Loss: 0.308581\n",
      "Epoch [100/500] | Train Loss: 0.247470 | Val Loss: 0.419088\n",
      "Epoch [200/500] | Train Loss: 0.213377 | Val Loss: 0.433630\n",
      "Epoch [300/500] | Train Loss: 0.186200 | Val Loss: 0.437715\n",
      "Epoch [400/500] | Train Loss: 0.141556 | Val Loss: 0.492237\n",
      "Epoch [500/500] | Train Loss: 0.151968 | Val Loss: 0.523578\n",
      "Epoch [100/500] | Train Loss: 0.262555 | Val Loss: 0.688741\n",
      "Epoch [200/500] | Train Loss: 0.213427 | Val Loss: 0.744366\n",
      "Epoch [300/500] | Train Loss: 0.181986 | Val Loss: 0.711129\n",
      "Epoch [400/500] | Train Loss: 0.184746 | Val Loss: 0.737987\n",
      "Epoch [500/500] | Train Loss: 0.170682 | Val Loss: 0.742072\n",
      "Epoch [100/500] | Train Loss: 0.324955 | Val Loss: 1.202317\n",
      "Epoch [200/500] | Train Loss: 0.286411 | Val Loss: 1.191963\n",
      "Epoch [300/500] | Train Loss: 0.271939 | Val Loss: 1.126151\n",
      "Epoch [400/500] | Train Loss: 0.236912 | Val Loss: 1.178654\n",
      "Epoch [500/500] | Train Loss: 0.246627 | Val Loss: 1.120872\n",
      "Epoch [100/500] | Train Loss: 0.434992 | Val Loss: 1.712925\n",
      "Epoch [200/500] | Train Loss: 0.397210 | Val Loss: 1.832317\n",
      "Epoch [300/500] | Train Loss: 0.359374 | Val Loss: 1.817275\n",
      "Epoch [400/500] | Train Loss: 0.345339 | Val Loss: 1.819777\n",
      "Epoch [500/500] | Train Loss: 0.335807 | Val Loss: 1.857170\n",
      "Epoch [100/500] | Train Loss: 0.358019 | Val Loss: 0.248301\n",
      "Epoch [200/500] | Train Loss: 0.323836 | Val Loss: 0.252430\n",
      "Epoch [300/500] | Train Loss: 0.287336 | Val Loss: 0.259992\n",
      "Epoch [400/500] | Train Loss: 0.283807 | Val Loss: 0.267641\n",
      "Epoch [500/500] | Train Loss: 0.268076 | Val Loss: 0.274755\n",
      "Epoch [100/500] | Train Loss: 0.288531 | Val Loss: 0.384541\n",
      "Epoch [200/500] | Train Loss: 0.275222 | Val Loss: 0.389064\n",
      "Epoch [300/500] | Train Loss: 0.265021 | Val Loss: 0.401549\n",
      "Epoch [400/500] | Train Loss: 0.242269 | Val Loss: 0.406144\n",
      "Epoch [500/500] | Train Loss: 0.231468 | Val Loss: 0.414198\n",
      "Epoch [100/500] | Train Loss: 0.320133 | Val Loss: 0.615523\n",
      "Epoch [200/500] | Train Loss: 0.311626 | Val Loss: 0.617408\n",
      "Epoch [300/500] | Train Loss: 0.307850 | Val Loss: 0.627360\n",
      "Epoch [400/500] | Train Loss: 0.288394 | Val Loss: 0.632833\n",
      "Epoch [500/500] | Train Loss: 0.290025 | Val Loss: 0.634342\n",
      "Epoch [100/500] | Train Loss: 0.388175 | Val Loss: 1.063241\n",
      "Epoch [200/500] | Train Loss: 0.380983 | Val Loss: 1.065027\n",
      "Epoch [300/500] | Train Loss: 0.375304 | Val Loss: 1.067527\n",
      "Epoch [400/500] | Train Loss: 0.367976 | Val Loss: 1.060490\n",
      "Epoch [500/500] | Train Loss: 0.364209 | Val Loss: 1.055739\n",
      "Epoch [100/500] | Train Loss: 0.516970 | Val Loss: 1.679508\n",
      "Epoch [200/500] | Train Loss: 0.506941 | Val Loss: 1.606046\n",
      "Epoch [300/500] | Train Loss: 0.484202 | Val Loss: 1.592243\n",
      "Epoch [400/500] | Train Loss: 0.473826 | Val Loss: 1.618631\n",
      "Epoch [500/500] | Train Loss: 0.455841 | Val Loss: 1.676430\n",
      "Epoch [100/500] | Train Loss: 0.261431 | Val Loss: 0.256654\n",
      "Epoch [200/500] | Train Loss: 0.214600 | Val Loss: 0.269548\n",
      "Epoch [300/500] | Train Loss: 0.184509 | Val Loss: 0.273938\n",
      "Epoch [400/500] | Train Loss: 0.182237 | Val Loss: 0.287575\n",
      "Epoch [500/500] | Train Loss: 0.166543 | Val Loss: 0.293576\n",
      "Epoch [100/500] | Train Loss: 0.253579 | Val Loss: 0.414323\n",
      "Epoch [200/500] | Train Loss: 0.206134 | Val Loss: 0.451146\n",
      "Epoch [300/500] | Train Loss: 0.211153 | Val Loss: 0.440185\n",
      "Epoch [400/500] | Train Loss: 0.195020 | Val Loss: 0.443929\n",
      "Epoch [500/500] | Train Loss: 0.182683 | Val Loss: 0.443200\n",
      "Epoch [100/500] | Train Loss: 0.303762 | Val Loss: 0.632084\n",
      "Epoch [200/500] | Train Loss: 0.269777 | Val Loss: 0.631567\n",
      "Epoch [300/500] | Train Loss: 0.255081 | Val Loss: 0.661847\n",
      "Epoch [400/500] | Train Loss: 0.249213 | Val Loss: 0.706521\n",
      "Epoch [500/500] | Train Loss: 0.224577 | Val Loss: 0.704729\n",
      "Epoch [100/500] | Train Loss: 0.371766 | Val Loss: 1.110578\n",
      "Epoch [200/500] | Train Loss: 0.348699 | Val Loss: 1.161783\n",
      "Epoch [300/500] | Train Loss: 0.315410 | Val Loss: 1.177315\n",
      "Epoch [400/500] | Train Loss: 0.316011 | Val Loss: 1.198408\n",
      "Epoch [500/500] | Train Loss: 0.303398 | Val Loss: 1.204429\n",
      "Epoch [100/500] | Train Loss: 0.497243 | Val Loss: 1.695505\n",
      "Epoch [200/500] | Train Loss: 0.464444 | Val Loss: 1.645468\n",
      "Epoch [300/500] | Train Loss: 0.451953 | Val Loss: 1.717054\n",
      "Epoch [400/500] | Train Loss: 0.384407 | Val Loss: 1.739191\n",
      "Epoch [500/500] | Train Loss: 0.388719 | Val Loss: 1.749454\n",
      "Epoch [100/500] | Train Loss: 0.322642 | Val Loss: 0.251429\n",
      "Epoch [200/500] | Train Loss: 0.262780 | Val Loss: 0.282989\n",
      "Epoch [300/500] | Train Loss: 0.172175 | Val Loss: 0.317272\n",
      "Epoch [400/500] | Train Loss: 0.185386 | Val Loss: 0.335691\n",
      "Epoch [500/500] | Train Loss: 0.137438 | Val Loss: 0.335715\n",
      "Epoch [100/500] | Train Loss: 0.291210 | Val Loss: 0.380169\n",
      "Epoch [200/500] | Train Loss: 0.289813 | Val Loss: 0.391165\n",
      "Epoch [300/500] | Train Loss: 0.240880 | Val Loss: 0.434022\n",
      "Epoch [400/500] | Train Loss: 0.217630 | Val Loss: 0.430744\n",
      "Epoch [500/500] | Train Loss: 0.207144 | Val Loss: 0.440761\n",
      "Epoch [100/500] | Train Loss: 0.312712 | Val Loss: 0.617566\n",
      "Epoch [200/500] | Train Loss: 0.271728 | Val Loss: 0.654870\n",
      "Epoch [300/500] | Train Loss: 0.239304 | Val Loss: 0.705599\n",
      "Epoch [400/500] | Train Loss: 0.240061 | Val Loss: 0.731973\n",
      "Epoch [500/500] | Train Loss: 0.225006 | Val Loss: 0.747174\n",
      "Epoch [100/500] | Train Loss: 0.390256 | Val Loss: 1.057478\n",
      "Epoch [200/500] | Train Loss: 0.358415 | Val Loss: 1.096958\n",
      "Epoch [300/500] | Train Loss: 0.329822 | Val Loss: 1.161121\n",
      "Epoch [400/500] | Train Loss: 0.317144 | Val Loss: 1.222328\n",
      "Epoch [500/500] | Train Loss: 0.291116 | Val Loss: 1.239739\n",
      "Epoch [100/500] | Train Loss: 0.539566 | Val Loss: 1.696272\n",
      "Epoch [200/500] | Train Loss: 0.484307 | Val Loss: 1.624398\n",
      "Epoch [300/500] | Train Loss: 0.469517 | Val Loss: 1.640905\n",
      "Epoch [400/500] | Train Loss: 0.451502 | Val Loss: 1.695380\n",
      "Epoch [500/500] | Train Loss: 0.415264 | Val Loss: 1.796005\n",
      "Epoch [100/500] | Train Loss: 0.262121 | Val Loss: 0.283842\n",
      "Epoch [200/500] | Train Loss: 0.193439 | Val Loss: 0.277254\n",
      "Epoch [300/500] | Train Loss: 0.172158 | Val Loss: 0.309871\n",
      "Epoch [400/500] | Train Loss: 0.149245 | Val Loss: 0.327919\n",
      "Epoch [500/500] | Train Loss: 0.146864 | Val Loss: 0.309489\n",
      "Epoch [100/500] | Train Loss: 0.197612 | Val Loss: 0.397498\n",
      "Epoch [200/500] | Train Loss: 0.167575 | Val Loss: 0.469893\n",
      "Epoch [300/500] | Train Loss: 0.136180 | Val Loss: 0.478264\n",
      "Epoch [400/500] | Train Loss: 0.125687 | Val Loss: 0.482375\n",
      "Epoch [500/500] | Train Loss: 0.120880 | Val Loss: 0.518813\n",
      "Epoch [100/500] | Train Loss: 0.233950 | Val Loss: 0.692021\n",
      "Epoch [200/500] | Train Loss: 0.183797 | Val Loss: 0.668152\n",
      "Epoch [300/500] | Train Loss: 0.189338 | Val Loss: 0.706027\n",
      "Epoch [400/500] | Train Loss: 0.161418 | Val Loss: 0.732836\n",
      "Epoch [500/500] | Train Loss: 0.135337 | Val Loss: 0.721848\n",
      "Epoch [100/500] | Train Loss: 0.311463 | Val Loss: 1.308429\n",
      "Epoch [200/500] | Train Loss: 0.252012 | Val Loss: 1.332643\n",
      "Epoch [300/500] | Train Loss: 0.229121 | Val Loss: 1.261572\n",
      "Epoch [400/500] | Train Loss: 0.202579 | Val Loss: 1.422113\n",
      "Epoch [500/500] | Train Loss: 0.204311 | Val Loss: 1.462316\n",
      "Epoch [100/500] | Train Loss: 0.399425 | Val Loss: 1.753802\n",
      "Epoch [200/500] | Train Loss: 0.314647 | Val Loss: 1.881757\n",
      "Epoch [300/500] | Train Loss: 0.299941 | Val Loss: 1.884904\n",
      "Epoch [400/500] | Train Loss: 0.254257 | Val Loss: 1.909662\n",
      "Epoch [500/500] | Train Loss: 0.267476 | Val Loss: 1.958597\n",
      "Epoch [100/500] | Train Loss: 0.350989 | Val Loss: 0.254874\n",
      "Epoch [200/500] | Train Loss: 0.314333 | Val Loss: 0.250495\n",
      "Epoch [300/500] | Train Loss: 0.275008 | Val Loss: 0.254146\n",
      "Epoch [400/500] | Train Loss: 0.251302 | Val Loss: 0.273877\n",
      "Epoch [500/500] | Train Loss: 0.227660 | Val Loss: 0.284435\n",
      "Epoch [100/500] | Train Loss: 0.284601 | Val Loss: 0.389027\n",
      "Epoch [200/500] | Train Loss: 0.272417 | Val Loss: 0.400698\n",
      "Epoch [300/500] | Train Loss: 0.247273 | Val Loss: 0.409321\n",
      "Epoch [400/500] | Train Loss: 0.239439 | Val Loss: 0.415909\n",
      "Epoch [500/500] | Train Loss: 0.236835 | Val Loss: 0.419969\n",
      "Epoch [100/500] | Train Loss: 0.321668 | Val Loss: 0.615835\n",
      "Epoch [200/500] | Train Loss: 0.292488 | Val Loss: 0.650789\n",
      "Epoch [300/500] | Train Loss: 0.289787 | Val Loss: 0.666461\n",
      "Epoch [400/500] | Train Loss: 0.267655 | Val Loss: 0.676440\n",
      "Epoch [500/500] | Train Loss: 0.245219 | Val Loss: 0.692723\n",
      "Epoch [100/500] | Train Loss: 0.386072 | Val Loss: 1.060288\n",
      "Epoch [200/500] | Train Loss: 0.369849 | Val Loss: 1.064157\n",
      "Epoch [300/500] | Train Loss: 0.360646 | Val Loss: 1.100865\n",
      "Epoch [400/500] | Train Loss: 0.343107 | Val Loss: 1.136143\n",
      "Epoch [500/500] | Train Loss: 0.323276 | Val Loss: 1.138601\n",
      "Epoch [100/500] | Train Loss: 0.495804 | Val Loss: 1.667169\n",
      "Epoch [200/500] | Train Loss: 0.492966 | Val Loss: 1.687813\n",
      "Epoch [300/500] | Train Loss: 0.476305 | Val Loss: 1.705397\n",
      "Epoch [400/500] | Train Loss: 0.443262 | Val Loss: 1.729461\n",
      "Epoch [500/500] | Train Loss: 0.432784 | Val Loss: 1.744116\n",
      "Epoch [100/500] | Train Loss: 0.272243 | Val Loss: 0.245116\n",
      "Epoch [200/500] | Train Loss: 0.172348 | Val Loss: 0.277476\n",
      "Epoch [300/500] | Train Loss: 0.149834 | Val Loss: 0.267982\n",
      "Epoch [400/500] | Train Loss: 0.130942 | Val Loss: 0.297436\n",
      "Epoch [500/500] | Train Loss: 0.116106 | Val Loss: 0.305439\n",
      "Epoch [100/500] | Train Loss: 0.239117 | Val Loss: 0.439143\n",
      "Epoch [200/500] | Train Loss: 0.201256 | Val Loss: 0.427622\n",
      "Epoch [300/500] | Train Loss: 0.171533 | Val Loss: 0.431740\n",
      "Epoch [400/500] | Train Loss: 0.176899 | Val Loss: 0.431030\n",
      "Epoch [500/500] | Train Loss: 0.167137 | Val Loss: 0.449932\n",
      "Epoch [100/500] | Train Loss: 0.288165 | Val Loss: 0.612523\n",
      "Epoch [200/500] | Train Loss: 0.247266 | Val Loss: 0.648192\n",
      "Epoch [300/500] | Train Loss: 0.218492 | Val Loss: 0.656759\n",
      "Epoch [400/500] | Train Loss: 0.211221 | Val Loss: 0.659817\n",
      "Epoch [500/500] | Train Loss: 0.203172 | Val Loss: 0.693360\n",
      "Epoch [100/500] | Train Loss: 0.333331 | Val Loss: 1.097333\n",
      "Epoch [200/500] | Train Loss: 0.299297 | Val Loss: 1.153865\n",
      "Epoch [300/500] | Train Loss: 0.275113 | Val Loss: 1.214067\n",
      "Epoch [400/500] | Train Loss: 0.277246 | Val Loss: 1.163678\n",
      "Epoch [500/500] | Train Loss: 0.257391 | Val Loss: 1.129776\n",
      "Epoch [100/500] | Train Loss: 0.434454 | Val Loss: 1.696061\n",
      "Epoch [200/500] | Train Loss: 0.397452 | Val Loss: 1.801970\n",
      "Epoch [300/500] | Train Loss: 0.412333 | Val Loss: 1.760241\n",
      "Epoch [400/500] | Train Loss: 0.360270 | Val Loss: 1.728090\n",
      "Epoch [500/500] | Train Loss: 0.384024 | Val Loss: 1.699676\n",
      "[Year=1999] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.811093 Test MSE=1.211486\n",
      "Year 1999 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.188782 | Val Loss: 0.538532\n",
      "Epoch [200/500] | Train Loss: 0.156762 | Val Loss: 0.595723\n",
      "Epoch [300/500] | Train Loss: 0.139155 | Val Loss: 0.623093\n",
      "Epoch [400/500] | Train Loss: 0.139325 | Val Loss: 0.627333\n",
      "Epoch [500/500] | Train Loss: 0.136898 | Val Loss: 0.632051\n",
      "Epoch [100/500] | Train Loss: 0.357505 | Val Loss: 0.557534\n",
      "Epoch [200/500] | Train Loss: 0.323359 | Val Loss: 0.593224\n",
      "Epoch [300/500] | Train Loss: 0.316485 | Val Loss: 0.606127\n",
      "Epoch [400/500] | Train Loss: 0.292266 | Val Loss: 0.622649\n",
      "Epoch [500/500] | Train Loss: 0.284285 | Val Loss: 0.629525\n",
      "Epoch [100/500] | Train Loss: 0.416718 | Val Loss: 1.044909\n",
      "Epoch [200/500] | Train Loss: 0.395003 | Val Loss: 1.073154\n",
      "Epoch [300/500] | Train Loss: 0.365976 | Val Loss: 1.092238\n",
      "Epoch [400/500] | Train Loss: 0.359466 | Val Loss: 1.135343\n",
      "Epoch [500/500] | Train Loss: 0.353821 | Val Loss: 1.156930\n",
      "Epoch [100/500] | Train Loss: 0.553815 | Val Loss: 1.866553\n",
      "Epoch [200/500] | Train Loss: 0.508705 | Val Loss: 1.853815\n",
      "Epoch [300/500] | Train Loss: 0.496184 | Val Loss: 1.898938\n",
      "Epoch [400/500] | Train Loss: 0.476550 | Val Loss: 1.923167\n",
      "Epoch [500/500] | Train Loss: 0.448287 | Val Loss: 2.008726\n",
      "Epoch [100/500] | Train Loss: 0.895875 | Val Loss: 1.190653\n",
      "Epoch [200/500] | Train Loss: 0.867827 | Val Loss: 1.165605\n",
      "Epoch [300/500] | Train Loss: 0.849925 | Val Loss: 1.149897\n",
      "Epoch [400/500] | Train Loss: 0.847773 | Val Loss: 1.142839\n",
      "Epoch [500/500] | Train Loss: 0.841135 | Val Loss: 1.142137\n",
      "Epoch [100/500] | Train Loss: 0.167667 | Val Loss: 0.620203\n",
      "Epoch [200/500] | Train Loss: 0.119890 | Val Loss: 0.703945\n",
      "Epoch [300/500] | Train Loss: 0.109992 | Val Loss: 0.619475\n",
      "Epoch [400/500] | Train Loss: 0.087898 | Val Loss: 0.633245\n",
      "Epoch [500/500] | Train Loss: 0.081758 | Val Loss: 0.600582\n",
      "Epoch [100/500] | Train Loss: 0.291725 | Val Loss: 0.684982\n",
      "Epoch [200/500] | Train Loss: 0.257132 | Val Loss: 0.676147\n",
      "Epoch [300/500] | Train Loss: 0.209530 | Val Loss: 0.685072\n",
      "Epoch [400/500] | Train Loss: 0.207028 | Val Loss: 0.694098\n",
      "Epoch [500/500] | Train Loss: 0.188740 | Val Loss: 0.711577\n",
      "Epoch [100/500] | Train Loss: 0.356913 | Val Loss: 1.079586\n",
      "Epoch [200/500] | Train Loss: 0.311909 | Val Loss: 1.174395\n",
      "Epoch [300/500] | Train Loss: 0.289671 | Val Loss: 1.201672\n",
      "Epoch [400/500] | Train Loss: 0.250960 | Val Loss: 1.207971\n",
      "Epoch [500/500] | Train Loss: 0.243659 | Val Loss: 1.183264\n",
      "Epoch [100/500] | Train Loss: 0.487943 | Val Loss: 1.845171\n",
      "Epoch [200/500] | Train Loss: 0.426341 | Val Loss: 1.926718\n",
      "Epoch [300/500] | Train Loss: 0.334597 | Val Loss: 1.940035\n",
      "Epoch [400/500] | Train Loss: 0.315583 | Val Loss: 1.893158\n",
      "Epoch [500/500] | Train Loss: 0.303612 | Val Loss: 1.877344\n",
      "Epoch [100/500] | Train Loss: 0.633898 | Val Loss: 1.196175\n",
      "Epoch [200/500] | Train Loss: 0.540418 | Val Loss: 1.206345\n",
      "Epoch [300/500] | Train Loss: 0.541956 | Val Loss: 1.249193\n",
      "Epoch [400/500] | Train Loss: 0.537590 | Val Loss: 1.211551\n",
      "Epoch [500/500] | Train Loss: 0.463448 | Val Loss: 1.276701\n",
      "Epoch [100/500] | Train Loss: 0.210303 | Val Loss: 0.522314\n",
      "Epoch [200/500] | Train Loss: 0.216249 | Val Loss: 0.543331\n",
      "Epoch [300/500] | Train Loss: 0.186757 | Val Loss: 0.565644\n",
      "Epoch [400/500] | Train Loss: 0.190192 | Val Loss: 0.581416\n",
      "Epoch [500/500] | Train Loss: 0.190276 | Val Loss: 0.574284\n",
      "Epoch [100/500] | Train Loss: 0.350117 | Val Loss: 0.560570\n",
      "Epoch [200/500] | Train Loss: 0.347615 | Val Loss: 0.573355\n",
      "Epoch [300/500] | Train Loss: 0.329353 | Val Loss: 0.586311\n",
      "Epoch [400/500] | Train Loss: 0.310207 | Val Loss: 0.599035\n",
      "Epoch [500/500] | Train Loss: 0.307299 | Val Loss: 0.611358\n",
      "Epoch [100/500] | Train Loss: 0.420341 | Val Loss: 1.027564\n",
      "Epoch [200/500] | Train Loss: 0.406173 | Val Loss: 1.041124\n",
      "Epoch [300/500] | Train Loss: 0.391131 | Val Loss: 1.072796\n",
      "Epoch [400/500] | Train Loss: 0.390078 | Val Loss: 1.089772\n",
      "Epoch [500/500] | Train Loss: 0.385401 | Val Loss: 1.097405\n",
      "Epoch [100/500] | Train Loss: 0.584631 | Val Loss: 1.896873\n",
      "Epoch [200/500] | Train Loss: 0.578692 | Val Loss: 1.887604\n",
      "Epoch [300/500] | Train Loss: 0.555123 | Val Loss: 1.897053\n",
      "Epoch [400/500] | Train Loss: 0.531685 | Val Loss: 1.917136\n",
      "Epoch [500/500] | Train Loss: 0.510107 | Val Loss: 1.963993\n",
      "Epoch [100/500] | Train Loss: 0.853490 | Val Loss: 1.133153\n",
      "Epoch [200/500] | Train Loss: 0.801163 | Val Loss: 1.140031\n",
      "Epoch [300/500] | Train Loss: 0.762987 | Val Loss: 1.136122\n",
      "Epoch [400/500] | Train Loss: 0.734894 | Val Loss: 1.140119\n",
      "Epoch [500/500] | Train Loss: 0.716615 | Val Loss: 1.138587\n",
      "Epoch [100/500] | Train Loss: 0.206657 | Val Loss: 0.563169\n",
      "Epoch [200/500] | Train Loss: 0.164095 | Val Loss: 0.657951\n",
      "Epoch [300/500] | Train Loss: 0.169557 | Val Loss: 0.707066\n",
      "Epoch [400/500] | Train Loss: 0.126709 | Val Loss: 0.675759\n",
      "Epoch [500/500] | Train Loss: 0.137966 | Val Loss: 0.665416\n",
      "Epoch [100/500] | Train Loss: 0.278608 | Val Loss: 0.612383\n",
      "Epoch [200/500] | Train Loss: 0.263302 | Val Loss: 0.628173\n",
      "Epoch [300/500] | Train Loss: 0.252386 | Val Loss: 0.673855\n",
      "Epoch [400/500] | Train Loss: 0.230956 | Val Loss: 0.716785\n",
      "Epoch [500/500] | Train Loss: 0.214164 | Val Loss: 0.642825\n",
      "Epoch [100/500] | Train Loss: 0.384011 | Val Loss: 1.045902\n",
      "Epoch [200/500] | Train Loss: 0.331683 | Val Loss: 1.100126\n",
      "Epoch [300/500] | Train Loss: 0.334268 | Val Loss: 1.066590\n",
      "Epoch [400/500] | Train Loss: 0.297757 | Val Loss: 1.174604\n",
      "Epoch [500/500] | Train Loss: 0.304348 | Val Loss: 1.092684\n",
      "Epoch [100/500] | Train Loss: 0.494916 | Val Loss: 1.880701\n",
      "Epoch [200/500] | Train Loss: 0.501185 | Val Loss: 1.837536\n",
      "Epoch [300/500] | Train Loss: 0.459301 | Val Loss: 1.843314\n",
      "Epoch [400/500] | Train Loss: 0.412649 | Val Loss: 1.834737\n",
      "Epoch [500/500] | Train Loss: 0.378191 | Val Loss: 1.810312\n",
      "Epoch [100/500] | Train Loss: 0.692185 | Val Loss: 1.171535\n",
      "Epoch [200/500] | Train Loss: 0.629044 | Val Loss: 1.316918\n",
      "Epoch [300/500] | Train Loss: 0.597777 | Val Loss: 1.264745\n",
      "Epoch [400/500] | Train Loss: 0.569220 | Val Loss: 1.263164\n",
      "Epoch [500/500] | Train Loss: 0.621739 | Val Loss: 1.262470\n",
      "Epoch [100/500] | Train Loss: 0.193989 | Val Loss: 0.536309\n",
      "Epoch [200/500] | Train Loss: 0.172185 | Val Loss: 0.568599\n",
      "Epoch [300/500] | Train Loss: 0.157480 | Val Loss: 0.564120\n",
      "Epoch [400/500] | Train Loss: 0.136463 | Val Loss: 0.586805\n",
      "Epoch [500/500] | Train Loss: 0.119720 | Val Loss: 0.613272\n",
      "Epoch [100/500] | Train Loss: 0.342625 | Val Loss: 0.581629\n",
      "Epoch [200/500] | Train Loss: 0.284595 | Val Loss: 0.627967\n",
      "Epoch [300/500] | Train Loss: 0.261520 | Val Loss: 0.658741\n",
      "Epoch [400/500] | Train Loss: 0.231916 | Val Loss: 0.691834\n",
      "Epoch [500/500] | Train Loss: 0.228314 | Val Loss: 0.708018\n",
      "Epoch [100/500] | Train Loss: 0.393187 | Val Loss: 1.047472\n",
      "Epoch [200/500] | Train Loss: 0.355694 | Val Loss: 1.042675\n",
      "Epoch [300/500] | Train Loss: 0.318961 | Val Loss: 1.101978\n",
      "Epoch [400/500] | Train Loss: 0.306751 | Val Loss: 1.146735\n",
      "Epoch [500/500] | Train Loss: 0.273072 | Val Loss: 1.152572\n",
      "Epoch [100/500] | Train Loss: 0.562965 | Val Loss: 1.912236\n",
      "Epoch [200/500] | Train Loss: 0.514057 | Val Loss: 1.897618\n",
      "Epoch [300/500] | Train Loss: 0.488204 | Val Loss: 1.910607\n",
      "Epoch [400/500] | Train Loss: 0.462118 | Val Loss: 2.024432\n",
      "Epoch [500/500] | Train Loss: 0.397097 | Val Loss: 2.042355\n",
      "Epoch [100/500] | Train Loss: 0.801005 | Val Loss: 1.127007\n",
      "Epoch [200/500] | Train Loss: 0.704663 | Val Loss: 1.188335\n",
      "Epoch [300/500] | Train Loss: 0.658235 | Val Loss: 1.201367\n",
      "Epoch [400/500] | Train Loss: 0.641027 | Val Loss: 1.209891\n",
      "Epoch [500/500] | Train Loss: 0.609427 | Val Loss: 1.222144\n",
      "Epoch [100/500] | Train Loss: 0.122959 | Val Loss: 0.657308\n",
      "Epoch [200/500] | Train Loss: 0.083911 | Val Loss: 0.634820\n",
      "Epoch [300/500] | Train Loss: 0.056840 | Val Loss: 0.639619\n",
      "Epoch [400/500] | Train Loss: 0.073131 | Val Loss: 0.627380\n",
      "Epoch [500/500] | Train Loss: 0.039370 | Val Loss: 0.626215\n",
      "Epoch [100/500] | Train Loss: 0.219162 | Val Loss: 0.730791\n",
      "Epoch [200/500] | Train Loss: 0.148221 | Val Loss: 0.729654\n",
      "Epoch [300/500] | Train Loss: 0.132630 | Val Loss: 0.747835\n",
      "Epoch [400/500] | Train Loss: 0.123826 | Val Loss: 0.738388\n",
      "Epoch [500/500] | Train Loss: 0.120615 | Val Loss: 0.757574\n",
      "Epoch [100/500] | Train Loss: 0.287056 | Val Loss: 1.151069\n",
      "Epoch [200/500] | Train Loss: 0.231765 | Val Loss: 1.068088\n",
      "Epoch [300/500] | Train Loss: 0.223035 | Val Loss: 1.133904\n",
      "Epoch [400/500] | Train Loss: 0.213721 | Val Loss: 1.132053\n",
      "Epoch [500/500] | Train Loss: 0.187826 | Val Loss: 1.125129\n",
      "Epoch [100/500] | Train Loss: 0.373794 | Val Loss: 2.066930\n",
      "Epoch [200/500] | Train Loss: 0.296680 | Val Loss: 2.197016\n",
      "Epoch [300/500] | Train Loss: 0.269293 | Val Loss: 2.209533\n",
      "Epoch [400/500] | Train Loss: 0.268735 | Val Loss: 2.230212\n",
      "Epoch [500/500] | Train Loss: 0.249772 | Val Loss: 2.150878\n",
      "Epoch [100/500] | Train Loss: 0.596177 | Val Loss: 1.239300\n",
      "Epoch [200/500] | Train Loss: 0.502938 | Val Loss: 1.249984\n",
      "Epoch [300/500] | Train Loss: 0.443585 | Val Loss: 1.340572\n",
      "Epoch [400/500] | Train Loss: 0.422246 | Val Loss: 1.374509\n",
      "Epoch [500/500] | Train Loss: 0.382257 | Val Loss: 1.402759\n",
      "Epoch [100/500] | Train Loss: 0.207240 | Val Loss: 0.534349\n",
      "Epoch [200/500] | Train Loss: 0.193063 | Val Loss: 0.549016\n",
      "Epoch [300/500] | Train Loss: 0.161721 | Val Loss: 0.562114\n",
      "Epoch [400/500] | Train Loss: 0.157107 | Val Loss: 0.582920\n",
      "Epoch [500/500] | Train Loss: 0.141709 | Val Loss: 0.589738\n",
      "Epoch [100/500] | Train Loss: 0.362132 | Val Loss: 0.566518\n",
      "Epoch [200/500] | Train Loss: 0.326135 | Val Loss: 0.589554\n",
      "Epoch [300/500] | Train Loss: 0.309812 | Val Loss: 0.607652\n",
      "Epoch [400/500] | Train Loss: 0.276852 | Val Loss: 0.636576\n",
      "Epoch [500/500] | Train Loss: 0.260494 | Val Loss: 0.654020\n",
      "Epoch [100/500] | Train Loss: 0.419899 | Val Loss: 1.049322\n",
      "Epoch [200/500] | Train Loss: 0.397173 | Val Loss: 1.014875\n",
      "Epoch [300/500] | Train Loss: 0.389798 | Val Loss: 1.024175\n",
      "Epoch [400/500] | Train Loss: 0.368954 | Val Loss: 1.069681\n",
      "Epoch [500/500] | Train Loss: 0.351879 | Val Loss: 1.200204\n",
      "Epoch [100/500] | Train Loss: 0.555503 | Val Loss: 1.863848\n",
      "Epoch [200/500] | Train Loss: 0.528131 | Val Loss: 1.844978\n",
      "Epoch [300/500] | Train Loss: 0.520945 | Val Loss: 1.866201\n",
      "Epoch [400/500] | Train Loss: 0.489188 | Val Loss: 1.915401\n",
      "Epoch [500/500] | Train Loss: 0.493567 | Val Loss: 1.945381\n",
      "Epoch [100/500] | Train Loss: 0.817399 | Val Loss: 1.133685\n",
      "Epoch [200/500] | Train Loss: 0.749175 | Val Loss: 1.147555\n",
      "Epoch [300/500] | Train Loss: 0.686238 | Val Loss: 1.169097\n",
      "Epoch [400/500] | Train Loss: 0.651729 | Val Loss: 1.163613\n",
      "Epoch [500/500] | Train Loss: 0.624809 | Val Loss: 1.174787\n",
      "Epoch [100/500] | Train Loss: 0.157392 | Val Loss: 0.604842\n",
      "Epoch [200/500] | Train Loss: 0.130887 | Val Loss: 0.638807\n",
      "Epoch [300/500] | Train Loss: 0.108703 | Val Loss: 0.652996\n",
      "Epoch [400/500] | Train Loss: 0.101094 | Val Loss: 0.605111\n",
      "Epoch [500/500] | Train Loss: 0.092373 | Val Loss: 0.644096\n",
      "Epoch [100/500] | Train Loss: 0.283032 | Val Loss: 0.664985\n",
      "Epoch [200/500] | Train Loss: 0.211569 | Val Loss: 0.677294\n",
      "Epoch [300/500] | Train Loss: 0.219707 | Val Loss: 0.665124\n",
      "Epoch [400/500] | Train Loss: 0.183849 | Val Loss: 0.667096\n",
      "Epoch [500/500] | Train Loss: 0.175030 | Val Loss: 0.678212\n",
      "Epoch [100/500] | Train Loss: 0.352454 | Val Loss: 1.135355\n",
      "Epoch [200/500] | Train Loss: 0.324082 | Val Loss: 1.207276\n",
      "Epoch [300/500] | Train Loss: 0.279578 | Val Loss: 1.126680\n",
      "Epoch [400/500] | Train Loss: 0.261034 | Val Loss: 1.091999\n",
      "Epoch [500/500] | Train Loss: 0.277912 | Val Loss: 1.163041\n",
      "Epoch [100/500] | Train Loss: 0.485523 | Val Loss: 1.874662\n",
      "Epoch [200/500] | Train Loss: 0.419904 | Val Loss: 1.892291\n",
      "Epoch [300/500] | Train Loss: 0.392855 | Val Loss: 1.924136\n",
      "Epoch [400/500] | Train Loss: 0.385737 | Val Loss: 1.915566\n",
      "Epoch [500/500] | Train Loss: 0.395069 | Val Loss: 1.872040\n",
      "Epoch [100/500] | Train Loss: 0.699353 | Val Loss: 1.184623\n",
      "Epoch [200/500] | Train Loss: 0.656052 | Val Loss: 1.234067\n",
      "Epoch [300/500] | Train Loss: 0.630185 | Val Loss: 1.187649\n",
      "Epoch [400/500] | Train Loss: 0.500456 | Val Loss: 1.316328\n",
      "Epoch [500/500] | Train Loss: 0.532811 | Val Loss: 1.274355\n",
      "[Year=2000] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.077125 Test MSE=2.763483\n",
      "Year 2000 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.471929 | Val Loss: 0.680120\n",
      "Epoch [200/500] | Train Loss: 0.376189 | Val Loss: 0.732489\n",
      "Epoch [300/500] | Train Loss: 0.336488 | Val Loss: 0.795343\n",
      "Epoch [400/500] | Train Loss: 0.300836 | Val Loss: 0.813400\n",
      "Epoch [500/500] | Train Loss: 0.291513 | Val Loss: 0.856346\n",
      "Epoch [100/500] | Train Loss: 0.559609 | Val Loss: 0.982390\n",
      "Epoch [200/500] | Train Loss: 0.524757 | Val Loss: 1.002447\n",
      "Epoch [300/500] | Train Loss: 0.471956 | Val Loss: 1.024562\n",
      "Epoch [400/500] | Train Loss: 0.420929 | Val Loss: 1.043201\n",
      "Epoch [500/500] | Train Loss: 0.360980 | Val Loss: 1.046637\n",
      "Epoch [100/500] | Train Loss: 0.689107 | Val Loss: 2.019312\n",
      "Epoch [200/500] | Train Loss: 0.617063 | Val Loss: 2.031275\n",
      "Epoch [300/500] | Train Loss: 0.574106 | Val Loss: 2.070524\n",
      "Epoch [400/500] | Train Loss: 0.534024 | Val Loss: 2.124446\n",
      "Epoch [500/500] | Train Loss: 0.505328 | Val Loss: 2.123410\n",
      "Epoch [100/500] | Train Loss: 1.045873 | Val Loss: 1.290960\n",
      "Epoch [200/500] | Train Loss: 0.903382 | Val Loss: 1.332265\n",
      "Epoch [300/500] | Train Loss: 0.821025 | Val Loss: 1.386241\n",
      "Epoch [400/500] | Train Loss: 0.873660 | Val Loss: 1.454410\n",
      "Epoch [500/500] | Train Loss: 0.757416 | Val Loss: 1.491125\n",
      "Epoch [100/500] | Train Loss: 1.013695 | Val Loss: 2.458207\n",
      "Epoch [200/500] | Train Loss: 0.959812 | Val Loss: 2.586798\n",
      "Epoch [300/500] | Train Loss: 0.863202 | Val Loss: 2.688045\n",
      "Epoch [400/500] | Train Loss: 0.841915 | Val Loss: 2.732305\n",
      "Epoch [500/500] | Train Loss: 0.867008 | Val Loss: 2.660760\n",
      "Epoch [100/500] | Train Loss: 0.237158 | Val Loss: 0.944827\n",
      "Epoch [200/500] | Train Loss: 0.161132 | Val Loss: 0.945324\n",
      "Epoch [300/500] | Train Loss: 0.146224 | Val Loss: 0.968100\n",
      "Epoch [400/500] | Train Loss: 0.131469 | Val Loss: 0.939562\n",
      "Epoch [500/500] | Train Loss: 0.130912 | Val Loss: 0.963703\n",
      "Epoch [100/500] | Train Loss: 0.542217 | Val Loss: 0.939412\n",
      "Epoch [200/500] | Train Loss: 0.406366 | Val Loss: 0.966304\n",
      "Epoch [300/500] | Train Loss: 0.391660 | Val Loss: 0.990036\n",
      "Epoch [400/500] | Train Loss: 0.344802 | Val Loss: 0.957515\n",
      "Epoch [500/500] | Train Loss: 0.286748 | Val Loss: 0.985648\n",
      "Epoch [100/500] | Train Loss: 0.494340 | Val Loss: 2.366639\n",
      "Epoch [200/500] | Train Loss: 0.421381 | Val Loss: 2.340058\n",
      "Epoch [300/500] | Train Loss: 0.383876 | Val Loss: 2.496873\n",
      "Epoch [400/500] | Train Loss: 0.332041 | Val Loss: 2.503260\n",
      "Epoch [500/500] | Train Loss: 0.358463 | Val Loss: 2.358280\n",
      "Epoch [100/500] | Train Loss: 0.772208 | Val Loss: 1.465293\n",
      "Epoch [200/500] | Train Loss: 0.661613 | Val Loss: 1.625946\n",
      "Epoch [300/500] | Train Loss: 0.590120 | Val Loss: 1.724945\n",
      "Epoch [400/500] | Train Loss: 0.541260 | Val Loss: 1.736880\n",
      "Epoch [500/500] | Train Loss: 0.536066 | Val Loss: 1.748309\n",
      "Epoch [100/500] | Train Loss: 0.972172 | Val Loss: 2.622099\n",
      "Epoch [200/500] | Train Loss: 0.864639 | Val Loss: 2.620517\n",
      "Epoch [300/500] | Train Loss: 0.843534 | Val Loss: 2.782111\n",
      "Epoch [400/500] | Train Loss: 0.719004 | Val Loss: 2.770184\n",
      "Epoch [500/500] | Train Loss: 0.691515 | Val Loss: 2.812245\n",
      "Epoch [100/500] | Train Loss: 0.466727 | Val Loss: 0.693965\n",
      "Epoch [200/500] | Train Loss: 0.416046 | Val Loss: 0.720082\n",
      "Epoch [300/500] | Train Loss: 0.396042 | Val Loss: 0.758097\n",
      "Epoch [400/500] | Train Loss: 0.360173 | Val Loss: 0.789907\n",
      "Epoch [500/500] | Train Loss: 0.317876 | Val Loss: 0.816253\n",
      "Epoch [100/500] | Train Loss: 0.592378 | Val Loss: 0.994472\n",
      "Epoch [200/500] | Train Loss: 0.560601 | Val Loss: 0.985067\n",
      "Epoch [300/500] | Train Loss: 0.529568 | Val Loss: 0.993010\n",
      "Epoch [400/500] | Train Loss: 0.515689 | Val Loss: 0.998696\n",
      "Epoch [500/500] | Train Loss: 0.499042 | Val Loss: 0.996350\n",
      "Epoch [100/500] | Train Loss: 0.716364 | Val Loss: 2.016702\n",
      "Epoch [200/500] | Train Loss: 0.696197 | Val Loss: 1.996448\n",
      "Epoch [300/500] | Train Loss: 0.639046 | Val Loss: 2.074819\n",
      "Epoch [400/500] | Train Loss: 0.618916 | Val Loss: 2.103609\n",
      "Epoch [500/500] | Train Loss: 0.606874 | Val Loss: 2.098809\n",
      "Epoch [100/500] | Train Loss: 1.020530 | Val Loss: 1.292501\n",
      "Epoch [200/500] | Train Loss: 0.949804 | Val Loss: 1.321338\n",
      "Epoch [300/500] | Train Loss: 0.909024 | Val Loss: 1.338167\n",
      "Epoch [400/500] | Train Loss: 0.925380 | Val Loss: 1.375059\n",
      "Epoch [500/500] | Train Loss: 0.874710 | Val Loss: 1.399981\n",
      "Epoch [100/500] | Train Loss: 1.066247 | Val Loss: 2.462370\n",
      "Epoch [200/500] | Train Loss: 1.013139 | Val Loss: 2.489061\n",
      "Epoch [300/500] | Train Loss: 1.009237 | Val Loss: 2.544731\n",
      "Epoch [400/500] | Train Loss: 0.977933 | Val Loss: 2.583323\n",
      "Epoch [500/500] | Train Loss: 0.973786 | Val Loss: 2.627473\n",
      "Epoch [100/500] | Train Loss: 0.319408 | Val Loss: 0.787889\n",
      "Epoch [200/500] | Train Loss: 0.298320 | Val Loss: 0.800764\n",
      "Epoch [300/500] | Train Loss: 0.264159 | Val Loss: 0.823030\n",
      "Epoch [400/500] | Train Loss: 0.239651 | Val Loss: 0.801402\n",
      "Epoch [500/500] | Train Loss: 0.177609 | Val Loss: 0.831977\n",
      "Epoch [100/500] | Train Loss: 0.525726 | Val Loss: 0.999630\n",
      "Epoch [200/500] | Train Loss: 0.492739 | Val Loss: 1.005977\n",
      "Epoch [300/500] | Train Loss: 0.461269 | Val Loss: 1.001893\n",
      "Epoch [400/500] | Train Loss: 0.447982 | Val Loss: 1.015975\n",
      "Epoch [500/500] | Train Loss: 0.441732 | Val Loss: 1.020302\n",
      "Epoch [100/500] | Train Loss: 0.615918 | Val Loss: 1.985979\n",
      "Epoch [200/500] | Train Loss: 0.600506 | Val Loss: 2.007725\n",
      "Epoch [300/500] | Train Loss: 0.490681 | Val Loss: 1.976952\n",
      "Epoch [400/500] | Train Loss: 0.505428 | Val Loss: 1.976876\n",
      "Epoch [500/500] | Train Loss: 0.484556 | Val Loss: 1.991455\n",
      "Epoch [100/500] | Train Loss: 0.913244 | Val Loss: 1.325859\n",
      "Epoch [200/500] | Train Loss: 0.801441 | Val Loss: 1.361361\n",
      "Epoch [300/500] | Train Loss: 0.774659 | Val Loss: 1.481887\n",
      "Epoch [400/500] | Train Loss: 0.800159 | Val Loss: 1.488190\n",
      "Epoch [500/500] | Train Loss: 0.699021 | Val Loss: 1.602032\n",
      "Epoch [100/500] | Train Loss: 0.982858 | Val Loss: 2.712376\n",
      "Epoch [200/500] | Train Loss: 0.908189 | Val Loss: 2.837782\n",
      "Epoch [300/500] | Train Loss: 0.879828 | Val Loss: 2.823996\n",
      "Epoch [400/500] | Train Loss: 0.847321 | Val Loss: 3.064048\n",
      "Epoch [500/500] | Train Loss: 0.811137 | Val Loss: 2.753065\n",
      "Epoch [100/500] | Train Loss: 0.407660 | Val Loss: 0.712719\n",
      "Epoch [200/500] | Train Loss: 0.324836 | Val Loss: 0.790249\n",
      "Epoch [300/500] | Train Loss: 0.277182 | Val Loss: 0.870413\n",
      "Epoch [400/500] | Train Loss: 0.228457 | Val Loss: 0.889024\n",
      "Epoch [500/500] | Train Loss: 0.225992 | Val Loss: 0.945618\n",
      "Epoch [100/500] | Train Loss: 0.581095 | Val Loss: 1.000639\n",
      "Epoch [200/500] | Train Loss: 0.503012 | Val Loss: 1.011296\n",
      "Epoch [300/500] | Train Loss: 0.431123 | Val Loss: 1.041941\n",
      "Epoch [400/500] | Train Loss: 0.387169 | Val Loss: 1.038284\n",
      "Epoch [500/500] | Train Loss: 0.366421 | Val Loss: 1.053340\n",
      "Epoch [100/500] | Train Loss: 0.704669 | Val Loss: 2.036528\n",
      "Epoch [200/500] | Train Loss: 0.626333 | Val Loss: 1.977059\n",
      "Epoch [300/500] | Train Loss: 0.560612 | Val Loss: 2.067284\n",
      "Epoch [400/500] | Train Loss: 0.509492 | Val Loss: 2.224002\n",
      "Epoch [500/500] | Train Loss: 0.455088 | Val Loss: 2.308308\n",
      "Epoch [100/500] | Train Loss: 0.977912 | Val Loss: 1.315820\n",
      "Epoch [200/500] | Train Loss: 0.877110 | Val Loss: 1.422171\n",
      "Epoch [300/500] | Train Loss: 0.763995 | Val Loss: 1.505716\n",
      "Epoch [400/500] | Train Loss: 0.764423 | Val Loss: 1.525446\n",
      "Epoch [500/500] | Train Loss: 0.692601 | Val Loss: 1.598390\n",
      "Epoch [100/500] | Train Loss: 1.027244 | Val Loss: 2.494403\n",
      "Epoch [200/500] | Train Loss: 0.921890 | Val Loss: 2.735746\n",
      "Epoch [300/500] | Train Loss: 0.871474 | Val Loss: 2.943006\n",
      "Epoch [400/500] | Train Loss: 0.832550 | Val Loss: 3.084671\n",
      "Epoch [500/500] | Train Loss: 0.784482 | Val Loss: 3.111561\n",
      "Epoch [100/500] | Train Loss: 0.193086 | Val Loss: 1.042784\n",
      "Epoch [200/500] | Train Loss: 0.141263 | Val Loss: 1.049359\n",
      "Epoch [300/500] | Train Loss: 0.107911 | Val Loss: 1.012236\n",
      "Epoch [400/500] | Train Loss: 0.104869 | Val Loss: 1.010626\n",
      "Epoch [500/500] | Train Loss: 0.097112 | Val Loss: 1.000372\n",
      "Epoch [100/500] | Train Loss: 0.367428 | Val Loss: 1.110768\n",
      "Epoch [200/500] | Train Loss: 0.267277 | Val Loss: 1.110557\n",
      "Epoch [300/500] | Train Loss: 0.215743 | Val Loss: 1.133837\n",
      "Epoch [400/500] | Train Loss: 0.183106 | Val Loss: 1.154481\n",
      "Epoch [500/500] | Train Loss: 0.168200 | Val Loss: 1.153251\n",
      "Epoch [100/500] | Train Loss: 0.617070 | Val Loss: 2.104719\n",
      "Epoch [200/500] | Train Loss: 0.539600 | Val Loss: 2.186133\n",
      "Epoch [300/500] | Train Loss: 0.486688 | Val Loss: 2.241062\n",
      "Epoch [400/500] | Train Loss: 0.456607 | Val Loss: 2.300370\n",
      "Epoch [500/500] | Train Loss: 0.395710 | Val Loss: 2.474431\n",
      "Epoch [100/500] | Train Loss: 0.723339 | Val Loss: 1.681983\n",
      "Epoch [200/500] | Train Loss: 0.626670 | Val Loss: 1.615728\n",
      "Epoch [300/500] | Train Loss: 0.554536 | Val Loss: 1.636304\n",
      "Epoch [400/500] | Train Loss: 0.550009 | Val Loss: 1.741095\n",
      "Epoch [500/500] | Train Loss: 0.526464 | Val Loss: 1.645619\n",
      "Epoch [100/500] | Train Loss: 0.880453 | Val Loss: 2.932655\n",
      "Epoch [200/500] | Train Loss: 0.702752 | Val Loss: 2.959954\n",
      "Epoch [300/500] | Train Loss: 0.677683 | Val Loss: 2.940917\n",
      "Epoch [400/500] | Train Loss: 0.630615 | Val Loss: 3.180174\n",
      "Epoch [500/500] | Train Loss: 0.599012 | Val Loss: 3.260432\n",
      "Epoch [100/500] | Train Loss: 0.467315 | Val Loss: 0.682346\n",
      "Epoch [200/500] | Train Loss: 0.402530 | Val Loss: 0.736782\n",
      "Epoch [300/500] | Train Loss: 0.373024 | Val Loss: 0.798727\n",
      "Epoch [400/500] | Train Loss: 0.324226 | Val Loss: 0.818181\n",
      "Epoch [500/500] | Train Loss: 0.272625 | Val Loss: 0.848558\n",
      "Epoch [100/500] | Train Loss: 0.565384 | Val Loss: 0.975468\n",
      "Epoch [200/500] | Train Loss: 0.546161 | Val Loss: 0.981205\n",
      "Epoch [300/500] | Train Loss: 0.518021 | Val Loss: 0.973207\n",
      "Epoch [400/500] | Train Loss: 0.501512 | Val Loss: 0.979236\n",
      "Epoch [500/500] | Train Loss: 0.500023 | Val Loss: 0.989047\n",
      "Epoch [100/500] | Train Loss: 0.687775 | Val Loss: 2.002026\n",
      "Epoch [200/500] | Train Loss: 0.648252 | Val Loss: 1.945602\n",
      "Epoch [300/500] | Train Loss: 0.612557 | Val Loss: 1.989731\n",
      "Epoch [400/500] | Train Loss: 0.598090 | Val Loss: 2.043781\n",
      "Epoch [500/500] | Train Loss: 0.549831 | Val Loss: 2.083727\n",
      "Epoch [100/500] | Train Loss: 1.031534 | Val Loss: 1.299494\n",
      "Epoch [200/500] | Train Loss: 0.934929 | Val Loss: 1.337260\n",
      "Epoch [300/500] | Train Loss: 0.887801 | Val Loss: 1.350895\n",
      "Epoch [400/500] | Train Loss: 0.873419 | Val Loss: 1.371447\n",
      "Epoch [500/500] | Train Loss: 0.834587 | Val Loss: 1.419377\n",
      "Epoch [100/500] | Train Loss: 1.053447 | Val Loss: 2.493263\n",
      "Epoch [200/500] | Train Loss: 0.983501 | Val Loss: 2.545081\n",
      "Epoch [300/500] | Train Loss: 0.926194 | Val Loss: 2.603732\n",
      "Epoch [400/500] | Train Loss: 0.908956 | Val Loss: 2.638273\n",
      "Epoch [500/500] | Train Loss: 0.853222 | Val Loss: 2.643096\n",
      "Epoch [100/500] | Train Loss: 0.296471 | Val Loss: 0.818371\n",
      "Epoch [200/500] | Train Loss: 0.246032 | Val Loss: 0.899681\n",
      "Epoch [300/500] | Train Loss: 0.168613 | Val Loss: 0.836011\n",
      "Epoch [400/500] | Train Loss: 0.175254 | Val Loss: 0.821273\n",
      "Epoch [500/500] | Train Loss: 0.168186 | Val Loss: 0.900046\n",
      "Epoch [100/500] | Train Loss: 0.482788 | Val Loss: 0.948131\n",
      "Epoch [200/500] | Train Loss: 0.398166 | Val Loss: 0.986480\n",
      "Epoch [300/500] | Train Loss: 0.394858 | Val Loss: 1.028096\n",
      "Epoch [400/500] | Train Loss: 0.338667 | Val Loss: 1.011304\n",
      "Epoch [500/500] | Train Loss: 0.321692 | Val Loss: 1.059067\n",
      "Epoch [100/500] | Train Loss: 0.589571 | Val Loss: 2.117025\n",
      "Epoch [200/500] | Train Loss: 0.502349 | Val Loss: 2.213602\n",
      "Epoch [300/500] | Train Loss: 0.486450 | Val Loss: 2.171952\n",
      "Epoch [400/500] | Train Loss: 0.427458 | Val Loss: 2.197623\n",
      "Epoch [500/500] | Train Loss: 0.392494 | Val Loss: 2.074821\n",
      "Epoch [100/500] | Train Loss: 0.890910 | Val Loss: 1.513448\n",
      "Epoch [200/500] | Train Loss: 0.700572 | Val Loss: 1.516336\n",
      "Epoch [300/500] | Train Loss: 0.673240 | Val Loss: 1.421971\n",
      "Epoch [400/500] | Train Loss: 0.671339 | Val Loss: 1.479613\n",
      "Epoch [500/500] | Train Loss: 0.650370 | Val Loss: 1.512923\n",
      "Epoch [100/500] | Train Loss: 0.925686 | Val Loss: 2.998165\n",
      "Epoch [200/500] | Train Loss: 0.816134 | Val Loss: 2.723749\n",
      "Epoch [300/500] | Train Loss: 0.748719 | Val Loss: 2.796408\n",
      "Epoch [400/500] | Train Loss: 0.717136 | Val Loss: 2.873712\n",
      "Epoch [500/500] | Train Loss: 0.724277 | Val Loss: 2.859978\n",
      "[Year=2001] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.587773 Test MSE=1.994229\n",
      "Year 2001 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.872098 | Val Loss: 1.268714\n",
      "Epoch [200/500] | Train Loss: 0.740248 | Val Loss: 1.300068\n",
      "Epoch [300/500] | Train Loss: 0.682480 | Val Loss: 1.401718\n",
      "Epoch [400/500] | Train Loss: 0.527373 | Val Loss: 1.467936\n",
      "Epoch [500/500] | Train Loss: 0.452124 | Val Loss: 1.471415\n",
      "Epoch [100/500] | Train Loss: 1.011851 | Val Loss: 1.626188\n",
      "Epoch [200/500] | Train Loss: 0.942492 | Val Loss: 1.637882\n",
      "Epoch [300/500] | Train Loss: 0.834059 | Val Loss: 1.707594\n",
      "Epoch [400/500] | Train Loss: 0.763703 | Val Loss: 1.768085\n",
      "Epoch [500/500] | Train Loss: 0.679596 | Val Loss: 1.808837\n",
      "Epoch [100/500] | Train Loss: 1.201429 | Val Loss: 1.918968\n",
      "Epoch [200/500] | Train Loss: 1.133625 | Val Loss: 2.022921\n",
      "Epoch [300/500] | Train Loss: 1.057254 | Val Loss: 2.049793\n",
      "Epoch [400/500] | Train Loss: 1.005393 | Val Loss: 2.102134\n",
      "Epoch [500/500] | Train Loss: 0.920515 | Val Loss: 2.167364\n",
      "Epoch [100/500] | Train Loss: 1.347721 | Val Loss: 2.152255\n",
      "Epoch [200/500] | Train Loss: 1.225945 | Val Loss: 2.215967\n",
      "Epoch [300/500] | Train Loss: 1.097841 | Val Loss: 2.333187\n",
      "Epoch [400/500] | Train Loss: 1.064748 | Val Loss: 2.357364\n",
      "Epoch [500/500] | Train Loss: 1.028460 | Val Loss: 2.482329\n",
      "Epoch [100/500] | Train Loss: 1.545092 | Val Loss: 1.906170\n",
      "Epoch [200/500] | Train Loss: 1.419389 | Val Loss: 1.916135\n",
      "Epoch [300/500] | Train Loss: 1.332637 | Val Loss: 2.004968\n",
      "Epoch [400/500] | Train Loss: 1.271268 | Val Loss: 2.110830\n",
      "Epoch [500/500] | Train Loss: 1.207018 | Val Loss: 2.198158\n",
      "Epoch [100/500] | Train Loss: 0.414138 | Val Loss: 1.229734\n",
      "Epoch [200/500] | Train Loss: 0.386639 | Val Loss: 1.275707\n",
      "Epoch [300/500] | Train Loss: 0.229363 | Val Loss: 1.370998\n",
      "Epoch [400/500] | Train Loss: 0.234705 | Val Loss: 1.322937\n",
      "Epoch [500/500] | Train Loss: 0.199554 | Val Loss: 1.496175\n",
      "Epoch [100/500] | Train Loss: 0.640420 | Val Loss: 1.796316\n",
      "Epoch [200/500] | Train Loss: 0.505070 | Val Loss: 1.893076\n",
      "Epoch [300/500] | Train Loss: 0.448012 | Val Loss: 1.920874\n",
      "Epoch [400/500] | Train Loss: 0.420247 | Val Loss: 1.725404\n",
      "Epoch [500/500] | Train Loss: 0.356632 | Val Loss: 1.768609\n",
      "Epoch [100/500] | Train Loss: 1.016860 | Val Loss: 2.223935\n",
      "Epoch [200/500] | Train Loss: 0.879012 | Val Loss: 2.585853\n",
      "Epoch [300/500] | Train Loss: 0.684924 | Val Loss: 2.661463\n",
      "Epoch [400/500] | Train Loss: 0.615890 | Val Loss: 2.449014\n",
      "Epoch [500/500] | Train Loss: 0.577709 | Val Loss: 2.549950\n",
      "Epoch [100/500] | Train Loss: 1.173628 | Val Loss: 2.259660\n",
      "Epoch [200/500] | Train Loss: 0.945850 | Val Loss: 2.429536\n",
      "Epoch [300/500] | Train Loss: 0.883998 | Val Loss: 2.363396\n",
      "Epoch [400/500] | Train Loss: 0.800700 | Val Loss: 2.387271\n",
      "Epoch [500/500] | Train Loss: 0.723859 | Val Loss: 2.517650\n",
      "Epoch [100/500] | Train Loss: 1.344079 | Val Loss: 1.951568\n",
      "Epoch [200/500] | Train Loss: 1.171088 | Val Loss: 2.152035\n",
      "Epoch [300/500] | Train Loss: 1.066666 | Val Loss: 2.456129\n",
      "Epoch [400/500] | Train Loss: 0.910540 | Val Loss: 2.215642\n",
      "Epoch [500/500] | Train Loss: 0.911883 | Val Loss: 2.224370\n",
      "Epoch [100/500] | Train Loss: 1.012965 | Val Loss: 1.181477\n",
      "Epoch [200/500] | Train Loss: 0.920973 | Val Loss: 1.196728\n",
      "Epoch [300/500] | Train Loss: 0.851641 | Val Loss: 1.251531\n",
      "Epoch [400/500] | Train Loss: 0.627206 | Val Loss: 1.283522\n",
      "Epoch [500/500] | Train Loss: 0.621044 | Val Loss: 1.268677\n",
      "Epoch [100/500] | Train Loss: 1.096719 | Val Loss: 1.647121\n",
      "Epoch [200/500] | Train Loss: 1.004145 | Val Loss: 1.613537\n",
      "Epoch [300/500] | Train Loss: 0.965986 | Val Loss: 1.631889\n",
      "Epoch [400/500] | Train Loss: 0.956015 | Val Loss: 1.611510\n",
      "Epoch [500/500] | Train Loss: 0.807435 | Val Loss: 1.612565\n",
      "Epoch [100/500] | Train Loss: 1.271321 | Val Loss: 1.895369\n",
      "Epoch [200/500] | Train Loss: 1.191028 | Val Loss: 1.961828\n",
      "Epoch [300/500] | Train Loss: 1.080161 | Val Loss: 1.989441\n",
      "Epoch [400/500] | Train Loss: 1.031250 | Val Loss: 2.048742\n",
      "Epoch [500/500] | Train Loss: 0.923900 | Val Loss: 2.160540\n",
      "Epoch [100/500] | Train Loss: 1.417550 | Val Loss: 2.120388\n",
      "Epoch [200/500] | Train Loss: 1.381495 | Val Loss: 2.142600\n",
      "Epoch [300/500] | Train Loss: 1.264266 | Val Loss: 2.150466\n",
      "Epoch [400/500] | Train Loss: 1.240880 | Val Loss: 2.108875\n",
      "Epoch [500/500] | Train Loss: 1.258321 | Val Loss: 2.077346\n",
      "Epoch [100/500] | Train Loss: 1.569182 | Val Loss: 1.902440\n",
      "Epoch [200/500] | Train Loss: 1.498284 | Val Loss: 1.917375\n",
      "Epoch [300/500] | Train Loss: 1.436836 | Val Loss: 1.931776\n",
      "Epoch [400/500] | Train Loss: 1.360582 | Val Loss: 1.987191\n",
      "Epoch [500/500] | Train Loss: 1.358098 | Val Loss: 2.030703\n",
      "Epoch [100/500] | Train Loss: 0.679446 | Val Loss: 1.298373\n",
      "Epoch [200/500] | Train Loss: 0.571338 | Val Loss: 1.331480\n",
      "Epoch [300/500] | Train Loss: 0.497556 | Val Loss: 1.406027\n",
      "Epoch [400/500] | Train Loss: 0.506229 | Val Loss: 1.428441\n",
      "Epoch [500/500] | Train Loss: 0.664357 | Val Loss: 1.424629\n",
      "Epoch [100/500] | Train Loss: 0.863166 | Val Loss: 1.912874\n",
      "Epoch [200/500] | Train Loss: 0.701150 | Val Loss: 1.881022\n",
      "Epoch [300/500] | Train Loss: 0.663654 | Val Loss: 1.732246\n",
      "Epoch [400/500] | Train Loss: 0.652004 | Val Loss: 1.726965\n",
      "Epoch [500/500] | Train Loss: 0.557622 | Val Loss: 1.898504\n",
      "Epoch [100/500] | Train Loss: 1.170827 | Val Loss: 2.048901\n",
      "Epoch [200/500] | Train Loss: 0.887825 | Val Loss: 2.164196\n",
      "Epoch [300/500] | Train Loss: 0.862095 | Val Loss: 2.173787\n",
      "Epoch [400/500] | Train Loss: 0.890672 | Val Loss: 2.154992\n",
      "Epoch [500/500] | Train Loss: 0.793898 | Val Loss: 2.179925\n",
      "Epoch [100/500] | Train Loss: 1.237059 | Val Loss: 2.034350\n",
      "Epoch [200/500] | Train Loss: 1.077781 | Val Loss: 2.141582\n",
      "Epoch [300/500] | Train Loss: 1.071568 | Val Loss: 2.180579\n",
      "Epoch [400/500] | Train Loss: 1.059781 | Val Loss: 2.159079\n",
      "Epoch [500/500] | Train Loss: 1.073177 | Val Loss: 2.090256\n",
      "Epoch [100/500] | Train Loss: 1.342838 | Val Loss: 2.010450\n",
      "Epoch [200/500] | Train Loss: 1.214225 | Val Loss: 2.003850\n",
      "Epoch [300/500] | Train Loss: 1.188020 | Val Loss: 2.095178\n",
      "Epoch [400/500] | Train Loss: 1.080026 | Val Loss: 2.191045\n",
      "Epoch [500/500] | Train Loss: 1.126235 | Val Loss: 2.108692\n",
      "Epoch [100/500] | Train Loss: 0.842303 | Val Loss: 1.237486\n",
      "Epoch [200/500] | Train Loss: 0.635661 | Val Loss: 1.359135\n",
      "Epoch [300/500] | Train Loss: 0.509482 | Val Loss: 1.419041\n",
      "Epoch [400/500] | Train Loss: 0.442354 | Val Loss: 1.409691\n",
      "Epoch [500/500] | Train Loss: 0.381464 | Val Loss: 1.437052\n",
      "Epoch [100/500] | Train Loss: 0.968535 | Val Loss: 1.651400\n",
      "Epoch [200/500] | Train Loss: 0.861371 | Val Loss: 1.744460\n",
      "Epoch [300/500] | Train Loss: 0.632799 | Val Loss: 1.837461\n",
      "Epoch [400/500] | Train Loss: 0.565928 | Val Loss: 1.906918\n",
      "Epoch [500/500] | Train Loss: 0.495262 | Val Loss: 1.906336\n",
      "Epoch [100/500] | Train Loss: 1.166947 | Val Loss: 1.989240\n",
      "Epoch [200/500] | Train Loss: 1.057697 | Val Loss: 2.149442\n",
      "Epoch [300/500] | Train Loss: 0.964294 | Val Loss: 2.265216\n",
      "Epoch [400/500] | Train Loss: 0.891484 | Val Loss: 2.279825\n",
      "Epoch [500/500] | Train Loss: 0.788964 | Val Loss: 2.347428\n",
      "Epoch [100/500] | Train Loss: 1.332366 | Val Loss: 2.152421\n",
      "Epoch [200/500] | Train Loss: 1.196928 | Val Loss: 2.254878\n",
      "Epoch [300/500] | Train Loss: 1.047735 | Val Loss: 2.344978\n",
      "Epoch [400/500] | Train Loss: 0.972315 | Val Loss: 2.333558\n",
      "Epoch [500/500] | Train Loss: 0.940667 | Val Loss: 2.358886\n",
      "Epoch [100/500] | Train Loss: 1.486948 | Val Loss: 1.969838\n",
      "Epoch [200/500] | Train Loss: 1.351279 | Val Loss: 2.144175\n",
      "Epoch [300/500] | Train Loss: 1.257652 | Val Loss: 2.162887\n",
      "Epoch [400/500] | Train Loss: 1.100580 | Val Loss: 2.268617\n",
      "Epoch [500/500] | Train Loss: 1.039714 | Val Loss: 2.254953\n",
      "Epoch [100/500] | Train Loss: 0.494863 | Val Loss: 1.405333\n",
      "Epoch [200/500] | Train Loss: 0.281447 | Val Loss: 1.365456\n",
      "Epoch [300/500] | Train Loss: 0.254554 | Val Loss: 1.417595\n",
      "Epoch [400/500] | Train Loss: 0.394295 | Val Loss: 1.387149\n",
      "Epoch [500/500] | Train Loss: 0.353702 | Val Loss: 1.492500\n",
      "Epoch [100/500] | Train Loss: 0.690191 | Val Loss: 2.160070\n",
      "Epoch [200/500] | Train Loss: 0.429320 | Val Loss: 1.976230\n",
      "Epoch [300/500] | Train Loss: 0.372039 | Val Loss: 2.102053\n",
      "Epoch [400/500] | Train Loss: 0.339316 | Val Loss: 2.161914\n",
      "Epoch [500/500] | Train Loss: 0.283083 | Val Loss: 2.194758\n",
      "Epoch [100/500] | Train Loss: 0.825932 | Val Loss: 2.480216\n",
      "Epoch [200/500] | Train Loss: 0.600251 | Val Loss: 2.456190\n",
      "Epoch [300/500] | Train Loss: 0.523776 | Val Loss: 2.521679\n",
      "Epoch [400/500] | Train Loss: 0.565584 | Val Loss: 2.605840\n",
      "Epoch [500/500] | Train Loss: 0.528982 | Val Loss: 2.518447\n",
      "Epoch [100/500] | Train Loss: 1.070728 | Val Loss: 2.201620\n",
      "Epoch [200/500] | Train Loss: 0.790352 | Val Loss: 2.261770\n",
      "Epoch [300/500] | Train Loss: 0.804799 | Val Loss: 2.442218\n",
      "Epoch [400/500] | Train Loss: 0.696732 | Val Loss: 2.514153\n",
      "Epoch [500/500] | Train Loss: 0.662009 | Val Loss: 2.568348\n",
      "Epoch [100/500] | Train Loss: 1.099378 | Val Loss: 2.194801\n",
      "Epoch [200/500] | Train Loss: 0.939643 | Val Loss: 2.335240\n",
      "Epoch [300/500] | Train Loss: 0.856261 | Val Loss: 2.347567\n",
      "Epoch [400/500] | Train Loss: 0.792218 | Val Loss: 2.515891\n",
      "Epoch [500/500] | Train Loss: 0.755397 | Val Loss: 2.554273\n",
      "Epoch [100/500] | Train Loss: 0.865079 | Val Loss: 1.161727\n",
      "Epoch [200/500] | Train Loss: 0.838577 | Val Loss: 1.171138\n",
      "Epoch [300/500] | Train Loss: 0.759973 | Val Loss: 1.231411\n",
      "Epoch [400/500] | Train Loss: 0.650713 | Val Loss: 1.297580\n",
      "Epoch [500/500] | Train Loss: 0.529367 | Val Loss: 1.336271\n",
      "Epoch [100/500] | Train Loss: 1.071835 | Val Loss: 1.659733\n",
      "Epoch [200/500] | Train Loss: 0.867477 | Val Loss: 1.686336\n",
      "Epoch [300/500] | Train Loss: 0.924989 | Val Loss: 1.817533\n",
      "Epoch [400/500] | Train Loss: 0.801043 | Val Loss: 1.814090\n",
      "Epoch [500/500] | Train Loss: 0.641681 | Val Loss: 1.791667\n",
      "Epoch [100/500] | Train Loss: 1.221438 | Val Loss: 1.900016\n",
      "Epoch [200/500] | Train Loss: 1.130557 | Val Loss: 1.963615\n",
      "Epoch [300/500] | Train Loss: 1.057176 | Val Loss: 2.045180\n",
      "Epoch [400/500] | Train Loss: 1.034059 | Val Loss: 2.098196\n",
      "Epoch [500/500] | Train Loss: 0.966351 | Val Loss: 2.099450\n",
      "Epoch [100/500] | Train Loss: 1.386248 | Val Loss: 2.095309\n",
      "Epoch [200/500] | Train Loss: 1.323015 | Val Loss: 2.145854\n",
      "Epoch [300/500] | Train Loss: 1.237030 | Val Loss: 2.175017\n",
      "Epoch [400/500] | Train Loss: 1.163445 | Val Loss: 2.130455\n",
      "Epoch [500/500] | Train Loss: 1.164862 | Val Loss: 2.145026\n",
      "Epoch [100/500] | Train Loss: 1.537423 | Val Loss: 1.886064\n",
      "Epoch [200/500] | Train Loss: 1.479101 | Val Loss: 1.911389\n",
      "Epoch [300/500] | Train Loss: 1.395374 | Val Loss: 1.951678\n",
      "Epoch [400/500] | Train Loss: 1.312155 | Val Loss: 2.029251\n",
      "Epoch [500/500] | Train Loss: 1.223420 | Val Loss: 2.112393\n",
      "Epoch [100/500] | Train Loss: 0.609539 | Val Loss: 1.269106\n",
      "Epoch [200/500] | Train Loss: 0.463117 | Val Loss: 1.311951\n",
      "Epoch [300/500] | Train Loss: 0.490507 | Val Loss: 1.250191\n",
      "Epoch [400/500] | Train Loss: 0.489768 | Val Loss: 1.254922\n",
      "Epoch [500/500] | Train Loss: 0.373734 | Val Loss: 1.287208\n",
      "Epoch [100/500] | Train Loss: 0.694387 | Val Loss: 1.967690\n",
      "Epoch [200/500] | Train Loss: 0.605878 | Val Loss: 1.721985\n",
      "Epoch [300/500] | Train Loss: 0.576474 | Val Loss: 1.860579\n",
      "Epoch [400/500] | Train Loss: 0.566209 | Val Loss: 1.854295\n",
      "Epoch [500/500] | Train Loss: 0.572608 | Val Loss: 1.828661\n",
      "Epoch [100/500] | Train Loss: 0.985141 | Val Loss: 2.236108\n",
      "Epoch [200/500] | Train Loss: 0.844831 | Val Loss: 2.152101\n",
      "Epoch [300/500] | Train Loss: 0.742320 | Val Loss: 2.465245\n",
      "Epoch [400/500] | Train Loss: 0.747221 | Val Loss: 2.417124\n",
      "Epoch [500/500] | Train Loss: 0.746453 | Val Loss: 2.388842\n",
      "Epoch [100/500] | Train Loss: 1.244737 | Val Loss: 2.255988\n",
      "Epoch [200/500] | Train Loss: 1.023474 | Val Loss: 2.134495\n",
      "Epoch [300/500] | Train Loss: 0.929287 | Val Loss: 2.214725\n",
      "Epoch [400/500] | Train Loss: 0.928420 | Val Loss: 2.135712\n",
      "Epoch [500/500] | Train Loss: 0.831662 | Val Loss: 2.170397\n",
      "Epoch [100/500] | Train Loss: 1.298914 | Val Loss: 1.998170\n",
      "Epoch [200/500] | Train Loss: 1.202613 | Val Loss: 2.052210\n",
      "Epoch [300/500] | Train Loss: 1.134769 | Val Loss: 2.056950\n",
      "Epoch [400/500] | Train Loss: 1.071360 | Val Loss: 2.129752\n",
      "Epoch [500/500] | Train Loss: 1.029606 | Val Loss: 2.186806\n",
      "[Year=2002] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.829966 Test MSE=3.000699\n",
      "Year 2002 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.460958 | Val Loss: 1.249518\n",
      "Epoch [200/500] | Train Loss: 1.077568 | Val Loss: 1.460510\n",
      "Epoch [300/500] | Train Loss: 0.784474 | Val Loss: 1.538647\n",
      "Epoch [400/500] | Train Loss: 0.910734 | Val Loss: 1.593887\n",
      "Epoch [500/500] | Train Loss: 0.807459 | Val Loss: 1.628436\n",
      "Epoch [100/500] | Train Loss: 1.300658 | Val Loss: 2.205536\n",
      "Epoch [200/500] | Train Loss: 1.078398 | Val Loss: 2.387902\n",
      "Epoch [300/500] | Train Loss: 1.046634 | Val Loss: 2.373623\n",
      "Epoch [400/500] | Train Loss: 0.880045 | Val Loss: 2.413804\n",
      "Epoch [500/500] | Train Loss: 0.810651 | Val Loss: 2.478498\n",
      "Epoch [100/500] | Train Loss: 1.637189 | Val Loss: 2.401633\n",
      "Epoch [200/500] | Train Loss: 1.474604 | Val Loss: 2.486435\n",
      "Epoch [300/500] | Train Loss: 1.299942 | Val Loss: 2.612063\n",
      "Epoch [400/500] | Train Loss: 1.250180 | Val Loss: 2.755392\n",
      "Epoch [500/500] | Train Loss: 1.220676 | Val Loss: 2.792393\n",
      "Epoch [100/500] | Train Loss: 1.856250 | Val Loss: 1.423416\n",
      "Epoch [200/500] | Train Loss: 1.708163 | Val Loss: 1.411527\n",
      "Epoch [300/500] | Train Loss: 1.595643 | Val Loss: 1.450441\n",
      "Epoch [400/500] | Train Loss: 1.558545 | Val Loss: 1.473598\n",
      "Epoch [500/500] | Train Loss: 1.436688 | Val Loss: 1.475741\n",
      "Epoch [100/500] | Train Loss: 1.712523 | Val Loss: 2.834993\n",
      "Epoch [200/500] | Train Loss: 1.598548 | Val Loss: 3.079165\n",
      "Epoch [300/500] | Train Loss: 1.467432 | Val Loss: 3.307688\n",
      "Epoch [400/500] | Train Loss: 1.444714 | Val Loss: 3.401222\n",
      "Epoch [500/500] | Train Loss: 1.366180 | Val Loss: 3.478386\n",
      "Epoch [100/500] | Train Loss: 0.704479 | Val Loss: 1.618596\n",
      "Epoch [200/500] | Train Loss: 0.455598 | Val Loss: 1.667072\n",
      "Epoch [300/500] | Train Loss: 0.451503 | Val Loss: 1.861802\n",
      "Epoch [400/500] | Train Loss: 0.391829 | Val Loss: 1.726415\n",
      "Epoch [500/500] | Train Loss: 0.281372 | Val Loss: 1.986548\n",
      "Epoch [100/500] | Train Loss: 0.946069 | Val Loss: 2.668869\n",
      "Epoch [200/500] | Train Loss: 0.606736 | Val Loss: 2.810229\n",
      "Epoch [300/500] | Train Loss: 0.688931 | Val Loss: 2.759732\n",
      "Epoch [400/500] | Train Loss: 0.604550 | Val Loss: 2.940205\n",
      "Epoch [500/500] | Train Loss: 0.467758 | Val Loss: 2.766269\n",
      "Epoch [100/500] | Train Loss: 1.142597 | Val Loss: 2.674056\n",
      "Epoch [200/500] | Train Loss: 0.900185 | Val Loss: 2.720172\n",
      "Epoch [300/500] | Train Loss: 0.835620 | Val Loss: 2.706399\n",
      "Epoch [400/500] | Train Loss: 0.799469 | Val Loss: 2.865427\n",
      "Epoch [500/500] | Train Loss: 0.850422 | Val Loss: 2.881781\n",
      "Epoch [100/500] | Train Loss: 1.430504 | Val Loss: 1.365822\n",
      "Epoch [200/500] | Train Loss: 1.341602 | Val Loss: 1.482199\n",
      "Epoch [300/500] | Train Loss: 1.149559 | Val Loss: 1.641934\n",
      "Epoch [400/500] | Train Loss: 1.091518 | Val Loss: 1.746869\n",
      "Epoch [500/500] | Train Loss: 0.970566 | Val Loss: 1.783969\n",
      "Epoch [100/500] | Train Loss: 1.348585 | Val Loss: 3.493481\n",
      "Epoch [200/500] | Train Loss: 1.202747 | Val Loss: 3.707596\n",
      "Epoch [300/500] | Train Loss: 1.146322 | Val Loss: 3.451186\n",
      "Epoch [400/500] | Train Loss: 1.020404 | Val Loss: 3.622811\n",
      "Epoch [500/500] | Train Loss: 1.004649 | Val Loss: 3.826277\n",
      "Epoch [100/500] | Train Loss: 1.505323 | Val Loss: 1.223722\n",
      "Epoch [200/500] | Train Loss: 1.365848 | Val Loss: 1.278431\n",
      "Epoch [300/500] | Train Loss: 1.132395 | Val Loss: 1.345928\n",
      "Epoch [400/500] | Train Loss: 0.990886 | Val Loss: 1.338970\n",
      "Epoch [500/500] | Train Loss: 0.993841 | Val Loss: 1.398208\n",
      "Epoch [100/500] | Train Loss: 1.388309 | Val Loss: 2.160642\n",
      "Epoch [200/500] | Train Loss: 1.295601 | Val Loss: 2.235932\n",
      "Epoch [300/500] | Train Loss: 1.137537 | Val Loss: 2.355800\n",
      "Epoch [400/500] | Train Loss: 1.100831 | Val Loss: 2.374113\n",
      "Epoch [500/500] | Train Loss: 1.069161 | Val Loss: 2.403600\n",
      "Epoch [100/500] | Train Loss: 1.653888 | Val Loss: 2.385752\n",
      "Epoch [200/500] | Train Loss: 1.588607 | Val Loss: 2.397642\n",
      "Epoch [300/500] | Train Loss: 1.512337 | Val Loss: 2.421259\n",
      "Epoch [400/500] | Train Loss: 1.450498 | Val Loss: 2.471516\n",
      "Epoch [500/500] | Train Loss: 1.334211 | Val Loss: 2.522708\n",
      "Epoch [100/500] | Train Loss: 1.848266 | Val Loss: 1.413094\n",
      "Epoch [200/500] | Train Loss: 1.745714 | Val Loss: 1.407638\n",
      "Epoch [300/500] | Train Loss: 1.716024 | Val Loss: 1.443557\n",
      "Epoch [400/500] | Train Loss: 1.648024 | Val Loss: 1.476070\n",
      "Epoch [500/500] | Train Loss: 1.584374 | Val Loss: 1.497819\n",
      "Epoch [100/500] | Train Loss: 1.742645 | Val Loss: 2.807140\n",
      "Epoch [200/500] | Train Loss: 1.718710 | Val Loss: 2.849307\n",
      "Epoch [300/500] | Train Loss: 1.658033 | Val Loss: 2.964063\n",
      "Epoch [400/500] | Train Loss: 1.635311 | Val Loss: 3.029295\n",
      "Epoch [500/500] | Train Loss: 1.582846 | Val Loss: 3.085620\n",
      "Epoch [100/500] | Train Loss: 0.908974 | Val Loss: 1.488052\n",
      "Epoch [200/500] | Train Loss: 0.724267 | Val Loss: 1.595508\n",
      "Epoch [300/500] | Train Loss: 0.674727 | Val Loss: 1.555790\n",
      "Epoch [400/500] | Train Loss: 0.577118 | Val Loss: 1.558822\n",
      "Epoch [500/500] | Train Loss: 0.519594 | Val Loss: 1.667795\n",
      "Epoch [100/500] | Train Loss: 1.111198 | Val Loss: 2.340473\n",
      "Epoch [200/500] | Train Loss: 1.009592 | Val Loss: 2.365082\n",
      "Epoch [300/500] | Train Loss: 0.985715 | Val Loss: 2.335109\n",
      "Epoch [400/500] | Train Loss: 0.805691 | Val Loss: 2.391061\n",
      "Epoch [500/500] | Train Loss: 0.811540 | Val Loss: 2.494085\n",
      "Epoch [100/500] | Train Loss: 1.464604 | Val Loss: 2.590111\n",
      "Epoch [200/500] | Train Loss: 1.159163 | Val Loss: 2.755366\n",
      "Epoch [300/500] | Train Loss: 1.182649 | Val Loss: 2.715975\n",
      "Epoch [400/500] | Train Loss: 1.066892 | Val Loss: 2.870340\n",
      "Epoch [500/500] | Train Loss: 0.977962 | Val Loss: 2.779382\n",
      "Epoch [100/500] | Train Loss: 1.564315 | Val Loss: 1.474981\n",
      "Epoch [200/500] | Train Loss: 1.394962 | Val Loss: 1.577286\n",
      "Epoch [300/500] | Train Loss: 1.404853 | Val Loss: 1.628608\n",
      "Epoch [400/500] | Train Loss: 1.362204 | Val Loss: 1.605511\n",
      "Epoch [500/500] | Train Loss: 1.345126 | Val Loss: 1.721112\n",
      "Epoch [100/500] | Train Loss: 1.616386 | Val Loss: 3.013870\n",
      "Epoch [200/500] | Train Loss: 1.532168 | Val Loss: 3.292267\n",
      "Epoch [300/500] | Train Loss: 1.454344 | Val Loss: 3.263155\n",
      "Epoch [400/500] | Train Loss: 1.462568 | Val Loss: 3.325022\n",
      "Epoch [500/500] | Train Loss: 1.361982 | Val Loss: 3.488426\n",
      "Epoch [100/500] | Train Loss: 1.366785 | Val Loss: 1.316275\n",
      "Epoch [200/500] | Train Loss: 0.897860 | Val Loss: 1.572421\n",
      "Epoch [300/500] | Train Loss: 0.696316 | Val Loss: 1.708940\n",
      "Epoch [400/500] | Train Loss: 0.535362 | Val Loss: 1.717689\n",
      "Epoch [500/500] | Train Loss: 0.527114 | Val Loss: 1.828972\n",
      "Epoch [100/500] | Train Loss: 1.337187 | Val Loss: 2.182819\n",
      "Epoch [200/500] | Train Loss: 1.039422 | Val Loss: 2.458368\n",
      "Epoch [300/500] | Train Loss: 0.877720 | Val Loss: 2.571311\n",
      "Epoch [400/500] | Train Loss: 0.754236 | Val Loss: 2.539728\n",
      "Epoch [500/500] | Train Loss: 0.727571 | Val Loss: 2.617853\n",
      "Epoch [100/500] | Train Loss: 1.514434 | Val Loss: 2.622517\n",
      "Epoch [200/500] | Train Loss: 1.288180 | Val Loss: 2.867947\n",
      "Epoch [300/500] | Train Loss: 1.174692 | Val Loss: 3.024735\n",
      "Epoch [400/500] | Train Loss: 1.063790 | Val Loss: 2.946829\n",
      "Epoch [500/500] | Train Loss: 0.990117 | Val Loss: 2.930844\n",
      "Epoch [100/500] | Train Loss: 1.730224 | Val Loss: 1.395674\n",
      "Epoch [200/500] | Train Loss: 1.605838 | Val Loss: 1.422483\n",
      "Epoch [300/500] | Train Loss: 1.441248 | Val Loss: 1.495488\n",
      "Epoch [400/500] | Train Loss: 1.352901 | Val Loss: 1.499181\n",
      "Epoch [500/500] | Train Loss: 1.313472 | Val Loss: 1.516950\n",
      "Epoch [100/500] | Train Loss: 1.732958 | Val Loss: 2.869673\n",
      "Epoch [200/500] | Train Loss: 1.529861 | Val Loss: 3.142069\n",
      "Epoch [300/500] | Train Loss: 1.438693 | Val Loss: 3.394778\n",
      "Epoch [400/500] | Train Loss: 1.343503 | Val Loss: 3.545704\n",
      "Epoch [500/500] | Train Loss: 1.234947 | Val Loss: 3.713232\n",
      "Epoch [100/500] | Train Loss: 0.609640 | Val Loss: 1.881739\n",
      "Epoch [200/500] | Train Loss: 0.415758 | Val Loss: 2.016065\n",
      "Epoch [300/500] | Train Loss: 0.338878 | Val Loss: 1.927936\n",
      "Epoch [400/500] | Train Loss: 0.387695 | Val Loss: 2.016098\n",
      "Epoch [500/500] | Train Loss: 0.320070 | Val Loss: 2.029480\n",
      "Epoch [100/500] | Train Loss: 0.783403 | Val Loss: 2.620400\n",
      "Epoch [200/500] | Train Loss: 0.574756 | Val Loss: 2.839015\n",
      "Epoch [300/500] | Train Loss: 0.490463 | Val Loss: 2.745431\n",
      "Epoch [400/500] | Train Loss: 0.475026 | Val Loss: 2.855848\n",
      "Epoch [500/500] | Train Loss: 0.387346 | Val Loss: 2.901062\n",
      "Epoch [100/500] | Train Loss: 1.122012 | Val Loss: 2.701940\n",
      "Epoch [200/500] | Train Loss: 0.972577 | Val Loss: 3.092400\n",
      "Epoch [300/500] | Train Loss: 0.777822 | Val Loss: 3.296063\n",
      "Epoch [400/500] | Train Loss: 0.636626 | Val Loss: 3.192887\n",
      "Epoch [500/500] | Train Loss: 0.676827 | Val Loss: 3.338749\n",
      "Epoch [100/500] | Train Loss: 1.280893 | Val Loss: 1.705179\n",
      "Epoch [200/500] | Train Loss: 1.081739 | Val Loss: 1.675074\n",
      "Epoch [300/500] | Train Loss: 0.971469 | Val Loss: 1.842615\n",
      "Epoch [400/500] | Train Loss: 0.940325 | Val Loss: 1.834638\n",
      "Epoch [500/500] | Train Loss: 0.940473 | Val Loss: 1.835123\n",
      "Epoch [100/500] | Train Loss: 1.390792 | Val Loss: 3.478701\n",
      "Epoch [200/500] | Train Loss: 1.179698 | Val Loss: 4.082355\n",
      "Epoch [300/500] | Train Loss: 1.108946 | Val Loss: 4.029816\n",
      "Epoch [400/500] | Train Loss: 0.992903 | Val Loss: 3.927791\n",
      "Epoch [500/500] | Train Loss: 0.987535 | Val Loss: 3.947284\n",
      "Epoch [100/500] | Train Loss: 1.542650 | Val Loss: 1.232605\n",
      "Epoch [200/500] | Train Loss: 1.304438 | Val Loss: 1.371941\n",
      "Epoch [300/500] | Train Loss: 0.952693 | Val Loss: 1.476430\n",
      "Epoch [400/500] | Train Loss: 0.963320 | Val Loss: 1.514761\n",
      "Epoch [500/500] | Train Loss: 0.707955 | Val Loss: 1.599595\n",
      "Epoch [100/500] | Train Loss: 1.333166 | Val Loss: 2.164154\n",
      "Epoch [200/500] | Train Loss: 1.125945 | Val Loss: 2.336123\n",
      "Epoch [300/500] | Train Loss: 1.015562 | Val Loss: 2.429232\n",
      "Epoch [400/500] | Train Loss: 0.990733 | Val Loss: 2.482835\n",
      "Epoch [500/500] | Train Loss: 0.920808 | Val Loss: 2.441886\n",
      "Epoch [100/500] | Train Loss: 1.611733 | Val Loss: 2.394095\n",
      "Epoch [200/500] | Train Loss: 1.538679 | Val Loss: 2.472683\n",
      "Epoch [300/500] | Train Loss: 1.375526 | Val Loss: 2.565820\n",
      "Epoch [400/500] | Train Loss: 1.257660 | Val Loss: 2.668392\n",
      "Epoch [500/500] | Train Loss: 1.191946 | Val Loss: 2.695680\n",
      "Epoch [100/500] | Train Loss: 1.773155 | Val Loss: 1.407019\n",
      "Epoch [200/500] | Train Loss: 1.700059 | Val Loss: 1.423118\n",
      "Epoch [300/500] | Train Loss: 1.583414 | Val Loss: 1.449592\n",
      "Epoch [400/500] | Train Loss: 1.494158 | Val Loss: 1.486394\n",
      "Epoch [500/500] | Train Loss: 1.491677 | Val Loss: 1.544953\n",
      "Epoch [100/500] | Train Loss: 1.700040 | Val Loss: 2.854948\n",
      "Epoch [200/500] | Train Loss: 1.579685 | Val Loss: 3.049332\n",
      "Epoch [300/500] | Train Loss: 1.558053 | Val Loss: 3.122133\n",
      "Epoch [400/500] | Train Loss: 1.459644 | Val Loss: 3.153243\n",
      "Epoch [500/500] | Train Loss: 1.411187 | Val Loss: 3.147752\n",
      "Epoch [100/500] | Train Loss: 0.754647 | Val Loss: 1.488645\n",
      "Epoch [200/500] | Train Loss: 0.619059 | Val Loss: 1.599487\n",
      "Epoch [300/500] | Train Loss: 0.692871 | Val Loss: 1.578242\n",
      "Epoch [400/500] | Train Loss: 0.520122 | Val Loss: 1.702519\n",
      "Epoch [500/500] | Train Loss: 0.465529 | Val Loss: 1.699197\n",
      "Epoch [100/500] | Train Loss: 1.068676 | Val Loss: 2.348354\n",
      "Epoch [200/500] | Train Loss: 0.891155 | Val Loss: 2.437325\n",
      "Epoch [300/500] | Train Loss: 0.938466 | Val Loss: 2.655644\n",
      "Epoch [400/500] | Train Loss: 0.716602 | Val Loss: 2.581183\n",
      "Epoch [500/500] | Train Loss: 0.734037 | Val Loss: 2.542916\n",
      "Epoch [100/500] | Train Loss: 1.290340 | Val Loss: 2.473753\n",
      "Epoch [200/500] | Train Loss: 1.151282 | Val Loss: 2.528444\n",
      "Epoch [300/500] | Train Loss: 1.018175 | Val Loss: 2.696448\n",
      "Epoch [400/500] | Train Loss: 1.017688 | Val Loss: 2.689840\n",
      "Epoch [500/500] | Train Loss: 0.957954 | Val Loss: 2.660017\n",
      "Epoch [100/500] | Train Loss: 1.486814 | Val Loss: 1.550799\n",
      "Epoch [200/500] | Train Loss: 1.248903 | Val Loss: 1.666104\n",
      "Epoch [300/500] | Train Loss: 1.265560 | Val Loss: 1.639480\n",
      "Epoch [400/500] | Train Loss: 1.168883 | Val Loss: 1.634593\n",
      "Epoch [500/500] | Train Loss: 1.209091 | Val Loss: 1.697277\n",
      "Epoch [100/500] | Train Loss: 1.572931 | Val Loss: 3.229035\n",
      "Epoch [200/500] | Train Loss: 1.418566 | Val Loss: 3.218789\n",
      "Epoch [300/500] | Train Loss: 1.332206 | Val Loss: 3.189771\n",
      "Epoch [400/500] | Train Loss: 1.296044 | Val Loss: 3.472497\n",
      "Epoch [500/500] | Train Loss: 1.211264 | Val Loss: 3.412496\n",
      "[Year=2003] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=2.181591 Test MSE=1.184613\n",
      "Year 2003 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.218826 | Val Loss: 2.131271\n",
      "Epoch [200/500] | Train Loss: 0.989578 | Val Loss: 2.452767\n",
      "Epoch [300/500] | Train Loss: 0.738115 | Val Loss: 2.655857\n",
      "Epoch [400/500] | Train Loss: 0.637552 | Val Loss: 2.899987\n",
      "Epoch [500/500] | Train Loss: 0.556729 | Val Loss: 2.893365\n",
      "Epoch [100/500] | Train Loss: 1.587415 | Val Loss: 2.434837\n",
      "Epoch [200/500] | Train Loss: 1.413336 | Val Loss: 2.714920\n",
      "Epoch [300/500] | Train Loss: 1.285532 | Val Loss: 2.991445\n",
      "Epoch [400/500] | Train Loss: 1.159138 | Val Loss: 3.058794\n",
      "Epoch [500/500] | Train Loss: 1.035872 | Val Loss: 3.088438\n",
      "Epoch [100/500] | Train Loss: 1.811465 | Val Loss: 1.387570\n",
      "Epoch [200/500] | Train Loss: 1.664792 | Val Loss: 1.471076\n",
      "Epoch [300/500] | Train Loss: 1.532343 | Val Loss: 1.569717\n",
      "Epoch [400/500] | Train Loss: 1.587324 | Val Loss: 1.612110\n",
      "Epoch [500/500] | Train Loss: 1.362289 | Val Loss: 1.669126\n",
      "Epoch [100/500] | Train Loss: 1.689111 | Val Loss: 2.990333\n",
      "Epoch [200/500] | Train Loss: 1.598479 | Val Loss: 3.145259\n",
      "Epoch [300/500] | Train Loss: 1.456256 | Val Loss: 3.316419\n",
      "Epoch [400/500] | Train Loss: 1.425345 | Val Loss: 3.403139\n",
      "Epoch [500/500] | Train Loss: 1.350130 | Val Loss: 3.497139\n",
      "Epoch [100/500] | Train Loss: 1.986534 | Val Loss: 1.024191\n",
      "Epoch [200/500] | Train Loss: 1.895182 | Val Loss: 1.064721\n",
      "Epoch [300/500] | Train Loss: 1.790268 | Val Loss: 1.079325\n",
      "Epoch [400/500] | Train Loss: 1.659003 | Val Loss: 1.128958\n",
      "Epoch [500/500] | Train Loss: 1.643950 | Val Loss: 1.166557\n",
      "Epoch [100/500] | Train Loss: 0.689498 | Val Loss: 2.879620\n",
      "Epoch [200/500] | Train Loss: 0.561706 | Val Loss: 2.577987\n",
      "Epoch [300/500] | Train Loss: 0.447658 | Val Loss: 2.742765\n",
      "Epoch [400/500] | Train Loss: 0.440263 | Val Loss: 2.801733\n",
      "Epoch [500/500] | Train Loss: 0.348642 | Val Loss: 2.705638\n",
      "Epoch [100/500] | Train Loss: 1.582621 | Val Loss: 2.438397\n",
      "Epoch [200/500] | Train Loss: 1.274299 | Val Loss: 2.757375\n",
      "Epoch [300/500] | Train Loss: 1.024458 | Val Loss: 2.889958\n",
      "Epoch [400/500] | Train Loss: 0.891237 | Val Loss: 3.223520\n",
      "Epoch [500/500] | Train Loss: 0.831226 | Val Loss: 3.237231\n",
      "Epoch [100/500] | Train Loss: 1.551246 | Val Loss: 1.561067\n",
      "Epoch [200/500] | Train Loss: 1.223771 | Val Loss: 1.848790\n",
      "Epoch [300/500] | Train Loss: 1.096318 | Val Loss: 1.973405\n",
      "Epoch [400/500] | Train Loss: 1.027151 | Val Loss: 1.946734\n",
      "Epoch [500/500] | Train Loss: 1.000020 | Val Loss: 1.874229\n",
      "Epoch [100/500] | Train Loss: 1.357376 | Val Loss: 3.786698\n",
      "Epoch [200/500] | Train Loss: 1.176352 | Val Loss: 4.232356\n",
      "Epoch [300/500] | Train Loss: 1.159998 | Val Loss: 4.163465\n",
      "Epoch [400/500] | Train Loss: 1.108037 | Val Loss: 4.330149\n",
      "Epoch [500/500] | Train Loss: 0.990569 | Val Loss: 4.292663\n",
      "Epoch [100/500] | Train Loss: 1.720034 | Val Loss: 1.146232\n",
      "Epoch [200/500] | Train Loss: 1.396512 | Val Loss: 1.367197\n",
      "Epoch [300/500] | Train Loss: 1.415143 | Val Loss: 1.340546\n",
      "Epoch [400/500] | Train Loss: 1.345729 | Val Loss: 1.432079\n",
      "Epoch [500/500] | Train Loss: 1.227682 | Val Loss: 1.390009\n",
      "Epoch [100/500] | Train Loss: 1.235873 | Val Loss: 2.073693\n",
      "Epoch [200/500] | Train Loss: 1.168143 | Val Loss: 2.085104\n",
      "Epoch [300/500] | Train Loss: 1.182854 | Val Loss: 2.146704\n",
      "Epoch [400/500] | Train Loss: 1.044433 | Val Loss: 2.237687\n",
      "Epoch [500/500] | Train Loss: 0.931958 | Val Loss: 2.324500\n",
      "Epoch [100/500] | Train Loss: 1.635990 | Val Loss: 2.472129\n",
      "Epoch [200/500] | Train Loss: 1.616602 | Val Loss: 2.497020\n",
      "Epoch [300/500] | Train Loss: 1.436449 | Val Loss: 2.542162\n",
      "Epoch [400/500] | Train Loss: 1.394068 | Val Loss: 2.600225\n",
      "Epoch [500/500] | Train Loss: 1.354873 | Val Loss: 2.594791\n",
      "Epoch [100/500] | Train Loss: 1.924689 | Val Loss: 1.356830\n",
      "Epoch [200/500] | Train Loss: 1.807874 | Val Loss: 1.384814\n",
      "Epoch [300/500] | Train Loss: 1.781733 | Val Loss: 1.410613\n",
      "Epoch [400/500] | Train Loss: 1.682622 | Val Loss: 1.465207\n",
      "Epoch [500/500] | Train Loss: 1.642416 | Val Loss: 1.472900\n",
      "Epoch [100/500] | Train Loss: 1.715858 | Val Loss: 2.951128\n",
      "Epoch [200/500] | Train Loss: 1.714091 | Val Loss: 2.975652\n",
      "Epoch [300/500] | Train Loss: 1.670836 | Val Loss: 3.039428\n",
      "Epoch [400/500] | Train Loss: 1.646982 | Val Loss: 3.100615\n",
      "Epoch [500/500] | Train Loss: 1.583646 | Val Loss: 3.103390\n",
      "Epoch [100/500] | Train Loss: 1.982118 | Val Loss: 1.001995\n",
      "Epoch [200/500] | Train Loss: 1.962790 | Val Loss: 1.018347\n",
      "Epoch [300/500] | Train Loss: 1.922377 | Val Loss: 1.038949\n",
      "Epoch [400/500] | Train Loss: 1.918477 | Val Loss: 1.051138\n",
      "Epoch [500/500] | Train Loss: 1.854663 | Val Loss: 1.065039\n",
      "Epoch [100/500] | Train Loss: 1.038041 | Val Loss: 2.328710\n",
      "Epoch [200/500] | Train Loss: 0.792664 | Val Loss: 2.606958\n",
      "Epoch [300/500] | Train Loss: 0.752626 | Val Loss: 2.447455\n",
      "Epoch [400/500] | Train Loss: 0.569232 | Val Loss: 2.720906\n",
      "Epoch [500/500] | Train Loss: 0.757986 | Val Loss: 2.680463\n",
      "Epoch [100/500] | Train Loss: 1.219499 | Val Loss: 2.642605\n",
      "Epoch [200/500] | Train Loss: 1.113603 | Val Loss: 2.703439\n",
      "Epoch [300/500] | Train Loss: 1.066957 | Val Loss: 2.876101\n",
      "Epoch [400/500] | Train Loss: 1.101068 | Val Loss: 2.759616\n",
      "Epoch [500/500] | Train Loss: 0.978662 | Val Loss: 2.904261\n",
      "Epoch [100/500] | Train Loss: 1.645795 | Val Loss: 1.538194\n",
      "Epoch [200/500] | Train Loss: 1.491025 | Val Loss: 1.566627\n",
      "Epoch [300/500] | Train Loss: 1.337168 | Val Loss: 1.552662\n",
      "Epoch [400/500] | Train Loss: 1.307145 | Val Loss: 1.629485\n",
      "Epoch [500/500] | Train Loss: 1.272848 | Val Loss: 1.650674\n",
      "Epoch [100/500] | Train Loss: 1.691202 | Val Loss: 3.111632\n",
      "Epoch [200/500] | Train Loss: 1.621771 | Val Loss: 3.180234\n",
      "Epoch [300/500] | Train Loss: 1.525939 | Val Loss: 3.358967\n",
      "Epoch [400/500] | Train Loss: 1.446083 | Val Loss: 3.325789\n",
      "Epoch [500/500] | Train Loss: 1.454368 | Val Loss: 3.484976\n",
      "Epoch [100/500] | Train Loss: 1.886711 | Val Loss: 1.068389\n",
      "Epoch [200/500] | Train Loss: 1.747687 | Val Loss: 1.189991\n",
      "Epoch [300/500] | Train Loss: 1.649175 | Val Loss: 1.160673\n",
      "Epoch [400/500] | Train Loss: 1.519618 | Val Loss: 1.136298\n",
      "Epoch [500/500] | Train Loss: 1.599079 | Val Loss: 1.171822\n",
      "Epoch [100/500] | Train Loss: 1.191613 | Val Loss: 2.169184\n",
      "Epoch [200/500] | Train Loss: 0.902531 | Val Loss: 2.663247\n",
      "Epoch [300/500] | Train Loss: 0.715564 | Val Loss: 2.905216\n",
      "Epoch [400/500] | Train Loss: 0.618739 | Val Loss: 2.883824\n",
      "Epoch [500/500] | Train Loss: 0.556304 | Val Loss: 2.948048\n",
      "Epoch [100/500] | Train Loss: 1.554878 | Val Loss: 2.505585\n",
      "Epoch [200/500] | Train Loss: 1.375912 | Val Loss: 2.695954\n",
      "Epoch [300/500] | Train Loss: 1.178217 | Val Loss: 3.034560\n",
      "Epoch [400/500] | Train Loss: 1.079066 | Val Loss: 3.195431\n",
      "Epoch [500/500] | Train Loss: 0.871822 | Val Loss: 3.296083\n",
      "Epoch [100/500] | Train Loss: 1.848756 | Val Loss: 1.370281\n",
      "Epoch [200/500] | Train Loss: 1.624522 | Val Loss: 1.500075\n",
      "Epoch [300/500] | Train Loss: 1.467344 | Val Loss: 1.614144\n",
      "Epoch [400/500] | Train Loss: 1.421926 | Val Loss: 1.729676\n",
      "Epoch [500/500] | Train Loss: 1.262357 | Val Loss: 1.872424\n",
      "Epoch [100/500] | Train Loss: 1.713071 | Val Loss: 2.979803\n",
      "Epoch [200/500] | Train Loss: 1.588341 | Val Loss: 3.249222\n",
      "Epoch [300/500] | Train Loss: 1.435949 | Val Loss: 3.580147\n",
      "Epoch [400/500] | Train Loss: 1.376276 | Val Loss: 3.836763\n",
      "Epoch [500/500] | Train Loss: 1.315078 | Val Loss: 3.950881\n",
      "Epoch [100/500] | Train Loss: 1.933883 | Val Loss: 1.072517\n",
      "Epoch [200/500] | Train Loss: 1.800480 | Val Loss: 1.135916\n",
      "Epoch [300/500] | Train Loss: 1.643581 | Val Loss: 1.188676\n",
      "Epoch [400/500] | Train Loss: 1.569155 | Val Loss: 1.232014\n",
      "Epoch [500/500] | Train Loss: 1.518456 | Val Loss: 1.257758\n",
      "Epoch [100/500] | Train Loss: 0.709478 | Val Loss: 2.671358\n",
      "Epoch [200/500] | Train Loss: 0.532323 | Val Loss: 2.775353\n",
      "Epoch [300/500] | Train Loss: 0.403752 | Val Loss: 2.769308\n",
      "Epoch [400/500] | Train Loss: 0.351009 | Val Loss: 2.855582\n",
      "Epoch [500/500] | Train Loss: 0.379508 | Val Loss: 2.797499\n",
      "Epoch [100/500] | Train Loss: 1.062742 | Val Loss: 3.111577\n",
      "Epoch [200/500] | Train Loss: 0.813607 | Val Loss: 3.784070\n",
      "Epoch [300/500] | Train Loss: 0.640279 | Val Loss: 3.590843\n",
      "Epoch [400/500] | Train Loss: 0.641204 | Val Loss: 3.664561\n",
      "Epoch [500/500] | Train Loss: 0.567802 | Val Loss: 3.788901\n",
      "Epoch [100/500] | Train Loss: 1.273830 | Val Loss: 1.778805\n",
      "Epoch [200/500] | Train Loss: 1.064974 | Val Loss: 1.949642\n",
      "Epoch [300/500] | Train Loss: 0.841440 | Val Loss: 2.091696\n",
      "Epoch [400/500] | Train Loss: 0.950137 | Val Loss: 2.133192\n",
      "Epoch [500/500] | Train Loss: 0.864034 | Val Loss: 2.251298\n",
      "Epoch [100/500] | Train Loss: 1.377993 | Val Loss: 3.773926\n",
      "Epoch [200/500] | Train Loss: 1.202187 | Val Loss: 4.040223\n",
      "Epoch [300/500] | Train Loss: 1.029678 | Val Loss: 4.481699\n",
      "Epoch [400/500] | Train Loss: 1.029824 | Val Loss: 4.274992\n",
      "Epoch [500/500] | Train Loss: 0.858699 | Val Loss: 4.388857\n",
      "Epoch [100/500] | Train Loss: 1.728908 | Val Loss: 1.182333\n",
      "Epoch [200/500] | Train Loss: 1.396303 | Val Loss: 1.276257\n",
      "Epoch [300/500] | Train Loss: 1.364775 | Val Loss: 1.418942\n",
      "Epoch [400/500] | Train Loss: 1.257670 | Val Loss: 1.470721\n",
      "Epoch [500/500] | Train Loss: 1.187595 | Val Loss: 1.457564\n",
      "Epoch [100/500] | Train Loss: 1.186271 | Val Loss: 2.043599\n",
      "Epoch [200/500] | Train Loss: 1.031737 | Val Loss: 2.103883\n",
      "Epoch [300/500] | Train Loss: 0.991591 | Val Loss: 2.278363\n",
      "Epoch [400/500] | Train Loss: 0.811470 | Val Loss: 2.392897\n",
      "Epoch [500/500] | Train Loss: 0.821034 | Val Loss: 2.561297\n",
      "Epoch [100/500] | Train Loss: 1.585122 | Val Loss: 2.444392\n",
      "Epoch [200/500] | Train Loss: 1.479212 | Val Loss: 2.536660\n",
      "Epoch [300/500] | Train Loss: 1.364497 | Val Loss: 2.617815\n",
      "Epoch [400/500] | Train Loss: 1.236436 | Val Loss: 2.793105\n",
      "Epoch [500/500] | Train Loss: 1.129177 | Val Loss: 2.890351\n",
      "Epoch [100/500] | Train Loss: 1.851177 | Val Loss: 1.373344\n",
      "Epoch [200/500] | Train Loss: 1.782731 | Val Loss: 1.430166\n",
      "Epoch [300/500] | Train Loss: 1.558706 | Val Loss: 1.511377\n",
      "Epoch [400/500] | Train Loss: 1.603208 | Val Loss: 1.670901\n",
      "Epoch [500/500] | Train Loss: 1.465254 | Val Loss: 1.738735\n",
      "Epoch [100/500] | Train Loss: 1.737804 | Val Loss: 3.006792\n",
      "Epoch [200/500] | Train Loss: 1.625068 | Val Loss: 3.137500\n",
      "Epoch [300/500] | Train Loss: 1.640424 | Val Loss: 3.288593\n",
      "Epoch [400/500] | Train Loss: 1.506041 | Val Loss: 3.414461\n",
      "Epoch [500/500] | Train Loss: 1.367932 | Val Loss: 3.574078\n",
      "Epoch [100/500] | Train Loss: 1.952060 | Val Loss: 1.043472\n",
      "Epoch [200/500] | Train Loss: 1.874134 | Val Loss: 1.094654\n",
      "Epoch [300/500] | Train Loss: 1.870020 | Val Loss: 1.109748\n",
      "Epoch [400/500] | Train Loss: 1.777425 | Val Loss: 1.120548\n",
      "Epoch [500/500] | Train Loss: 1.739586 | Val Loss: 1.134856\n",
      "Epoch [100/500] | Train Loss: 0.886722 | Val Loss: 2.402790\n",
      "Epoch [200/500] | Train Loss: 0.657754 | Val Loss: 2.803952\n",
      "Epoch [300/500] | Train Loss: 0.581261 | Val Loss: 2.713402\n",
      "Epoch [400/500] | Train Loss: 0.560694 | Val Loss: 2.668568\n",
      "Epoch [500/500] | Train Loss: 0.488329 | Val Loss: 2.782990\n",
      "Epoch [100/500] | Train Loss: 1.165321 | Val Loss: 3.022713\n",
      "Epoch [200/500] | Train Loss: 1.003023 | Val Loss: 2.909919\n",
      "Epoch [300/500] | Train Loss: 0.903134 | Val Loss: 3.005248\n",
      "Epoch [400/500] | Train Loss: 0.832808 | Val Loss: 2.968482\n",
      "Epoch [500/500] | Train Loss: 0.801956 | Val Loss: 3.166447\n",
      "Epoch [100/500] | Train Loss: 1.510222 | Val Loss: 1.604834\n",
      "Epoch [200/500] | Train Loss: 1.328963 | Val Loss: 1.749523\n",
      "Epoch [300/500] | Train Loss: 1.334212 | Val Loss: 1.730232\n",
      "Epoch [400/500] | Train Loss: 1.175005 | Val Loss: 1.795273\n",
      "Epoch [500/500] | Train Loss: 1.176581 | Val Loss: 1.788347\n",
      "Epoch [100/500] | Train Loss: 1.520757 | Val Loss: 3.375262\n",
      "Epoch [200/500] | Train Loss: 1.436004 | Val Loss: 3.508228\n",
      "Epoch [300/500] | Train Loss: 1.306996 | Val Loss: 3.604248\n",
      "Epoch [400/500] | Train Loss: 1.239863 | Val Loss: 3.684106\n",
      "Epoch [500/500] | Train Loss: 1.220252 | Val Loss: 3.553973\n",
      "Epoch [100/500] | Train Loss: 1.880161 | Val Loss: 1.097227\n",
      "Epoch [200/500] | Train Loss: 1.762834 | Val Loss: 1.101862\n",
      "Epoch [300/500] | Train Loss: 1.645824 | Val Loss: 1.223583\n",
      "Epoch [400/500] | Train Loss: 1.546273 | Val Loss: 1.283644\n",
      "Epoch [500/500] | Train Loss: 1.490115 | Val Loss: 1.313453\n",
      "[Year=2004] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=2.112124 Test MSE=0.530044\n",
      "Year 2004 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 2.038945 | Val Loss: 2.281160\n",
      "Epoch [200/500] | Train Loss: 1.759354 | Val Loss: 2.529493\n",
      "Epoch [300/500] | Train Loss: 1.407452 | Val Loss: 2.764238\n",
      "Epoch [400/500] | Train Loss: 1.159012 | Val Loss: 3.075504\n",
      "Epoch [500/500] | Train Loss: 1.044253 | Val Loss: 3.185391\n",
      "Epoch [100/500] | Train Loss: 2.132689 | Val Loss: 1.580982\n",
      "Epoch [200/500] | Train Loss: 1.834940 | Val Loss: 1.776238\n",
      "Epoch [300/500] | Train Loss: 1.638444 | Val Loss: 1.877945\n",
      "Epoch [400/500] | Train Loss: 1.564561 | Val Loss: 2.010060\n",
      "Epoch [500/500] | Train Loss: 1.501466 | Val Loss: 2.070409\n",
      "Epoch [100/500] | Train Loss: 1.980904 | Val Loss: 2.969698\n",
      "Epoch [200/500] | Train Loss: 1.748690 | Val Loss: 3.218084\n",
      "Epoch [300/500] | Train Loss: 1.626455 | Val Loss: 3.457737\n",
      "Epoch [400/500] | Train Loss: 1.500256 | Val Loss: 3.656285\n",
      "Epoch [500/500] | Train Loss: 1.451147 | Val Loss: 3.631751\n",
      "Epoch [100/500] | Train Loss: 2.199286 | Val Loss: 0.732716\n",
      "Epoch [200/500] | Train Loss: 2.098803 | Val Loss: 0.770710\n",
      "Epoch [300/500] | Train Loss: 1.967813 | Val Loss: 0.732911\n",
      "Epoch [400/500] | Train Loss: 1.869406 | Val Loss: 0.733080\n",
      "Epoch [500/500] | Train Loss: 1.794784 | Val Loss: 0.761454\n",
      "Epoch [100/500] | Train Loss: 1.853393 | Val Loss: 0.565057\n",
      "Epoch [200/500] | Train Loss: 1.727669 | Val Loss: 0.572135\n",
      "Epoch [300/500] | Train Loss: 1.653360 | Val Loss: 0.578665\n",
      "Epoch [400/500] | Train Loss: 1.620974 | Val Loss: 0.586119\n",
      "Epoch [500/500] | Train Loss: 1.516071 | Val Loss: 0.575436\n",
      "Epoch [100/500] | Train Loss: 1.013123 | Val Loss: 3.235697\n",
      "Epoch [200/500] | Train Loss: 1.013196 | Val Loss: 3.547300\n",
      "Epoch [300/500] | Train Loss: 0.634667 | Val Loss: 3.850548\n",
      "Epoch [400/500] | Train Loss: 0.590172 | Val Loss: 4.033344\n",
      "Epoch [500/500] | Train Loss: 0.557096 | Val Loss: 3.793796\n",
      "Epoch [100/500] | Train Loss: 1.518323 | Val Loss: 2.084920\n",
      "Epoch [200/500] | Train Loss: 1.218973 | Val Loss: 2.325971\n",
      "Epoch [300/500] | Train Loss: 1.218317 | Val Loss: 2.486188\n",
      "Epoch [400/500] | Train Loss: 0.910588 | Val Loss: 2.569923\n",
      "Epoch [500/500] | Train Loss: 0.987492 | Val Loss: 2.676672\n",
      "Epoch [100/500] | Train Loss: 1.654705 | Val Loss: 3.408742\n",
      "Epoch [200/500] | Train Loss: 1.509184 | Val Loss: 3.952554\n",
      "Epoch [300/500] | Train Loss: 1.250474 | Val Loss: 4.057293\n",
      "Epoch [400/500] | Train Loss: 1.229250 | Val Loss: 3.892053\n",
      "Epoch [500/500] | Train Loss: 1.219079 | Val Loss: 4.029730\n",
      "Epoch [100/500] | Train Loss: 1.982076 | Val Loss: 0.762841\n",
      "Epoch [200/500] | Train Loss: 1.680222 | Val Loss: 0.882885\n",
      "Epoch [300/500] | Train Loss: 1.588851 | Val Loss: 0.955237\n",
      "Epoch [400/500] | Train Loss: 1.511535 | Val Loss: 0.897024\n",
      "Epoch [500/500] | Train Loss: 1.376891 | Val Loss: 0.976248\n",
      "Epoch [100/500] | Train Loss: 1.751622 | Val Loss: 0.571024\n",
      "Epoch [200/500] | Train Loss: 1.477969 | Val Loss: 0.575529\n",
      "Epoch [300/500] | Train Loss: 1.391066 | Val Loss: 0.631811\n",
      "Epoch [400/500] | Train Loss: 1.329993 | Val Loss: 0.650031\n",
      "Epoch [500/500] | Train Loss: 1.287831 | Val Loss: 0.705802\n",
      "Epoch [100/500] | Train Loss: 2.066875 | Val Loss: 2.277377\n",
      "Epoch [200/500] | Train Loss: 1.722075 | Val Loss: 2.450995\n",
      "Epoch [300/500] | Train Loss: 1.706391 | Val Loss: 2.581582\n",
      "Epoch [400/500] | Train Loss: 1.480122 | Val Loss: 2.636529\n",
      "Epoch [500/500] | Train Loss: 1.362826 | Val Loss: 2.774923\n",
      "Epoch [100/500] | Train Loss: 2.135922 | Val Loss: 1.589487\n",
      "Epoch [200/500] | Train Loss: 1.960524 | Val Loss: 1.691453\n",
      "Epoch [300/500] | Train Loss: 1.842665 | Val Loss: 1.728130\n",
      "Epoch [400/500] | Train Loss: 1.824692 | Val Loss: 1.767526\n",
      "Epoch [500/500] | Train Loss: 1.771973 | Val Loss: 1.774515\n",
      "Epoch [100/500] | Train Loss: 1.978829 | Val Loss: 2.964778\n",
      "Epoch [200/500] | Train Loss: 1.855285 | Val Loss: 3.051389\n",
      "Epoch [300/500] | Train Loss: 1.811742 | Val Loss: 3.152049\n",
      "Epoch [400/500] | Train Loss: 1.738037 | Val Loss: 3.269264\n",
      "Epoch [500/500] | Train Loss: 1.755905 | Val Loss: 3.337250\n",
      "Epoch [100/500] | Train Loss: 2.161839 | Val Loss: 0.724258\n",
      "Epoch [200/500] | Train Loss: 2.140562 | Val Loss: 0.759571\n",
      "Epoch [300/500] | Train Loss: 2.122379 | Val Loss: 0.754750\n",
      "Epoch [400/500] | Train Loss: 2.119996 | Val Loss: 0.728212\n",
      "Epoch [500/500] | Train Loss: 2.021435 | Val Loss: 0.750383\n",
      "Epoch [100/500] | Train Loss: 1.923759 | Val Loss: 0.545163\n",
      "Epoch [200/500] | Train Loss: 1.875420 | Val Loss: 0.553742\n",
      "Epoch [300/500] | Train Loss: 1.842745 | Val Loss: 0.563493\n",
      "Epoch [400/500] | Train Loss: 1.814369 | Val Loss: 0.567092\n",
      "Epoch [500/500] | Train Loss: 1.761563 | Val Loss: 0.559108\n",
      "Epoch [100/500] | Train Loss: 1.401883 | Val Loss: 2.902611\n",
      "Epoch [200/500] | Train Loss: 1.248368 | Val Loss: 2.947851\n",
      "Epoch [300/500] | Train Loss: 1.030870 | Val Loss: 3.103152\n",
      "Epoch [400/500] | Train Loss: 1.021903 | Val Loss: 3.072787\n",
      "Epoch [500/500] | Train Loss: 0.975354 | Val Loss: 3.205021\n",
      "Epoch [100/500] | Train Loss: 1.855587 | Val Loss: 1.730115\n",
      "Epoch [200/500] | Train Loss: 1.525774 | Val Loss: 1.847270\n",
      "Epoch [300/500] | Train Loss: 1.495131 | Val Loss: 1.854198\n",
      "Epoch [400/500] | Train Loss: 1.479803 | Val Loss: 1.986409\n",
      "Epoch [500/500] | Train Loss: 1.306226 | Val Loss: 1.962290\n",
      "Epoch [100/500] | Train Loss: 1.728642 | Val Loss: 3.141121\n",
      "Epoch [200/500] | Train Loss: 1.561360 | Val Loss: 3.487426\n",
      "Epoch [300/500] | Train Loss: 1.443672 | Val Loss: 3.416322\n",
      "Epoch [400/500] | Train Loss: 1.470996 | Val Loss: 3.590722\n",
      "Epoch [500/500] | Train Loss: 1.418735 | Val Loss: 3.533180\n",
      "Epoch [100/500] | Train Loss: 2.115699 | Val Loss: 0.723087\n",
      "Epoch [200/500] | Train Loss: 1.872832 | Val Loss: 0.788987\n",
      "Epoch [300/500] | Train Loss: 1.794707 | Val Loss: 0.707692\n",
      "Epoch [400/500] | Train Loss: 1.663163 | Val Loss: 0.784045\n",
      "Epoch [500/500] | Train Loss: 1.755746 | Val Loss: 0.777248\n",
      "Epoch [100/500] | Train Loss: 1.762928 | Val Loss: 0.548576\n",
      "Epoch [200/500] | Train Loss: 1.643461 | Val Loss: 0.556362\n",
      "Epoch [300/500] | Train Loss: 1.630561 | Val Loss: 0.557230\n",
      "Epoch [400/500] | Train Loss: 1.562493 | Val Loss: 0.571617\n",
      "Epoch [500/500] | Train Loss: 1.568632 | Val Loss: 0.575971\n",
      "Epoch [100/500] | Train Loss: 1.910154 | Val Loss: 2.340510\n",
      "Epoch [200/500] | Train Loss: 1.458897 | Val Loss: 2.857891\n",
      "Epoch [300/500] | Train Loss: 1.137215 | Val Loss: 3.231512\n",
      "Epoch [400/500] | Train Loss: 0.871779 | Val Loss: 3.527470\n",
      "Epoch [500/500] | Train Loss: 0.858669 | Val Loss: 3.655358\n",
      "Epoch [100/500] | Train Loss: 2.006574 | Val Loss: 1.711445\n",
      "Epoch [200/500] | Train Loss: 1.648999 | Val Loss: 1.943192\n",
      "Epoch [300/500] | Train Loss: 1.424795 | Val Loss: 2.050540\n",
      "Epoch [400/500] | Train Loss: 1.246045 | Val Loss: 2.189000\n",
      "Epoch [500/500] | Train Loss: 1.241843 | Val Loss: 2.219283\n",
      "Epoch [100/500] | Train Loss: 1.865107 | Val Loss: 3.154040\n",
      "Epoch [200/500] | Train Loss: 1.639219 | Val Loss: 3.506034\n",
      "Epoch [300/500] | Train Loss: 1.475096 | Val Loss: 3.732502\n",
      "Epoch [400/500] | Train Loss: 1.377224 | Val Loss: 3.954733\n",
      "Epoch [500/500] | Train Loss: 1.351419 | Val Loss: 4.059022\n",
      "Epoch [100/500] | Train Loss: 2.098345 | Val Loss: 0.778477\n",
      "Epoch [200/500] | Train Loss: 1.876670 | Val Loss: 0.787778\n",
      "Epoch [300/500] | Train Loss: 1.801368 | Val Loss: 0.749852\n",
      "Epoch [400/500] | Train Loss: 1.659124 | Val Loss: 0.747805\n",
      "Epoch [500/500] | Train Loss: 1.536765 | Val Loss: 0.758580\n",
      "Epoch [100/500] | Train Loss: 1.846128 | Val Loss: 0.557952\n",
      "Epoch [200/500] | Train Loss: 1.795130 | Val Loss: 0.545979\n",
      "Epoch [300/500] | Train Loss: 1.653684 | Val Loss: 0.548765\n",
      "Epoch [400/500] | Train Loss: 1.502740 | Val Loss: 0.567205\n",
      "Epoch [500/500] | Train Loss: 1.434139 | Val Loss: 0.606413\n",
      "Epoch [100/500] | Train Loss: 0.948244 | Val Loss: 3.360016\n",
      "Epoch [200/500] | Train Loss: 0.606813 | Val Loss: 3.649218\n",
      "Epoch [300/500] | Train Loss: 0.516838 | Val Loss: 3.871441\n",
      "Epoch [400/500] | Train Loss: 0.422039 | Val Loss: 3.890865\n",
      "Epoch [500/500] | Train Loss: 0.462077 | Val Loss: 3.594455\n",
      "Epoch [100/500] | Train Loss: 1.383726 | Val Loss: 2.132617\n",
      "Epoch [200/500] | Train Loss: 0.975678 | Val Loss: 2.431827\n",
      "Epoch [300/500] | Train Loss: 0.862455 | Val Loss: 2.828882\n",
      "Epoch [400/500] | Train Loss: 0.756948 | Val Loss: 2.722474\n",
      "Epoch [500/500] | Train Loss: 0.690620 | Val Loss: 2.805071\n",
      "Epoch [100/500] | Train Loss: 1.397710 | Val Loss: 3.883160\n",
      "Epoch [200/500] | Train Loss: 1.185578 | Val Loss: 4.322282\n",
      "Epoch [300/500] | Train Loss: 0.993400 | Val Loss: 4.767061\n",
      "Epoch [400/500] | Train Loss: 0.828344 | Val Loss: 4.752131\n",
      "Epoch [500/500] | Train Loss: 0.804771 | Val Loss: 4.423828\n",
      "Epoch [100/500] | Train Loss: 1.849552 | Val Loss: 0.743770\n",
      "Epoch [200/500] | Train Loss: 1.441652 | Val Loss: 0.838445\n",
      "Epoch [300/500] | Train Loss: 1.330756 | Val Loss: 0.855727\n",
      "Epoch [400/500] | Train Loss: 1.216325 | Val Loss: 0.830311\n",
      "Epoch [500/500] | Train Loss: 1.209817 | Val Loss: 0.892446\n",
      "Epoch [100/500] | Train Loss: 1.563494 | Val Loss: 0.569717\n",
      "Epoch [200/500] | Train Loss: 1.339337 | Val Loss: 0.611733\n",
      "Epoch [300/500] | Train Loss: 1.248390 | Val Loss: 0.650452\n",
      "Epoch [400/500] | Train Loss: 1.065799 | Val Loss: 0.694796\n",
      "Epoch [500/500] | Train Loss: 1.047634 | Val Loss: 0.739509\n",
      "Epoch [100/500] | Train Loss: 2.164530 | Val Loss: 2.280295\n",
      "Epoch [200/500] | Train Loss: 1.779848 | Val Loss: 2.394833\n",
      "Epoch [300/500] | Train Loss: 1.610919 | Val Loss: 2.568735\n",
      "Epoch [400/500] | Train Loss: 1.313808 | Val Loss: 2.658137\n",
      "Epoch [500/500] | Train Loss: 1.433386 | Val Loss: 2.850150\n",
      "Epoch [100/500] | Train Loss: 2.209340 | Val Loss: 1.561911\n",
      "Epoch [200/500] | Train Loss: 1.941215 | Val Loss: 1.668747\n",
      "Epoch [300/500] | Train Loss: 1.799651 | Val Loss: 1.753391\n",
      "Epoch [400/500] | Train Loss: 1.726749 | Val Loss: 1.802080\n",
      "Epoch [500/500] | Train Loss: 1.607647 | Val Loss: 1.846626\n",
      "Epoch [100/500] | Train Loss: 1.965811 | Val Loss: 2.986925\n",
      "Epoch [200/500] | Train Loss: 1.865622 | Val Loss: 3.191013\n",
      "Epoch [300/500] | Train Loss: 1.701548 | Val Loss: 3.498069\n",
      "Epoch [400/500] | Train Loss: 1.621768 | Val Loss: 3.613914\n",
      "Epoch [500/500] | Train Loss: 1.522860 | Val Loss: 3.815951\n",
      "Epoch [100/500] | Train Loss: 2.193931 | Val Loss: 0.729867\n",
      "Epoch [200/500] | Train Loss: 2.130467 | Val Loss: 0.768611\n",
      "Epoch [300/500] | Train Loss: 2.006851 | Val Loss: 0.758099\n",
      "Epoch [400/500] | Train Loss: 1.976794 | Val Loss: 0.752180\n",
      "Epoch [500/500] | Train Loss: 1.851929 | Val Loss: 0.745371\n",
      "Epoch [100/500] | Train Loss: 1.934836 | Val Loss: 0.540913\n",
      "Epoch [200/500] | Train Loss: 1.844479 | Val Loss: 0.546520\n",
      "Epoch [300/500] | Train Loss: 1.808711 | Val Loss: 0.553811\n",
      "Epoch [400/500] | Train Loss: 1.768881 | Val Loss: 0.549381\n",
      "Epoch [500/500] | Train Loss: 1.699694 | Val Loss: 0.551591\n",
      "Epoch [100/500] | Train Loss: 1.488533 | Val Loss: 2.749975\n",
      "Epoch [200/500] | Train Loss: 1.008750 | Val Loss: 3.289927\n",
      "Epoch [300/500] | Train Loss: 0.957570 | Val Loss: 3.206634\n",
      "Epoch [400/500] | Train Loss: 0.769382 | Val Loss: 3.435698\n",
      "Epoch [500/500] | Train Loss: 0.784842 | Val Loss: 3.557220\n",
      "Epoch [100/500] | Train Loss: 1.716396 | Val Loss: 1.857384\n",
      "Epoch [200/500] | Train Loss: 1.485907 | Val Loss: 1.868844\n",
      "Epoch [300/500] | Train Loss: 1.193462 | Val Loss: 1.968791\n",
      "Epoch [400/500] | Train Loss: 1.180493 | Val Loss: 2.027574\n",
      "Epoch [500/500] | Train Loss: 1.078424 | Val Loss: 2.130155\n",
      "Epoch [100/500] | Train Loss: 1.630768 | Val Loss: 3.337530\n",
      "Epoch [200/500] | Train Loss: 1.347450 | Val Loss: 3.771380\n",
      "Epoch [300/500] | Train Loss: 1.320943 | Val Loss: 3.850891\n",
      "Epoch [400/500] | Train Loss: 1.257191 | Val Loss: 3.824924\n",
      "Epoch [500/500] | Train Loss: 1.319155 | Val Loss: 3.757693\n",
      "Epoch [100/500] | Train Loss: 1.987098 | Val Loss: 0.738813\n",
      "Epoch [200/500] | Train Loss: 1.819294 | Val Loss: 0.787004\n",
      "Epoch [300/500] | Train Loss: 1.701889 | Val Loss: 0.824360\n",
      "Epoch [400/500] | Train Loss: 1.579052 | Val Loss: 0.822121\n",
      "Epoch [500/500] | Train Loss: 1.765556 | Val Loss: 0.783825\n",
      "Epoch [100/500] | Train Loss: 1.762644 | Val Loss: 0.568384\n",
      "Epoch [200/500] | Train Loss: 1.588545 | Val Loss: 0.611197\n",
      "Epoch [300/500] | Train Loss: 1.508386 | Val Loss: 0.624487\n",
      "Epoch [400/500] | Train Loss: 1.408222 | Val Loss: 0.631822\n",
      "Epoch [500/500] | Train Loss: 1.385141 | Val Loss: 0.666235\n",
      "[Year=2005] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.839236 Test MSE=0.437275\n",
      "Year 2005 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.959150 | Val Loss: 2.238355\n",
      "Epoch [200/500] | Train Loss: 1.548277 | Val Loss: 2.449445\n",
      "Epoch [300/500] | Train Loss: 1.483238 | Val Loss: 2.653550\n",
      "Epoch [400/500] | Train Loss: 1.366109 | Val Loss: 2.852346\n",
      "Epoch [500/500] | Train Loss: 1.181589 | Val Loss: 2.938759\n",
      "Epoch [100/500] | Train Loss: 2.023514 | Val Loss: 2.145671\n",
      "Epoch [200/500] | Train Loss: 1.860328 | Val Loss: 2.242510\n",
      "Epoch [300/500] | Train Loss: 1.683229 | Val Loss: 2.338232\n",
      "Epoch [400/500] | Train Loss: 1.387561 | Val Loss: 2.362995\n",
      "Epoch [500/500] | Train Loss: 1.439844 | Val Loss: 2.396096\n",
      "Epoch [100/500] | Train Loss: 2.020508 | Val Loss: 0.629968\n",
      "Epoch [200/500] | Train Loss: 1.865314 | Val Loss: 0.655272\n",
      "Epoch [300/500] | Train Loss: 1.727241 | Val Loss: 0.658260\n",
      "Epoch [400/500] | Train Loss: 1.658826 | Val Loss: 0.644660\n",
      "Epoch [500/500] | Train Loss: 1.528183 | Val Loss: 0.651090\n",
      "Epoch [100/500] | Train Loss: 1.665364 | Val Loss: 0.486275\n",
      "Epoch [200/500] | Train Loss: 1.543613 | Val Loss: 0.503104\n",
      "Epoch [300/500] | Train Loss: 1.486649 | Val Loss: 0.495709\n",
      "Epoch [400/500] | Train Loss: 1.371054 | Val Loss: 0.502738\n",
      "Epoch [500/500] | Train Loss: 1.350668 | Val Loss: 0.511947\n",
      "Epoch [100/500] | Train Loss: 1.470918 | Val Loss: 0.441571\n",
      "Epoch [200/500] | Train Loss: 1.422732 | Val Loss: 0.444801\n",
      "Epoch [300/500] | Train Loss: 1.330959 | Val Loss: 0.456861\n",
      "Epoch [400/500] | Train Loss: 1.224259 | Val Loss: 0.463495\n",
      "Epoch [500/500] | Train Loss: 1.167439 | Val Loss: 0.457510\n",
      "Epoch [100/500] | Train Loss: 1.159093 | Val Loss: 2.998165\n",
      "Epoch [200/500] | Train Loss: 0.773309 | Val Loss: 2.874290\n",
      "Epoch [300/500] | Train Loss: 0.761010 | Val Loss: 2.947964\n",
      "Epoch [400/500] | Train Loss: 0.625883 | Val Loss: 2.876218\n",
      "Epoch [500/500] | Train Loss: 0.523474 | Val Loss: 2.850149\n",
      "Epoch [100/500] | Train Loss: 1.502166 | Val Loss: 2.597102\n",
      "Epoch [200/500] | Train Loss: 1.092238 | Val Loss: 2.824500\n",
      "Epoch [300/500] | Train Loss: 1.126252 | Val Loss: 2.728733\n",
      "Epoch [400/500] | Train Loss: 0.991715 | Val Loss: 2.809830\n",
      "Epoch [500/500] | Train Loss: 1.017270 | Val Loss: 2.829041\n",
      "Epoch [100/500] | Train Loss: 1.628331 | Val Loss: 0.662926\n",
      "Epoch [200/500] | Train Loss: 1.263781 | Val Loss: 0.784896\n",
      "Epoch [300/500] | Train Loss: 1.238233 | Val Loss: 0.839840\n",
      "Epoch [400/500] | Train Loss: 1.117578 | Val Loss: 0.882756\n",
      "Epoch [500/500] | Train Loss: 0.987832 | Val Loss: 0.996171\n",
      "Epoch [100/500] | Train Loss: 1.352239 | Val Loss: 0.513875\n",
      "Epoch [200/500] | Train Loss: 1.127221 | Val Loss: 0.594587\n",
      "Epoch [300/500] | Train Loss: 1.072988 | Val Loss: 0.580717\n",
      "Epoch [400/500] | Train Loss: 1.000780 | Val Loss: 0.578771\n",
      "Epoch [500/500] | Train Loss: 0.978325 | Val Loss: 0.645544\n",
      "Epoch [100/500] | Train Loss: 1.190465 | Val Loss: 0.445935\n",
      "Epoch [200/500] | Train Loss: 1.000041 | Val Loss: 0.458627\n",
      "Epoch [300/500] | Train Loss: 0.961475 | Val Loss: 0.465334\n",
      "Epoch [400/500] | Train Loss: 0.909525 | Val Loss: 0.462031\n",
      "Epoch [500/500] | Train Loss: 0.892353 | Val Loss: 0.454061\n",
      "Epoch [100/500] | Train Loss: 2.051574 | Val Loss: 2.175777\n",
      "Epoch [200/500] | Train Loss: 1.995597 | Val Loss: 2.275774\n",
      "Epoch [300/500] | Train Loss: 1.584785 | Val Loss: 2.500334\n",
      "Epoch [400/500] | Train Loss: 1.644708 | Val Loss: 2.556201\n",
      "Epoch [500/500] | Train Loss: 1.426709 | Val Loss: 2.589376\n",
      "Epoch [100/500] | Train Loss: 2.069966 | Val Loss: 2.130772\n",
      "Epoch [200/500] | Train Loss: 2.013427 | Val Loss: 2.283198\n",
      "Epoch [300/500] | Train Loss: 1.956685 | Val Loss: 2.350887\n",
      "Epoch [400/500] | Train Loss: 1.876445 | Val Loss: 2.415402\n",
      "Epoch [500/500] | Train Loss: 1.800637 | Val Loss: 2.399831\n",
      "Epoch [100/500] | Train Loss: 2.076097 | Val Loss: 0.631880\n",
      "Epoch [200/500] | Train Loss: 1.957407 | Val Loss: 0.647472\n",
      "Epoch [300/500] | Train Loss: 1.935746 | Val Loss: 0.643326\n",
      "Epoch [400/500] | Train Loss: 1.880776 | Val Loss: 0.633856\n",
      "Epoch [500/500] | Train Loss: 1.695164 | Val Loss: 0.633224\n",
      "Epoch [100/500] | Train Loss: 1.729595 | Val Loss: 0.474948\n",
      "Epoch [200/500] | Train Loss: 1.699187 | Val Loss: 0.494599\n",
      "Epoch [300/500] | Train Loss: 1.692816 | Val Loss: 0.492287\n",
      "Epoch [400/500] | Train Loss: 1.543957 | Val Loss: 0.497201\n",
      "Epoch [500/500] | Train Loss: 1.577203 | Val Loss: 0.500887\n",
      "Epoch [100/500] | Train Loss: 1.479421 | Val Loss: 0.439148\n",
      "Epoch [200/500] | Train Loss: 1.415912 | Val Loss: 0.440313\n",
      "Epoch [300/500] | Train Loss: 1.388499 | Val Loss: 0.444384\n",
      "Epoch [400/500] | Train Loss: 1.359078 | Val Loss: 0.445965\n",
      "Epoch [500/500] | Train Loss: 1.343282 | Val Loss: 0.447150\n",
      "Epoch [100/500] | Train Loss: 1.624628 | Val Loss: 2.516610\n",
      "Epoch [200/500] | Train Loss: 1.277851 | Val Loss: 2.589951\n",
      "Epoch [300/500] | Train Loss: 1.195992 | Val Loss: 2.647693\n",
      "Epoch [400/500] | Train Loss: 1.080623 | Val Loss: 2.656355\n",
      "Epoch [500/500] | Train Loss: 1.061704 | Val Loss: 2.816229\n",
      "Epoch [100/500] | Train Loss: 1.884591 | Val Loss: 2.286825\n",
      "Epoch [200/500] | Train Loss: 1.655976 | Val Loss: 2.477529\n",
      "Epoch [300/500] | Train Loss: 1.367314 | Val Loss: 2.501005\n",
      "Epoch [400/500] | Train Loss: 1.385412 | Val Loss: 2.550465\n",
      "Epoch [500/500] | Train Loss: 1.321284 | Val Loss: 2.601765\n",
      "Epoch [100/500] | Train Loss: 1.804059 | Val Loss: 0.651115\n",
      "Epoch [200/500] | Train Loss: 1.600017 | Val Loss: 0.686144\n",
      "Epoch [300/500] | Train Loss: 1.407100 | Val Loss: 0.775796\n",
      "Epoch [400/500] | Train Loss: 1.483865 | Val Loss: 0.727637\n",
      "Epoch [500/500] | Train Loss: 1.340774 | Val Loss: 0.739636\n",
      "Epoch [100/500] | Train Loss: 1.573911 | Val Loss: 0.515951\n",
      "Epoch [200/500] | Train Loss: 1.433365 | Val Loss: 0.523853\n",
      "Epoch [300/500] | Train Loss: 1.367373 | Val Loss: 0.535857\n",
      "Epoch [400/500] | Train Loss: 1.382801 | Val Loss: 0.524674\n",
      "Epoch [500/500] | Train Loss: 1.313145 | Val Loss: 0.550401\n",
      "Epoch [100/500] | Train Loss: 1.392541 | Val Loss: 0.441375\n",
      "Epoch [200/500] | Train Loss: 1.282773 | Val Loss: 0.441653\n",
      "Epoch [300/500] | Train Loss: 1.230224 | Val Loss: 0.439067\n",
      "Epoch [400/500] | Train Loss: 1.170908 | Val Loss: 0.444597\n",
      "Epoch [500/500] | Train Loss: 1.142963 | Val Loss: 0.455585\n",
      "Epoch [100/500] | Train Loss: 1.985666 | Val Loss: 2.245977\n",
      "Epoch [200/500] | Train Loss: 1.530379 | Val Loss: 2.582396\n",
      "Epoch [300/500] | Train Loss: 1.313563 | Val Loss: 2.868509\n",
      "Epoch [400/500] | Train Loss: 1.116642 | Val Loss: 2.861558\n",
      "Epoch [500/500] | Train Loss: 0.899479 | Val Loss: 3.043489\n",
      "Epoch [100/500] | Train Loss: 1.943053 | Val Loss: 2.192991\n",
      "Epoch [200/500] | Train Loss: 1.665714 | Val Loss: 2.428188\n",
      "Epoch [300/500] | Train Loss: 1.521081 | Val Loss: 2.582631\n",
      "Epoch [400/500] | Train Loss: 1.302600 | Val Loss: 2.700660\n",
      "Epoch [500/500] | Train Loss: 1.259945 | Val Loss: 2.690860\n",
      "Epoch [100/500] | Train Loss: 1.977919 | Val Loss: 0.625160\n",
      "Epoch [200/500] | Train Loss: 1.796147 | Val Loss: 0.661975\n",
      "Epoch [300/500] | Train Loss: 1.667067 | Val Loss: 0.679713\n",
      "Epoch [400/500] | Train Loss: 1.562143 | Val Loss: 0.673231\n",
      "Epoch [500/500] | Train Loss: 1.499511 | Val Loss: 0.663578\n",
      "Epoch [100/500] | Train Loss: 1.674736 | Val Loss: 0.491625\n",
      "Epoch [200/500] | Train Loss: 1.509262 | Val Loss: 0.518146\n",
      "Epoch [300/500] | Train Loss: 1.284966 | Val Loss: 0.535090\n",
      "Epoch [400/500] | Train Loss: 1.203081 | Val Loss: 0.525505\n",
      "Epoch [500/500] | Train Loss: 1.142181 | Val Loss: 0.542233\n",
      "Epoch [100/500] | Train Loss: 1.460671 | Val Loss: 0.436581\n",
      "Epoch [200/500] | Train Loss: 1.310306 | Val Loss: 0.442821\n",
      "Epoch [300/500] | Train Loss: 1.194852 | Val Loss: 0.445020\n",
      "Epoch [400/500] | Train Loss: 1.087276 | Val Loss: 0.450702\n",
      "Epoch [500/500] | Train Loss: 1.053875 | Val Loss: 0.456882\n",
      "Epoch [100/500] | Train Loss: 1.248597 | Val Loss: 2.977982\n",
      "Epoch [200/500] | Train Loss: 0.762184 | Val Loss: 2.937126\n",
      "Epoch [300/500] | Train Loss: 0.552324 | Val Loss: 2.990041\n",
      "Epoch [400/500] | Train Loss: 0.492519 | Val Loss: 3.017847\n",
      "Epoch [500/500] | Train Loss: 0.398327 | Val Loss: 3.076453\n",
      "Epoch [100/500] | Train Loss: 1.215051 | Val Loss: 2.648105\n",
      "Epoch [200/500] | Train Loss: 1.106956 | Val Loss: 3.099626\n",
      "Epoch [300/500] | Train Loss: 0.786779 | Val Loss: 2.927744\n",
      "Epoch [400/500] | Train Loss: 0.710365 | Val Loss: 2.931805\n",
      "Epoch [500/500] | Train Loss: 0.785064 | Val Loss: 2.944031\n",
      "Epoch [100/500] | Train Loss: 1.552829 | Val Loss: 0.683083\n",
      "Epoch [200/500] | Train Loss: 1.388269 | Val Loss: 0.788240\n",
      "Epoch [300/500] | Train Loss: 0.998273 | Val Loss: 0.862842\n",
      "Epoch [400/500] | Train Loss: 1.015622 | Val Loss: 0.931728\n",
      "Epoch [500/500] | Train Loss: 1.002843 | Val Loss: 0.889842\n",
      "Epoch [100/500] | Train Loss: 1.192244 | Val Loss: 0.551926\n",
      "Epoch [200/500] | Train Loss: 1.025814 | Val Loss: 0.636833\n",
      "Epoch [300/500] | Train Loss: 0.861396 | Val Loss: 0.679822\n",
      "Epoch [400/500] | Train Loss: 0.816146 | Val Loss: 0.713127\n",
      "Epoch [500/500] | Train Loss: 0.882820 | Val Loss: 0.700385\n",
      "Epoch [100/500] | Train Loss: 1.246821 | Val Loss: 0.448091\n",
      "Epoch [200/500] | Train Loss: 1.119067 | Val Loss: 0.457527\n",
      "Epoch [300/500] | Train Loss: 0.941422 | Val Loss: 0.470504\n",
      "Epoch [400/500] | Train Loss: 0.871879 | Val Loss: 0.473404\n",
      "Epoch [500/500] | Train Loss: 0.942861 | Val Loss: 0.491514\n",
      "Epoch [100/500] | Train Loss: 2.035563 | Val Loss: 2.218294\n",
      "Epoch [200/500] | Train Loss: 1.756323 | Val Loss: 2.379213\n",
      "Epoch [300/500] | Train Loss: 1.793149 | Val Loss: 2.574095\n",
      "Epoch [400/500] | Train Loss: 1.487255 | Val Loss: 2.707501\n",
      "Epoch [500/500] | Train Loss: 1.136166 | Val Loss: 2.870551\n",
      "Epoch [100/500] | Train Loss: 2.077625 | Val Loss: 2.109365\n",
      "Epoch [200/500] | Train Loss: 1.975160 | Val Loss: 2.200890\n",
      "Epoch [300/500] | Train Loss: 1.823424 | Val Loss: 2.375781\n",
      "Epoch [400/500] | Train Loss: 1.662578 | Val Loss: 2.461578\n",
      "Epoch [500/500] | Train Loss: 1.510012 | Val Loss: 2.523225\n",
      "Epoch [100/500] | Train Loss: 2.099909 | Val Loss: 0.625928\n",
      "Epoch [200/500] | Train Loss: 2.031569 | Val Loss: 0.628997\n",
      "Epoch [300/500] | Train Loss: 1.824861 | Val Loss: 0.636145\n",
      "Epoch [400/500] | Train Loss: 1.776195 | Val Loss: 0.626493\n",
      "Epoch [500/500] | Train Loss: 1.682425 | Val Loss: 0.622415\n",
      "Epoch [100/500] | Train Loss: 1.712678 | Val Loss: 0.500803\n",
      "Epoch [200/500] | Train Loss: 1.637820 | Val Loss: 0.518000\n",
      "Epoch [300/500] | Train Loss: 1.588091 | Val Loss: 0.509115\n",
      "Epoch [400/500] | Train Loss: 1.440030 | Val Loss: 0.518956\n",
      "Epoch [500/500] | Train Loss: 1.403978 | Val Loss: 0.519018\n",
      "Epoch [100/500] | Train Loss: 1.471533 | Val Loss: 0.440361\n",
      "Epoch [200/500] | Train Loss: 1.382757 | Val Loss: 0.436266\n",
      "Epoch [300/500] | Train Loss: 1.353936 | Val Loss: 0.434840\n",
      "Epoch [400/500] | Train Loss: 1.278798 | Val Loss: 0.432785\n",
      "Epoch [500/500] | Train Loss: 1.272074 | Val Loss: 0.433040\n",
      "Epoch [100/500] | Train Loss: 1.440272 | Val Loss: 2.788928\n",
      "Epoch [200/500] | Train Loss: 1.036084 | Val Loss: 2.849794\n",
      "Epoch [300/500] | Train Loss: 0.959895 | Val Loss: 2.835212\n",
      "Epoch [400/500] | Train Loss: 0.720184 | Val Loss: 2.770780\n",
      "Epoch [500/500] | Train Loss: 1.055068 | Val Loss: 2.696671\n",
      "Epoch [100/500] | Train Loss: 1.650825 | Val Loss: 2.411039\n",
      "Epoch [200/500] | Train Loss: 1.340986 | Val Loss: 2.676383\n",
      "Epoch [300/500] | Train Loss: 1.292899 | Val Loss: 2.797424\n",
      "Epoch [400/500] | Train Loss: 1.308911 | Val Loss: 2.747621\n",
      "Epoch [500/500] | Train Loss: 1.071556 | Val Loss: 2.752020\n",
      "Epoch [100/500] | Train Loss: 1.801628 | Val Loss: 0.621767\n",
      "Epoch [200/500] | Train Loss: 1.618974 | Val Loss: 0.692098\n",
      "Epoch [300/500] | Train Loss: 1.362173 | Val Loss: 0.774388\n",
      "Epoch [400/500] | Train Loss: 1.410663 | Val Loss: 0.831981\n",
      "Epoch [500/500] | Train Loss: 1.272109 | Val Loss: 0.876712\n",
      "Epoch [100/500] | Train Loss: 1.454534 | Val Loss: 0.495234\n",
      "Epoch [200/500] | Train Loss: 1.339111 | Val Loss: 0.490105\n",
      "Epoch [300/500] | Train Loss: 1.204952 | Val Loss: 0.529676\n",
      "Epoch [400/500] | Train Loss: 1.180717 | Val Loss: 0.543919\n",
      "Epoch [500/500] | Train Loss: 1.079370 | Val Loss: 0.578828\n",
      "Epoch [100/500] | Train Loss: 1.325276 | Val Loss: 0.442384\n",
      "Epoch [200/500] | Train Loss: 1.163146 | Val Loss: 0.454080\n",
      "Epoch [300/500] | Train Loss: 1.118551 | Val Loss: 0.475553\n",
      "Epoch [400/500] | Train Loss: 0.964796 | Val Loss: 0.490929\n",
      "Epoch [500/500] | Train Loss: 0.959885 | Val Loss: 0.484402\n",
      "[Year=2006] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.314094 Test MSE=0.456122\n",
      "Year 2006 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 2.377384 | Val Loss: 1.549297\n",
      "Epoch [200/500] | Train Loss: 1.942830 | Val Loss: 1.802997\n",
      "Epoch [300/500] | Train Loss: 1.506080 | Val Loss: 1.871806\n",
      "Epoch [400/500] | Train Loss: 1.699466 | Val Loss: 1.882996\n",
      "Epoch [500/500] | Train Loss: 1.282849 | Val Loss: 1.908428\n",
      "Epoch [100/500] | Train Loss: 1.978639 | Val Loss: 0.603059\n",
      "Epoch [200/500] | Train Loss: 1.773537 | Val Loss: 0.647588\n",
      "Epoch [300/500] | Train Loss: 1.594752 | Val Loss: 0.653059\n",
      "Epoch [400/500] | Train Loss: 1.508491 | Val Loss: 0.685927\n",
      "Epoch [500/500] | Train Loss: 1.260337 | Val Loss: 0.708219\n",
      "Epoch [100/500] | Train Loss: 1.511232 | Val Loss: 0.515397\n",
      "Epoch [200/500] | Train Loss: 1.379177 | Val Loss: 0.551323\n",
      "Epoch [300/500] | Train Loss: 1.350213 | Val Loss: 0.591104\n",
      "Epoch [400/500] | Train Loss: 1.243506 | Val Loss: 0.613070\n",
      "Epoch [500/500] | Train Loss: 1.178401 | Val Loss: 0.636395\n",
      "Epoch [100/500] | Train Loss: 1.269733 | Val Loss: 0.388523\n",
      "Epoch [200/500] | Train Loss: 1.150352 | Val Loss: 0.395341\n",
      "Epoch [300/500] | Train Loss: 1.077540 | Val Loss: 0.406997\n",
      "Epoch [400/500] | Train Loss: 1.025220 | Val Loss: 0.404178\n",
      "Epoch [500/500] | Train Loss: 1.020428 | Val Loss: 0.403826\n",
      "Epoch [100/500] | Train Loss: 1.106703 | Val Loss: 0.464210\n",
      "Epoch [200/500] | Train Loss: 1.033737 | Val Loss: 0.467906\n",
      "Epoch [300/500] | Train Loss: 0.934263 | Val Loss: 0.461996\n",
      "Epoch [400/500] | Train Loss: 0.887977 | Val Loss: 0.456487\n",
      "Epoch [500/500] | Train Loss: 0.839958 | Val Loss: 0.458475\n",
      "Epoch [100/500] | Train Loss: 1.547382 | Val Loss: 1.829214\n",
      "Epoch [200/500] | Train Loss: 0.969176 | Val Loss: 1.957250\n",
      "Epoch [300/500] | Train Loss: 0.675593 | Val Loss: 2.054986\n",
      "Epoch [400/500] | Train Loss: 0.687081 | Val Loss: 2.095712\n",
      "Epoch [500/500] | Train Loss: 0.852011 | Val Loss: 2.107214\n",
      "Epoch [100/500] | Train Loss: 1.451373 | Val Loss: 0.664935\n",
      "Epoch [200/500] | Train Loss: 1.231187 | Val Loss: 0.707524\n",
      "Epoch [300/500] | Train Loss: 1.136900 | Val Loss: 0.712789\n",
      "Epoch [400/500] | Train Loss: 0.923193 | Val Loss: 0.801292\n",
      "Epoch [500/500] | Train Loss: 0.821130 | Val Loss: 0.826715\n",
      "Epoch [100/500] | Train Loss: 1.114335 | Val Loss: 0.525911\n",
      "Epoch [200/500] | Train Loss: 0.946937 | Val Loss: 0.586901\n",
      "Epoch [300/500] | Train Loss: 0.850141 | Val Loss: 0.583883\n",
      "Epoch [400/500] | Train Loss: 0.792878 | Val Loss: 0.603366\n",
      "Epoch [500/500] | Train Loss: 0.727833 | Val Loss: 0.614083\n",
      "Epoch [100/500] | Train Loss: 0.996266 | Val Loss: 0.392294\n",
      "Epoch [200/500] | Train Loss: 0.901729 | Val Loss: 0.394566\n",
      "Epoch [300/500] | Train Loss: 0.790646 | Val Loss: 0.381999\n",
      "Epoch [400/500] | Train Loss: 0.753762 | Val Loss: 0.396414\n",
      "Epoch [500/500] | Train Loss: 0.724643 | Val Loss: 0.390542\n",
      "Epoch [100/500] | Train Loss: 0.853914 | Val Loss: 0.465753\n",
      "Epoch [200/500] | Train Loss: 0.724851 | Val Loss: 0.491650\n",
      "Epoch [300/500] | Train Loss: 0.653113 | Val Loss: 0.492506\n",
      "Epoch [400/500] | Train Loss: 0.687497 | Val Loss: 0.520064\n",
      "Epoch [500/500] | Train Loss: 0.652070 | Val Loss: 0.521112\n",
      "Epoch [100/500] | Train Loss: 2.462394 | Val Loss: 1.501312\n",
      "Epoch [200/500] | Train Loss: 1.998364 | Val Loss: 1.619242\n",
      "Epoch [300/500] | Train Loss: 1.942897 | Val Loss: 1.666526\n",
      "Epoch [400/500] | Train Loss: 1.759260 | Val Loss: 1.678431\n",
      "Epoch [500/500] | Train Loss: 1.614894 | Val Loss: 1.717417\n",
      "Epoch [100/500] | Train Loss: 2.036088 | Val Loss: 0.598215\n",
      "Epoch [200/500] | Train Loss: 1.886419 | Val Loss: 0.625673\n",
      "Epoch [300/500] | Train Loss: 1.701800 | Val Loss: 0.641784\n",
      "Epoch [400/500] | Train Loss: 1.628676 | Val Loss: 0.635697\n",
      "Epoch [500/500] | Train Loss: 1.605512 | Val Loss: 0.639968\n",
      "Epoch [100/500] | Train Loss: 1.533462 | Val Loss: 0.508659\n",
      "Epoch [200/500] | Train Loss: 1.460451 | Val Loss: 0.520968\n",
      "Epoch [300/500] | Train Loss: 1.435935 | Val Loss: 0.519450\n",
      "Epoch [400/500] | Train Loss: 1.330362 | Val Loss: 0.518344\n",
      "Epoch [500/500] | Train Loss: 1.291428 | Val Loss: 0.521457\n",
      "Epoch [100/500] | Train Loss: 1.273276 | Val Loss: 0.385601\n",
      "Epoch [200/500] | Train Loss: 1.227553 | Val Loss: 0.392175\n",
      "Epoch [300/500] | Train Loss: 1.150447 | Val Loss: 0.393686\n",
      "Epoch [400/500] | Train Loss: 1.111543 | Val Loss: 0.390199\n",
      "Epoch [500/500] | Train Loss: 1.089728 | Val Loss: 0.390029\n",
      "Epoch [100/500] | Train Loss: 1.114201 | Val Loss: 0.462432\n",
      "Epoch [200/500] | Train Loss: 1.094108 | Val Loss: 0.465635\n",
      "Epoch [300/500] | Train Loss: 1.041838 | Val Loss: 0.477003\n",
      "Epoch [400/500] | Train Loss: 0.977919 | Val Loss: 0.473295\n",
      "Epoch [500/500] | Train Loss: 0.958544 | Val Loss: 0.473665\n",
      "Epoch [100/500] | Train Loss: 1.679302 | Val Loss: 1.786791\n",
      "Epoch [200/500] | Train Loss: 1.618755 | Val Loss: 1.962006\n",
      "Epoch [300/500] | Train Loss: 1.321598 | Val Loss: 2.051402\n",
      "Epoch [400/500] | Train Loss: 1.083181 | Val Loss: 1.989739\n",
      "Epoch [500/500] | Train Loss: 1.107106 | Val Loss: 2.109686\n",
      "Epoch [100/500] | Train Loss: 1.512213 | Val Loss: 0.652966\n",
      "Epoch [200/500] | Train Loss: 1.351031 | Val Loss: 0.709942\n",
      "Epoch [300/500] | Train Loss: 1.279972 | Val Loss: 0.700469\n",
      "Epoch [400/500] | Train Loss: 1.293683 | Val Loss: 0.747447\n",
      "Epoch [500/500] | Train Loss: 1.109271 | Val Loss: 0.737967\n",
      "Epoch [100/500] | Train Loss: 1.326747 | Val Loss: 0.508700\n",
      "Epoch [200/500] | Train Loss: 1.233215 | Val Loss: 0.523051\n",
      "Epoch [300/500] | Train Loss: 1.088159 | Val Loss: 0.558486\n",
      "Epoch [400/500] | Train Loss: 1.093792 | Val Loss: 0.565635\n",
      "Epoch [500/500] | Train Loss: 0.977569 | Val Loss: 0.590738\n",
      "Epoch [100/500] | Train Loss: 1.201880 | Val Loss: 0.392841\n",
      "Epoch [200/500] | Train Loss: 1.138577 | Val Loss: 0.375956\n",
      "Epoch [300/500] | Train Loss: 0.910215 | Val Loss: 0.369568\n",
      "Epoch [400/500] | Train Loss: 0.963341 | Val Loss: 0.391043\n",
      "Epoch [500/500] | Train Loss: 0.896978 | Val Loss: 0.390337\n",
      "Epoch [100/500] | Train Loss: 0.979501 | Val Loss: 0.477749\n",
      "Epoch [200/500] | Train Loss: 0.903359 | Val Loss: 0.487973\n",
      "Epoch [300/500] | Train Loss: 0.819425 | Val Loss: 0.488723\n",
      "Epoch [400/500] | Train Loss: 0.834063 | Val Loss: 0.494841\n",
      "Epoch [500/500] | Train Loss: 0.810633 | Val Loss: 0.494715\n",
      "Epoch [100/500] | Train Loss: 2.414064 | Val Loss: 1.516172\n",
      "Epoch [200/500] | Train Loss: 1.752134 | Val Loss: 1.811595\n",
      "Epoch [300/500] | Train Loss: 1.332836 | Val Loss: 1.898911\n",
      "Epoch [400/500] | Train Loss: 1.176095 | Val Loss: 1.855953\n",
      "Epoch [500/500] | Train Loss: 1.155684 | Val Loss: 1.934954\n",
      "Epoch [100/500] | Train Loss: 1.766635 | Val Loss: 0.630070\n",
      "Epoch [200/500] | Train Loss: 1.519336 | Val Loss: 0.653083\n",
      "Epoch [300/500] | Train Loss: 1.383275 | Val Loss: 0.667113\n",
      "Epoch [400/500] | Train Loss: 1.203840 | Val Loss: 0.690768\n",
      "Epoch [500/500] | Train Loss: 1.172983 | Val Loss: 0.718080\n",
      "Epoch [100/500] | Train Loss: 1.541807 | Val Loss: 0.508545\n",
      "Epoch [200/500] | Train Loss: 1.351539 | Val Loss: 0.532881\n",
      "Epoch [300/500] | Train Loss: 1.095969 | Val Loss: 0.533220\n",
      "Epoch [400/500] | Train Loss: 1.054842 | Val Loss: 0.549757\n",
      "Epoch [500/500] | Train Loss: 1.011415 | Val Loss: 0.554951\n",
      "Epoch [100/500] | Train Loss: 1.186590 | Val Loss: 0.386598\n",
      "Epoch [200/500] | Train Loss: 1.063568 | Val Loss: 0.389462\n",
      "Epoch [300/500] | Train Loss: 0.991212 | Val Loss: 0.386106\n",
      "Epoch [400/500] | Train Loss: 0.938698 | Val Loss: 0.387817\n",
      "Epoch [500/500] | Train Loss: 0.891658 | Val Loss: 0.393561\n",
      "Epoch [100/500] | Train Loss: 1.026967 | Val Loss: 0.470981\n",
      "Epoch [200/500] | Train Loss: 0.894783 | Val Loss: 0.468564\n",
      "Epoch [300/500] | Train Loss: 0.831205 | Val Loss: 0.474935\n",
      "Epoch [400/500] | Train Loss: 0.790177 | Val Loss: 0.480818\n",
      "Epoch [500/500] | Train Loss: 0.712399 | Val Loss: 0.497502\n",
      "Epoch [100/500] | Train Loss: 1.498163 | Val Loss: 1.967478\n",
      "Epoch [200/500] | Train Loss: 0.834510 | Val Loss: 2.231618\n",
      "Epoch [300/500] | Train Loss: 0.747470 | Val Loss: 2.427417\n",
      "Epoch [400/500] | Train Loss: 0.727617 | Val Loss: 2.298371\n",
      "Epoch [500/500] | Train Loss: 0.842598 | Val Loss: 2.201510\n",
      "Epoch [100/500] | Train Loss: 1.241619 | Val Loss: 0.694331\n",
      "Epoch [200/500] | Train Loss: 1.003105 | Val Loss: 0.760954\n",
      "Epoch [300/500] | Train Loss: 0.818373 | Val Loss: 0.969993\n",
      "Epoch [400/500] | Train Loss: 0.651642 | Val Loss: 0.987093\n",
      "Epoch [500/500] | Train Loss: 0.676317 | Val Loss: 1.063813\n",
      "Epoch [100/500] | Train Loss: 1.014241 | Val Loss: 0.607859\n",
      "Epoch [200/500] | Train Loss: 0.713096 | Val Loss: 0.718266\n",
      "Epoch [300/500] | Train Loss: 0.709488 | Val Loss: 0.831358\n",
      "Epoch [400/500] | Train Loss: 0.531467 | Val Loss: 0.827232\n",
      "Epoch [500/500] | Train Loss: 0.485284 | Val Loss: 0.811293\n",
      "Epoch [100/500] | Train Loss: 1.002450 | Val Loss: 0.414905\n",
      "Epoch [200/500] | Train Loss: 0.866356 | Val Loss: 0.400895\n",
      "Epoch [300/500] | Train Loss: 0.758182 | Val Loss: 0.407074\n",
      "Epoch [400/500] | Train Loss: 0.718470 | Val Loss: 0.424291\n",
      "Epoch [500/500] | Train Loss: 0.683986 | Val Loss: 0.429759\n",
      "Epoch [100/500] | Train Loss: 1.117286 | Val Loss: 0.456961\n",
      "Epoch [200/500] | Train Loss: 1.117523 | Val Loss: 0.456910\n",
      "Epoch [300/500] | Train Loss: 1.099250 | Val Loss: 0.466550\n",
      "Epoch [400/500] | Train Loss: 0.959023 | Val Loss: 0.471180\n",
      "Epoch [500/500] | Train Loss: 0.923925 | Val Loss: 0.497881\n",
      "Epoch [100/500] | Train Loss: 2.442688 | Val Loss: 1.531931\n",
      "Epoch [200/500] | Train Loss: 1.875987 | Val Loss: 1.707969\n",
      "Epoch [300/500] | Train Loss: 1.716655 | Val Loss: 1.804850\n",
      "Epoch [400/500] | Train Loss: 1.496947 | Val Loss: 1.855765\n",
      "Epoch [500/500] | Train Loss: 1.423959 | Val Loss: 1.897825\n",
      "Epoch [100/500] | Train Loss: 1.999222 | Val Loss: 0.595790\n",
      "Epoch [200/500] | Train Loss: 1.777780 | Val Loss: 0.624530\n",
      "Epoch [300/500] | Train Loss: 1.718885 | Val Loss: 0.617946\n",
      "Epoch [400/500] | Train Loss: 1.522252 | Val Loss: 0.615234\n",
      "Epoch [500/500] | Train Loss: 1.418334 | Val Loss: 0.620166\n",
      "Epoch [100/500] | Train Loss: 1.504287 | Val Loss: 0.510105\n",
      "Epoch [200/500] | Train Loss: 1.457935 | Val Loss: 0.522440\n",
      "Epoch [300/500] | Train Loss: 1.356889 | Val Loss: 0.516887\n",
      "Epoch [400/500] | Train Loss: 1.274523 | Val Loss: 0.521390\n",
      "Epoch [500/500] | Train Loss: 1.196801 | Val Loss: 0.526049\n",
      "Epoch [100/500] | Train Loss: 1.246527 | Val Loss: 0.394519\n",
      "Epoch [200/500] | Train Loss: 1.172472 | Val Loss: 0.391733\n",
      "Epoch [300/500] | Train Loss: 1.112997 | Val Loss: 0.383295\n",
      "Epoch [400/500] | Train Loss: 1.054457 | Val Loss: 0.391273\n",
      "Epoch [500/500] | Train Loss: 1.004928 | Val Loss: 0.385906\n",
      "Epoch [100/500] | Train Loss: 1.085421 | Val Loss: 0.465068\n",
      "Epoch [200/500] | Train Loss: 0.990895 | Val Loss: 0.467049\n",
      "Epoch [300/500] | Train Loss: 0.968630 | Val Loss: 0.468584\n",
      "Epoch [400/500] | Train Loss: 0.905083 | Val Loss: 0.470434\n",
      "Epoch [500/500] | Train Loss: 0.881012 | Val Loss: 0.470985\n",
      "Epoch [100/500] | Train Loss: 1.709447 | Val Loss: 1.897399\n",
      "Epoch [200/500] | Train Loss: 1.325930 | Val Loss: 2.126227\n",
      "Epoch [300/500] | Train Loss: 1.167549 | Val Loss: 2.183734\n",
      "Epoch [400/500] | Train Loss: 0.942802 | Val Loss: 2.072630\n",
      "Epoch [500/500] | Train Loss: 0.946011 | Val Loss: 2.309831\n",
      "Epoch [100/500] | Train Loss: 1.741689 | Val Loss: 0.647682\n",
      "Epoch [200/500] | Train Loss: 1.340408 | Val Loss: 0.828575\n",
      "Epoch [300/500] | Train Loss: 1.090061 | Val Loss: 0.829006\n",
      "Epoch [400/500] | Train Loss: 1.221088 | Val Loss: 0.941239\n",
      "Epoch [500/500] | Train Loss: 1.142129 | Val Loss: 0.918573\n",
      "Epoch [100/500] | Train Loss: 1.212614 | Val Loss: 0.518658\n",
      "Epoch [200/500] | Train Loss: 1.069365 | Val Loss: 0.530402\n",
      "Epoch [300/500] | Train Loss: 0.964568 | Val Loss: 0.565157\n",
      "Epoch [400/500] | Train Loss: 0.936337 | Val Loss: 0.619283\n",
      "Epoch [500/500] | Train Loss: 0.830622 | Val Loss: 0.667754\n",
      "Epoch [100/500] | Train Loss: 1.103039 | Val Loss: 0.416134\n",
      "Epoch [200/500] | Train Loss: 0.990938 | Val Loss: 0.411567\n",
      "Epoch [300/500] | Train Loss: 0.915007 | Val Loss: 0.426382\n",
      "Epoch [400/500] | Train Loss: 0.910093 | Val Loss: 0.401808\n",
      "Epoch [500/500] | Train Loss: 0.794671 | Val Loss: 0.417757\n",
      "Epoch [100/500] | Train Loss: 0.913378 | Val Loss: 0.461277\n",
      "Epoch [200/500] | Train Loss: 0.797857 | Val Loss: 0.461122\n",
      "Epoch [300/500] | Train Loss: 0.770639 | Val Loss: 0.478531\n",
      "Epoch [400/500] | Train Loss: 0.713709 | Val Loss: 0.503705\n",
      "Epoch [500/500] | Train Loss: 0.754433 | Val Loss: 0.473127\n",
      "[Year=2007] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.748507 Test MSE=1.003582\n",
      "Year 2007 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.062979 | Val Loss: 0.593485\n",
      "Epoch [200/500] | Train Loss: 0.869984 | Val Loss: 0.640885\n",
      "Epoch [300/500] | Train Loss: 0.816456 | Val Loss: 0.691788\n",
      "Epoch [400/500] | Train Loss: 0.712076 | Val Loss: 0.712837\n",
      "Epoch [500/500] | Train Loss: 0.689220 | Val Loss: 0.743840\n",
      "Epoch [100/500] | Train Loss: 0.861193 | Val Loss: 0.459751\n",
      "Epoch [200/500] | Train Loss: 0.766009 | Val Loss: 0.463008\n",
      "Epoch [300/500] | Train Loss: 0.683221 | Val Loss: 0.478143\n",
      "Epoch [400/500] | Train Loss: 0.641468 | Val Loss: 0.488068\n",
      "Epoch [500/500] | Train Loss: 0.612030 | Val Loss: 0.505478\n",
      "Epoch [100/500] | Train Loss: 0.702666 | Val Loss: 0.374452\n",
      "Epoch [200/500] | Train Loss: 0.619172 | Val Loss: 0.384788\n",
      "Epoch [300/500] | Train Loss: 0.581118 | Val Loss: 0.406357\n",
      "Epoch [400/500] | Train Loss: 0.573215 | Val Loss: 0.419081\n",
      "Epoch [500/500] | Train Loss: 0.527076 | Val Loss: 0.431400\n",
      "Epoch [100/500] | Train Loss: 0.638764 | Val Loss: 0.523783\n",
      "Epoch [200/500] | Train Loss: 0.575010 | Val Loss: 0.547867\n",
      "Epoch [300/500] | Train Loss: 0.554573 | Val Loss: 0.577029\n",
      "Epoch [400/500] | Train Loss: 0.524399 | Val Loss: 0.585973\n",
      "Epoch [500/500] | Train Loss: 0.477746 | Val Loss: 0.603612\n",
      "Epoch [100/500] | Train Loss: 0.612922 | Val Loss: 1.073223\n",
      "Epoch [200/500] | Train Loss: 0.572818 | Val Loss: 1.090145\n",
      "Epoch [300/500] | Train Loss: 0.540450 | Val Loss: 1.101527\n",
      "Epoch [400/500] | Train Loss: 0.509816 | Val Loss: 1.093698\n",
      "Epoch [500/500] | Train Loss: 0.496522 | Val Loss: 1.093182\n",
      "Epoch [100/500] | Train Loss: 0.670548 | Val Loss: 0.841833\n",
      "Epoch [200/500] | Train Loss: 0.565194 | Val Loss: 1.070668\n",
      "Epoch [300/500] | Train Loss: 0.481880 | Val Loss: 1.017347\n",
      "Epoch [400/500] | Train Loss: 0.371601 | Val Loss: 1.145666\n",
      "Epoch [500/500] | Train Loss: 0.276658 | Val Loss: 1.144821\n",
      "Epoch [100/500] | Train Loss: 0.655655 | Val Loss: 0.554955\n",
      "Epoch [200/500] | Train Loss: 0.548156 | Val Loss: 0.561342\n",
      "Epoch [300/500] | Train Loss: 0.437080 | Val Loss: 0.608776\n",
      "Epoch [400/500] | Train Loss: 0.413774 | Val Loss: 0.654545\n",
      "Epoch [500/500] | Train Loss: 0.442920 | Val Loss: 0.671174\n",
      "Epoch [100/500] | Train Loss: 0.570069 | Val Loss: 0.406006\n",
      "Epoch [200/500] | Train Loss: 0.470127 | Val Loss: 0.449135\n",
      "Epoch [300/500] | Train Loss: 0.433161 | Val Loss: 0.464293\n",
      "Epoch [400/500] | Train Loss: 0.412038 | Val Loss: 0.479490\n",
      "Epoch [500/500] | Train Loss: 0.375232 | Val Loss: 0.480397\n",
      "Epoch [100/500] | Train Loss: 0.558726 | Val Loss: 0.580222\n",
      "Epoch [200/500] | Train Loss: 0.479458 | Val Loss: 0.630174\n",
      "Epoch [300/500] | Train Loss: 0.449995 | Val Loss: 0.675315\n",
      "Epoch [400/500] | Train Loss: 0.460714 | Val Loss: 0.721556\n",
      "Epoch [500/500] | Train Loss: 0.383522 | Val Loss: 0.687347\n",
      "Epoch [100/500] | Train Loss: 0.497960 | Val Loss: 1.162014\n",
      "Epoch [200/500] | Train Loss: 0.459330 | Val Loss: 1.158273\n",
      "Epoch [300/500] | Train Loss: 0.396014 | Val Loss: 1.280952\n",
      "Epoch [400/500] | Train Loss: 0.403841 | Val Loss: 1.261482\n",
      "Epoch [500/500] | Train Loss: 0.383619 | Val Loss: 1.212814\n",
      "Epoch [100/500] | Train Loss: 1.176220 | Val Loss: 0.573902\n",
      "Epoch [200/500] | Train Loss: 1.061100 | Val Loss: 0.613930\n",
      "Epoch [300/500] | Train Loss: 1.002522 | Val Loss: 0.627540\n",
      "Epoch [400/500] | Train Loss: 0.917070 | Val Loss: 0.630249\n",
      "Epoch [500/500] | Train Loss: 0.859338 | Val Loss: 0.646596\n",
      "Epoch [100/500] | Train Loss: 0.885056 | Val Loss: 0.448083\n",
      "Epoch [200/500] | Train Loss: 0.847878 | Val Loss: 0.451552\n",
      "Epoch [300/500] | Train Loss: 0.760990 | Val Loss: 0.453324\n",
      "Epoch [400/500] | Train Loss: 0.766833 | Val Loss: 0.454663\n",
      "Epoch [500/500] | Train Loss: 0.732874 | Val Loss: 0.455780\n",
      "Epoch [100/500] | Train Loss: 0.728109 | Val Loss: 0.376169\n",
      "Epoch [200/500] | Train Loss: 0.689829 | Val Loss: 0.385518\n",
      "Epoch [300/500] | Train Loss: 0.648915 | Val Loss: 0.388804\n",
      "Epoch [400/500] | Train Loss: 0.642867 | Val Loss: 0.392606\n",
      "Epoch [500/500] | Train Loss: 0.649773 | Val Loss: 0.397624\n",
      "Epoch [100/500] | Train Loss: 0.638085 | Val Loss: 0.524421\n",
      "Epoch [200/500] | Train Loss: 0.628764 | Val Loss: 0.545045\n",
      "Epoch [300/500] | Train Loss: 0.593938 | Val Loss: 0.573653\n",
      "Epoch [400/500] | Train Loss: 0.593250 | Val Loss: 0.600225\n",
      "Epoch [500/500] | Train Loss: 0.569517 | Val Loss: 0.626621\n",
      "Epoch [100/500] | Train Loss: 0.643032 | Val Loss: 1.066705\n",
      "Epoch [200/500] | Train Loss: 0.621972 | Val Loss: 1.066453\n",
      "Epoch [300/500] | Train Loss: 0.617138 | Val Loss: 1.066328\n",
      "Epoch [400/500] | Train Loss: 0.586812 | Val Loss: 1.076088\n",
      "Epoch [500/500] | Train Loss: 0.578620 | Val Loss: 1.079937\n",
      "Epoch [100/500] | Train Loss: 0.927300 | Val Loss: 0.596086\n",
      "Epoch [200/500] | Train Loss: 0.700076 | Val Loss: 0.735171\n",
      "Epoch [300/500] | Train Loss: 0.658352 | Val Loss: 0.804162\n",
      "Epoch [400/500] | Train Loss: 0.653887 | Val Loss: 0.850401\n",
      "Epoch [500/500] | Train Loss: 0.591258 | Val Loss: 0.916243\n",
      "Epoch [100/500] | Train Loss: 0.683826 | Val Loss: 0.479103\n",
      "Epoch [200/500] | Train Loss: 0.565257 | Val Loss: 0.560677\n",
      "Epoch [300/500] | Train Loss: 0.564435 | Val Loss: 0.642077\n",
      "Epoch [400/500] | Train Loss: 0.550785 | Val Loss: 0.639985\n",
      "Epoch [500/500] | Train Loss: 0.501267 | Val Loss: 0.682066\n",
      "Epoch [100/500] | Train Loss: 0.657598 | Val Loss: 0.383218\n",
      "Epoch [200/500] | Train Loss: 0.603730 | Val Loss: 0.389930\n",
      "Epoch [300/500] | Train Loss: 0.574053 | Val Loss: 0.393219\n",
      "Epoch [400/500] | Train Loss: 0.522964 | Val Loss: 0.396512\n",
      "Epoch [500/500] | Train Loss: 0.524197 | Val Loss: 0.393727\n",
      "Epoch [100/500] | Train Loss: 0.603119 | Val Loss: 0.556588\n",
      "Epoch [200/500] | Train Loss: 0.575795 | Val Loss: 0.625164\n",
      "Epoch [300/500] | Train Loss: 0.562756 | Val Loss: 0.619772\n",
      "Epoch [400/500] | Train Loss: 0.502362 | Val Loss: 0.701513\n",
      "Epoch [500/500] | Train Loss: 0.504483 | Val Loss: 0.670380\n",
      "Epoch [100/500] | Train Loss: 0.547503 | Val Loss: 1.079025\n",
      "Epoch [200/500] | Train Loss: 0.523782 | Val Loss: 1.058111\n",
      "Epoch [300/500] | Train Loss: 0.502471 | Val Loss: 1.076661\n",
      "Epoch [400/500] | Train Loss: 0.502185 | Val Loss: 1.093399\n",
      "Epoch [500/500] | Train Loss: 0.476448 | Val Loss: 1.071808\n",
      "Epoch [100/500] | Train Loss: 1.083019 | Val Loss: 0.607260\n",
      "Epoch [200/500] | Train Loss: 0.875511 | Val Loss: 0.689343\n",
      "Epoch [300/500] | Train Loss: 0.780334 | Val Loss: 0.779335\n",
      "Epoch [400/500] | Train Loss: 0.558471 | Val Loss: 0.835775\n",
      "Epoch [500/500] | Train Loss: 0.548190 | Val Loss: 0.838207\n",
      "Epoch [100/500] | Train Loss: 0.817937 | Val Loss: 0.463452\n",
      "Epoch [200/500] | Train Loss: 0.630955 | Val Loss: 0.514257\n",
      "Epoch [300/500] | Train Loss: 0.544621 | Val Loss: 0.568188\n",
      "Epoch [400/500] | Train Loss: 0.510732 | Val Loss: 0.573747\n",
      "Epoch [500/500] | Train Loss: 0.472740 | Val Loss: 0.608698\n",
      "Epoch [100/500] | Train Loss: 0.716457 | Val Loss: 0.377157\n",
      "Epoch [200/500] | Train Loss: 0.635777 | Val Loss: 0.395234\n",
      "Epoch [300/500] | Train Loss: 0.579809 | Val Loss: 0.404145\n",
      "Epoch [400/500] | Train Loss: 0.547424 | Val Loss: 0.412930\n",
      "Epoch [500/500] | Train Loss: 0.500303 | Val Loss: 0.430625\n",
      "Epoch [100/500] | Train Loss: 0.627931 | Val Loss: 0.519583\n",
      "Epoch [200/500] | Train Loss: 0.555445 | Val Loss: 0.535702\n",
      "Epoch [300/500] | Train Loss: 0.491347 | Val Loss: 0.588523\n",
      "Epoch [400/500] | Train Loss: 0.467989 | Val Loss: 0.615994\n",
      "Epoch [500/500] | Train Loss: 0.439182 | Val Loss: 0.645109\n",
      "Epoch [100/500] | Train Loss: 0.611067 | Val Loss: 1.073695\n",
      "Epoch [200/500] | Train Loss: 0.545093 | Val Loss: 1.104274\n",
      "Epoch [300/500] | Train Loss: 0.535525 | Val Loss: 1.115577\n",
      "Epoch [400/500] | Train Loss: 0.495318 | Val Loss: 1.093503\n",
      "Epoch [500/500] | Train Loss: 0.468444 | Val Loss: 1.088557\n",
      "Epoch [100/500] | Train Loss: 0.515465 | Val Loss: 0.903620\n",
      "Epoch [200/500] | Train Loss: 0.396527 | Val Loss: 1.083190\n",
      "Epoch [300/500] | Train Loss: 0.268957 | Val Loss: 1.135149\n",
      "Epoch [400/500] | Train Loss: 0.286124 | Val Loss: 1.181995\n",
      "Epoch [500/500] | Train Loss: 0.306622 | Val Loss: 1.136968\n",
      "Epoch [100/500] | Train Loss: 0.741239 | Val Loss: 0.459492\n",
      "Epoch [200/500] | Train Loss: 0.518000 | Val Loss: 0.522918\n",
      "Epoch [300/500] | Train Loss: 0.524850 | Val Loss: 0.577824\n",
      "Epoch [400/500] | Train Loss: 0.450970 | Val Loss: 0.589054\n",
      "Epoch [500/500] | Train Loss: 0.447197 | Val Loss: 0.604003\n",
      "Epoch [100/500] | Train Loss: 0.562331 | Val Loss: 0.395918\n",
      "Epoch [200/500] | Train Loss: 0.423223 | Val Loss: 0.422900\n",
      "Epoch [300/500] | Train Loss: 0.428553 | Val Loss: 0.472716\n",
      "Epoch [400/500] | Train Loss: 0.378122 | Val Loss: 0.488454\n",
      "Epoch [500/500] | Train Loss: 0.385344 | Val Loss: 0.471649\n",
      "Epoch [100/500] | Train Loss: 0.476567 | Val Loss: 0.677668\n",
      "Epoch [200/500] | Train Loss: 0.409931 | Val Loss: 0.755006\n",
      "Epoch [300/500] | Train Loss: 0.378731 | Val Loss: 0.773407\n",
      "Epoch [400/500] | Train Loss: 0.354077 | Val Loss: 0.853315\n",
      "Epoch [500/500] | Train Loss: 0.332300 | Val Loss: 0.839750\n",
      "Epoch [100/500] | Train Loss: 0.475045 | Val Loss: 1.167232\n",
      "Epoch [200/500] | Train Loss: 0.407437 | Val Loss: 1.215517\n",
      "Epoch [300/500] | Train Loss: 0.356391 | Val Loss: 1.193196\n",
      "Epoch [400/500] | Train Loss: 0.348562 | Val Loss: 1.265145\n",
      "Epoch [500/500] | Train Loss: 0.326556 | Val Loss: 1.253208\n",
      "Epoch [100/500] | Train Loss: 1.182977 | Val Loss: 0.584515\n",
      "Epoch [200/500] | Train Loss: 1.041273 | Val Loss: 0.610391\n",
      "Epoch [300/500] | Train Loss: 0.959686 | Val Loss: 0.623101\n",
      "Epoch [400/500] | Train Loss: 0.792547 | Val Loss: 0.640104\n",
      "Epoch [500/500] | Train Loss: 0.730968 | Val Loss: 0.652619\n",
      "Epoch [100/500] | Train Loss: 0.846677 | Val Loss: 0.450158\n",
      "Epoch [200/500] | Train Loss: 0.782334 | Val Loss: 0.458815\n",
      "Epoch [300/500] | Train Loss: 0.714027 | Val Loss: 0.486106\n",
      "Epoch [400/500] | Train Loss: 0.659775 | Val Loss: 0.493396\n",
      "Epoch [500/500] | Train Loss: 0.677160 | Val Loss: 0.515040\n",
      "Epoch [100/500] | Train Loss: 0.722869 | Val Loss: 0.374604\n",
      "Epoch [200/500] | Train Loss: 0.674465 | Val Loss: 0.374492\n",
      "Epoch [300/500] | Train Loss: 0.603903 | Val Loss: 0.378963\n",
      "Epoch [400/500] | Train Loss: 0.611684 | Val Loss: 0.385723\n",
      "Epoch [500/500] | Train Loss: 0.566668 | Val Loss: 0.403593\n",
      "Epoch [100/500] | Train Loss: 0.642187 | Val Loss: 0.515560\n",
      "Epoch [200/500] | Train Loss: 0.619570 | Val Loss: 0.536443\n",
      "Epoch [300/500] | Train Loss: 0.576349 | Val Loss: 0.564003\n",
      "Epoch [400/500] | Train Loss: 0.562515 | Val Loss: 0.601457\n",
      "Epoch [500/500] | Train Loss: 0.505538 | Val Loss: 0.628251\n",
      "Epoch [100/500] | Train Loss: 0.623027 | Val Loss: 1.068093\n",
      "Epoch [200/500] | Train Loss: 0.610773 | Val Loss: 1.068004\n",
      "Epoch [300/500] | Train Loss: 0.586872 | Val Loss: 1.108725\n",
      "Epoch [400/500] | Train Loss: 0.557319 | Val Loss: 1.119716\n",
      "Epoch [500/500] | Train Loss: 0.523964 | Val Loss: 1.136810\n",
      "Epoch [100/500] | Train Loss: 0.629093 | Val Loss: 0.769273\n",
      "Epoch [200/500] | Train Loss: 0.632519 | Val Loss: 0.939268\n",
      "Epoch [300/500] | Train Loss: 0.511767 | Val Loss: 1.006000\n",
      "Epoch [400/500] | Train Loss: 0.423533 | Val Loss: 1.020170\n",
      "Epoch [500/500] | Train Loss: 0.487857 | Val Loss: 1.140839\n",
      "Epoch [100/500] | Train Loss: 0.756231 | Val Loss: 0.491408\n",
      "Epoch [200/500] | Train Loss: 0.683668 | Val Loss: 0.507242\n",
      "Epoch [300/500] | Train Loss: 0.641670 | Val Loss: 0.538394\n",
      "Epoch [400/500] | Train Loss: 0.631195 | Val Loss: 0.585429\n",
      "Epoch [500/500] | Train Loss: 0.597565 | Val Loss: 0.574009\n",
      "Epoch [100/500] | Train Loss: 0.642156 | Val Loss: 0.373686\n",
      "Epoch [200/500] | Train Loss: 0.552723 | Val Loss: 0.419867\n",
      "Epoch [300/500] | Train Loss: 0.477888 | Val Loss: 0.456446\n",
      "Epoch [400/500] | Train Loss: 0.455385 | Val Loss: 0.449840\n",
      "Epoch [500/500] | Train Loss: 0.435252 | Val Loss: 0.437678\n",
      "Epoch [100/500] | Train Loss: 0.541630 | Val Loss: 0.560482\n",
      "Epoch [200/500] | Train Loss: 0.480344 | Val Loss: 0.609354\n",
      "Epoch [300/500] | Train Loss: 0.465449 | Val Loss: 0.661479\n",
      "Epoch [400/500] | Train Loss: 0.444090 | Val Loss: 0.693483\n",
      "Epoch [500/500] | Train Loss: 0.407829 | Val Loss: 0.659852\n",
      "Epoch [100/500] | Train Loss: 0.578636 | Val Loss: 1.055129\n",
      "Epoch [200/500] | Train Loss: 0.515792 | Val Loss: 1.093367\n",
      "Epoch [300/500] | Train Loss: 0.473334 | Val Loss: 1.117289\n",
      "Epoch [400/500] | Train Loss: 0.445323 | Val Loss: 1.135024\n",
      "Epoch [500/500] | Train Loss: 0.421415 | Val Loss: 1.133563\n",
      "[Year=2008] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.641312 Test MSE=6.537753\n",
      "Year 2008 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.506256 | Val Loss: 0.425338\n",
      "Epoch [200/500] | Train Loss: 0.393443 | Val Loss: 0.457686\n",
      "Epoch [300/500] | Train Loss: 0.335641 | Val Loss: 0.488212\n",
      "Epoch [400/500] | Train Loss: 0.294957 | Val Loss: 0.519839\n",
      "Epoch [500/500] | Train Loss: 0.257610 | Val Loss: 0.554714\n",
      "Epoch [100/500] | Train Loss: 0.474505 | Val Loss: 0.499155\n",
      "Epoch [200/500] | Train Loss: 0.475170 | Val Loss: 0.496379\n",
      "Epoch [300/500] | Train Loss: 0.443912 | Val Loss: 0.509014\n",
      "Epoch [400/500] | Train Loss: 0.394691 | Val Loss: 0.517209\n",
      "Epoch [500/500] | Train Loss: 0.391704 | Val Loss: 0.546273\n",
      "Epoch [100/500] | Train Loss: 0.480397 | Val Loss: 0.422783\n",
      "Epoch [200/500] | Train Loss: 0.435339 | Val Loss: 0.468335\n",
      "Epoch [300/500] | Train Loss: 0.410278 | Val Loss: 0.503448\n",
      "Epoch [400/500] | Train Loss: 0.380485 | Val Loss: 0.508234\n",
      "Epoch [500/500] | Train Loss: 0.359673 | Val Loss: 0.521541\n",
      "Epoch [100/500] | Train Loss: 0.458646 | Val Loss: 1.381072\n",
      "Epoch [200/500] | Train Loss: 0.428100 | Val Loss: 1.452669\n",
      "Epoch [300/500] | Train Loss: 0.405676 | Val Loss: 1.480446\n",
      "Epoch [400/500] | Train Loss: 0.394318 | Val Loss: 1.529199\n",
      "Epoch [500/500] | Train Loss: 0.365445 | Val Loss: 1.566036\n",
      "Epoch [100/500] | Train Loss: 0.641531 | Val Loss: 7.134521\n",
      "Epoch [200/500] | Train Loss: 0.611909 | Val Loss: 7.067826\n",
      "Epoch [300/500] | Train Loss: 0.593864 | Val Loss: 7.150056\n",
      "Epoch [400/500] | Train Loss: 0.562941 | Val Loss: 7.171829\n",
      "Epoch [500/500] | Train Loss: 0.531133 | Val Loss: 7.533954\n",
      "Epoch [100/500] | Train Loss: 0.348648 | Val Loss: 0.512774\n",
      "Epoch [200/500] | Train Loss: 0.228406 | Val Loss: 0.621045\n",
      "Epoch [300/500] | Train Loss: 0.164648 | Val Loss: 0.663488\n",
      "Epoch [400/500] | Train Loss: 0.174731 | Val Loss: 0.661632\n",
      "Epoch [500/500] | Train Loss: 0.198904 | Val Loss: 0.735206\n",
      "Epoch [100/500] | Train Loss: 0.363707 | Val Loss: 0.553922\n",
      "Epoch [200/500] | Train Loss: 0.295465 | Val Loss: 0.652641\n",
      "Epoch [300/500] | Train Loss: 0.263379 | Val Loss: 0.658243\n",
      "Epoch [400/500] | Train Loss: 0.216410 | Val Loss: 0.714229\n",
      "Epoch [500/500] | Train Loss: 0.235675 | Val Loss: 0.697047\n",
      "Epoch [100/500] | Train Loss: 0.393278 | Val Loss: 0.578793\n",
      "Epoch [200/500] | Train Loss: 0.316654 | Val Loss: 0.629678\n",
      "Epoch [300/500] | Train Loss: 0.279843 | Val Loss: 0.608134\n",
      "Epoch [400/500] | Train Loss: 0.272223 | Val Loss: 0.633171\n",
      "Epoch [500/500] | Train Loss: 0.242600 | Val Loss: 0.617832\n",
      "Epoch [100/500] | Train Loss: 0.399102 | Val Loss: 1.527673\n",
      "Epoch [200/500] | Train Loss: 0.358277 | Val Loss: 1.711934\n",
      "Epoch [300/500] | Train Loss: 0.351512 | Val Loss: 1.677565\n",
      "Epoch [400/500] | Train Loss: 0.311621 | Val Loss: 1.626104\n",
      "Epoch [500/500] | Train Loss: 0.302596 | Val Loss: 1.786424\n",
      "Epoch [100/500] | Train Loss: 0.584589 | Val Loss: 7.392780\n",
      "Epoch [200/500] | Train Loss: 0.500854 | Val Loss: 7.754143\n",
      "Epoch [300/500] | Train Loss: 0.488061 | Val Loss: 8.070152\n",
      "Epoch [400/500] | Train Loss: 0.441856 | Val Loss: 7.749069\n",
      "Epoch [500/500] | Train Loss: 0.426061 | Val Loss: 8.774060\n",
      "Epoch [100/500] | Train Loss: 0.550445 | Val Loss: 0.415391\n",
      "Epoch [200/500] | Train Loss: 0.517047 | Val Loss: 0.426353\n",
      "Epoch [300/500] | Train Loss: 0.460474 | Val Loss: 0.438890\n",
      "Epoch [400/500] | Train Loss: 0.436368 | Val Loss: 0.446494\n",
      "Epoch [500/500] | Train Loss: 0.408989 | Val Loss: 0.464569\n",
      "Epoch [100/500] | Train Loss: 0.475048 | Val Loss: 0.493501\n",
      "Epoch [200/500] | Train Loss: 0.455665 | Val Loss: 0.486932\n",
      "Epoch [300/500] | Train Loss: 0.434785 | Val Loss: 0.484211\n",
      "Epoch [400/500] | Train Loss: 0.416764 | Val Loss: 0.487680\n",
      "Epoch [500/500] | Train Loss: 0.403019 | Val Loss: 0.487793\n",
      "Epoch [100/500] | Train Loss: 0.480515 | Val Loss: 0.416358\n",
      "Epoch [200/500] | Train Loss: 0.472086 | Val Loss: 0.430855\n",
      "Epoch [300/500] | Train Loss: 0.441801 | Val Loss: 0.448587\n",
      "Epoch [400/500] | Train Loss: 0.431207 | Val Loss: 0.463790\n",
      "Epoch [500/500] | Train Loss: 0.427083 | Val Loss: 0.478838\n",
      "Epoch [100/500] | Train Loss: 0.464878 | Val Loss: 1.369750\n",
      "Epoch [200/500] | Train Loss: 0.458033 | Val Loss: 1.397074\n",
      "Epoch [300/500] | Train Loss: 0.446283 | Val Loss: 1.413791\n",
      "Epoch [400/500] | Train Loss: 0.432383 | Val Loss: 1.438379\n",
      "Epoch [500/500] | Train Loss: 0.412913 | Val Loss: 1.470053\n",
      "Epoch [100/500] | Train Loss: 0.643192 | Val Loss: 7.057768\n",
      "Epoch [200/500] | Train Loss: 0.630948 | Val Loss: 7.052339\n",
      "Epoch [300/500] | Train Loss: 0.624584 | Val Loss: 7.195055\n",
      "Epoch [400/500] | Train Loss: 0.593304 | Val Loss: 7.507516\n",
      "Epoch [500/500] | Train Loss: 0.561640 | Val Loss: 7.784636\n",
      "Epoch [100/500] | Train Loss: 0.434626 | Val Loss: 0.466612\n",
      "Epoch [200/500] | Train Loss: 0.362593 | Val Loss: 0.493420\n",
      "Epoch [300/500] | Train Loss: 0.296793 | Val Loss: 0.541577\n",
      "Epoch [400/500] | Train Loss: 0.308419 | Val Loss: 0.546514\n",
      "Epoch [500/500] | Train Loss: 0.271193 | Val Loss: 0.541320\n",
      "Epoch [100/500] | Train Loss: 0.440732 | Val Loss: 0.488951\n",
      "Epoch [200/500] | Train Loss: 0.353876 | Val Loss: 0.532760\n",
      "Epoch [300/500] | Train Loss: 0.345382 | Val Loss: 0.553471\n",
      "Epoch [400/500] | Train Loss: 0.364014 | Val Loss: 0.560540\n",
      "Epoch [500/500] | Train Loss: 0.326914 | Val Loss: 0.552855\n",
      "Epoch [100/500] | Train Loss: 0.450563 | Val Loss: 0.450871\n",
      "Epoch [200/500] | Train Loss: 0.382887 | Val Loss: 0.498262\n",
      "Epoch [300/500] | Train Loss: 0.374453 | Val Loss: 0.553262\n",
      "Epoch [400/500] | Train Loss: 0.359763 | Val Loss: 0.530177\n",
      "Epoch [500/500] | Train Loss: 0.334135 | Val Loss: 0.580947\n",
      "Epoch [100/500] | Train Loss: 0.438590 | Val Loss: 1.386447\n",
      "Epoch [200/500] | Train Loss: 0.397457 | Val Loss: 1.375889\n",
      "Epoch [300/500] | Train Loss: 0.372252 | Val Loss: 1.370793\n",
      "Epoch [400/500] | Train Loss: 0.368133 | Val Loss: 1.370058\n",
      "Epoch [500/500] | Train Loss: 0.362642 | Val Loss: 1.339223\n",
      "Epoch [100/500] | Train Loss: 0.587576 | Val Loss: 7.071267\n",
      "Epoch [200/500] | Train Loss: 0.535049 | Val Loss: 7.477149\n",
      "Epoch [300/500] | Train Loss: 0.492763 | Val Loss: 7.278582\n",
      "Epoch [400/500] | Train Loss: 0.511403 | Val Loss: 7.155375\n",
      "Epoch [500/500] | Train Loss: 0.471799 | Val Loss: 7.529470\n",
      "Epoch [100/500] | Train Loss: 0.514641 | Val Loss: 0.421490\n",
      "Epoch [200/500] | Train Loss: 0.385160 | Val Loss: 0.479779\n",
      "Epoch [300/500] | Train Loss: 0.308408 | Val Loss: 0.511522\n",
      "Epoch [400/500] | Train Loss: 0.234948 | Val Loss: 0.537625\n",
      "Epoch [500/500] | Train Loss: 0.221519 | Val Loss: 0.543306\n",
      "Epoch [100/500] | Train Loss: 0.473154 | Val Loss: 0.497887\n",
      "Epoch [200/500] | Train Loss: 0.448903 | Val Loss: 0.502261\n",
      "Epoch [300/500] | Train Loss: 0.400183 | Val Loss: 0.539300\n",
      "Epoch [400/500] | Train Loss: 0.356862 | Val Loss: 0.581303\n",
      "Epoch [500/500] | Train Loss: 0.321087 | Val Loss: 0.609441\n",
      "Epoch [100/500] | Train Loss: 0.467365 | Val Loss: 0.441633\n",
      "Epoch [200/500] | Train Loss: 0.412024 | Val Loss: 0.502357\n",
      "Epoch [300/500] | Train Loss: 0.363497 | Val Loss: 0.572745\n",
      "Epoch [400/500] | Train Loss: 0.333117 | Val Loss: 0.607325\n",
      "Epoch [500/500] | Train Loss: 0.309556 | Val Loss: 0.644834\n",
      "Epoch [100/500] | Train Loss: 0.441871 | Val Loss: 1.425152\n",
      "Epoch [200/500] | Train Loss: 0.404230 | Val Loss: 1.468076\n",
      "Epoch [300/500] | Train Loss: 0.385851 | Val Loss: 1.527502\n",
      "Epoch [400/500] | Train Loss: 0.357363 | Val Loss: 1.575776\n",
      "Epoch [500/500] | Train Loss: 0.345652 | Val Loss: 1.585360\n",
      "Epoch [100/500] | Train Loss: 0.651639 | Val Loss: 7.194139\n",
      "Epoch [200/500] | Train Loss: 0.625564 | Val Loss: 7.138103\n",
      "Epoch [300/500] | Train Loss: 0.568403 | Val Loss: 7.550275\n",
      "Epoch [400/500] | Train Loss: 0.526429 | Val Loss: 8.446949\n",
      "Epoch [500/500] | Train Loss: 0.479392 | Val Loss: 9.439803\n",
      "Epoch [100/500] | Train Loss: 0.311229 | Val Loss: 0.514449\n",
      "Epoch [200/500] | Train Loss: 0.214937 | Val Loss: 0.675021\n",
      "Epoch [300/500] | Train Loss: 0.147918 | Val Loss: 0.672889\n",
      "Epoch [400/500] | Train Loss: 0.138522 | Val Loss: 0.667789\n",
      "Epoch [500/500] | Train Loss: 0.138774 | Val Loss: 0.657319\n",
      "Epoch [100/500] | Train Loss: 0.285189 | Val Loss: 0.642540\n",
      "Epoch [200/500] | Train Loss: 0.191889 | Val Loss: 0.701251\n",
      "Epoch [300/500] | Train Loss: 0.175144 | Val Loss: 0.741487\n",
      "Epoch [400/500] | Train Loss: 0.161209 | Val Loss: 0.717765\n",
      "Epoch [500/500] | Train Loss: 0.147945 | Val Loss: 0.728349\n",
      "Epoch [100/500] | Train Loss: 0.301346 | Val Loss: 0.624297\n",
      "Epoch [200/500] | Train Loss: 0.257721 | Val Loss: 0.595841\n",
      "Epoch [300/500] | Train Loss: 0.234602 | Val Loss: 0.587098\n",
      "Epoch [400/500] | Train Loss: 0.197670 | Val Loss: 0.600527\n",
      "Epoch [500/500] | Train Loss: 0.192804 | Val Loss: 0.639754\n",
      "Epoch [100/500] | Train Loss: 0.382686 | Val Loss: 1.423761\n",
      "Epoch [200/500] | Train Loss: 0.321921 | Val Loss: 1.474372\n",
      "Epoch [300/500] | Train Loss: 0.277705 | Val Loss: 1.519052\n",
      "Epoch [400/500] | Train Loss: 0.268775 | Val Loss: 1.604216\n",
      "Epoch [500/500] | Train Loss: 0.256388 | Val Loss: 1.534635\n",
      "Epoch [100/500] | Train Loss: 0.497989 | Val Loss: 10.560793\n",
      "Epoch [200/500] | Train Loss: 0.405434 | Val Loss: 9.602010\n",
      "Epoch [300/500] | Train Loss: 0.399722 | Val Loss: 9.129168\n",
      "Epoch [400/500] | Train Loss: 0.403963 | Val Loss: 9.446493\n",
      "Epoch [500/500] | Train Loss: 0.338483 | Val Loss: 9.454137\n",
      "Epoch [100/500] | Train Loss: 0.573754 | Val Loss: 0.418429\n",
      "Epoch [200/500] | Train Loss: 0.513032 | Val Loss: 0.432266\n",
      "Epoch [300/500] | Train Loss: 0.442602 | Val Loss: 0.449359\n",
      "Epoch [400/500] | Train Loss: 0.402970 | Val Loss: 0.484082\n",
      "Epoch [500/500] | Train Loss: 0.308367 | Val Loss: 0.516294\n",
      "Epoch [100/500] | Train Loss: 0.480501 | Val Loss: 0.491764\n",
      "Epoch [200/500] | Train Loss: 0.444308 | Val Loss: 0.503636\n",
      "Epoch [300/500] | Train Loss: 0.426805 | Val Loss: 0.521516\n",
      "Epoch [400/500] | Train Loss: 0.389562 | Val Loss: 0.540977\n",
      "Epoch [500/500] | Train Loss: 0.377798 | Val Loss: 0.552070\n",
      "Epoch [100/500] | Train Loss: 0.482905 | Val Loss: 0.421874\n",
      "Epoch [200/500] | Train Loss: 0.451469 | Val Loss: 0.447564\n",
      "Epoch [300/500] | Train Loss: 0.426650 | Val Loss: 0.454706\n",
      "Epoch [400/500] | Train Loss: 0.416845 | Val Loss: 0.467459\n",
      "Epoch [500/500] | Train Loss: 0.380470 | Val Loss: 0.468890\n",
      "Epoch [100/500] | Train Loss: 0.482570 | Val Loss: 1.363764\n",
      "Epoch [200/500] | Train Loss: 0.469938 | Val Loss: 1.365115\n",
      "Epoch [300/500] | Train Loss: 0.461499 | Val Loss: 1.391961\n",
      "Epoch [400/500] | Train Loss: 0.441233 | Val Loss: 1.451249\n",
      "Epoch [500/500] | Train Loss: 0.427014 | Val Loss: 1.468825\n",
      "Epoch [100/500] | Train Loss: 0.633453 | Val Loss: 7.083249\n",
      "Epoch [200/500] | Train Loss: 0.604452 | Val Loss: 7.264127\n",
      "Epoch [300/500] | Train Loss: 0.593101 | Val Loss: 7.735610\n",
      "Epoch [400/500] | Train Loss: 0.550130 | Val Loss: 8.314639\n",
      "Epoch [500/500] | Train Loss: 0.545569 | Val Loss: 8.798413\n",
      "Epoch [100/500] | Train Loss: 0.379579 | Val Loss: 0.481902\n",
      "Epoch [200/500] | Train Loss: 0.277761 | Val Loss: 0.539846\n",
      "Epoch [300/500] | Train Loss: 0.243691 | Val Loss: 0.595708\n",
      "Epoch [400/500] | Train Loss: 0.191637 | Val Loss: 0.586721\n",
      "Epoch [500/500] | Train Loss: 0.207003 | Val Loss: 0.580903\n",
      "Epoch [100/500] | Train Loss: 0.434097 | Val Loss: 0.535739\n",
      "Epoch [200/500] | Train Loss: 0.389497 | Val Loss: 0.508303\n",
      "Epoch [300/500] | Train Loss: 0.347417 | Val Loss: 0.533356\n",
      "Epoch [400/500] | Train Loss: 0.340192 | Val Loss: 0.527328\n",
      "Epoch [500/500] | Train Loss: 0.319623 | Val Loss: 0.568799\n",
      "Epoch [100/500] | Train Loss: 0.432653 | Val Loss: 0.501381\n",
      "Epoch [200/500] | Train Loss: 0.361094 | Val Loss: 0.539731\n",
      "Epoch [300/500] | Train Loss: 0.366915 | Val Loss: 0.531345\n",
      "Epoch [400/500] | Train Loss: 0.324534 | Val Loss: 0.575844\n",
      "Epoch [500/500] | Train Loss: 0.311251 | Val Loss: 0.571090\n",
      "Epoch [100/500] | Train Loss: 0.408006 | Val Loss: 1.446794\n",
      "Epoch [200/500] | Train Loss: 0.388504 | Val Loss: 1.451477\n",
      "Epoch [300/500] | Train Loss: 0.363230 | Val Loss: 1.428415\n",
      "Epoch [400/500] | Train Loss: 0.342706 | Val Loss: 1.425002\n",
      "Epoch [500/500] | Train Loss: 0.345310 | Val Loss: 1.467077\n",
      "Epoch [100/500] | Train Loss: 0.596844 | Val Loss: 7.323760\n",
      "Epoch [200/500] | Train Loss: 0.529681 | Val Loss: 7.769732\n",
      "Epoch [300/500] | Train Loss: 0.488098 | Val Loss: 7.679394\n",
      "Epoch [400/500] | Train Loss: 0.480274 | Val Loss: 7.832801\n",
      "Epoch [500/500] | Train Loss: 0.437883 | Val Loss: 8.398932\n",
      "[Year=2009] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.01} CV-MSE=2.108763 Test MSE=3.540363\n",
      "Year 2009 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.438095 | Val Loss: 0.506315\n",
      "Epoch [200/500] | Train Loss: 0.366033 | Val Loss: 0.545005\n",
      "Epoch [300/500] | Train Loss: 0.326835 | Val Loss: 0.568355\n",
      "Epoch [400/500] | Train Loss: 0.300683 | Val Loss: 0.556613\n",
      "Epoch [500/500] | Train Loss: 0.276985 | Val Loss: 0.548231\n",
      "Epoch [100/500] | Train Loss: 0.464016 | Val Loss: 0.405407\n",
      "Epoch [200/500] | Train Loss: 0.395205 | Val Loss: 0.445779\n",
      "Epoch [300/500] | Train Loss: 0.370857 | Val Loss: 0.500243\n",
      "Epoch [400/500] | Train Loss: 0.316246 | Val Loss: 0.514929\n",
      "Epoch [500/500] | Train Loss: 0.288790 | Val Loss: 0.517585\n",
      "Epoch [100/500] | Train Loss: 0.444130 | Val Loss: 1.745026\n",
      "Epoch [200/500] | Train Loss: 0.405823 | Val Loss: 1.969900\n",
      "Epoch [300/500] | Train Loss: 0.364290 | Val Loss: 2.131718\n",
      "Epoch [400/500] | Train Loss: 0.359171 | Val Loss: 2.260058\n",
      "Epoch [500/500] | Train Loss: 0.343945 | Val Loss: 2.389895\n",
      "Epoch [100/500] | Train Loss: 0.754370 | Val Loss: 8.001972\n",
      "Epoch [200/500] | Train Loss: 0.714239 | Val Loss: 8.431699\n",
      "Epoch [300/500] | Train Loss: 0.674600 | Val Loss: 10.136713\n",
      "Epoch [400/500] | Train Loss: 0.649495 | Val Loss: 10.897809\n",
      "Epoch [500/500] | Train Loss: 0.601716 | Val Loss: 11.341537\n",
      "Epoch [100/500] | Train Loss: 2.090122 | Val Loss: 2.586364\n",
      "Epoch [200/500] | Train Loss: 1.789189 | Val Loss: 2.769537\n",
      "Epoch [300/500] | Train Loss: 1.689211 | Val Loss: 2.802396\n",
      "Epoch [400/500] | Train Loss: 1.656381 | Val Loss: 2.761776\n",
      "Epoch [500/500] | Train Loss: 1.358246 | Val Loss: 2.906228\n",
      "Epoch [100/500] | Train Loss: 0.291163 | Val Loss: 0.595565\n",
      "Epoch [200/500] | Train Loss: 0.206132 | Val Loss: 0.621086\n",
      "Epoch [300/500] | Train Loss: 0.146601 | Val Loss: 0.629225\n",
      "Epoch [400/500] | Train Loss: 0.144162 | Val Loss: 0.621860\n",
      "Epoch [500/500] | Train Loss: 0.133904 | Val Loss: 0.625269\n",
      "Epoch [100/500] | Train Loss: 0.323073 | Val Loss: 0.519388\n",
      "Epoch [200/500] | Train Loss: 0.245844 | Val Loss: 0.571911\n",
      "Epoch [300/500] | Train Loss: 0.233472 | Val Loss: 0.632311\n",
      "Epoch [400/500] | Train Loss: 0.204845 | Val Loss: 0.617666\n",
      "Epoch [500/500] | Train Loss: 0.192268 | Val Loss: 0.610877\n",
      "Epoch [100/500] | Train Loss: 0.345511 | Val Loss: 2.369618\n",
      "Epoch [200/500] | Train Loss: 0.284413 | Val Loss: 2.457876\n",
      "Epoch [300/500] | Train Loss: 0.289821 | Val Loss: 2.253644\n",
      "Epoch [400/500] | Train Loss: 0.253708 | Val Loss: 2.416469\n",
      "Epoch [500/500] | Train Loss: 0.235832 | Val Loss: 2.166290\n",
      "Epoch [100/500] | Train Loss: 0.598537 | Val Loss: 11.036407\n",
      "Epoch [200/500] | Train Loss: 0.513744 | Val Loss: 11.083364\n",
      "Epoch [300/500] | Train Loss: 0.491087 | Val Loss: 10.212916\n",
      "Epoch [400/500] | Train Loss: 0.451677 | Val Loss: 9.924421\n",
      "Epoch [500/500] | Train Loss: 0.415791 | Val Loss: 8.668105\n",
      "Epoch [100/500] | Train Loss: 1.229885 | Val Loss: 2.942618\n",
      "Epoch [200/500] | Train Loss: 1.191177 | Val Loss: 3.037907\n",
      "Epoch [300/500] | Train Loss: 1.003873 | Val Loss: 3.375272\n",
      "Epoch [400/500] | Train Loss: 0.958874 | Val Loss: 3.205820\n",
      "Epoch [500/500] | Train Loss: 0.968438 | Val Loss: 3.209815\n",
      "Epoch [100/500] | Train Loss: 0.472318 | Val Loss: 0.478632\n",
      "Epoch [200/500] | Train Loss: 0.457292 | Val Loss: 0.487152\n",
      "Epoch [300/500] | Train Loss: 0.423885 | Val Loss: 0.493334\n",
      "Epoch [400/500] | Train Loss: 0.399547 | Val Loss: 0.505635\n",
      "Epoch [500/500] | Train Loss: 0.356986 | Val Loss: 0.512904\n",
      "Epoch [100/500] | Train Loss: 0.471802 | Val Loss: 0.400781\n",
      "Epoch [200/500] | Train Loss: 0.445326 | Val Loss: 0.413356\n",
      "Epoch [300/500] | Train Loss: 0.422628 | Val Loss: 0.428352\n",
      "Epoch [400/500] | Train Loss: 0.397838 | Val Loss: 0.437503\n",
      "Epoch [500/500] | Train Loss: 0.383843 | Val Loss: 0.448150\n",
      "Epoch [100/500] | Train Loss: 0.449620 | Val Loss: 1.720584\n",
      "Epoch [200/500] | Train Loss: 0.442889 | Val Loss: 1.797513\n",
      "Epoch [300/500] | Train Loss: 0.408120 | Val Loss: 1.866382\n",
      "Epoch [400/500] | Train Loss: 0.388668 | Val Loss: 1.936624\n",
      "Epoch [500/500] | Train Loss: 0.390015 | Val Loss: 1.975898\n",
      "Epoch [100/500] | Train Loss: 0.744955 | Val Loss: 7.916720\n",
      "Epoch [200/500] | Train Loss: 0.715089 | Val Loss: 7.987546\n",
      "Epoch [300/500] | Train Loss: 0.715974 | Val Loss: 8.201511\n",
      "Epoch [400/500] | Train Loss: 0.691522 | Val Loss: 8.591204\n",
      "Epoch [500/500] | Train Loss: 0.668116 | Val Loss: 8.843813\n",
      "Epoch [100/500] | Train Loss: 2.125230 | Val Loss: 2.501223\n",
      "Epoch [200/500] | Train Loss: 2.046345 | Val Loss: 2.632483\n",
      "Epoch [300/500] | Train Loss: 1.776886 | Val Loss: 2.621306\n",
      "Epoch [400/500] | Train Loss: 1.656010 | Val Loss: 2.671658\n",
      "Epoch [500/500] | Train Loss: 1.480893 | Val Loss: 2.702708\n",
      "Epoch [100/500] | Train Loss: 0.419552 | Val Loss: 0.517763\n",
      "Epoch [200/500] | Train Loss: 0.388259 | Val Loss: 0.556674\n",
      "Epoch [300/500] | Train Loss: 0.289225 | Val Loss: 0.618142\n",
      "Epoch [400/500] | Train Loss: 0.265554 | Val Loss: 0.644082\n",
      "Epoch [500/500] | Train Loss: 0.287036 | Val Loss: 0.703370\n",
      "Epoch [100/500] | Train Loss: 0.383493 | Val Loss: 0.439965\n",
      "Epoch [200/500] | Train Loss: 0.337031 | Val Loss: 0.467760\n",
      "Epoch [300/500] | Train Loss: 0.327348 | Val Loss: 0.465919\n",
      "Epoch [400/500] | Train Loss: 0.313612 | Val Loss: 0.497054\n",
      "Epoch [500/500] | Train Loss: 0.318720 | Val Loss: 0.487590\n",
      "Epoch [100/500] | Train Loss: 0.398452 | Val Loss: 2.076916\n",
      "Epoch [200/500] | Train Loss: 0.341384 | Val Loss: 2.290725\n",
      "Epoch [300/500] | Train Loss: 0.336817 | Val Loss: 2.415744\n",
      "Epoch [400/500] | Train Loss: 0.321021 | Val Loss: 2.197763\n",
      "Epoch [500/500] | Train Loss: 0.294868 | Val Loss: 2.123066\n",
      "Epoch [100/500] | Train Loss: 0.674348 | Val Loss: 8.780376\n",
      "Epoch [200/500] | Train Loss: 0.623190 | Val Loss: 8.998028\n",
      "Epoch [300/500] | Train Loss: 0.608401 | Val Loss: 8.827067\n",
      "Epoch [400/500] | Train Loss: 0.591440 | Val Loss: 8.725143\n",
      "Epoch [500/500] | Train Loss: 0.553693 | Val Loss: 8.549691\n",
      "Epoch [100/500] | Train Loss: 1.691721 | Val Loss: 2.690161\n",
      "Epoch [200/500] | Train Loss: 1.414597 | Val Loss: 2.841550\n",
      "Epoch [300/500] | Train Loss: 1.339761 | Val Loss: 2.775503\n",
      "Epoch [400/500] | Train Loss: 1.248083 | Val Loss: 2.860034\n",
      "Epoch [500/500] | Train Loss: 1.370820 | Val Loss: 2.821494\n",
      "Epoch [100/500] | Train Loss: 0.442774 | Val Loss: 0.511263\n",
      "Epoch [200/500] | Train Loss: 0.378759 | Val Loss: 0.542260\n",
      "Epoch [300/500] | Train Loss: 0.306296 | Val Loss: 0.567457\n",
      "Epoch [400/500] | Train Loss: 0.265831 | Val Loss: 0.617702\n",
      "Epoch [500/500] | Train Loss: 0.203652 | Val Loss: 0.647615\n",
      "Epoch [100/500] | Train Loss: 0.465692 | Val Loss: 0.407649\n",
      "Epoch [200/500] | Train Loss: 0.414751 | Val Loss: 0.422703\n",
      "Epoch [300/500] | Train Loss: 0.337555 | Val Loss: 0.457299\n",
      "Epoch [400/500] | Train Loss: 0.320998 | Val Loss: 0.483772\n",
      "Epoch [500/500] | Train Loss: 0.297061 | Val Loss: 0.502475\n",
      "Epoch [100/500] | Train Loss: 0.470759 | Val Loss: 1.735554\n",
      "Epoch [200/500] | Train Loss: 0.419894 | Val Loss: 1.886534\n",
      "Epoch [300/500] | Train Loss: 0.390042 | Val Loss: 1.984151\n",
      "Epoch [400/500] | Train Loss: 0.352637 | Val Loss: 2.059635\n",
      "Epoch [500/500] | Train Loss: 0.322235 | Val Loss: 2.076463\n",
      "Epoch [100/500] | Train Loss: 0.705299 | Val Loss: 8.358394\n",
      "Epoch [200/500] | Train Loss: 0.625454 | Val Loss: 9.361614\n",
      "Epoch [300/500] | Train Loss: 0.577757 | Val Loss: 10.090587\n",
      "Epoch [400/500] | Train Loss: 0.544879 | Val Loss: 10.649041\n",
      "Epoch [500/500] | Train Loss: 0.520122 | Val Loss: 10.633422\n",
      "Epoch [100/500] | Train Loss: 1.969391 | Val Loss: 2.761406\n",
      "Epoch [200/500] | Train Loss: 1.467841 | Val Loss: 3.002617\n",
      "Epoch [300/500] | Train Loss: 1.242573 | Val Loss: 2.921032\n",
      "Epoch [400/500] | Train Loss: 1.190420 | Val Loss: 3.017441\n",
      "Epoch [500/500] | Train Loss: 1.035260 | Val Loss: 3.105652\n",
      "Epoch [100/500] | Train Loss: 0.235594 | Val Loss: 0.605543\n",
      "Epoch [200/500] | Train Loss: 0.149899 | Val Loss: 0.725953\n",
      "Epoch [300/500] | Train Loss: 0.132224 | Val Loss: 0.691043\n",
      "Epoch [400/500] | Train Loss: 0.117289 | Val Loss: 0.744941\n",
      "Epoch [500/500] | Train Loss: 0.097654 | Val Loss: 0.761343\n",
      "Epoch [100/500] | Train Loss: 0.326012 | Val Loss: 0.512165\n",
      "Epoch [200/500] | Train Loss: 0.265600 | Val Loss: 0.522307\n",
      "Epoch [300/500] | Train Loss: 0.238430 | Val Loss: 0.544515\n",
      "Epoch [400/500] | Train Loss: 0.198776 | Val Loss: 0.576616\n",
      "Epoch [500/500] | Train Loss: 0.196195 | Val Loss: 0.567631\n",
      "Epoch [100/500] | Train Loss: 0.383316 | Val Loss: 2.109983\n",
      "Epoch [200/500] | Train Loss: 0.332292 | Val Loss: 2.057904\n",
      "Epoch [300/500] | Train Loss: 0.300826 | Val Loss: 1.990887\n",
      "Epoch [400/500] | Train Loss: 0.277380 | Val Loss: 1.955726\n",
      "Epoch [500/500] | Train Loss: 0.239994 | Val Loss: 2.087654\n",
      "Epoch [100/500] | Train Loss: 0.558459 | Val Loss: 12.246339\n",
      "Epoch [200/500] | Train Loss: 0.425995 | Val Loss: 10.896266\n",
      "Epoch [300/500] | Train Loss: 0.377167 | Val Loss: 9.780890\n",
      "Epoch [400/500] | Train Loss: 0.374350 | Val Loss: 9.444507\n",
      "Epoch [500/500] | Train Loss: 0.370624 | Val Loss: 9.546769\n",
      "Epoch [100/500] | Train Loss: 1.145709 | Val Loss: 3.100351\n",
      "Epoch [200/500] | Train Loss: 0.955381 | Val Loss: 2.870070\n",
      "Epoch [300/500] | Train Loss: 0.919753 | Val Loss: 3.065794\n",
      "Epoch [400/500] | Train Loss: 0.833917 | Val Loss: 3.005685\n",
      "Epoch [500/500] | Train Loss: 0.848109 | Val Loss: 2.963882\n",
      "Epoch [100/500] | Train Loss: 0.459233 | Val Loss: 0.490925\n",
      "Epoch [200/500] | Train Loss: 0.409325 | Val Loss: 0.528594\n",
      "Epoch [300/500] | Train Loss: 0.352012 | Val Loss: 0.534754\n",
      "Epoch [400/500] | Train Loss: 0.326377 | Val Loss: 0.565459\n",
      "Epoch [500/500] | Train Loss: 0.308440 | Val Loss: 0.569245\n",
      "Epoch [100/500] | Train Loss: 0.476794 | Val Loss: 0.411136\n",
      "Epoch [200/500] | Train Loss: 0.438680 | Val Loss: 0.427057\n",
      "Epoch [300/500] | Train Loss: 0.412365 | Val Loss: 0.446815\n",
      "Epoch [400/500] | Train Loss: 0.380524 | Val Loss: 0.486605\n",
      "Epoch [500/500] | Train Loss: 0.344466 | Val Loss: 0.500633\n",
      "Epoch [100/500] | Train Loss: 0.449802 | Val Loss: 1.732040\n",
      "Epoch [200/500] | Train Loss: 0.425808 | Val Loss: 1.859865\n",
      "Epoch [300/500] | Train Loss: 0.397592 | Val Loss: 2.094476\n",
      "Epoch [400/500] | Train Loss: 0.368593 | Val Loss: 2.223032\n",
      "Epoch [500/500] | Train Loss: 0.347800 | Val Loss: 2.238112\n",
      "Epoch [100/500] | Train Loss: 0.738638 | Val Loss: 8.013108\n",
      "Epoch [200/500] | Train Loss: 0.698128 | Val Loss: 8.492832\n",
      "Epoch [300/500] | Train Loss: 0.640053 | Val Loss: 9.226732\n",
      "Epoch [400/500] | Train Loss: 0.635330 | Val Loss: 9.049788\n",
      "Epoch [500/500] | Train Loss: 0.608720 | Val Loss: 9.203106\n",
      "Epoch [100/500] | Train Loss: 2.110673 | Val Loss: 2.538401\n",
      "Epoch [200/500] | Train Loss: 1.854381 | Val Loss: 2.685156\n",
      "Epoch [300/500] | Train Loss: 1.561473 | Val Loss: 2.712301\n",
      "Epoch [400/500] | Train Loss: 1.459733 | Val Loss: 2.759119\n",
      "Epoch [500/500] | Train Loss: 1.627954 | Val Loss: 2.630361\n",
      "Epoch [100/500] | Train Loss: 0.336967 | Val Loss: 0.536924\n",
      "Epoch [200/500] | Train Loss: 0.268921 | Val Loss: 0.576576\n",
      "Epoch [300/500] | Train Loss: 0.208701 | Val Loss: 0.595285\n",
      "Epoch [400/500] | Train Loss: 0.206499 | Val Loss: 0.651225\n",
      "Epoch [500/500] | Train Loss: 0.195797 | Val Loss: 0.616943\n",
      "Epoch [100/500] | Train Loss: 0.395863 | Val Loss: 0.444654\n",
      "Epoch [200/500] | Train Loss: 0.283777 | Val Loss: 0.492646\n",
      "Epoch [300/500] | Train Loss: 0.297398 | Val Loss: 0.514688\n",
      "Epoch [400/500] | Train Loss: 0.244682 | Val Loss: 0.535121\n",
      "Epoch [500/500] | Train Loss: 0.226916 | Val Loss: 0.547534\n",
      "Epoch [100/500] | Train Loss: 0.403932 | Val Loss: 1.973861\n",
      "Epoch [200/500] | Train Loss: 0.337823 | Val Loss: 2.051656\n",
      "Epoch [300/500] | Train Loss: 0.302583 | Val Loss: 1.980188\n",
      "Epoch [400/500] | Train Loss: 0.299713 | Val Loss: 1.995758\n",
      "Epoch [500/500] | Train Loss: 0.281447 | Val Loss: 2.083184\n",
      "Epoch [100/500] | Train Loss: 0.625846 | Val Loss: 9.171088\n",
      "Epoch [200/500] | Train Loss: 0.596855 | Val Loss: 9.821139\n",
      "Epoch [300/500] | Train Loss: 0.571395 | Val Loss: 9.328458\n",
      "Epoch [400/500] | Train Loss: 0.567380 | Val Loss: 9.136784\n",
      "Epoch [500/500] | Train Loss: 0.552289 | Val Loss: 9.285134\n",
      "Epoch [100/500] | Train Loss: 1.515299 | Val Loss: 2.719850\n",
      "Epoch [200/500] | Train Loss: 1.445958 | Val Loss: 2.876536\n",
      "Epoch [300/500] | Train Loss: 1.259239 | Val Loss: 2.615141\n",
      "Epoch [400/500] | Train Loss: 1.124428 | Val Loss: 2.834031\n",
      "Epoch [500/500] | Train Loss: 1.178992 | Val Loss: 2.703356\n",
      "[Year=2010] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=2.896694 Test MSE=1.466143\n",
      "Year 2010 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.424997 | Val Loss: 0.752221\n",
      "Epoch [200/500] | Train Loss: 0.349916 | Val Loss: 0.866549\n",
      "Epoch [300/500] | Train Loss: 0.274443 | Val Loss: 0.936607\n",
      "Epoch [400/500] | Train Loss: 0.222475 | Val Loss: 1.000274\n",
      "Epoch [500/500] | Train Loss: 0.209258 | Val Loss: 0.996998\n",
      "Epoch [100/500] | Train Loss: 0.548737 | Val Loss: 1.756075\n",
      "Epoch [200/500] | Train Loss: 0.460639 | Val Loss: 2.021887\n",
      "Epoch [300/500] | Train Loss: 0.431396 | Val Loss: 2.111954\n",
      "Epoch [400/500] | Train Loss: 0.399730 | Val Loss: 2.122071\n",
      "Epoch [500/500] | Train Loss: 0.387809 | Val Loss: 2.137988\n",
      "Epoch [100/500] | Train Loss: 0.899421 | Val Loss: 9.059427\n",
      "Epoch [200/500] | Train Loss: 0.829364 | Val Loss: 9.199406\n",
      "Epoch [300/500] | Train Loss: 0.772691 | Val Loss: 10.237164\n",
      "Epoch [400/500] | Train Loss: 0.782113 | Val Loss: 11.230791\n",
      "Epoch [500/500] | Train Loss: 0.664674 | Val Loss: 12.099215\n",
      "Epoch [100/500] | Train Loss: 2.692537 | Val Loss: 1.570865\n",
      "Epoch [200/500] | Train Loss: 2.302026 | Val Loss: 1.666867\n",
      "Epoch [300/500] | Train Loss: 1.964596 | Val Loss: 1.634571\n",
      "Epoch [400/500] | Train Loss: 1.713393 | Val Loss: 1.582376\n",
      "Epoch [500/500] | Train Loss: 1.688773 | Val Loss: 1.641935\n",
      "Epoch [100/500] | Train Loss: 2.535925 | Val Loss: 1.479817\n",
      "Epoch [200/500] | Train Loss: 2.167460 | Val Loss: 1.649496\n",
      "Epoch [300/500] | Train Loss: 2.001468 | Val Loss: 1.699816\n",
      "Epoch [400/500] | Train Loss: 1.702356 | Val Loss: 1.689203\n",
      "Epoch [500/500] | Train Loss: 1.699445 | Val Loss: 1.652249\n",
      "Epoch [100/500] | Train Loss: 0.235685 | Val Loss: 0.934489\n",
      "Epoch [200/500] | Train Loss: 0.149557 | Val Loss: 1.056365\n",
      "Epoch [300/500] | Train Loss: 0.143432 | Val Loss: 1.029340\n",
      "Epoch [400/500] | Train Loss: 0.135841 | Val Loss: 1.172282\n",
      "Epoch [500/500] | Train Loss: 0.133219 | Val Loss: 1.107530\n",
      "Epoch [100/500] | Train Loss: 0.387711 | Val Loss: 2.272098\n",
      "Epoch [200/500] | Train Loss: 0.304025 | Val Loss: 2.269077\n",
      "Epoch [300/500] | Train Loss: 0.264142 | Val Loss: 2.359512\n",
      "Epoch [400/500] | Train Loss: 0.258749 | Val Loss: 2.291075\n",
      "Epoch [500/500] | Train Loss: 0.247847 | Val Loss: 2.234277\n",
      "Epoch [100/500] | Train Loss: 0.665159 | Val Loss: 11.149286\n",
      "Epoch [200/500] | Train Loss: 0.524819 | Val Loss: 11.391899\n",
      "Epoch [300/500] | Train Loss: 0.488868 | Val Loss: 11.611551\n",
      "Epoch [400/500] | Train Loss: 0.502425 | Val Loss: 11.703176\n",
      "Epoch [500/500] | Train Loss: 0.430485 | Val Loss: 11.312563\n",
      "Epoch [100/500] | Train Loss: 1.859346 | Val Loss: 1.625503\n",
      "Epoch [200/500] | Train Loss: 1.633615 | Val Loss: 1.516694\n",
      "Epoch [300/500] | Train Loss: 1.357713 | Val Loss: 1.574673\n",
      "Epoch [400/500] | Train Loss: 1.229174 | Val Loss: 1.527662\n",
      "Epoch [500/500] | Train Loss: 1.379246 | Val Loss: 1.643478\n",
      "Epoch [100/500] | Train Loss: 1.801299 | Val Loss: 1.508414\n",
      "Epoch [200/500] | Train Loss: 1.671949 | Val Loss: 1.526199\n",
      "Epoch [300/500] | Train Loss: 1.636604 | Val Loss: 1.663237\n",
      "Epoch [400/500] | Train Loss: 1.436695 | Val Loss: 1.604954\n",
      "Epoch [500/500] | Train Loss: 1.267555 | Val Loss: 1.743750\n",
      "Epoch [100/500] | Train Loss: 0.435592 | Val Loss: 0.732477\n",
      "Epoch [200/500] | Train Loss: 0.431860 | Val Loss: 0.779931\n",
      "Epoch [300/500] | Train Loss: 0.395220 | Val Loss: 0.823360\n",
      "Epoch [400/500] | Train Loss: 0.334961 | Val Loss: 0.836781\n",
      "Epoch [500/500] | Train Loss: 0.314363 | Val Loss: 0.837544\n",
      "Epoch [100/500] | Train Loss: 0.568740 | Val Loss: 1.627101\n",
      "Epoch [200/500] | Train Loss: 0.517862 | Val Loss: 1.892733\n",
      "Epoch [300/500] | Train Loss: 0.486951 | Val Loss: 2.051500\n",
      "Epoch [400/500] | Train Loss: 0.475115 | Val Loss: 2.031159\n",
      "Epoch [500/500] | Train Loss: 0.464359 | Val Loss: 2.141743\n",
      "Epoch [100/500] | Train Loss: 0.884372 | Val Loss: 8.978338\n",
      "Epoch [200/500] | Train Loss: 0.847490 | Val Loss: 9.211645\n",
      "Epoch [300/500] | Train Loss: 0.827663 | Val Loss: 9.998546\n",
      "Epoch [400/500] | Train Loss: 0.770545 | Val Loss: 10.199359\n",
      "Epoch [500/500] | Train Loss: 0.808174 | Val Loss: 10.480503\n",
      "Epoch [100/500] | Train Loss: 2.814403 | Val Loss: 1.478158\n",
      "Epoch [200/500] | Train Loss: 2.729004 | Val Loss: 1.485976\n",
      "Epoch [300/500] | Train Loss: 2.403483 | Val Loss: 1.442627\n",
      "Epoch [400/500] | Train Loss: 2.278895 | Val Loss: 1.421868\n",
      "Epoch [500/500] | Train Loss: 2.154080 | Val Loss: 1.434772\n",
      "Epoch [100/500] | Train Loss: 2.491542 | Val Loss: 1.438473\n",
      "Epoch [200/500] | Train Loss: 2.425027 | Val Loss: 1.503811\n",
      "Epoch [300/500] | Train Loss: 2.358705 | Val Loss: 1.554416\n",
      "Epoch [400/500] | Train Loss: 2.160634 | Val Loss: 1.528203\n",
      "Epoch [500/500] | Train Loss: 1.986203 | Val Loss: 1.546644\n",
      "Epoch [100/500] | Train Loss: 0.375752 | Val Loss: 0.782150\n",
      "Epoch [200/500] | Train Loss: 0.275558 | Val Loss: 0.864963\n",
      "Epoch [300/500] | Train Loss: 0.251805 | Val Loss: 0.896958\n",
      "Epoch [400/500] | Train Loss: 0.228267 | Val Loss: 0.979887\n",
      "Epoch [500/500] | Train Loss: 0.211332 | Val Loss: 0.934345\n",
      "Epoch [100/500] | Train Loss: 0.512955 | Val Loss: 1.917501\n",
      "Epoch [200/500] | Train Loss: 0.435928 | Val Loss: 1.882972\n",
      "Epoch [300/500] | Train Loss: 0.387346 | Val Loss: 2.035010\n",
      "Epoch [400/500] | Train Loss: 0.397860 | Val Loss: 2.038164\n",
      "Epoch [500/500] | Train Loss: 0.375994 | Val Loss: 2.046450\n",
      "Epoch [100/500] | Train Loss: 0.814701 | Val Loss: 10.405964\n",
      "Epoch [200/500] | Train Loss: 0.744586 | Val Loss: 9.894770\n",
      "Epoch [300/500] | Train Loss: 0.641861 | Val Loss: 10.062971\n",
      "Epoch [400/500] | Train Loss: 0.615060 | Val Loss: 10.299253\n",
      "Epoch [500/500] | Train Loss: 0.605033 | Val Loss: 10.463575\n",
      "Epoch [100/500] | Train Loss: 2.085573 | Val Loss: 1.434767\n",
      "Epoch [200/500] | Train Loss: 1.965384 | Val Loss: 1.487259\n",
      "Epoch [300/500] | Train Loss: 1.664993 | Val Loss: 1.622585\n",
      "Epoch [400/500] | Train Loss: 1.743671 | Val Loss: 1.632598\n",
      "Epoch [500/500] | Train Loss: 1.579502 | Val Loss: 1.708214\n",
      "Epoch [100/500] | Train Loss: 2.017889 | Val Loss: 1.467953\n",
      "Epoch [200/500] | Train Loss: 1.925060 | Val Loss: 1.524439\n",
      "Epoch [300/500] | Train Loss: 1.734343 | Val Loss: 1.534084\n",
      "Epoch [400/500] | Train Loss: 1.693941 | Val Loss: 1.603909\n",
      "Epoch [500/500] | Train Loss: 1.548329 | Val Loss: 1.618965\n",
      "Epoch [100/500] | Train Loss: 0.399883 | Val Loss: 0.782383\n",
      "Epoch [200/500] | Train Loss: 0.295869 | Val Loss: 0.862551\n",
      "Epoch [300/500] | Train Loss: 0.279839 | Val Loss: 0.878665\n",
      "Epoch [400/500] | Train Loss: 0.249578 | Val Loss: 0.909012\n",
      "Epoch [500/500] | Train Loss: 0.203081 | Val Loss: 0.909286\n",
      "Epoch [100/500] | Train Loss: 0.562348 | Val Loss: 1.648517\n",
      "Epoch [200/500] | Train Loss: 0.486395 | Val Loss: 1.693136\n",
      "Epoch [300/500] | Train Loss: 0.403342 | Val Loss: 1.794519\n",
      "Epoch [400/500] | Train Loss: 0.352768 | Val Loss: 2.106281\n",
      "Epoch [500/500] | Train Loss: 0.328386 | Val Loss: 2.252570\n",
      "Epoch [100/500] | Train Loss: 0.850590 | Val Loss: 9.150631\n",
      "Epoch [200/500] | Train Loss: 0.727663 | Val Loss: 10.595881\n",
      "Epoch [300/500] | Train Loss: 0.693654 | Val Loss: 11.637564\n",
      "Epoch [400/500] | Train Loss: 0.616581 | Val Loss: 11.652976\n",
      "Epoch [500/500] | Train Loss: 0.595958 | Val Loss: 11.296896\n",
      "Epoch [100/500] | Train Loss: 2.656633 | Val Loss: 1.586618\n",
      "Epoch [200/500] | Train Loss: 2.096027 | Val Loss: 1.759460\n",
      "Epoch [300/500] | Train Loss: 1.718045 | Val Loss: 1.659063\n",
      "Epoch [400/500] | Train Loss: 1.705892 | Val Loss: 1.678573\n",
      "Epoch [500/500] | Train Loss: 1.502969 | Val Loss: 1.658247\n",
      "Epoch [100/500] | Train Loss: 2.468829 | Val Loss: 1.480186\n",
      "Epoch [200/500] | Train Loss: 2.170078 | Val Loss: 1.655907\n",
      "Epoch [300/500] | Train Loss: 1.676395 | Val Loss: 1.692318\n",
      "Epoch [400/500] | Train Loss: 1.609980 | Val Loss: 1.737551\n",
      "Epoch [500/500] | Train Loss: 1.409890 | Val Loss: 1.701124\n",
      "Epoch [100/500] | Train Loss: 0.187754 | Val Loss: 0.960097\n",
      "Epoch [200/500] | Train Loss: 0.138106 | Val Loss: 0.993485\n",
      "Epoch [300/500] | Train Loss: 0.107862 | Val Loss: 0.922386\n",
      "Epoch [400/500] | Train Loss: 0.111532 | Val Loss: 0.915702\n",
      "Epoch [500/500] | Train Loss: 0.093193 | Val Loss: 0.942515\n",
      "Epoch [100/500] | Train Loss: 0.367883 | Val Loss: 2.256338\n",
      "Epoch [200/500] | Train Loss: 0.287336 | Val Loss: 2.361726\n",
      "Epoch [300/500] | Train Loss: 0.257849 | Val Loss: 2.521513\n",
      "Epoch [400/500] | Train Loss: 0.229566 | Val Loss: 2.301534\n",
      "Epoch [500/500] | Train Loss: 0.202512 | Val Loss: 2.328067\n",
      "Epoch [100/500] | Train Loss: 0.677736 | Val Loss: 9.882397\n",
      "Epoch [200/500] | Train Loss: 0.568229 | Val Loss: 10.294459\n",
      "Epoch [300/500] | Train Loss: 0.514234 | Val Loss: 9.934430\n",
      "Epoch [400/500] | Train Loss: 0.452730 | Val Loss: 10.200215\n",
      "Epoch [500/500] | Train Loss: 0.500169 | Val Loss: 9.842660\n",
      "Epoch [100/500] | Train Loss: 1.601287 | Val Loss: 1.610623\n",
      "Epoch [200/500] | Train Loss: 1.306403 | Val Loss: 1.736344\n",
      "Epoch [300/500] | Train Loss: 1.329835 | Val Loss: 1.872942\n",
      "Epoch [400/500] | Train Loss: 1.198509 | Val Loss: 1.899633\n",
      "Epoch [500/500] | Train Loss: 1.468641 | Val Loss: 1.903442\n",
      "Epoch [100/500] | Train Loss: 1.768438 | Val Loss: 1.585961\n",
      "Epoch [200/500] | Train Loss: 1.552193 | Val Loss: 1.781950\n",
      "Epoch [300/500] | Train Loss: 1.452343 | Val Loss: 1.606115\n",
      "Epoch [400/500] | Train Loss: 1.202250 | Val Loss: 1.620519\n",
      "Epoch [500/500] | Train Loss: 1.230536 | Val Loss: 1.724725\n",
      "Epoch [100/500] | Train Loss: 0.461197 | Val Loss: 0.722883\n",
      "Epoch [200/500] | Train Loss: 0.399482 | Val Loss: 0.770950\n",
      "Epoch [300/500] | Train Loss: 0.321814 | Val Loss: 0.877516\n",
      "Epoch [400/500] | Train Loss: 0.323956 | Val Loss: 0.971315\n",
      "Epoch [500/500] | Train Loss: 0.287144 | Val Loss: 1.014280\n",
      "Epoch [100/500] | Train Loss: 0.575340 | Val Loss: 1.588775\n",
      "Epoch [200/500] | Train Loss: 0.513537 | Val Loss: 1.877899\n",
      "Epoch [300/500] | Train Loss: 0.494323 | Val Loss: 1.996734\n",
      "Epoch [400/500] | Train Loss: 0.464376 | Val Loss: 2.108819\n",
      "Epoch [500/500] | Train Loss: 0.411791 | Val Loss: 2.206323\n",
      "Epoch [100/500] | Train Loss: 0.894849 | Val Loss: 8.951653\n",
      "Epoch [200/500] | Train Loss: 0.818087 | Val Loss: 9.364919\n",
      "Epoch [300/500] | Train Loss: 0.764607 | Val Loss: 9.375272\n",
      "Epoch [400/500] | Train Loss: 0.718352 | Val Loss: 9.600513\n",
      "Epoch [500/500] | Train Loss: 0.729117 | Val Loss: 9.699893\n",
      "Epoch [100/500] | Train Loss: 2.693050 | Val Loss: 1.539738\n",
      "Epoch [200/500] | Train Loss: 2.533115 | Val Loss: 1.608361\n",
      "Epoch [300/500] | Train Loss: 2.331292 | Val Loss: 1.565649\n",
      "Epoch [400/500] | Train Loss: 2.234700 | Val Loss: 1.569615\n",
      "Epoch [500/500] | Train Loss: 2.136403 | Val Loss: 1.518069\n",
      "Epoch [100/500] | Train Loss: 2.549359 | Val Loss: 1.449537\n",
      "Epoch [200/500] | Train Loss: 2.395904 | Val Loss: 1.452838\n",
      "Epoch [300/500] | Train Loss: 2.222305 | Val Loss: 1.464646\n",
      "Epoch [400/500] | Train Loss: 2.100275 | Val Loss: 1.487179\n",
      "Epoch [500/500] | Train Loss: 2.004639 | Val Loss: 1.519812\n",
      "Epoch [100/500] | Train Loss: 0.309329 | Val Loss: 0.794174\n",
      "Epoch [200/500] | Train Loss: 0.236548 | Val Loss: 0.871191\n",
      "Epoch [300/500] | Train Loss: 0.184206 | Val Loss: 0.890019\n",
      "Epoch [400/500] | Train Loss: 0.147255 | Val Loss: 0.866310\n",
      "Epoch [500/500] | Train Loss: 0.159027 | Val Loss: 0.908571\n",
      "Epoch [100/500] | Train Loss: 0.424660 | Val Loss: 2.010504\n",
      "Epoch [200/500] | Train Loss: 0.329680 | Val Loss: 1.984195\n",
      "Epoch [300/500] | Train Loss: 0.283976 | Val Loss: 1.958690\n",
      "Epoch [400/500] | Train Loss: 0.276488 | Val Loss: 1.945806\n",
      "Epoch [500/500] | Train Loss: 0.258003 | Val Loss: 1.836471\n",
      "Epoch [100/500] | Train Loss: 0.757825 | Val Loss: 9.715089\n",
      "Epoch [200/500] | Train Loss: 0.692587 | Val Loss: 10.659471\n",
      "Epoch [300/500] | Train Loss: 0.608643 | Val Loss: 10.265052\n",
      "Epoch [400/500] | Train Loss: 0.535724 | Val Loss: 10.427744\n",
      "Epoch [500/500] | Train Loss: 0.577855 | Val Loss: 10.688960\n",
      "Epoch [100/500] | Train Loss: 2.068094 | Val Loss: 1.565201\n",
      "Epoch [200/500] | Train Loss: 1.830205 | Val Loss: 1.649330\n",
      "Epoch [300/500] | Train Loss: 1.678998 | Val Loss: 1.832361\n",
      "Epoch [400/500] | Train Loss: 1.535106 | Val Loss: 1.851993\n",
      "Epoch [500/500] | Train Loss: 1.673245 | Val Loss: 1.774916\n",
      "Epoch [100/500] | Train Loss: 1.940244 | Val Loss: 1.528756\n",
      "Epoch [200/500] | Train Loss: 1.817920 | Val Loss: 1.675352\n",
      "Epoch [300/500] | Train Loss: 1.745336 | Val Loss: 1.611571\n",
      "Epoch [400/500] | Train Loss: 1.662456 | Val Loss: 1.667685\n",
      "Epoch [500/500] | Train Loss: 1.480165 | Val Loss: 1.731059\n",
      "[Year=2011] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=3.191675 Test MSE=2.368713\n",
      "Year 2011 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.711853 | Val Loss: 1.806264\n",
      "Epoch [200/500] | Train Loss: 0.517926 | Val Loss: 2.183179\n",
      "Epoch [300/500] | Train Loss: 0.455944 | Val Loss: 2.190573\n",
      "Epoch [400/500] | Train Loss: 0.404974 | Val Loss: 2.214634\n",
      "Epoch [500/500] | Train Loss: 0.416643 | Val Loss: 2.330934\n",
      "Epoch [100/500] | Train Loss: 1.181465 | Val Loss: 9.028236\n",
      "Epoch [200/500] | Train Loss: 1.157710 | Val Loss: 9.092074\n",
      "Epoch [300/500] | Train Loss: 0.981119 | Val Loss: 9.466155\n",
      "Epoch [400/500] | Train Loss: 0.938959 | Val Loss: 9.770942\n",
      "Epoch [500/500] | Train Loss: 0.916263 | Val Loss: 10.128812\n",
      "Epoch [100/500] | Train Loss: 3.538761 | Val Loss: 1.184113\n",
      "Epoch [200/500] | Train Loss: 2.880697 | Val Loss: 1.254208\n",
      "Epoch [300/500] | Train Loss: 2.634496 | Val Loss: 1.265263\n",
      "Epoch [400/500] | Train Loss: 2.532486 | Val Loss: 1.244986\n",
      "Epoch [500/500] | Train Loss: 2.270675 | Val Loss: 1.284615\n",
      "Epoch [100/500] | Train Loss: 2.952344 | Val Loss: 1.487420\n",
      "Epoch [200/500] | Train Loss: 2.705564 | Val Loss: 1.580566\n",
      "Epoch [300/500] | Train Loss: 2.476884 | Val Loss: 1.673687\n",
      "Epoch [400/500] | Train Loss: 2.053516 | Val Loss: 1.720140\n",
      "Epoch [500/500] | Train Loss: 1.960009 | Val Loss: 1.703049\n",
      "Epoch [100/500] | Train Loss: 2.754795 | Val Loss: 2.757042\n",
      "Epoch [200/500] | Train Loss: 2.454216 | Val Loss: 2.885033\n",
      "Epoch [300/500] | Train Loss: 2.138653 | Val Loss: 2.984038\n",
      "Epoch [400/500] | Train Loss: 1.878841 | Val Loss: 3.061557\n",
      "Epoch [500/500] | Train Loss: 1.867824 | Val Loss: 3.139911\n",
      "Epoch [100/500] | Train Loss: 0.480796 | Val Loss: 2.346235\n",
      "Epoch [200/500] | Train Loss: 0.315994 | Val Loss: 2.274832\n",
      "Epoch [300/500] | Train Loss: 0.278581 | Val Loss: 2.174225\n",
      "Epoch [400/500] | Train Loss: 0.262120 | Val Loss: 2.247071\n",
      "Epoch [500/500] | Train Loss: 0.238508 | Val Loss: 2.357932\n",
      "Epoch [100/500] | Train Loss: 0.980891 | Val Loss: 10.538636\n",
      "Epoch [200/500] | Train Loss: 0.723434 | Val Loss: 11.382149\n",
      "Epoch [300/500] | Train Loss: 0.620787 | Val Loss: 11.620362\n",
      "Epoch [400/500] | Train Loss: 0.543614 | Val Loss: 11.497647\n",
      "Epoch [500/500] | Train Loss: 0.516283 | Val Loss: 11.677809\n",
      "Epoch [100/500] | Train Loss: 2.454320 | Val Loss: 1.391180\n",
      "Epoch [200/500] | Train Loss: 1.765571 | Val Loss: 1.300911\n",
      "Epoch [300/500] | Train Loss: 1.958102 | Val Loss: 1.344755\n",
      "Epoch [400/500] | Train Loss: 1.804373 | Val Loss: 1.459308\n",
      "Epoch [500/500] | Train Loss: 1.736716 | Val Loss: 1.397878\n",
      "Epoch [100/500] | Train Loss: 2.165234 | Val Loss: 1.617109\n",
      "Epoch [200/500] | Train Loss: 1.961680 | Val Loss: 1.776831\n",
      "Epoch [300/500] | Train Loss: 1.723385 | Val Loss: 1.811161\n",
      "Epoch [400/500] | Train Loss: 1.488553 | Val Loss: 1.846183\n",
      "Epoch [500/500] | Train Loss: 1.674693 | Val Loss: 1.938050\n",
      "Epoch [100/500] | Train Loss: 1.876820 | Val Loss: 3.627355\n",
      "Epoch [200/500] | Train Loss: 1.678354 | Val Loss: 3.301431\n",
      "Epoch [300/500] | Train Loss: 1.680856 | Val Loss: 3.520543\n",
      "Epoch [400/500] | Train Loss: 1.404656 | Val Loss: 3.188632\n",
      "Epoch [500/500] | Train Loss: 1.438952 | Val Loss: 3.261369\n",
      "Epoch [100/500] | Train Loss: 0.729239 | Val Loss: 1.802737\n",
      "Epoch [200/500] | Train Loss: 0.664237 | Val Loss: 1.867099\n",
      "Epoch [300/500] | Train Loss: 0.677483 | Val Loss: 1.931017\n",
      "Epoch [400/500] | Train Loss: 0.587318 | Val Loss: 1.959967\n",
      "Epoch [500/500] | Train Loss: 0.549319 | Val Loss: 2.046597\n",
      "Epoch [100/500] | Train Loss: 1.234443 | Val Loss: 9.083416\n",
      "Epoch [200/500] | Train Loss: 1.153431 | Val Loss: 9.442554\n",
      "Epoch [300/500] | Train Loss: 1.097921 | Val Loss: 9.534787\n",
      "Epoch [400/500] | Train Loss: 1.055044 | Val Loss: 9.643112\n",
      "Epoch [500/500] | Train Loss: 1.023350 | Val Loss: 9.699429\n",
      "Epoch [100/500] | Train Loss: 3.617328 | Val Loss: 1.182192\n",
      "Epoch [200/500] | Train Loss: 3.461288 | Val Loss: 1.138539\n",
      "Epoch [300/500] | Train Loss: 3.164031 | Val Loss: 1.147962\n",
      "Epoch [400/500] | Train Loss: 2.802858 | Val Loss: 1.130795\n",
      "Epoch [500/500] | Train Loss: 2.582473 | Val Loss: 1.159417\n",
      "Epoch [100/500] | Train Loss: 3.068995 | Val Loss: 1.430683\n",
      "Epoch [200/500] | Train Loss: 3.008151 | Val Loss: 1.464452\n",
      "Epoch [300/500] | Train Loss: 2.574954 | Val Loss: 1.502443\n",
      "Epoch [400/500] | Train Loss: 2.513783 | Val Loss: 1.571980\n",
      "Epoch [500/500] | Train Loss: 2.517358 | Val Loss: 1.556101\n",
      "Epoch [100/500] | Train Loss: 2.727820 | Val Loss: 2.695917\n",
      "Epoch [200/500] | Train Loss: 2.695651 | Val Loss: 2.772719\n",
      "Epoch [300/500] | Train Loss: 2.624400 | Val Loss: 2.863859\n",
      "Epoch [400/500] | Train Loss: 2.277257 | Val Loss: 2.859153\n",
      "Epoch [500/500] | Train Loss: 2.307795 | Val Loss: 2.790452\n",
      "Epoch [100/500] | Train Loss: 0.608771 | Val Loss: 2.121607\n",
      "Epoch [200/500] | Train Loss: 0.449829 | Val Loss: 2.150584\n",
      "Epoch [300/500] | Train Loss: 0.463498 | Val Loss: 2.424648\n",
      "Epoch [400/500] | Train Loss: 0.384621 | Val Loss: 2.355275\n",
      "Epoch [500/500] | Train Loss: 0.437244 | Val Loss: 2.214063\n",
      "Epoch [100/500] | Train Loss: 1.010804 | Val Loss: 9.873141\n",
      "Epoch [200/500] | Train Loss: 0.891439 | Val Loss: 10.135598\n",
      "Epoch [300/500] | Train Loss: 0.810771 | Val Loss: 9.757472\n",
      "Epoch [400/500] | Train Loss: 0.824057 | Val Loss: 9.715002\n",
      "Epoch [500/500] | Train Loss: 0.799148 | Val Loss: 9.655056\n",
      "Epoch [100/500] | Train Loss: 2.902916 | Val Loss: 1.204114\n",
      "Epoch [200/500] | Train Loss: 2.793647 | Val Loss: 1.218235\n",
      "Epoch [300/500] | Train Loss: 2.362739 | Val Loss: 1.219658\n",
      "Epoch [400/500] | Train Loss: 2.233003 | Val Loss: 1.191496\n",
      "Epoch [500/500] | Train Loss: 2.354769 | Val Loss: 1.230330\n",
      "Epoch [100/500] | Train Loss: 2.369708 | Val Loss: 1.503760\n",
      "Epoch [200/500] | Train Loss: 2.312012 | Val Loss: 1.505232\n",
      "Epoch [300/500] | Train Loss: 2.114059 | Val Loss: 1.528824\n",
      "Epoch [400/500] | Train Loss: 2.075553 | Val Loss: 1.590548\n",
      "Epoch [500/500] | Train Loss: 2.160229 | Val Loss: 1.522757\n",
      "Epoch [100/500] | Train Loss: 2.197850 | Val Loss: 2.922475\n",
      "Epoch [200/500] | Train Loss: 2.082849 | Val Loss: 2.910067\n",
      "Epoch [300/500] | Train Loss: 1.974707 | Val Loss: 2.834820\n",
      "Epoch [400/500] | Train Loss: 2.075051 | Val Loss: 3.027038\n",
      "Epoch [500/500] | Train Loss: 1.910288 | Val Loss: 2.910330\n",
      "Epoch [100/500] | Train Loss: 0.697217 | Val Loss: 1.793940\n",
      "Epoch [200/500] | Train Loss: 0.583427 | Val Loss: 1.851983\n",
      "Epoch [300/500] | Train Loss: 0.429286 | Val Loss: 2.120198\n",
      "Epoch [400/500] | Train Loss: 0.405109 | Val Loss: 2.130012\n",
      "Epoch [500/500] | Train Loss: 0.330902 | Val Loss: 2.212071\n",
      "Epoch [100/500] | Train Loss: 1.173867 | Val Loss: 9.363242\n",
      "Epoch [200/500] | Train Loss: 0.952697 | Val Loss: 9.829288\n",
      "Epoch [300/500] | Train Loss: 0.934758 | Val Loss: 10.224327\n",
      "Epoch [400/500] | Train Loss: 0.696633 | Val Loss: 10.806345\n",
      "Epoch [500/500] | Train Loss: 0.763641 | Val Loss: 11.159019\n",
      "Epoch [100/500] | Train Loss: 3.546887 | Val Loss: 1.204555\n",
      "Epoch [200/500] | Train Loss: 2.840507 | Val Loss: 1.278288\n",
      "Epoch [300/500] | Train Loss: 2.446439 | Val Loss: 1.332583\n",
      "Epoch [400/500] | Train Loss: 1.964313 | Val Loss: 1.387267\n",
      "Epoch [500/500] | Train Loss: 1.987565 | Val Loss: 1.407938\n",
      "Epoch [100/500] | Train Loss: 2.944896 | Val Loss: 1.503946\n",
      "Epoch [200/500] | Train Loss: 2.264285 | Val Loss: 1.755292\n",
      "Epoch [300/500] | Train Loss: 2.049876 | Val Loss: 1.806367\n",
      "Epoch [400/500] | Train Loss: 1.869274 | Val Loss: 1.795922\n",
      "Epoch [500/500] | Train Loss: 1.785478 | Val Loss: 1.802226\n",
      "Epoch [100/500] | Train Loss: 2.582763 | Val Loss: 2.826312\n",
      "Epoch [200/500] | Train Loss: 2.183348 | Val Loss: 3.108003\n",
      "Epoch [300/500] | Train Loss: 1.907501 | Val Loss: 3.200552\n",
      "Epoch [400/500] | Train Loss: 1.811312 | Val Loss: 3.219140\n",
      "Epoch [500/500] | Train Loss: 1.669060 | Val Loss: 3.129310\n",
      "Epoch [100/500] | Train Loss: 0.378057 | Val Loss: 2.394067\n",
      "Epoch [200/500] | Train Loss: 0.214231 | Val Loss: 2.642821\n",
      "Epoch [300/500] | Train Loss: 0.214544 | Val Loss: 2.763018\n",
      "Epoch [400/500] | Train Loss: 0.196868 | Val Loss: 2.399478\n",
      "Epoch [500/500] | Train Loss: 0.161375 | Val Loss: 2.545364\n",
      "Epoch [100/500] | Train Loss: 0.891938 | Val Loss: 10.752316\n",
      "Epoch [200/500] | Train Loss: 0.683670 | Val Loss: 10.765547\n",
      "Epoch [300/500] | Train Loss: 0.536667 | Val Loss: 10.350288\n",
      "Epoch [400/500] | Train Loss: 0.413797 | Val Loss: 10.385101\n",
      "Epoch [500/500] | Train Loss: 0.401250 | Val Loss: 10.504142\n",
      "Epoch [100/500] | Train Loss: 2.068257 | Val Loss: 1.382852\n",
      "Epoch [200/500] | Train Loss: 1.687467 | Val Loss: 1.432787\n",
      "Epoch [300/500] | Train Loss: 1.603124 | Val Loss: 1.563227\n",
      "Epoch [400/500] | Train Loss: 1.357468 | Val Loss: 1.527128\n",
      "Epoch [500/500] | Train Loss: 1.582869 | Val Loss: 1.583719\n",
      "Epoch [100/500] | Train Loss: 2.062897 | Val Loss: 1.700228\n",
      "Epoch [200/500] | Train Loss: 1.537086 | Val Loss: 1.684484\n",
      "Epoch [300/500] | Train Loss: 1.533951 | Val Loss: 1.748545\n",
      "Epoch [400/500] | Train Loss: 1.370849 | Val Loss: 1.880176\n",
      "Epoch [500/500] | Train Loss: 1.316386 | Val Loss: 1.818702\n",
      "Epoch [100/500] | Train Loss: 2.330821 | Val Loss: 2.806726\n",
      "Epoch [200/500] | Train Loss: 2.419293 | Val Loss: 2.700207\n",
      "Epoch [300/500] | Train Loss: 2.040210 | Val Loss: 2.891050\n",
      "Epoch [400/500] | Train Loss: 1.840292 | Val Loss: 2.878201\n",
      "Epoch [500/500] | Train Loss: 1.759753 | Val Loss: 2.905750\n",
      "Epoch [100/500] | Train Loss: 0.729335 | Val Loss: 1.837031\n",
      "Epoch [200/500] | Train Loss: 0.617304 | Val Loss: 1.998274\n",
      "Epoch [300/500] | Train Loss: 0.506043 | Val Loss: 2.120124\n",
      "Epoch [400/500] | Train Loss: 0.466425 | Val Loss: 2.251409\n",
      "Epoch [500/500] | Train Loss: 0.379368 | Val Loss: 2.278254\n",
      "Epoch [100/500] | Train Loss: 1.229337 | Val Loss: 9.025923\n",
      "Epoch [200/500] | Train Loss: 1.168579 | Val Loss: 9.101145\n",
      "Epoch [300/500] | Train Loss: 1.033986 | Val Loss: 9.569524\n",
      "Epoch [400/500] | Train Loss: 1.010113 | Val Loss: 9.891224\n",
      "Epoch [500/500] | Train Loss: 0.919288 | Val Loss: 9.885068\n",
      "Epoch [100/500] | Train Loss: 3.655047 | Val Loss: 1.094006\n",
      "Epoch [200/500] | Train Loss: 3.495688 | Val Loss: 1.208341\n",
      "Epoch [300/500] | Train Loss: 2.971264 | Val Loss: 1.208592\n",
      "Epoch [400/500] | Train Loss: 2.585823 | Val Loss: 1.172327\n",
      "Epoch [500/500] | Train Loss: 2.570316 | Val Loss: 1.192111\n",
      "Epoch [100/500] | Train Loss: 2.961785 | Val Loss: 1.456282\n",
      "Epoch [200/500] | Train Loss: 2.767156 | Val Loss: 1.535273\n",
      "Epoch [300/500] | Train Loss: 2.576621 | Val Loss: 1.593939\n",
      "Epoch [400/500] | Train Loss: 2.480910 | Val Loss: 1.659050\n",
      "Epoch [500/500] | Train Loss: 2.162539 | Val Loss: 1.667088\n",
      "Epoch [100/500] | Train Loss: 2.722312 | Val Loss: 2.735273\n",
      "Epoch [200/500] | Train Loss: 2.587534 | Val Loss: 2.913295\n",
      "Epoch [300/500] | Train Loss: 2.298399 | Val Loss: 3.010453\n",
      "Epoch [400/500] | Train Loss: 2.073137 | Val Loss: 3.007074\n",
      "Epoch [500/500] | Train Loss: 1.941405 | Val Loss: 2.952520\n",
      "Epoch [100/500] | Train Loss: 0.519907 | Val Loss: 2.124810\n",
      "Epoch [200/500] | Train Loss: 0.394544 | Val Loss: 2.182099\n",
      "Epoch [300/500] | Train Loss: 0.406150 | Val Loss: 2.231701\n",
      "Epoch [400/500] | Train Loss: 0.314484 | Val Loss: 2.252201\n",
      "Epoch [500/500] | Train Loss: 0.264960 | Val Loss: 2.419251\n",
      "Epoch [100/500] | Train Loss: 0.981710 | Val Loss: 9.806791\n",
      "Epoch [200/500] | Train Loss: 0.860192 | Val Loss: 10.037423\n",
      "Epoch [300/500] | Train Loss: 0.765982 | Val Loss: 10.694032\n",
      "Epoch [400/500] | Train Loss: 0.640002 | Val Loss: 10.839535\n",
      "Epoch [500/500] | Train Loss: 0.687055 | Val Loss: 10.714142\n",
      "Epoch [100/500] | Train Loss: 2.885842 | Val Loss: 1.176078\n",
      "Epoch [200/500] | Train Loss: 2.143029 | Val Loss: 1.277278\n",
      "Epoch [300/500] | Train Loss: 2.114472 | Val Loss: 1.403338\n",
      "Epoch [400/500] | Train Loss: 2.208773 | Val Loss: 1.293019\n",
      "Epoch [500/500] | Train Loss: 2.006396 | Val Loss: 1.349812\n",
      "Epoch [100/500] | Train Loss: 2.275372 | Val Loss: 1.575593\n",
      "Epoch [200/500] | Train Loss: 2.125735 | Val Loss: 1.522337\n",
      "Epoch [300/500] | Train Loss: 1.878068 | Val Loss: 1.676088\n",
      "Epoch [400/500] | Train Loss: 1.916124 | Val Loss: 1.765158\n",
      "Epoch [500/500] | Train Loss: 1.705845 | Val Loss: 1.717683\n",
      "Epoch [100/500] | Train Loss: 2.153345 | Val Loss: 2.797862\n",
      "Epoch [200/500] | Train Loss: 1.947404 | Val Loss: 2.759718\n",
      "Epoch [300/500] | Train Loss: 1.790239 | Val Loss: 3.003379\n",
      "Epoch [400/500] | Train Loss: 1.725372 | Val Loss: 3.131284\n",
      "Epoch [500/500] | Train Loss: 1.916837 | Val Loss: 3.070400\n",
      "[Year=2012] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=3.450399 Test MSE=0.695070\n",
      "Year 2012 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 3.761082 | Val Loss: 6.272243\n",
      "Epoch [200/500] | Train Loss: 2.887331 | Val Loss: 7.245028\n",
      "Epoch [300/500] | Train Loss: 2.209034 | Val Loss: 7.711102\n",
      "Epoch [400/500] | Train Loss: 2.232346 | Val Loss: 7.992478\n",
      "Epoch [500/500] | Train Loss: 2.004361 | Val Loss: 8.489436\n",
      "Epoch [100/500] | Train Loss: 4.997883 | Val Loss: 1.521212\n",
      "Epoch [200/500] | Train Loss: 4.308437 | Val Loss: 1.619509\n",
      "Epoch [300/500] | Train Loss: 3.457068 | Val Loss: 1.714572\n",
      "Epoch [400/500] | Train Loss: 3.460435 | Val Loss: 1.780507\n",
      "Epoch [500/500] | Train Loss: 3.045475 | Val Loss: 1.797313\n",
      "Epoch [100/500] | Train Loss: 3.715572 | Val Loss: 0.897785\n",
      "Epoch [200/500] | Train Loss: 3.266349 | Val Loss: 0.881112\n",
      "Epoch [300/500] | Train Loss: 2.889682 | Val Loss: 0.893371\n",
      "Epoch [400/500] | Train Loss: 2.408167 | Val Loss: 0.914488\n",
      "Epoch [500/500] | Train Loss: 2.352918 | Val Loss: 0.952622\n",
      "Epoch [100/500] | Train Loss: 3.140915 | Val Loss: 2.793443\n",
      "Epoch [200/500] | Train Loss: 2.704023 | Val Loss: 2.845348\n",
      "Epoch [300/500] | Train Loss: 2.356913 | Val Loss: 2.940123\n",
      "Epoch [400/500] | Train Loss: 2.220261 | Val Loss: 3.069407\n",
      "Epoch [500/500] | Train Loss: 2.089594 | Val Loss: 3.166703\n",
      "Epoch [100/500] | Train Loss: 3.069852 | Val Loss: 0.755058\n",
      "Epoch [200/500] | Train Loss: 2.906046 | Val Loss: 0.778116\n",
      "Epoch [300/500] | Train Loss: 2.492347 | Val Loss: 0.767618\n",
      "Epoch [400/500] | Train Loss: 2.391522 | Val Loss: 0.767971\n",
      "Epoch [500/500] | Train Loss: 2.404942 | Val Loss: 0.776828\n",
      "Epoch [100/500] | Train Loss: 2.131525 | Val Loss: 7.952600\n",
      "Epoch [200/500] | Train Loss: 1.405791 | Val Loss: 9.285182\n",
      "Epoch [300/500] | Train Loss: 1.270157 | Val Loss: 9.139743\n",
      "Epoch [400/500] | Train Loss: 1.345058 | Val Loss: 9.419178\n",
      "Epoch [500/500] | Train Loss: 0.936703 | Val Loss: 9.490271\n",
      "Epoch [100/500] | Train Loss: 2.991854 | Val Loss: 1.799355\n",
      "Epoch [200/500] | Train Loss: 2.445453 | Val Loss: 1.880145\n",
      "Epoch [300/500] | Train Loss: 2.338507 | Val Loss: 2.203817\n",
      "Epoch [400/500] | Train Loss: 2.089433 | Val Loss: 1.987023\n",
      "Epoch [500/500] | Train Loss: 2.085866 | Val Loss: 2.289346\n",
      "Epoch [100/500] | Train Loss: 2.510185 | Val Loss: 0.900191\n",
      "Epoch [200/500] | Train Loss: 2.183042 | Val Loss: 0.999718\n",
      "Epoch [300/500] | Train Loss: 2.109357 | Val Loss: 0.965220\n",
      "Epoch [400/500] | Train Loss: 1.790273 | Val Loss: 0.925871\n",
      "Epoch [500/500] | Train Loss: 1.918782 | Val Loss: 1.135099\n",
      "Epoch [100/500] | Train Loss: 2.398826 | Val Loss: 3.037410\n",
      "Epoch [200/500] | Train Loss: 1.828226 | Val Loss: 3.277534\n",
      "Epoch [300/500] | Train Loss: 1.809652 | Val Loss: 3.451375\n",
      "Epoch [400/500] | Train Loss: 1.488453 | Val Loss: 3.491014\n",
      "Epoch [500/500] | Train Loss: 1.558336 | Val Loss: 3.928397\n",
      "Epoch [100/500] | Train Loss: 2.318501 | Val Loss: 0.797881\n",
      "Epoch [200/500] | Train Loss: 1.912930 | Val Loss: 0.843711\n",
      "Epoch [300/500] | Train Loss: 1.823216 | Val Loss: 0.872627\n",
      "Epoch [400/500] | Train Loss: 1.734111 | Val Loss: 0.934314\n",
      "Epoch [500/500] | Train Loss: 1.847778 | Val Loss: 0.912693\n",
      "Epoch [100/500] | Train Loss: 4.668487 | Val Loss: 5.938212\n",
      "Epoch [200/500] | Train Loss: 3.776715 | Val Loss: 6.497152\n",
      "Epoch [300/500] | Train Loss: 3.103672 | Val Loss: 7.310245\n",
      "Epoch [400/500] | Train Loss: 2.928221 | Val Loss: 7.381607\n",
      "Epoch [500/500] | Train Loss: 2.457222 | Val Loss: 7.040312\n",
      "Epoch [100/500] | Train Loss: 5.308802 | Val Loss: 1.449618\n",
      "Epoch [200/500] | Train Loss: 5.105881 | Val Loss: 1.558521\n",
      "Epoch [300/500] | Train Loss: 4.595358 | Val Loss: 1.633671\n",
      "Epoch [400/500] | Train Loss: 4.268192 | Val Loss: 1.713573\n",
      "Epoch [500/500] | Train Loss: 3.720348 | Val Loss: 1.712950\n",
      "Epoch [100/500] | Train Loss: 3.857721 | Val Loss: 0.899772\n",
      "Epoch [200/500] | Train Loss: 3.622987 | Val Loss: 0.907083\n",
      "Epoch [300/500] | Train Loss: 3.480592 | Val Loss: 0.916773\n",
      "Epoch [400/500] | Train Loss: 3.480592 | Val Loss: 0.911736\n",
      "Epoch [500/500] | Train Loss: 3.148615 | Val Loss: 0.913468\n",
      "Epoch [100/500] | Train Loss: 3.067761 | Val Loss: 2.792345\n",
      "Epoch [200/500] | Train Loss: 2.845860 | Val Loss: 2.882888\n",
      "Epoch [300/500] | Train Loss: 2.640525 | Val Loss: 2.835584\n",
      "Epoch [400/500] | Train Loss: 2.589354 | Val Loss: 2.809992\n",
      "Epoch [500/500] | Train Loss: 2.508957 | Val Loss: 2.844040\n",
      "Epoch [100/500] | Train Loss: 3.077543 | Val Loss: 0.775345\n",
      "Epoch [200/500] | Train Loss: 3.008353 | Val Loss: 0.770070\n",
      "Epoch [300/500] | Train Loss: 2.898381 | Val Loss: 0.758520\n",
      "Epoch [400/500] | Train Loss: 2.697231 | Val Loss: 0.765047\n",
      "Epoch [500/500] | Train Loss: 2.744298 | Val Loss: 0.771724\n",
      "Epoch [100/500] | Train Loss: 3.131831 | Val Loss: 6.694236\n",
      "Epoch [200/500] | Train Loss: 2.213627 | Val Loss: 7.220370\n",
      "Epoch [300/500] | Train Loss: 1.903809 | Val Loss: 7.681724\n",
      "Epoch [400/500] | Train Loss: 2.419195 | Val Loss: 7.496871\n",
      "Epoch [500/500] | Train Loss: 1.999810 | Val Loss: 7.633755\n",
      "Epoch [100/500] | Train Loss: 3.834135 | Val Loss: 1.598625\n",
      "Epoch [200/500] | Train Loss: 3.688997 | Val Loss: 1.675479\n",
      "Epoch [300/500] | Train Loss: 3.163983 | Val Loss: 1.666618\n",
      "Epoch [400/500] | Train Loss: 2.761759 | Val Loss: 1.801942\n",
      "Epoch [500/500] | Train Loss: 2.925799 | Val Loss: 1.781780\n",
      "Epoch [100/500] | Train Loss: 2.873850 | Val Loss: 0.883640\n",
      "Epoch [200/500] | Train Loss: 2.876353 | Val Loss: 0.971856\n",
      "Epoch [300/500] | Train Loss: 2.515020 | Val Loss: 0.971305\n",
      "Epoch [400/500] | Train Loss: 2.548031 | Val Loss: 0.984495\n",
      "Epoch [500/500] | Train Loss: 2.420100 | Val Loss: 0.924071\n",
      "Epoch [100/500] | Train Loss: 2.867857 | Val Loss: 3.028008\n",
      "Epoch [200/500] | Train Loss: 2.422355 | Val Loss: 3.192614\n",
      "Epoch [300/500] | Train Loss: 2.428310 | Val Loss: 3.092983\n",
      "Epoch [400/500] | Train Loss: 2.344085 | Val Loss: 3.181007\n",
      "Epoch [500/500] | Train Loss: 2.036949 | Val Loss: 3.163303\n",
      "Epoch [100/500] | Train Loss: 2.514499 | Val Loss: 0.755609\n",
      "Epoch [200/500] | Train Loss: 2.416785 | Val Loss: 0.768669\n",
      "Epoch [300/500] | Train Loss: 2.205493 | Val Loss: 0.753556\n",
      "Epoch [400/500] | Train Loss: 2.216007 | Val Loss: 0.797309\n",
      "Epoch [500/500] | Train Loss: 2.386414 | Val Loss: 0.800164\n",
      "Epoch [100/500] | Train Loss: 3.564246 | Val Loss: 6.865601\n",
      "Epoch [200/500] | Train Loss: 2.716133 | Val Loss: 8.165085\n",
      "Epoch [300/500] | Train Loss: 1.777719 | Val Loss: 8.277568\n",
      "Epoch [400/500] | Train Loss: 1.613603 | Val Loss: 8.504390\n",
      "Epoch [500/500] | Train Loss: 1.609943 | Val Loss: 8.882881\n",
      "Epoch [100/500] | Train Loss: 4.850942 | Val Loss: 1.607387\n",
      "Epoch [200/500] | Train Loss: 3.622705 | Val Loss: 1.967185\n",
      "Epoch [300/500] | Train Loss: 3.130975 | Val Loss: 2.046145\n",
      "Epoch [400/500] | Train Loss: 2.748571 | Val Loss: 2.003901\n",
      "Epoch [500/500] | Train Loss: 3.398188 | Val Loss: 2.028937\n",
      "Epoch [100/500] | Train Loss: 3.749819 | Val Loss: 0.928210\n",
      "Epoch [200/500] | Train Loss: 3.114144 | Val Loss: 0.968135\n",
      "Epoch [300/500] | Train Loss: 2.266838 | Val Loss: 0.954962\n",
      "Epoch [400/500] | Train Loss: 2.403731 | Val Loss: 0.981187\n",
      "Epoch [500/500] | Train Loss: 2.374525 | Val Loss: 0.985074\n",
      "Epoch [100/500] | Train Loss: 3.015363 | Val Loss: 2.833866\n",
      "Epoch [200/500] | Train Loss: 2.681329 | Val Loss: 3.179746\n",
      "Epoch [300/500] | Train Loss: 2.287017 | Val Loss: 3.520438\n",
      "Epoch [400/500] | Train Loss: 2.090761 | Val Loss: 3.476506\n",
      "Epoch [500/500] | Train Loss: 1.937838 | Val Loss: 3.426305\n",
      "Epoch [100/500] | Train Loss: 3.042847 | Val Loss: 0.757433\n",
      "Epoch [200/500] | Train Loss: 2.666891 | Val Loss: 0.777783\n",
      "Epoch [300/500] | Train Loss: 2.209679 | Val Loss: 0.801242\n",
      "Epoch [400/500] | Train Loss: 1.950857 | Val Loss: 0.807956\n",
      "Epoch [500/500] | Train Loss: 1.887647 | Val Loss: 0.826574\n",
      "Epoch [100/500] | Train Loss: 1.692082 | Val Loss: 8.350396\n",
      "Epoch [200/500] | Train Loss: 1.322700 | Val Loss: 8.307739\n",
      "Epoch [300/500] | Train Loss: 1.247377 | Val Loss: 8.297936\n",
      "Epoch [400/500] | Train Loss: 1.038285 | Val Loss: 8.729618\n",
      "Epoch [500/500] | Train Loss: 0.836176 | Val Loss: 7.870458\n",
      "Epoch [100/500] | Train Loss: 2.911738 | Val Loss: 1.777178\n",
      "Epoch [200/500] | Train Loss: 2.238994 | Val Loss: 1.910413\n",
      "Epoch [300/500] | Train Loss: 2.235746 | Val Loss: 2.066156\n",
      "Epoch [400/500] | Train Loss: 1.775391 | Val Loss: 2.123579\n",
      "Epoch [500/500] | Train Loss: 1.537199 | Val Loss: 2.251354\n",
      "Epoch [100/500] | Train Loss: 2.449644 | Val Loss: 0.959806\n",
      "Epoch [200/500] | Train Loss: 2.014840 | Val Loss: 1.042208\n",
      "Epoch [300/500] | Train Loss: 1.809301 | Val Loss: 1.028106\n",
      "Epoch [400/500] | Train Loss: 1.627303 | Val Loss: 1.055403\n",
      "Epoch [500/500] | Train Loss: 1.521534 | Val Loss: 1.134538\n",
      "Epoch [100/500] | Train Loss: 2.064890 | Val Loss: 3.203907\n",
      "Epoch [200/500] | Train Loss: 1.715229 | Val Loss: 2.829630\n",
      "Epoch [300/500] | Train Loss: 1.441820 | Val Loss: 2.797155\n",
      "Epoch [400/500] | Train Loss: 1.386495 | Val Loss: 2.822600\n",
      "Epoch [500/500] | Train Loss: 1.534263 | Val Loss: 3.091213\n",
      "Epoch [100/500] | Train Loss: 2.146532 | Val Loss: 0.793804\n",
      "Epoch [200/500] | Train Loss: 1.661894 | Val Loss: 0.853344\n",
      "Epoch [300/500] | Train Loss: 1.593362 | Val Loss: 0.967954\n",
      "Epoch [400/500] | Train Loss: 1.538965 | Val Loss: 0.934077\n",
      "Epoch [500/500] | Train Loss: 1.460007 | Val Loss: 1.019547\n",
      "Epoch [100/500] | Train Loss: 4.281487 | Val Loss: 6.083584\n",
      "Epoch [200/500] | Train Loss: 2.644984 | Val Loss: 7.080778\n",
      "Epoch [300/500] | Train Loss: 2.943472 | Val Loss: 7.440979\n",
      "Epoch [400/500] | Train Loss: 2.502709 | Val Loss: 7.406006\n",
      "Epoch [500/500] | Train Loss: 2.369525 | Val Loss: 7.511163\n",
      "Epoch [100/500] | Train Loss: 5.043047 | Val Loss: 1.531384\n",
      "Epoch [200/500] | Train Loss: 4.642998 | Val Loss: 1.632798\n",
      "Epoch [300/500] | Train Loss: 3.887636 | Val Loss: 1.702629\n",
      "Epoch [400/500] | Train Loss: 3.852638 | Val Loss: 1.740976\n",
      "Epoch [500/500] | Train Loss: 3.443807 | Val Loss: 1.798605\n",
      "Epoch [100/500] | Train Loss: 3.797731 | Val Loss: 0.909504\n",
      "Epoch [200/500] | Train Loss: 3.647537 | Val Loss: 0.897283\n",
      "Epoch [300/500] | Train Loss: 3.475787 | Val Loss: 0.890590\n",
      "Epoch [400/500] | Train Loss: 3.206637 | Val Loss: 0.883222\n",
      "Epoch [500/500] | Train Loss: 3.098989 | Val Loss: 0.902125\n",
      "Epoch [100/500] | Train Loss: 3.092167 | Val Loss: 2.743752\n",
      "Epoch [200/500] | Train Loss: 2.875782 | Val Loss: 2.758387\n",
      "Epoch [300/500] | Train Loss: 2.572385 | Val Loss: 2.879646\n",
      "Epoch [400/500] | Train Loss: 2.407162 | Val Loss: 2.939366\n",
      "Epoch [500/500] | Train Loss: 2.367019 | Val Loss: 2.991045\n",
      "Epoch [100/500] | Train Loss: 3.058117 | Val Loss: 0.757840\n",
      "Epoch [200/500] | Train Loss: 2.929997 | Val Loss: 0.753337\n",
      "Epoch [300/500] | Train Loss: 2.612881 | Val Loss: 0.765406\n",
      "Epoch [400/500] | Train Loss: 2.530898 | Val Loss: 0.781531\n",
      "Epoch [500/500] | Train Loss: 2.403186 | Val Loss: 0.779184\n",
      "Epoch [100/500] | Train Loss: 2.519832 | Val Loss: 7.675674\n",
      "Epoch [200/500] | Train Loss: 2.221984 | Val Loss: 7.142206\n",
      "Epoch [300/500] | Train Loss: 1.922819 | Val Loss: 6.605364\n",
      "Epoch [400/500] | Train Loss: 1.660151 | Val Loss: 6.876327\n",
      "Epoch [500/500] | Train Loss: 1.651001 | Val Loss: 7.263117\n",
      "Epoch [100/500] | Train Loss: 3.556946 | Val Loss: 1.752444\n",
      "Epoch [200/500] | Train Loss: 2.876766 | Val Loss: 1.779458\n",
      "Epoch [300/500] | Train Loss: 2.787926 | Val Loss: 1.966938\n",
      "Epoch [400/500] | Train Loss: 2.239916 | Val Loss: 2.165295\n",
      "Epoch [500/500] | Train Loss: 2.598795 | Val Loss: 2.060144\n",
      "Epoch [100/500] | Train Loss: 2.910721 | Val Loss: 0.886270\n",
      "Epoch [200/500] | Train Loss: 2.535238 | Val Loss: 0.940101\n",
      "Epoch [300/500] | Train Loss: 2.219882 | Val Loss: 0.953971\n",
      "Epoch [400/500] | Train Loss: 2.405686 | Val Loss: 0.948963\n",
      "Epoch [500/500] | Train Loss: 2.326683 | Val Loss: 1.023120\n",
      "Epoch [100/500] | Train Loss: 2.462506 | Val Loss: 2.947572\n",
      "Epoch [200/500] | Train Loss: 2.496364 | Val Loss: 2.874046\n",
      "Epoch [300/500] | Train Loss: 2.040014 | Val Loss: 2.867988\n",
      "Epoch [400/500] | Train Loss: 1.818324 | Val Loss: 2.778631\n",
      "Epoch [500/500] | Train Loss: 1.709882 | Val Loss: 3.259749\n",
      "Epoch [100/500] | Train Loss: 2.521205 | Val Loss: 0.797919\n",
      "Epoch [200/500] | Train Loss: 2.398756 | Val Loss: 0.795933\n",
      "Epoch [300/500] | Train Loss: 2.179708 | Val Loss: 0.808041\n",
      "Epoch [400/500] | Train Loss: 2.066918 | Val Loss: 0.821536\n",
      "Epoch [500/500] | Train Loss: 1.963144 | Val Loss: 0.835518\n",
      "[Year=2013] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=2.656499 Test MSE=0.524579\n",
      "Year 2013 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 2.930228 | Val Loss: 1.737794\n",
      "Epoch [200/500] | Train Loss: 2.412848 | Val Loss: 1.983580\n",
      "Epoch [300/500] | Train Loss: 1.950419 | Val Loss: 2.133217\n",
      "Epoch [400/500] | Train Loss: 2.004450 | Val Loss: 2.176149\n",
      "Epoch [500/500] | Train Loss: 1.503708 | Val Loss: 2.348820\n",
      "Epoch [100/500] | Train Loss: 2.340130 | Val Loss: 0.666251\n",
      "Epoch [200/500] | Train Loss: 2.060972 | Val Loss: 0.683418\n",
      "Epoch [300/500] | Train Loss: 1.868340 | Val Loss: 0.702659\n",
      "Epoch [400/500] | Train Loss: 1.617853 | Val Loss: 0.705931\n",
      "Epoch [500/500] | Train Loss: 1.483626 | Val Loss: 0.712239\n",
      "Epoch [100/500] | Train Loss: 1.790536 | Val Loss: 2.540634\n",
      "Epoch [200/500] | Train Loss: 1.588165 | Val Loss: 2.563773\n",
      "Epoch [300/500] | Train Loss: 1.387145 | Val Loss: 2.729193\n",
      "Epoch [400/500] | Train Loss: 1.307589 | Val Loss: 2.912708\n",
      "Epoch [500/500] | Train Loss: 1.167886 | Val Loss: 3.055938\n",
      "Epoch [100/500] | Train Loss: 1.968292 | Val Loss: 0.716965\n",
      "Epoch [200/500] | Train Loss: 1.833270 | Val Loss: 0.773424\n",
      "Epoch [300/500] | Train Loss: 1.689713 | Val Loss: 0.789538\n",
      "Epoch [400/500] | Train Loss: 1.611571 | Val Loss: 0.811857\n",
      "Epoch [500/500] | Train Loss: 1.564328 | Val Loss: 0.844445\n",
      "Epoch [100/500] | Train Loss: 1.714317 | Val Loss: 0.498037\n",
      "Epoch [200/500] | Train Loss: 1.549075 | Val Loss: 0.517758\n",
      "Epoch [300/500] | Train Loss: 1.468078 | Val Loss: 0.530823\n",
      "Epoch [400/500] | Train Loss: 1.397495 | Val Loss: 0.536365\n",
      "Epoch [500/500] | Train Loss: 1.387642 | Val Loss: 0.538057\n",
      "Epoch [100/500] | Train Loss: 1.690091 | Val Loss: 1.906366\n",
      "Epoch [200/500] | Train Loss: 1.173114 | Val Loss: 2.072816\n",
      "Epoch [300/500] | Train Loss: 0.897034 | Val Loss: 2.146492\n",
      "Epoch [400/500] | Train Loss: 0.755781 | Val Loss: 2.215727\n",
      "Epoch [500/500] | Train Loss: 0.893564 | Val Loss: 2.328947\n",
      "Epoch [100/500] | Train Loss: 1.662369 | Val Loss: 0.747123\n",
      "Epoch [200/500] | Train Loss: 1.162255 | Val Loss: 0.779802\n",
      "Epoch [300/500] | Train Loss: 0.937957 | Val Loss: 0.905290\n",
      "Epoch [400/500] | Train Loss: 0.838189 | Val Loss: 0.978067\n",
      "Epoch [500/500] | Train Loss: 0.888689 | Val Loss: 0.970276\n",
      "Epoch [100/500] | Train Loss: 1.411294 | Val Loss: 2.738112\n",
      "Epoch [200/500] | Train Loss: 1.045459 | Val Loss: 3.120610\n",
      "Epoch [300/500] | Train Loss: 0.919110 | Val Loss: 3.120172\n",
      "Epoch [400/500] | Train Loss: 0.911300 | Val Loss: 3.177573\n",
      "Epoch [500/500] | Train Loss: 0.881572 | Val Loss: 3.316908\n",
      "Epoch [100/500] | Train Loss: 1.448360 | Val Loss: 0.835385\n",
      "Epoch [200/500] | Train Loss: 1.277231 | Val Loss: 0.938994\n",
      "Epoch [300/500] | Train Loss: 1.137483 | Val Loss: 0.989850\n",
      "Epoch [400/500] | Train Loss: 1.050295 | Val Loss: 1.083674\n",
      "Epoch [500/500] | Train Loss: 0.976839 | Val Loss: 1.175249\n",
      "Epoch [100/500] | Train Loss: 1.355590 | Val Loss: 0.523584\n",
      "Epoch [200/500] | Train Loss: 1.174586 | Val Loss: 0.603092\n",
      "Epoch [300/500] | Train Loss: 1.179633 | Val Loss: 0.607134\n",
      "Epoch [400/500] | Train Loss: 1.075460 | Val Loss: 0.618597\n",
      "Epoch [500/500] | Train Loss: 1.019502 | Val Loss: 0.577048\n",
      "Epoch [100/500] | Train Loss: 3.277195 | Val Loss: 1.571339\n",
      "Epoch [200/500] | Train Loss: 2.868141 | Val Loss: 1.783050\n",
      "Epoch [300/500] | Train Loss: 2.603079 | Val Loss: 1.981797\n",
      "Epoch [400/500] | Train Loss: 2.488778 | Val Loss: 2.079293\n",
      "Epoch [500/500] | Train Loss: 2.174899 | Val Loss: 2.178956\n",
      "Epoch [100/500] | Train Loss: 2.401643 | Val Loss: 0.678111\n",
      "Epoch [200/500] | Train Loss: 2.192724 | Val Loss: 0.697139\n",
      "Epoch [300/500] | Train Loss: 2.047299 | Val Loss: 0.694096\n",
      "Epoch [400/500] | Train Loss: 2.049304 | Val Loss: 0.696732\n",
      "Epoch [500/500] | Train Loss: 2.007687 | Val Loss: 0.720168\n",
      "Epoch [100/500] | Train Loss: 1.824811 | Val Loss: 2.568505\n",
      "Epoch [200/500] | Train Loss: 1.756086 | Val Loss: 2.546260\n",
      "Epoch [300/500] | Train Loss: 1.660673 | Val Loss: 2.565500\n",
      "Epoch [400/500] | Train Loss: 1.544561 | Val Loss: 2.605126\n",
      "Epoch [500/500] | Train Loss: 1.459486 | Val Loss: 2.595795\n",
      "Epoch [100/500] | Train Loss: 1.991785 | Val Loss: 0.735637\n",
      "Epoch [200/500] | Train Loss: 1.877082 | Val Loss: 0.785956\n",
      "Epoch [300/500] | Train Loss: 1.812178 | Val Loss: 0.793578\n",
      "Epoch [400/500] | Train Loss: 1.777289 | Val Loss: 0.789107\n",
      "Epoch [500/500] | Train Loss: 1.755699 | Val Loss: 0.781926\n",
      "Epoch [100/500] | Train Loss: 1.708295 | Val Loss: 0.504177\n",
      "Epoch [200/500] | Train Loss: 1.715938 | Val Loss: 0.511204\n",
      "Epoch [300/500] | Train Loss: 1.597888 | Val Loss: 0.509295\n",
      "Epoch [400/500] | Train Loss: 1.544737 | Val Loss: 0.508261\n",
      "Epoch [500/500] | Train Loss: 1.465877 | Val Loss: 0.514251\n",
      "Epoch [100/500] | Train Loss: 2.077718 | Val Loss: 1.906893\n",
      "Epoch [200/500] | Train Loss: 1.603798 | Val Loss: 2.133193\n",
      "Epoch [300/500] | Train Loss: 1.510505 | Val Loss: 2.171737\n",
      "Epoch [400/500] | Train Loss: 1.552863 | Val Loss: 2.422843\n",
      "Epoch [500/500] | Train Loss: 1.129801 | Val Loss: 2.333776\n",
      "Epoch [100/500] | Train Loss: 2.078688 | Val Loss: 0.733415\n",
      "Epoch [200/500] | Train Loss: 1.660747 | Val Loss: 0.832018\n",
      "Epoch [300/500] | Train Loss: 1.376369 | Val Loss: 0.752627\n",
      "Epoch [400/500] | Train Loss: 1.350720 | Val Loss: 0.777774\n",
      "Epoch [500/500] | Train Loss: 1.417096 | Val Loss: 0.884826\n",
      "Epoch [100/500] | Train Loss: 1.612472 | Val Loss: 2.552524\n",
      "Epoch [200/500] | Train Loss: 1.346090 | Val Loss: 2.648621\n",
      "Epoch [300/500] | Train Loss: 1.381700 | Val Loss: 2.730507\n",
      "Epoch [400/500] | Train Loss: 1.213843 | Val Loss: 2.653752\n",
      "Epoch [500/500] | Train Loss: 1.108558 | Val Loss: 2.732481\n",
      "Epoch [100/500] | Train Loss: 1.823536 | Val Loss: 0.751738\n",
      "Epoch [200/500] | Train Loss: 1.472342 | Val Loss: 0.826322\n",
      "Epoch [300/500] | Train Loss: 1.361353 | Val Loss: 0.933371\n",
      "Epoch [400/500] | Train Loss: 1.348971 | Val Loss: 0.909582\n",
      "Epoch [500/500] | Train Loss: 1.455560 | Val Loss: 0.929587\n",
      "Epoch [100/500] | Train Loss: 1.531874 | Val Loss: 0.520046\n",
      "Epoch [200/500] | Train Loss: 1.428938 | Val Loss: 0.518470\n",
      "Epoch [300/500] | Train Loss: 1.385640 | Val Loss: 0.515985\n",
      "Epoch [400/500] | Train Loss: 1.341042 | Val Loss: 0.505884\n",
      "Epoch [500/500] | Train Loss: 1.288073 | Val Loss: 0.538123\n",
      "Epoch [100/500] | Train Loss: 2.836041 | Val Loss: 1.712896\n",
      "Epoch [200/500] | Train Loss: 1.915082 | Val Loss: 2.190829\n",
      "Epoch [300/500] | Train Loss: 1.513484 | Val Loss: 2.363363\n",
      "Epoch [400/500] | Train Loss: 1.191018 | Val Loss: 2.427821\n",
      "Epoch [500/500] | Train Loss: 0.938415 | Val Loss: 2.464191\n",
      "Epoch [100/500] | Train Loss: 2.244724 | Val Loss: 0.671454\n",
      "Epoch [200/500] | Train Loss: 1.771893 | Val Loss: 0.743078\n",
      "Epoch [300/500] | Train Loss: 1.606880 | Val Loss: 0.766629\n",
      "Epoch [400/500] | Train Loss: 1.401339 | Val Loss: 0.844607\n",
      "Epoch [500/500] | Train Loss: 1.287298 | Val Loss: 0.869080\n",
      "Epoch [100/500] | Train Loss: 1.757930 | Val Loss: 2.573261\n",
      "Epoch [200/500] | Train Loss: 1.474743 | Val Loss: 2.618048\n",
      "Epoch [300/500] | Train Loss: 1.227981 | Val Loss: 2.815446\n",
      "Epoch [400/500] | Train Loss: 1.076313 | Val Loss: 2.987903\n",
      "Epoch [500/500] | Train Loss: 1.059592 | Val Loss: 3.154577\n",
      "Epoch [100/500] | Train Loss: 1.875394 | Val Loss: 0.765824\n",
      "Epoch [200/500] | Train Loss: 1.649290 | Val Loss: 0.822982\n",
      "Epoch [300/500] | Train Loss: 1.498790 | Val Loss: 0.881427\n",
      "Epoch [400/500] | Train Loss: 1.287591 | Val Loss: 0.969048\n",
      "Epoch [500/500] | Train Loss: 1.266643 | Val Loss: 0.994813\n",
      "Epoch [100/500] | Train Loss: 1.674739 | Val Loss: 0.513295\n",
      "Epoch [200/500] | Train Loss: 1.477713 | Val Loss: 0.551017\n",
      "Epoch [300/500] | Train Loss: 1.312814 | Val Loss: 0.542433\n",
      "Epoch [400/500] | Train Loss: 1.287101 | Val Loss: 0.558989\n",
      "Epoch [500/500] | Train Loss: 1.148188 | Val Loss: 0.561021\n",
      "Epoch [100/500] | Train Loss: 0.994149 | Val Loss: 2.396348\n",
      "Epoch [200/500] | Train Loss: 0.872369 | Val Loss: 2.471649\n",
      "Epoch [300/500] | Train Loss: 0.581084 | Val Loss: 2.637898\n",
      "Epoch [400/500] | Train Loss: 0.813811 | Val Loss: 2.713702\n",
      "Epoch [500/500] | Train Loss: 0.597097 | Val Loss: 2.606749\n",
      "Epoch [100/500] | Train Loss: 1.545933 | Val Loss: 0.801112\n",
      "Epoch [200/500] | Train Loss: 0.968679 | Val Loss: 0.902753\n",
      "Epoch [300/500] | Train Loss: 0.983651 | Val Loss: 0.952123\n",
      "Epoch [400/500] | Train Loss: 1.077998 | Val Loss: 0.995004\n",
      "Epoch [500/500] | Train Loss: 0.791265 | Val Loss: 0.978009\n",
      "Epoch [100/500] | Train Loss: 1.224669 | Val Loss: 2.663960\n",
      "Epoch [200/500] | Train Loss: 0.926350 | Val Loss: 3.222870\n",
      "Epoch [300/500] | Train Loss: 0.800716 | Val Loss: 3.143085\n",
      "Epoch [400/500] | Train Loss: 0.811684 | Val Loss: 3.232327\n",
      "Epoch [500/500] | Train Loss: 0.732932 | Val Loss: 3.291718\n",
      "Epoch [100/500] | Train Loss: 1.327386 | Val Loss: 0.926644\n",
      "Epoch [200/500] | Train Loss: 1.132215 | Val Loss: 1.032701\n",
      "Epoch [300/500] | Train Loss: 1.045581 | Val Loss: 1.039682\n",
      "Epoch [400/500] | Train Loss: 0.915686 | Val Loss: 1.114103\n",
      "Epoch [500/500] | Train Loss: 0.887651 | Val Loss: 1.275494\n",
      "Epoch [100/500] | Train Loss: 1.317424 | Val Loss: 0.526366\n",
      "Epoch [200/500] | Train Loss: 1.018920 | Val Loss: 0.584492\n",
      "Epoch [300/500] | Train Loss: 0.970408 | Val Loss: 0.592918\n",
      "Epoch [400/500] | Train Loss: 0.916463 | Val Loss: 0.651998\n",
      "Epoch [500/500] | Train Loss: 0.926986 | Val Loss: 0.644412\n",
      "Epoch [100/500] | Train Loss: 3.120668 | Val Loss: 1.635817\n",
      "Epoch [200/500] | Train Loss: 2.655618 | Val Loss: 1.833873\n",
      "Epoch [300/500] | Train Loss: 2.198413 | Val Loss: 1.963440\n",
      "Epoch [400/500] | Train Loss: 1.993742 | Val Loss: 2.108595\n",
      "Epoch [500/500] | Train Loss: 1.862851 | Val Loss: 2.038603\n",
      "Epoch [100/500] | Train Loss: 2.385685 | Val Loss: 0.663160\n",
      "Epoch [200/500] | Train Loss: 2.089379 | Val Loss: 0.682291\n",
      "Epoch [300/500] | Train Loss: 1.906114 | Val Loss: 0.724908\n",
      "Epoch [400/500] | Train Loss: 1.759557 | Val Loss: 0.769594\n",
      "Epoch [500/500] | Train Loss: 1.707882 | Val Loss: 0.763832\n",
      "Epoch [100/500] | Train Loss: 1.782670 | Val Loss: 2.532094\n",
      "Epoch [200/500] | Train Loss: 1.668507 | Val Loss: 2.502701\n",
      "Epoch [300/500] | Train Loss: 1.576816 | Val Loss: 2.479205\n",
      "Epoch [400/500] | Train Loss: 1.411735 | Val Loss: 2.462941\n",
      "Epoch [500/500] | Train Loss: 1.388486 | Val Loss: 2.461082\n",
      "Epoch [100/500] | Train Loss: 1.983731 | Val Loss: 0.745683\n",
      "Epoch [200/500] | Train Loss: 1.877725 | Val Loss: 0.777641\n",
      "Epoch [300/500] | Train Loss: 1.843708 | Val Loss: 0.778704\n",
      "Epoch [400/500] | Train Loss: 1.666329 | Val Loss: 0.790545\n",
      "Epoch [500/500] | Train Loss: 1.581249 | Val Loss: 0.817579\n",
      "Epoch [100/500] | Train Loss: 1.725457 | Val Loss: 0.512414\n",
      "Epoch [200/500] | Train Loss: 1.627481 | Val Loss: 0.526872\n",
      "Epoch [300/500] | Train Loss: 1.539678 | Val Loss: 0.523200\n",
      "Epoch [400/500] | Train Loss: 1.385105 | Val Loss: 0.518134\n",
      "Epoch [500/500] | Train Loss: 1.407124 | Val Loss: 0.519753\n",
      "Epoch [100/500] | Train Loss: 2.377440 | Val Loss: 1.989870\n",
      "Epoch [200/500] | Train Loss: 1.894905 | Val Loss: 2.192568\n",
      "Epoch [300/500] | Train Loss: 1.495108 | Val Loss: 2.198762\n",
      "Epoch [400/500] | Train Loss: 1.214263 | Val Loss: 2.362183\n",
      "Epoch [500/500] | Train Loss: 1.452523 | Val Loss: 2.213001\n",
      "Epoch [100/500] | Train Loss: 1.885934 | Val Loss: 0.731721\n",
      "Epoch [200/500] | Train Loss: 1.575455 | Val Loss: 0.865381\n",
      "Epoch [300/500] | Train Loss: 1.329103 | Val Loss: 0.910802\n",
      "Epoch [400/500] | Train Loss: 1.219990 | Val Loss: 1.073993\n",
      "Epoch [500/500] | Train Loss: 1.316370 | Val Loss: 1.065800\n",
      "Epoch [100/500] | Train Loss: 1.478550 | Val Loss: 2.670941\n",
      "Epoch [200/500] | Train Loss: 1.253458 | Val Loss: 2.781685\n",
      "Epoch [300/500] | Train Loss: 1.183150 | Val Loss: 2.809408\n",
      "Epoch [400/500] | Train Loss: 1.028394 | Val Loss: 2.704420\n",
      "Epoch [500/500] | Train Loss: 1.072223 | Val Loss: 2.961471\n",
      "Epoch [100/500] | Train Loss: 1.812602 | Val Loss: 0.756557\n",
      "Epoch [200/500] | Train Loss: 1.539537 | Val Loss: 0.780907\n",
      "Epoch [300/500] | Train Loss: 1.408691 | Val Loss: 0.913318\n",
      "Epoch [400/500] | Train Loss: 1.252614 | Val Loss: 0.919823\n",
      "Epoch [500/500] | Train Loss: 1.330393 | Val Loss: 0.879980\n",
      "Epoch [100/500] | Train Loss: 1.349508 | Val Loss: 0.542058\n",
      "Epoch [200/500] | Train Loss: 1.346062 | Val Loss: 0.555663\n",
      "Epoch [300/500] | Train Loss: 1.227772 | Val Loss: 0.585516\n",
      "Epoch [400/500] | Train Loss: 1.162322 | Val Loss: 0.565757\n",
      "Epoch [500/500] | Train Loss: 1.102084 | Val Loss: 0.628351\n",
      "[Year=2014] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.320170 Test MSE=0.600449\n",
      "Year 2014 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 1.451407 | Val Loss: 1.654122\n",
      "Epoch [200/500] | Train Loss: 1.163117 | Val Loss: 1.768011\n",
      "Epoch [300/500] | Train Loss: 0.999832 | Val Loss: 1.835034\n",
      "Epoch [400/500] | Train Loss: 0.843100 | Val Loss: 1.988339\n",
      "Epoch [500/500] | Train Loss: 0.739947 | Val Loss: 1.931724\n",
      "Epoch [100/500] | Train Loss: 1.355115 | Val Loss: 1.770278\n",
      "Epoch [200/500] | Train Loss: 1.182438 | Val Loss: 1.898545\n",
      "Epoch [300/500] | Train Loss: 1.110330 | Val Loss: 1.946590\n",
      "Epoch [400/500] | Train Loss: 0.884968 | Val Loss: 2.000857\n",
      "Epoch [500/500] | Train Loss: 0.969678 | Val Loss: 2.039211\n",
      "Epoch [100/500] | Train Loss: 1.519677 | Val Loss: 0.603998\n",
      "Epoch [200/500] | Train Loss: 1.338084 | Val Loss: 0.649995\n",
      "Epoch [300/500] | Train Loss: 1.218992 | Val Loss: 0.624376\n",
      "Epoch [400/500] | Train Loss: 1.170674 | Val Loss: 0.641474\n",
      "Epoch [500/500] | Train Loss: 1.027740 | Val Loss: 0.656586\n",
      "Epoch [100/500] | Train Loss: 1.308756 | Val Loss: 0.554219\n",
      "Epoch [200/500] | Train Loss: 1.220178 | Val Loss: 0.568158\n",
      "Epoch [300/500] | Train Loss: 1.076687 | Val Loss: 0.567238\n",
      "Epoch [400/500] | Train Loss: 1.100609 | Val Loss: 0.570887\n",
      "Epoch [500/500] | Train Loss: 0.982179 | Val Loss: 0.584330\n",
      "Epoch [100/500] | Train Loss: 1.139730 | Val Loss: 0.524562\n",
      "Epoch [200/500] | Train Loss: 1.089097 | Val Loss: 0.540507\n",
      "Epoch [300/500] | Train Loss: 1.010341 | Val Loss: 0.549103\n",
      "Epoch [400/500] | Train Loss: 0.983561 | Val Loss: 0.555172\n",
      "Epoch [500/500] | Train Loss: 0.891319 | Val Loss: 0.561567\n",
      "Epoch [100/500] | Train Loss: 0.726119 | Val Loss: 2.073218\n",
      "Epoch [200/500] | Train Loss: 0.491514 | Val Loss: 2.078969\n",
      "Epoch [300/500] | Train Loss: 0.368038 | Val Loss: 1.836029\n",
      "Epoch [400/500] | Train Loss: 0.462648 | Val Loss: 2.103039\n",
      "Epoch [500/500] | Train Loss: 0.392014 | Val Loss: 2.153749\n",
      "Epoch [100/500] | Train Loss: 0.999241 | Val Loss: 1.951668\n",
      "Epoch [200/500] | Train Loss: 0.753087 | Val Loss: 2.141041\n",
      "Epoch [300/500] | Train Loss: 0.633875 | Val Loss: 2.147824\n",
      "Epoch [400/500] | Train Loss: 0.703811 | Val Loss: 2.246876\n",
      "Epoch [500/500] | Train Loss: 0.580999 | Val Loss: 2.337938\n",
      "Epoch [100/500] | Train Loss: 1.067901 | Val Loss: 0.684844\n",
      "Epoch [200/500] | Train Loss: 0.928646 | Val Loss: 0.770820\n",
      "Epoch [300/500] | Train Loss: 0.828271 | Val Loss: 0.848109\n",
      "Epoch [400/500] | Train Loss: 0.756416 | Val Loss: 0.887539\n",
      "Epoch [500/500] | Train Loss: 0.726088 | Val Loss: 0.870171\n",
      "Epoch [100/500] | Train Loss: 1.005836 | Val Loss: 0.542385\n",
      "Epoch [200/500] | Train Loss: 0.929987 | Val Loss: 0.560115\n",
      "Epoch [300/500] | Train Loss: 0.796292 | Val Loss: 0.597723\n",
      "Epoch [400/500] | Train Loss: 0.748237 | Val Loss: 0.597630\n",
      "Epoch [500/500] | Train Loss: 0.754223 | Val Loss: 0.607021\n",
      "Epoch [100/500] | Train Loss: 0.932772 | Val Loss: 0.537901\n",
      "Epoch [200/500] | Train Loss: 0.854844 | Val Loss: 0.560896\n",
      "Epoch [300/500] | Train Loss: 0.812072 | Val Loss: 0.573450\n",
      "Epoch [400/500] | Train Loss: 0.731426 | Val Loss: 0.571028\n",
      "Epoch [500/500] | Train Loss: 0.734450 | Val Loss: 0.654609\n",
      "Epoch [100/500] | Train Loss: 1.453396 | Val Loss: 1.652654\n",
      "Epoch [200/500] | Train Loss: 1.368617 | Val Loss: 1.756240\n",
      "Epoch [300/500] | Train Loss: 1.226621 | Val Loss: 1.792354\n",
      "Epoch [400/500] | Train Loss: 1.198663 | Val Loss: 1.803781\n",
      "Epoch [500/500] | Train Loss: 1.149537 | Val Loss: 1.771550\n",
      "Epoch [100/500] | Train Loss: 1.405693 | Val Loss: 1.759581\n",
      "Epoch [200/500] | Train Loss: 1.349779 | Val Loss: 1.840758\n",
      "Epoch [300/500] | Train Loss: 1.186080 | Val Loss: 1.902155\n",
      "Epoch [400/500] | Train Loss: 1.152653 | Val Loss: 1.909132\n",
      "Epoch [500/500] | Train Loss: 1.047082 | Val Loss: 1.975141\n",
      "Epoch [100/500] | Train Loss: 1.546775 | Val Loss: 0.588918\n",
      "Epoch [200/500] | Train Loss: 1.504789 | Val Loss: 0.609838\n",
      "Epoch [300/500] | Train Loss: 1.407324 | Val Loss: 0.612138\n",
      "Epoch [400/500] | Train Loss: 1.410871 | Val Loss: 0.614813\n",
      "Epoch [500/500] | Train Loss: 1.346428 | Val Loss: 0.617035\n",
      "Epoch [100/500] | Train Loss: 1.296913 | Val Loss: 0.544875\n",
      "Epoch [200/500] | Train Loss: 1.262803 | Val Loss: 0.543158\n",
      "Epoch [300/500] | Train Loss: 1.205048 | Val Loss: 0.548469\n",
      "Epoch [400/500] | Train Loss: 1.167984 | Val Loss: 0.552837\n",
      "Epoch [500/500] | Train Loss: 1.102045 | Val Loss: 0.558151\n",
      "Epoch [100/500] | Train Loss: 1.172456 | Val Loss: 0.526724\n",
      "Epoch [200/500] | Train Loss: 1.143671 | Val Loss: 0.527760\n",
      "Epoch [300/500] | Train Loss: 1.082100 | Val Loss: 0.524504\n",
      "Epoch [400/500] | Train Loss: 1.054119 | Val Loss: 0.528784\n",
      "Epoch [500/500] | Train Loss: 1.030854 | Val Loss: 0.526617\n",
      "Epoch [100/500] | Train Loss: 0.968142 | Val Loss: 1.790319\n",
      "Epoch [200/500] | Train Loss: 0.739203 | Val Loss: 1.911271\n",
      "Epoch [300/500] | Train Loss: 0.595038 | Val Loss: 1.802929\n",
      "Epoch [400/500] | Train Loss: 0.805741 | Val Loss: 1.862839\n",
      "Epoch [500/500] | Train Loss: 0.547937 | Val Loss: 1.842157\n",
      "Epoch [100/500] | Train Loss: 1.218399 | Val Loss: 1.843905\n",
      "Epoch [200/500] | Train Loss: 1.001076 | Val Loss: 2.079921\n",
      "Epoch [300/500] | Train Loss: 1.080271 | Val Loss: 2.108681\n",
      "Epoch [400/500] | Train Loss: 0.954229 | Val Loss: 2.075539\n",
      "Epoch [500/500] | Train Loss: 1.139649 | Val Loss: 2.288782\n",
      "Epoch [100/500] | Train Loss: 1.359405 | Val Loss: 0.595366\n",
      "Epoch [200/500] | Train Loss: 1.261822 | Val Loss: 0.616531\n",
      "Epoch [300/500] | Train Loss: 1.119094 | Val Loss: 0.610542\n",
      "Epoch [400/500] | Train Loss: 1.192437 | Val Loss: 0.651306\n",
      "Epoch [500/500] | Train Loss: 1.103310 | Val Loss: 0.633107\n",
      "Epoch [100/500] | Train Loss: 1.230326 | Val Loss: 0.564794\n",
      "Epoch [200/500] | Train Loss: 1.090789 | Val Loss: 0.556153\n",
      "Epoch [300/500] | Train Loss: 1.105565 | Val Loss: 0.578054\n",
      "Epoch [400/500] | Train Loss: 1.018813 | Val Loss: 0.572933\n",
      "Epoch [500/500] | Train Loss: 0.951666 | Val Loss: 0.566511\n",
      "Epoch [100/500] | Train Loss: 0.969297 | Val Loss: 0.522055\n",
      "Epoch [200/500] | Train Loss: 0.968636 | Val Loss: 0.537270\n",
      "Epoch [300/500] | Train Loss: 0.922860 | Val Loss: 0.548865\n",
      "Epoch [400/500] | Train Loss: 0.886051 | Val Loss: 0.560183\n",
      "Epoch [500/500] | Train Loss: 0.920971 | Val Loss: 0.565841\n",
      "Epoch [100/500] | Train Loss: 1.213993 | Val Loss: 1.653012\n",
      "Epoch [200/500] | Train Loss: 0.923005 | Val Loss: 1.793600\n",
      "Epoch [300/500] | Train Loss: 0.635676 | Val Loss: 1.874461\n",
      "Epoch [400/500] | Train Loss: 0.666438 | Val Loss: 1.843428\n",
      "Epoch [500/500] | Train Loss: 0.623935 | Val Loss: 1.801210\n",
      "Epoch [100/500] | Train Loss: 1.373264 | Val Loss: 1.767017\n",
      "Epoch [200/500] | Train Loss: 1.084745 | Val Loss: 2.066669\n",
      "Epoch [300/500] | Train Loss: 0.965115 | Val Loss: 2.175500\n",
      "Epoch [400/500] | Train Loss: 0.837443 | Val Loss: 2.193777\n",
      "Epoch [500/500] | Train Loss: 0.726125 | Val Loss: 2.323535\n",
      "Epoch [100/500] | Train Loss: 1.479408 | Val Loss: 0.613790\n",
      "Epoch [200/500] | Train Loss: 1.307004 | Val Loss: 0.643595\n",
      "Epoch [300/500] | Train Loss: 1.157721 | Val Loss: 0.641644\n",
      "Epoch [400/500] | Train Loss: 1.103972 | Val Loss: 0.661736\n",
      "Epoch [500/500] | Train Loss: 0.940607 | Val Loss: 0.677715\n",
      "Epoch [100/500] | Train Loss: 1.270243 | Val Loss: 0.550930\n",
      "Epoch [200/500] | Train Loss: 1.153282 | Val Loss: 0.561737\n",
      "Epoch [300/500] | Train Loss: 0.983891 | Val Loss: 0.559812\n",
      "Epoch [400/500] | Train Loss: 0.951883 | Val Loss: 0.562948\n",
      "Epoch [500/500] | Train Loss: 0.956148 | Val Loss: 0.575281\n",
      "Epoch [100/500] | Train Loss: 1.200760 | Val Loss: 0.532815\n",
      "Epoch [200/500] | Train Loss: 1.104835 | Val Loss: 0.526713\n",
      "Epoch [300/500] | Train Loss: 1.008051 | Val Loss: 0.520672\n",
      "Epoch [400/500] | Train Loss: 0.899677 | Val Loss: 0.534391\n",
      "Epoch [500/500] | Train Loss: 0.849797 | Val Loss: 0.548325\n",
      "Epoch [100/500] | Train Loss: 0.634744 | Val Loss: 1.913033\n",
      "Epoch [200/500] | Train Loss: 0.434291 | Val Loss: 1.936051\n",
      "Epoch [300/500] | Train Loss: 0.410574 | Val Loss: 2.058675\n",
      "Epoch [400/500] | Train Loss: 0.379724 | Val Loss: 2.062248\n",
      "Epoch [500/500] | Train Loss: 0.348330 | Val Loss: 1.909524\n",
      "Epoch [100/500] | Train Loss: 0.876926 | Val Loss: 1.946965\n",
      "Epoch [200/500] | Train Loss: 0.615967 | Val Loss: 2.024797\n",
      "Epoch [300/500] | Train Loss: 0.525556 | Val Loss: 1.986166\n",
      "Epoch [400/500] | Train Loss: 0.446567 | Val Loss: 2.101539\n",
      "Epoch [500/500] | Train Loss: 0.391827 | Val Loss: 2.226887\n",
      "Epoch [100/500] | Train Loss: 1.026808 | Val Loss: 0.701882\n",
      "Epoch [200/500] | Train Loss: 0.807366 | Val Loss: 0.812690\n",
      "Epoch [300/500] | Train Loss: 0.764562 | Val Loss: 0.820221\n",
      "Epoch [400/500] | Train Loss: 0.675266 | Val Loss: 0.839826\n",
      "Epoch [500/500] | Train Loss: 0.639879 | Val Loss: 0.884057\n",
      "Epoch [100/500] | Train Loss: 0.999755 | Val Loss: 0.584862\n",
      "Epoch [200/500] | Train Loss: 0.889056 | Val Loss: 0.603005\n",
      "Epoch [300/500] | Train Loss: 0.769713 | Val Loss: 0.645567\n",
      "Epoch [400/500] | Train Loss: 0.649866 | Val Loss: 0.654060\n",
      "Epoch [500/500] | Train Loss: 0.658276 | Val Loss: 0.711096\n",
      "Epoch [100/500] | Train Loss: 0.899783 | Val Loss: 0.558133\n",
      "Epoch [200/500] | Train Loss: 0.710496 | Val Loss: 0.591090\n",
      "Epoch [300/500] | Train Loss: 0.694941 | Val Loss: 0.618184\n",
      "Epoch [400/500] | Train Loss: 0.670421 | Val Loss: 0.614101\n",
      "Epoch [500/500] | Train Loss: 0.621492 | Val Loss: 0.728369\n",
      "Epoch [100/500] | Train Loss: 1.378272 | Val Loss: 1.581641\n",
      "Epoch [200/500] | Train Loss: 1.269396 | Val Loss: 1.611120\n",
      "Epoch [300/500] | Train Loss: 0.963709 | Val Loss: 1.686916\n",
      "Epoch [400/500] | Train Loss: 0.897502 | Val Loss: 1.663142\n",
      "Epoch [500/500] | Train Loss: 0.837164 | Val Loss: 1.737875\n",
      "Epoch [100/500] | Train Loss: 1.486129 | Val Loss: 1.722258\n",
      "Epoch [200/500] | Train Loss: 1.263282 | Val Loss: 1.834872\n",
      "Epoch [300/500] | Train Loss: 1.170397 | Val Loss: 1.970063\n",
      "Epoch [400/500] | Train Loss: 1.064248 | Val Loss: 1.935454\n",
      "Epoch [500/500] | Train Loss: 1.042648 | Val Loss: 1.972239\n",
      "Epoch [100/500] | Train Loss: 1.520926 | Val Loss: 0.584370\n",
      "Epoch [200/500] | Train Loss: 1.432990 | Val Loss: 0.606163\n",
      "Epoch [300/500] | Train Loss: 1.356603 | Val Loss: 0.602412\n",
      "Epoch [400/500] | Train Loss: 1.253248 | Val Loss: 0.608064\n",
      "Epoch [500/500] | Train Loss: 1.227221 | Val Loss: 0.625534\n",
      "Epoch [100/500] | Train Loss: 1.303944 | Val Loss: 0.547403\n",
      "Epoch [200/500] | Train Loss: 1.226493 | Val Loss: 0.547078\n",
      "Epoch [300/500] | Train Loss: 1.150638 | Val Loss: 0.538045\n",
      "Epoch [400/500] | Train Loss: 1.072763 | Val Loss: 0.536258\n",
      "Epoch [500/500] | Train Loss: 1.149486 | Val Loss: 0.543774\n",
      "Epoch [100/500] | Train Loss: 1.160907 | Val Loss: 0.519625\n",
      "Epoch [200/500] | Train Loss: 1.074000 | Val Loss: 0.515335\n",
      "Epoch [300/500] | Train Loss: 1.024410 | Val Loss: 0.523006\n",
      "Epoch [400/500] | Train Loss: 0.991093 | Val Loss: 0.528513\n",
      "Epoch [500/500] | Train Loss: 0.998964 | Val Loss: 0.528711\n",
      "Epoch [100/500] | Train Loss: 1.009086 | Val Loss: 1.645566\n",
      "Epoch [200/500] | Train Loss: 0.776715 | Val Loss: 1.594957\n",
      "Epoch [300/500] | Train Loss: 0.703651 | Val Loss: 1.785825\n",
      "Epoch [400/500] | Train Loss: 0.590760 | Val Loss: 1.949685\n",
      "Epoch [500/500] | Train Loss: 0.578989 | Val Loss: 1.814181\n",
      "Epoch [100/500] | Train Loss: 1.026505 | Val Loss: 1.938418\n",
      "Epoch [200/500] | Train Loss: 1.011952 | Val Loss: 1.946014\n",
      "Epoch [300/500] | Train Loss: 0.876206 | Val Loss: 1.826097\n",
      "Epoch [400/500] | Train Loss: 0.716949 | Val Loss: 1.906314\n",
      "Epoch [500/500] | Train Loss: 0.618749 | Val Loss: 1.914992\n",
      "Epoch [100/500] | Train Loss: 1.250700 | Val Loss: 0.606629\n",
      "Epoch [200/500] | Train Loss: 1.001143 | Val Loss: 0.653955\n",
      "Epoch [300/500] | Train Loss: 0.993525 | Val Loss: 0.710858\n",
      "Epoch [400/500] | Train Loss: 1.032174 | Val Loss: 0.718159\n",
      "Epoch [500/500] | Train Loss: 0.870550 | Val Loss: 0.755726\n",
      "Epoch [100/500] | Train Loss: 1.095556 | Val Loss: 0.535931\n",
      "Epoch [200/500] | Train Loss: 0.932287 | Val Loss: 0.566772\n",
      "Epoch [300/500] | Train Loss: 0.911240 | Val Loss: 0.641462\n",
      "Epoch [400/500] | Train Loss: 0.851749 | Val Loss: 0.599480\n",
      "Epoch [500/500] | Train Loss: 0.796525 | Val Loss: 0.618849\n",
      "Epoch [100/500] | Train Loss: 1.008612 | Val Loss: 0.530933\n",
      "Epoch [200/500] | Train Loss: 0.860300 | Val Loss: 0.545402\n",
      "Epoch [300/500] | Train Loss: 0.866102 | Val Loss: 0.543172\n",
      "Epoch [400/500] | Train Loss: 0.788302 | Val Loss: 0.581111\n",
      "Epoch [500/500] | Train Loss: 0.785669 | Val Loss: 0.563307\n",
      "[Year=2015] Best Params={'num_epochs': 500, 'hidden_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.081626 Test MSE=1.035977\n",
      "Year 2015 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 2.149429 | Val Loss: 1.126545\n",
      "Epoch [200/500] | Train Loss: 1.462753 | Val Loss: 1.445317\n",
      "Epoch [300/500] | Train Loss: 1.399658 | Val Loss: 1.483914\n",
      "Epoch [400/500] | Train Loss: 1.205692 | Val Loss: 1.581126\n",
      "Epoch [500/500] | Train Loss: 0.938649 | Val Loss: 1.589060\n",
      "Epoch [100/500] | Train Loss: 1.457689 | Val Loss: 0.677426\n",
      "Epoch [200/500] | Train Loss: 1.257136 | Val Loss: 0.715964\n",
      "Epoch [300/500] | Train Loss: 1.122353 | Val Loss: 0.711706\n",
      "Epoch [400/500] | Train Loss: 1.065799 | Val Loss: 0.709703\n",
      "Epoch [500/500] | Train Loss: 0.895118 | Val Loss: 0.720418\n",
      "Epoch [100/500] | Train Loss: 1.251976 | Val Loss: 0.520589\n",
      "Epoch [200/500] | Train Loss: 1.111558 | Val Loss: 0.531179\n",
      "Epoch [300/500] | Train Loss: 0.939737 | Val Loss: 0.549134\n",
      "Epoch [400/500] | Train Loss: 0.901614 | Val Loss: 0.559362\n",
      "Epoch [500/500] | Train Loss: 0.823558 | Val Loss: 0.568362\n",
      "Epoch [100/500] | Train Loss: 1.028841 | Val Loss: 0.567640\n",
      "Epoch [200/500] | Train Loss: 0.936561 | Val Loss: 0.575262\n",
      "Epoch [300/500] | Train Loss: 0.866209 | Val Loss: 0.593649\n",
      "Epoch [400/500] | Train Loss: 0.815053 | Val Loss: 0.599602\n",
      "Epoch [500/500] | Train Loss: 0.802092 | Val Loss: 0.608755\n",
      "Epoch [100/500] | Train Loss: 0.952779 | Val Loss: 0.978096\n",
      "Epoch [200/500] | Train Loss: 0.881252 | Val Loss: 1.016724\n",
      "Epoch [300/500] | Train Loss: 0.778683 | Val Loss: 1.119552\n",
      "Epoch [400/500] | Train Loss: 0.763096 | Val Loss: 1.182607\n",
      "Epoch [500/500] | Train Loss: 0.749659 | Val Loss: 1.213637\n",
      "Epoch [100/500] | Train Loss: 1.066945 | Val Loss: 1.600338\n",
      "Epoch [200/500] | Train Loss: 0.945833 | Val Loss: 1.803338\n",
      "Epoch [300/500] | Train Loss: 0.506183 | Val Loss: 1.841920\n",
      "Epoch [400/500] | Train Loss: 0.576792 | Val Loss: 1.866928\n",
      "Epoch [500/500] | Train Loss: 0.352613 | Val Loss: 1.973095\n",
      "Epoch [100/500] | Train Loss: 1.128680 | Val Loss: 0.731335\n",
      "Epoch [200/500] | Train Loss: 0.772084 | Val Loss: 0.811494\n",
      "Epoch [300/500] | Train Loss: 0.689654 | Val Loss: 0.771094\n",
      "Epoch [400/500] | Train Loss: 0.727417 | Val Loss: 0.794239\n",
      "Epoch [500/500] | Train Loss: 0.567750 | Val Loss: 0.875126\n",
      "Epoch [100/500] | Train Loss: 0.960884 | Val Loss: 0.526575\n",
      "Epoch [200/500] | Train Loss: 0.772432 | Val Loss: 0.572559\n",
      "Epoch [300/500] | Train Loss: 0.756901 | Val Loss: 0.611740\n",
      "Epoch [400/500] | Train Loss: 0.593626 | Val Loss: 0.607479\n",
      "Epoch [500/500] | Train Loss: 0.609530 | Val Loss: 0.613253\n",
      "Epoch [100/500] | Train Loss: 0.772165 | Val Loss: 0.602191\n",
      "Epoch [200/500] | Train Loss: 0.732021 | Val Loss: 0.597175\n",
      "Epoch [300/500] | Train Loss: 0.678363 | Val Loss: 0.632985\n",
      "Epoch [400/500] | Train Loss: 0.604090 | Val Loss: 0.617471\n",
      "Epoch [500/500] | Train Loss: 0.585326 | Val Loss: 0.629105\n",
      "Epoch [100/500] | Train Loss: 0.764737 | Val Loss: 1.162012\n",
      "Epoch [200/500] | Train Loss: 0.660340 | Val Loss: 1.172827\n",
      "Epoch [300/500] | Train Loss: 0.624980 | Val Loss: 1.170456\n",
      "Epoch [400/500] | Train Loss: 0.578104 | Val Loss: 1.203089\n",
      "Epoch [500/500] | Train Loss: 0.586441 | Val Loss: 1.214080\n",
      "Epoch [100/500] | Train Loss: 1.951135 | Val Loss: 1.169376\n",
      "Epoch [200/500] | Train Loss: 1.690974 | Val Loss: 1.289683\n",
      "Epoch [300/500] | Train Loss: 1.276340 | Val Loss: 1.374359\n",
      "Epoch [400/500] | Train Loss: 1.133990 | Val Loss: 1.508082\n",
      "Epoch [500/500] | Train Loss: 1.278409 | Val Loss: 1.457871\n",
      "Epoch [100/500] | Train Loss: 1.630512 | Val Loss: 0.646474\n",
      "Epoch [200/500] | Train Loss: 1.416278 | Val Loss: 0.670017\n",
      "Epoch [300/500] | Train Loss: 1.274469 | Val Loss: 0.651006\n",
      "Epoch [400/500] | Train Loss: 1.176959 | Val Loss: 0.642653\n",
      "Epoch [500/500] | Train Loss: 1.231514 | Val Loss: 0.649022\n",
      "Epoch [100/500] | Train Loss: 1.274046 | Val Loss: 0.522682\n",
      "Epoch [200/500] | Train Loss: 1.211056 | Val Loss: 0.523316\n",
      "Epoch [300/500] | Train Loss: 1.168555 | Val Loss: 0.529433\n",
      "Epoch [400/500] | Train Loss: 1.101155 | Val Loss: 0.525070\n",
      "Epoch [500/500] | Train Loss: 1.045183 | Val Loss: 0.529713\n",
      "Epoch [100/500] | Train Loss: 1.074260 | Val Loss: 0.561674\n",
      "Epoch [200/500] | Train Loss: 1.040442 | Val Loss: 0.566728\n",
      "Epoch [300/500] | Train Loss: 0.992744 | Val Loss: 0.565005\n",
      "Epoch [400/500] | Train Loss: 0.961917 | Val Loss: 0.572303\n",
      "Epoch [500/500] | Train Loss: 0.911016 | Val Loss: 0.576185\n",
      "Epoch [100/500] | Train Loss: 0.996027 | Val Loss: 1.012326\n",
      "Epoch [200/500] | Train Loss: 0.892056 | Val Loss: 1.064050\n",
      "Epoch [300/500] | Train Loss: 0.857839 | Val Loss: 1.094080\n",
      "Epoch [400/500] | Train Loss: 0.833622 | Val Loss: 1.096420\n",
      "Epoch [500/500] | Train Loss: 0.809577 | Val Loss: 1.113498\n",
      "Epoch [100/500] | Train Loss: 1.282035 | Val Loss: 1.504888\n",
      "Epoch [200/500] | Train Loss: 1.212327 | Val Loss: 1.603327\n",
      "Epoch [300/500] | Train Loss: 1.241069 | Val Loss: 1.421072\n",
      "Epoch [400/500] | Train Loss: 1.042722 | Val Loss: 1.529088\n",
      "Epoch [500/500] | Train Loss: 0.918210 | Val Loss: 1.482086\n",
      "Epoch [100/500] | Train Loss: 1.303989 | Val Loss: 0.638044\n",
      "Epoch [200/500] | Train Loss: 1.108128 | Val Loss: 0.701815\n",
      "Epoch [300/500] | Train Loss: 1.024043 | Val Loss: 0.684973\n",
      "Epoch [400/500] | Train Loss: 1.099348 | Val Loss: 0.708093\n",
      "Epoch [500/500] | Train Loss: 0.969800 | Val Loss: 0.749444\n",
      "Epoch [100/500] | Train Loss: 1.003547 | Val Loss: 0.526663\n",
      "Epoch [200/500] | Train Loss: 0.925835 | Val Loss: 0.551061\n",
      "Epoch [300/500] | Train Loss: 0.841242 | Val Loss: 0.549371\n",
      "Epoch [400/500] | Train Loss: 0.897503 | Val Loss: 0.561393\n",
      "Epoch [500/500] | Train Loss: 0.799386 | Val Loss: 0.570599\n",
      "Epoch [100/500] | Train Loss: 0.888088 | Val Loss: 0.579019\n",
      "Epoch [200/500] | Train Loss: 0.871634 | Val Loss: 0.585148\n",
      "Epoch [300/500] | Train Loss: 0.798989 | Val Loss: 0.603290\n",
      "Epoch [400/500] | Train Loss: 0.768445 | Val Loss: 0.580602\n",
      "Epoch [500/500] | Train Loss: 0.716998 | Val Loss: 0.615642\n",
      "Epoch [100/500] | Train Loss: 0.795657 | Val Loss: 1.101513\n",
      "Epoch [200/500] | Train Loss: 0.772979 | Val Loss: 1.135451\n",
      "Epoch [300/500] | Train Loss: 0.712914 | Val Loss: 1.089226\n",
      "Epoch [400/500] | Train Loss: 0.727025 | Val Loss: 1.139753\n",
      "Epoch [500/500] | Train Loss: 0.687310 | Val Loss: 1.183412\n",
      "Epoch [100/500] | Train Loss: 1.601663 | Val Loss: 1.290939\n",
      "Epoch [200/500] | Train Loss: 1.136031 | Val Loss: 1.651563\n",
      "Epoch [300/500] | Train Loss: 1.150319 | Val Loss: 1.680543\n",
      "Epoch [400/500] | Train Loss: 0.902153 | Val Loss: 1.670483\n",
      "Epoch [500/500] | Train Loss: 0.713008 | Val Loss: 1.774551\n",
      "Epoch [100/500] | Train Loss: 1.469231 | Val Loss: 0.652151\n",
      "Epoch [200/500] | Train Loss: 1.156243 | Val Loss: 0.707608\n",
      "Epoch [300/500] | Train Loss: 1.004094 | Val Loss: 0.736116\n",
      "Epoch [400/500] | Train Loss: 0.868022 | Val Loss: 0.786382\n",
      "Epoch [500/500] | Train Loss: 0.854518 | Val Loss: 0.827404\n",
      "Epoch [100/500] | Train Loss: 1.144602 | Val Loss: 0.535948\n",
      "Epoch [200/500] | Train Loss: 0.909468 | Val Loss: 0.556531\n",
      "Epoch [300/500] | Train Loss: 0.881182 | Val Loss: 0.557632\n",
      "Epoch [400/500] | Train Loss: 0.759276 | Val Loss: 0.575175\n",
      "Epoch [500/500] | Train Loss: 0.748640 | Val Loss: 0.593498\n",
      "Epoch [100/500] | Train Loss: 1.078855 | Val Loss: 0.571423\n",
      "Epoch [200/500] | Train Loss: 0.997182 | Val Loss: 0.567110\n",
      "Epoch [300/500] | Train Loss: 0.777778 | Val Loss: 0.598082\n",
      "Epoch [400/500] | Train Loss: 0.754870 | Val Loss: 0.615236\n",
      "Epoch [500/500] | Train Loss: 0.728296 | Val Loss: 0.616797\n",
      "Epoch [100/500] | Train Loss: 0.951418 | Val Loss: 0.998513\n",
      "Epoch [200/500] | Train Loss: 0.845986 | Val Loss: 1.063373\n",
      "Epoch [300/500] | Train Loss: 0.744289 | Val Loss: 1.137599\n",
      "Epoch [400/500] | Train Loss: 0.717604 | Val Loss: 1.161560\n",
      "Epoch [500/500] | Train Loss: 0.695107 | Val Loss: 1.212702\n",
      "Epoch [100/500] | Train Loss: 1.008608 | Val Loss: 1.465277\n",
      "Epoch [200/500] | Train Loss: 0.770985 | Val Loss: 1.758370\n",
      "Epoch [300/500] | Train Loss: 0.496588 | Val Loss: 1.909776\n",
      "Epoch [400/500] | Train Loss: 0.584075 | Val Loss: 1.987397\n",
      "Epoch [500/500] | Train Loss: 0.558623 | Val Loss: 1.823620\n",
      "Epoch [100/500] | Train Loss: 0.830441 | Val Loss: 0.773241\n",
      "Epoch [200/500] | Train Loss: 0.637704 | Val Loss: 0.870198\n",
      "Epoch [300/500] | Train Loss: 0.564552 | Val Loss: 0.897403\n",
      "Epoch [400/500] | Train Loss: 0.506947 | Val Loss: 0.867323\n",
      "Epoch [500/500] | Train Loss: 0.443575 | Val Loss: 0.936794\n",
      "Epoch [100/500] | Train Loss: 0.765054 | Val Loss: 0.565767\n",
      "Epoch [200/500] | Train Loss: 0.650060 | Val Loss: 0.643587\n",
      "Epoch [300/500] | Train Loss: 0.547930 | Val Loss: 0.664968\n",
      "Epoch [400/500] | Train Loss: 0.486498 | Val Loss: 0.708225\n",
      "Epoch [500/500] | Train Loss: 0.461496 | Val Loss: 0.759778\n",
      "Epoch [100/500] | Train Loss: 0.801564 | Val Loss: 0.626299\n",
      "Epoch [200/500] | Train Loss: 0.669926 | Val Loss: 0.604375\n",
      "Epoch [300/500] | Train Loss: 0.592796 | Val Loss: 0.627586\n",
      "Epoch [400/500] | Train Loss: 0.493590 | Val Loss: 0.645485\n",
      "Epoch [500/500] | Train Loss: 0.480757 | Val Loss: 0.644578\n",
      "Epoch [100/500] | Train Loss: 0.701677 | Val Loss: 1.165269\n",
      "Epoch [200/500] | Train Loss: 0.624239 | Val Loss: 1.230092\n",
      "Epoch [300/500] | Train Loss: 0.530187 | Val Loss: 1.353953\n",
      "Epoch [400/500] | Train Loss: 0.505764 | Val Loss: 1.373435\n",
      "Epoch [500/500] | Train Loss: 0.458984 | Val Loss: 1.512376\n",
      "Epoch [100/500] | Train Loss: 1.920378 | Val Loss: 1.241366\n",
      "Epoch [200/500] | Train Loss: 1.336934 | Val Loss: 1.370534\n",
      "Epoch [300/500] | Train Loss: 1.308502 | Val Loss: 1.464303\n",
      "Epoch [400/500] | Train Loss: 1.217251 | Val Loss: 1.447785\n",
      "Epoch [500/500] | Train Loss: 1.006119 | Val Loss: 1.440519\n",
      "Epoch [100/500] | Train Loss: 1.522610 | Val Loss: 0.647328\n",
      "Epoch [200/500] | Train Loss: 1.290594 | Val Loss: 0.675435\n",
      "Epoch [300/500] | Train Loss: 1.181549 | Val Loss: 0.675337\n",
      "Epoch [400/500] | Train Loss: 1.192212 | Val Loss: 0.662036\n",
      "Epoch [500/500] | Train Loss: 1.202553 | Val Loss: 0.678986\n",
      "Epoch [100/500] | Train Loss: 1.288050 | Val Loss: 0.522974\n",
      "Epoch [200/500] | Train Loss: 1.190934 | Val Loss: 0.530963\n",
      "Epoch [300/500] | Train Loss: 1.055853 | Val Loss: 0.528811\n",
      "Epoch [400/500] | Train Loss: 0.959013 | Val Loss: 0.545424\n",
      "Epoch [500/500] | Train Loss: 0.925942 | Val Loss: 0.555369\n",
      "Epoch [100/500] | Train Loss: 1.055594 | Val Loss: 0.556908\n",
      "Epoch [200/500] | Train Loss: 0.979545 | Val Loss: 0.550186\n",
      "Epoch [300/500] | Train Loss: 0.918212 | Val Loss: 0.549404\n",
      "Epoch [400/500] | Train Loss: 0.894182 | Val Loss: 0.558168\n",
      "Epoch [500/500] | Train Loss: 0.809312 | Val Loss: 0.556243\n",
      "Epoch [100/500] | Train Loss: 0.945787 | Val Loss: 0.978035\n",
      "Epoch [200/500] | Train Loss: 0.910344 | Val Loss: 1.025985\n",
      "Epoch [300/500] | Train Loss: 0.868199 | Val Loss: 1.114946\n",
      "Epoch [400/500] | Train Loss: 0.828635 | Val Loss: 1.133594\n",
      "Epoch [500/500] | Train Loss: 0.790385 | Val Loss: 1.190247\n",
      "Epoch [100/500] | Train Loss: 1.146798 | Val Loss: 1.492593\n",
      "Epoch [200/500] | Train Loss: 1.094025 | Val Loss: 1.728747\n",
      "Epoch [300/500] | Train Loss: 1.317022 | Val Loss: 1.663309\n",
      "Epoch [400/500] | Train Loss: 0.717766 | Val Loss: 1.706624\n",
      "Epoch [500/500] | Train Loss: 0.583627 | Val Loss: 1.779913\n",
      "Epoch [100/500] | Train Loss: 1.238683 | Val Loss: 0.683820\n",
      "Epoch [200/500] | Train Loss: 0.991607 | Val Loss: 0.724339\n",
      "Epoch [300/500] | Train Loss: 0.885174 | Val Loss: 0.759884\n",
      "Epoch [400/500] | Train Loss: 0.826181 | Val Loss: 0.801365\n",
      "Epoch [500/500] | Train Loss: 0.912599 | Val Loss: 0.778606\n",
      "Epoch [100/500] | Train Loss: 0.994996 | Val Loss: 0.557957\n",
      "Epoch [200/500] | Train Loss: 0.896053 | Val Loss: 0.600843\n",
      "Epoch [300/500] | Train Loss: 0.746540 | Val Loss: 0.615536\n",
      "Epoch [400/500] | Train Loss: 0.734662 | Val Loss: 0.603382\n",
      "Epoch [500/500] | Train Loss: 0.706233 | Val Loss: 0.637143\n",
      "Epoch [100/500] | Train Loss: 0.890201 | Val Loss: 0.571158\n",
      "Epoch [200/500] | Train Loss: 0.812554 | Val Loss: 0.585682\n",
      "Epoch [300/500] | Train Loss: 0.736972 | Val Loss: 0.604451\n",
      "Epoch [400/500] | Train Loss: 0.679061 | Val Loss: 0.603499\n",
      "Epoch [500/500] | Train Loss: 0.669025 | Val Loss: 0.624512\n",
      "Epoch [100/500] | Train Loss: 0.787302 | Val Loss: 1.051414\n",
      "Epoch [200/500] | Train Loss: 0.776146 | Val Loss: 1.174796\n",
      "Epoch [300/500] | Train Loss: 0.672963 | Val Loss: 1.272478\n",
      "Epoch [400/500] | Train Loss: 0.643586 | Val Loss: 1.155052\n",
      "Epoch [500/500] | Train Loss: 0.608766 | Val Loss: 1.202297\n",
      "[Year=2016] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.865258 Test MSE=0.756748\n",
      "Year 2016 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.589253 | Val Loss: 0.583270\n",
      "Epoch [200/500] | Train Loss: 0.518382 | Val Loss: 0.697213\n",
      "Epoch [300/500] | Train Loss: 0.421131 | Val Loss: 0.765516\n",
      "Epoch [400/500] | Train Loss: 0.361356 | Val Loss: 0.843901\n",
      "Epoch [500/500] | Train Loss: 0.311456 | Val Loss: 0.908004\n",
      "Epoch [100/500] | Train Loss: 0.586731 | Val Loss: 0.487149\n",
      "Epoch [200/500] | Train Loss: 0.537607 | Val Loss: 0.502141\n",
      "Epoch [300/500] | Train Loss: 0.498545 | Val Loss: 0.544674\n",
      "Epoch [400/500] | Train Loss: 0.458361 | Val Loss: 0.565442\n",
      "Epoch [500/500] | Train Loss: 0.435950 | Val Loss: 0.572042\n",
      "Epoch [100/500] | Train Loss: 0.557349 | Val Loss: 0.616268\n",
      "Epoch [200/500] | Train Loss: 0.526016 | Val Loss: 0.632331\n",
      "Epoch [300/500] | Train Loss: 0.510107 | Val Loss: 0.672471\n",
      "Epoch [400/500] | Train Loss: 0.476081 | Val Loss: 0.687131\n",
      "Epoch [500/500] | Train Loss: 0.462985 | Val Loss: 0.708407\n",
      "Epoch [100/500] | Train Loss: 0.572896 | Val Loss: 1.235648\n",
      "Epoch [200/500] | Train Loss: 0.562763 | Val Loss: 1.255966\n",
      "Epoch [300/500] | Train Loss: 0.549563 | Val Loss: 1.301939\n",
      "Epoch [400/500] | Train Loss: 0.528988 | Val Loss: 1.318246\n",
      "Epoch [500/500] | Train Loss: 0.508710 | Val Loss: 1.345411\n",
      "Epoch [100/500] | Train Loss: 0.686412 | Val Loss: 0.489888\n",
      "Epoch [200/500] | Train Loss: 0.646477 | Val Loss: 0.488027\n",
      "Epoch [300/500] | Train Loss: 0.611173 | Val Loss: 0.494033\n",
      "Epoch [400/500] | Train Loss: 0.585575 | Val Loss: 0.497686\n",
      "Epoch [500/500] | Train Loss: 0.585013 | Val Loss: 0.508567\n",
      "Epoch [100/500] | Train Loss: 0.330504 | Val Loss: 0.930708\n",
      "Epoch [200/500] | Train Loss: 0.254712 | Val Loss: 1.046546\n",
      "Epoch [300/500] | Train Loss: 0.215858 | Val Loss: 0.934373\n",
      "Epoch [400/500] | Train Loss: 0.154684 | Val Loss: 0.996712\n",
      "Epoch [500/500] | Train Loss: 0.140483 | Val Loss: 0.993977\n",
      "Epoch [100/500] | Train Loss: 0.517008 | Val Loss: 0.535580\n",
      "Epoch [200/500] | Train Loss: 0.464054 | Val Loss: 0.566295\n",
      "Epoch [300/500] | Train Loss: 0.403533 | Val Loss: 0.594257\n",
      "Epoch [400/500] | Train Loss: 0.371765 | Val Loss: 0.588368\n",
      "Epoch [500/500] | Train Loss: 0.353366 | Val Loss: 0.596304\n",
      "Epoch [100/500] | Train Loss: 0.479082 | Val Loss: 0.684140\n",
      "Epoch [200/500] | Train Loss: 0.376242 | Val Loss: 0.765663\n",
      "Epoch [300/500] | Train Loss: 0.336519 | Val Loss: 0.743692\n",
      "Epoch [400/500] | Train Loss: 0.313390 | Val Loss: 0.779422\n",
      "Epoch [500/500] | Train Loss: 0.288156 | Val Loss: 0.759045\n",
      "Epoch [100/500] | Train Loss: 0.468762 | Val Loss: 1.414515\n",
      "Epoch [200/500] | Train Loss: 0.422853 | Val Loss: 1.455348\n",
      "Epoch [300/500] | Train Loss: 0.382854 | Val Loss: 1.581172\n",
      "Epoch [400/500] | Train Loss: 0.372208 | Val Loss: 1.696105\n",
      "Epoch [500/500] | Train Loss: 0.336777 | Val Loss: 1.673762\n",
      "Epoch [100/500] | Train Loss: 0.619634 | Val Loss: 0.509869\n",
      "Epoch [200/500] | Train Loss: 0.521224 | Val Loss: 0.555627\n",
      "Epoch [300/500] | Train Loss: 0.484338 | Val Loss: 0.535449\n",
      "Epoch [400/500] | Train Loss: 0.495626 | Val Loss: 0.552348\n",
      "Epoch [500/500] | Train Loss: 0.458626 | Val Loss: 0.557401\n",
      "Epoch [100/500] | Train Loss: 0.657232 | Val Loss: 0.578574\n",
      "Epoch [200/500] | Train Loss: 0.583025 | Val Loss: 0.624357\n",
      "Epoch [300/500] | Train Loss: 0.524063 | Val Loss: 0.657602\n",
      "Epoch [400/500] | Train Loss: 0.459180 | Val Loss: 0.700705\n",
      "Epoch [500/500] | Train Loss: 0.421707 | Val Loss: 0.741592\n",
      "Epoch [100/500] | Train Loss: 0.618631 | Val Loss: 0.485510\n",
      "Epoch [200/500] | Train Loss: 0.578532 | Val Loss: 0.493276\n",
      "Epoch [300/500] | Train Loss: 0.567407 | Val Loss: 0.512913\n",
      "Epoch [400/500] | Train Loss: 0.569222 | Val Loss: 0.526040\n",
      "Epoch [500/500] | Train Loss: 0.518144 | Val Loss: 0.530781\n",
      "Epoch [100/500] | Train Loss: 0.559493 | Val Loss: 0.623237\n",
      "Epoch [200/500] | Train Loss: 0.539610 | Val Loss: 0.621746\n",
      "Epoch [300/500] | Train Loss: 0.532565 | Val Loss: 0.630116\n",
      "Epoch [400/500] | Train Loss: 0.521428 | Val Loss: 0.641766\n",
      "Epoch [500/500] | Train Loss: 0.531808 | Val Loss: 0.663339\n",
      "Epoch [100/500] | Train Loss: 0.584581 | Val Loss: 1.235713\n",
      "Epoch [200/500] | Train Loss: 0.581604 | Val Loss: 1.230875\n",
      "Epoch [300/500] | Train Loss: 0.561954 | Val Loss: 1.241886\n",
      "Epoch [400/500] | Train Loss: 0.559308 | Val Loss: 1.244912\n",
      "Epoch [500/500] | Train Loss: 0.547921 | Val Loss: 1.260106\n",
      "Epoch [100/500] | Train Loss: 0.700295 | Val Loss: 0.501184\n",
      "Epoch [200/500] | Train Loss: 0.689129 | Val Loss: 0.505374\n",
      "Epoch [300/500] | Train Loss: 0.667607 | Val Loss: 0.507707\n",
      "Epoch [400/500] | Train Loss: 0.666706 | Val Loss: 0.513475\n",
      "Epoch [500/500] | Train Loss: 0.637623 | Val Loss: 0.517820\n",
      "Epoch [100/500] | Train Loss: 0.443648 | Val Loss: 0.802384\n",
      "Epoch [200/500] | Train Loss: 0.344906 | Val Loss: 0.811762\n",
      "Epoch [300/500] | Train Loss: 0.316867 | Val Loss: 0.861754\n",
      "Epoch [400/500] | Train Loss: 0.375133 | Val Loss: 0.805394\n",
      "Epoch [500/500] | Train Loss: 0.257127 | Val Loss: 0.828235\n",
      "Epoch [100/500] | Train Loss: 0.515855 | Val Loss: 0.539770\n",
      "Epoch [200/500] | Train Loss: 0.448159 | Val Loss: 0.567097\n",
      "Epoch [300/500] | Train Loss: 0.428230 | Val Loss: 0.578537\n",
      "Epoch [400/500] | Train Loss: 0.403455 | Val Loss: 0.608195\n",
      "Epoch [500/500] | Train Loss: 0.391978 | Val Loss: 0.598082\n",
      "Epoch [100/500] | Train Loss: 0.506609 | Val Loss: 0.656556\n",
      "Epoch [200/500] | Train Loss: 0.501336 | Val Loss: 0.671648\n",
      "Epoch [300/500] | Train Loss: 0.467459 | Val Loss: 0.718621\n",
      "Epoch [400/500] | Train Loss: 0.420902 | Val Loss: 0.694052\n",
      "Epoch [500/500] | Train Loss: 0.447441 | Val Loss: 0.692046\n",
      "Epoch [100/500] | Train Loss: 0.551393 | Val Loss: 1.238356\n",
      "Epoch [200/500] | Train Loss: 0.519678 | Val Loss: 1.293827\n",
      "Epoch [300/500] | Train Loss: 0.462596 | Val Loss: 1.307620\n",
      "Epoch [400/500] | Train Loss: 0.461356 | Val Loss: 1.351079\n",
      "Epoch [500/500] | Train Loss: 0.442666 | Val Loss: 1.366794\n",
      "Epoch [100/500] | Train Loss: 0.653205 | Val Loss: 0.503679\n",
      "Epoch [200/500] | Train Loss: 0.604264 | Val Loss: 0.514273\n",
      "Epoch [300/500] | Train Loss: 0.571918 | Val Loss: 0.528311\n",
      "Epoch [400/500] | Train Loss: 0.575480 | Val Loss: 0.528553\n",
      "Epoch [500/500] | Train Loss: 0.533348 | Val Loss: 0.533405\n",
      "Epoch [100/500] | Train Loss: 0.513323 | Val Loss: 0.635019\n",
      "Epoch [200/500] | Train Loss: 0.448482 | Val Loss: 0.718642\n",
      "Epoch [300/500] | Train Loss: 0.388426 | Val Loss: 0.765218\n",
      "Epoch [400/500] | Train Loss: 0.309069 | Val Loss: 0.852677\n",
      "Epoch [500/500] | Train Loss: 0.280623 | Val Loss: 0.875496\n",
      "Epoch [100/500] | Train Loss: 0.595968 | Val Loss: 0.484817\n",
      "Epoch [200/500] | Train Loss: 0.527459 | Val Loss: 0.521273\n",
      "Epoch [300/500] | Train Loss: 0.469899 | Val Loss: 0.557855\n",
      "Epoch [400/500] | Train Loss: 0.450461 | Val Loss: 0.586951\n",
      "Epoch [500/500] | Train Loss: 0.390200 | Val Loss: 0.593375\n",
      "Epoch [100/500] | Train Loss: 0.559587 | Val Loss: 0.624713\n",
      "Epoch [200/500] | Train Loss: 0.501959 | Val Loss: 0.631805\n",
      "Epoch [300/500] | Train Loss: 0.469016 | Val Loss: 0.675117\n",
      "Epoch [400/500] | Train Loss: 0.420277 | Val Loss: 0.744372\n",
      "Epoch [500/500] | Train Loss: 0.395736 | Val Loss: 0.769344\n",
      "Epoch [100/500] | Train Loss: 0.582744 | Val Loss: 1.236919\n",
      "Epoch [200/500] | Train Loss: 0.559908 | Val Loss: 1.248420\n",
      "Epoch [300/500] | Train Loss: 0.513603 | Val Loss: 1.289001\n",
      "Epoch [400/500] | Train Loss: 0.466604 | Val Loss: 1.366572\n",
      "Epoch [500/500] | Train Loss: 0.432036 | Val Loss: 1.447868\n",
      "Epoch [100/500] | Train Loss: 0.715157 | Val Loss: 0.495441\n",
      "Epoch [200/500] | Train Loss: 0.629818 | Val Loss: 0.511948\n",
      "Epoch [300/500] | Train Loss: 0.588285 | Val Loss: 0.535111\n",
      "Epoch [400/500] | Train Loss: 0.552601 | Val Loss: 0.538294\n",
      "Epoch [500/500] | Train Loss: 0.525724 | Val Loss: 0.534573\n",
      "Epoch [100/500] | Train Loss: 0.287535 | Val Loss: 0.946072\n",
      "Epoch [200/500] | Train Loss: 0.170403 | Val Loss: 1.046778\n",
      "Epoch [300/500] | Train Loss: 0.169514 | Val Loss: 0.994066\n",
      "Epoch [400/500] | Train Loss: 0.149338 | Val Loss: 0.917313\n",
      "Epoch [500/500] | Train Loss: 0.119359 | Val Loss: 0.935697\n",
      "Epoch [100/500] | Train Loss: 0.343216 | Val Loss: 0.612757\n",
      "Epoch [200/500] | Train Loss: 0.293130 | Val Loss: 0.659077\n",
      "Epoch [300/500] | Train Loss: 0.227054 | Val Loss: 0.654206\n",
      "Epoch [400/500] | Train Loss: 0.202672 | Val Loss: 0.653828\n",
      "Epoch [500/500] | Train Loss: 0.195291 | Val Loss: 0.672646\n",
      "Epoch [100/500] | Train Loss: 0.435008 | Val Loss: 0.677271\n",
      "Epoch [200/500] | Train Loss: 0.324740 | Val Loss: 0.729277\n",
      "Epoch [300/500] | Train Loss: 0.295599 | Val Loss: 0.733898\n",
      "Epoch [400/500] | Train Loss: 0.301473 | Val Loss: 0.777609\n",
      "Epoch [500/500] | Train Loss: 0.299273 | Val Loss: 0.807793\n",
      "Epoch [100/500] | Train Loss: 0.488247 | Val Loss: 1.350015\n",
      "Epoch [200/500] | Train Loss: 0.387278 | Val Loss: 1.471312\n",
      "Epoch [300/500] | Train Loss: 0.350507 | Val Loss: 1.475390\n",
      "Epoch [400/500] | Train Loss: 0.306851 | Val Loss: 1.483775\n",
      "Epoch [500/500] | Train Loss: 0.327878 | Val Loss: 1.549209\n",
      "Epoch [100/500] | Train Loss: 0.617299 | Val Loss: 0.505245\n",
      "Epoch [200/500] | Train Loss: 0.496284 | Val Loss: 0.548721\n",
      "Epoch [300/500] | Train Loss: 0.441786 | Val Loss: 0.542193\n",
      "Epoch [400/500] | Train Loss: 0.405972 | Val Loss: 0.539062\n",
      "Epoch [500/500] | Train Loss: 0.407481 | Val Loss: 0.557359\n",
      "Epoch [100/500] | Train Loss: 0.664039 | Val Loss: 0.578123\n",
      "Epoch [200/500] | Train Loss: 0.575613 | Val Loss: 0.637330\n",
      "Epoch [300/500] | Train Loss: 0.505658 | Val Loss: 0.681163\n",
      "Epoch [400/500] | Train Loss: 0.452842 | Val Loss: 0.700296\n",
      "Epoch [500/500] | Train Loss: 0.386845 | Val Loss: 0.736575\n",
      "Epoch [100/500] | Train Loss: 0.599213 | Val Loss: 0.490093\n",
      "Epoch [200/500] | Train Loss: 0.571670 | Val Loss: 0.501010\n",
      "Epoch [300/500] | Train Loss: 0.536535 | Val Loss: 0.510523\n",
      "Epoch [400/500] | Train Loss: 0.539630 | Val Loss: 0.538279\n",
      "Epoch [500/500] | Train Loss: 0.491402 | Val Loss: 0.548234\n",
      "Epoch [100/500] | Train Loss: 0.557139 | Val Loss: 0.628316\n",
      "Epoch [200/500] | Train Loss: 0.548618 | Val Loss: 0.636159\n",
      "Epoch [300/500] | Train Loss: 0.499110 | Val Loss: 0.644124\n",
      "Epoch [400/500] | Train Loss: 0.473037 | Val Loss: 0.658394\n",
      "Epoch [500/500] | Train Loss: 0.460631 | Val Loss: 0.670704\n",
      "Epoch [100/500] | Train Loss: 0.586210 | Val Loss: 1.223752\n",
      "Epoch [200/500] | Train Loss: 0.566834 | Val Loss: 1.203872\n",
      "Epoch [300/500] | Train Loss: 0.555353 | Val Loss: 1.217776\n",
      "Epoch [400/500] | Train Loss: 0.539532 | Val Loss: 1.263342\n",
      "Epoch [500/500] | Train Loss: 0.508098 | Val Loss: 1.299956\n",
      "Epoch [100/500] | Train Loss: 0.697824 | Val Loss: 0.489281\n",
      "Epoch [200/500] | Train Loss: 0.660574 | Val Loss: 0.486029\n",
      "Epoch [300/500] | Train Loss: 0.633469 | Val Loss: 0.493731\n",
      "Epoch [400/500] | Train Loss: 0.628294 | Val Loss: 0.493580\n",
      "Epoch [500/500] | Train Loss: 0.603645 | Val Loss: 0.500100\n",
      "Epoch [100/500] | Train Loss: 0.369771 | Val Loss: 0.792919\n",
      "Epoch [200/500] | Train Loss: 0.307907 | Val Loss: 0.787552\n",
      "Epoch [300/500] | Train Loss: 0.234393 | Val Loss: 0.881009\n",
      "Epoch [400/500] | Train Loss: 0.213367 | Val Loss: 0.927534\n",
      "Epoch [500/500] | Train Loss: 0.216816 | Val Loss: 0.857957\n",
      "Epoch [100/500] | Train Loss: 0.483199 | Val Loss: 0.560662\n",
      "Epoch [200/500] | Train Loss: 0.400935 | Val Loss: 0.593646\n",
      "Epoch [300/500] | Train Loss: 0.371552 | Val Loss: 0.611113\n",
      "Epoch [400/500] | Train Loss: 0.339173 | Val Loss: 0.649634\n",
      "Epoch [500/500] | Train Loss: 0.359519 | Val Loss: 0.624408\n",
      "Epoch [100/500] | Train Loss: 0.489547 | Val Loss: 0.655340\n",
      "Epoch [200/500] | Train Loss: 0.459315 | Val Loss: 0.696805\n",
      "Epoch [300/500] | Train Loss: 0.410131 | Val Loss: 0.710987\n",
      "Epoch [400/500] | Train Loss: 0.421789 | Val Loss: 0.774546\n",
      "Epoch [500/500] | Train Loss: 0.371340 | Val Loss: 0.759111\n",
      "Epoch [100/500] | Train Loss: 0.529705 | Val Loss: 1.224382\n",
      "Epoch [200/500] | Train Loss: 0.489562 | Val Loss: 1.298558\n",
      "Epoch [300/500] | Train Loss: 0.442082 | Val Loss: 1.389371\n",
      "Epoch [400/500] | Train Loss: 0.429024 | Val Loss: 1.330688\n",
      "Epoch [500/500] | Train Loss: 0.413631 | Val Loss: 1.371117\n",
      "Epoch [100/500] | Train Loss: 0.628699 | Val Loss: 0.521911\n",
      "Epoch [200/500] | Train Loss: 0.596801 | Val Loss: 0.528458\n",
      "Epoch [300/500] | Train Loss: 0.582173 | Val Loss: 0.546303\n",
      "Epoch [400/500] | Train Loss: 0.536492 | Val Loss: 0.545366\n",
      "Epoch [500/500] | Train Loss: 0.503483 | Val Loss: 0.549963\n",
      "[Year=2017] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.742728 Test MSE=0.218307\n",
      "Year 2017 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.482313 | Val Loss: 0.487599\n",
      "Epoch [200/500] | Train Loss: 0.429917 | Val Loss: 0.536538\n",
      "Epoch [300/500] | Train Loss: 0.334804 | Val Loss: 0.571247\n",
      "Epoch [400/500] | Train Loss: 0.288579 | Val Loss: 0.606876\n",
      "Epoch [500/500] | Train Loss: 0.311221 | Val Loss: 0.591527\n",
      "Epoch [100/500] | Train Loss: 0.486386 | Val Loss: 0.634484\n",
      "Epoch [200/500] | Train Loss: 0.464005 | Val Loss: 0.638428\n",
      "Epoch [300/500] | Train Loss: 0.418790 | Val Loss: 0.646614\n",
      "Epoch [400/500] | Train Loss: 0.406939 | Val Loss: 0.683134\n",
      "Epoch [500/500] | Train Loss: 0.371553 | Val Loss: 0.674490\n",
      "Epoch [100/500] | Train Loss: 0.524383 | Val Loss: 1.267402\n",
      "Epoch [200/500] | Train Loss: 0.481754 | Val Loss: 1.342679\n",
      "Epoch [300/500] | Train Loss: 0.433206 | Val Loss: 1.378200\n",
      "Epoch [400/500] | Train Loss: 0.422596 | Val Loss: 1.464713\n",
      "Epoch [500/500] | Train Loss: 0.391798 | Val Loss: 1.491593\n",
      "Epoch [100/500] | Train Loss: 0.704501 | Val Loss: 0.445796\n",
      "Epoch [200/500] | Train Loss: 0.635718 | Val Loss: 0.439079\n",
      "Epoch [300/500] | Train Loss: 0.595434 | Val Loss: 0.470780\n",
      "Epoch [400/500] | Train Loss: 0.560047 | Val Loss: 0.484877\n",
      "Epoch [500/500] | Train Loss: 0.523752 | Val Loss: 0.490521\n",
      "Epoch [100/500] | Train Loss: 0.656111 | Val Loss: 0.205415\n",
      "Epoch [200/500] | Train Loss: 0.623464 | Val Loss: 0.210890\n",
      "Epoch [300/500] | Train Loss: 0.585384 | Val Loss: 0.218792\n",
      "Epoch [400/500] | Train Loss: 0.568323 | Val Loss: 0.223066\n",
      "Epoch [500/500] | Train Loss: 0.545345 | Val Loss: 0.227234\n",
      "Epoch [100/500] | Train Loss: 0.407769 | Val Loss: 0.536502\n",
      "Epoch [200/500] | Train Loss: 0.350193 | Val Loss: 0.605068\n",
      "Epoch [300/500] | Train Loss: 0.203094 | Val Loss: 0.573664\n",
      "Epoch [400/500] | Train Loss: 0.167833 | Val Loss: 0.585673\n",
      "Epoch [500/500] | Train Loss: 0.148217 | Val Loss: 0.641227\n",
      "Epoch [100/500] | Train Loss: 0.337874 | Val Loss: 0.628566\n",
      "Epoch [200/500] | Train Loss: 0.317913 | Val Loss: 0.657092\n",
      "Epoch [300/500] | Train Loss: 0.269399 | Val Loss: 0.722035\n",
      "Epoch [400/500] | Train Loss: 0.267809 | Val Loss: 0.688948\n",
      "Epoch [500/500] | Train Loss: 0.248059 | Val Loss: 0.710343\n",
      "Epoch [100/500] | Train Loss: 0.424599 | Val Loss: 1.557265\n",
      "Epoch [200/500] | Train Loss: 0.340553 | Val Loss: 1.623181\n",
      "Epoch [300/500] | Train Loss: 0.284505 | Val Loss: 1.589897\n",
      "Epoch [400/500] | Train Loss: 0.272657 | Val Loss: 1.630040\n",
      "Epoch [500/500] | Train Loss: 0.255790 | Val Loss: 1.618561\n",
      "Epoch [100/500] | Train Loss: 0.539339 | Val Loss: 0.467799\n",
      "Epoch [200/500] | Train Loss: 0.447980 | Val Loss: 0.489885\n",
      "Epoch [300/500] | Train Loss: 0.458956 | Val Loss: 0.503950\n",
      "Epoch [400/500] | Train Loss: 0.437749 | Val Loss: 0.496743\n",
      "Epoch [500/500] | Train Loss: 0.432011 | Val Loss: 0.519776\n",
      "Epoch [100/500] | Train Loss: 0.548749 | Val Loss: 0.218528\n",
      "Epoch [200/500] | Train Loss: 0.465253 | Val Loss: 0.236317\n",
      "Epoch [300/500] | Train Loss: 0.404915 | Val Loss: 0.252992\n",
      "Epoch [400/500] | Train Loss: 0.414057 | Val Loss: 0.267619\n",
      "Epoch [500/500] | Train Loss: 0.383344 | Val Loss: 0.286557\n",
      "Epoch [100/500] | Train Loss: 0.496159 | Val Loss: 0.462612\n",
      "Epoch [200/500] | Train Loss: 0.494810 | Val Loss: 0.474084\n",
      "Epoch [300/500] | Train Loss: 0.461084 | Val Loss: 0.500047\n",
      "Epoch [400/500] | Train Loss: 0.371400 | Val Loss: 0.521050\n",
      "Epoch [500/500] | Train Loss: 0.346153 | Val Loss: 0.518699\n",
      "Epoch [100/500] | Train Loss: 0.494660 | Val Loss: 0.635263\n",
      "Epoch [200/500] | Train Loss: 0.480198 | Val Loss: 0.635440\n",
      "Epoch [300/500] | Train Loss: 0.468420 | Val Loss: 0.641374\n",
      "Epoch [400/500] | Train Loss: 0.441339 | Val Loss: 0.638123\n",
      "Epoch [500/500] | Train Loss: 0.394600 | Val Loss: 0.640460\n",
      "Epoch [100/500] | Train Loss: 0.540355 | Val Loss: 1.259110\n",
      "Epoch [200/500] | Train Loss: 0.517484 | Val Loss: 1.291089\n",
      "Epoch [300/500] | Train Loss: 0.488621 | Val Loss: 1.313932\n",
      "Epoch [400/500] | Train Loss: 0.463099 | Val Loss: 1.352986\n",
      "Epoch [500/500] | Train Loss: 0.456290 | Val Loss: 1.394581\n",
      "Epoch [100/500] | Train Loss: 0.714558 | Val Loss: 0.463133\n",
      "Epoch [200/500] | Train Loss: 0.717384 | Val Loss: 0.454759\n",
      "Epoch [300/500] | Train Loss: 0.670304 | Val Loss: 0.453794\n",
      "Epoch [400/500] | Train Loss: 0.672211 | Val Loss: 0.454613\n",
      "Epoch [500/500] | Train Loss: 0.690990 | Val Loss: 0.457435\n",
      "Epoch [100/500] | Train Loss: 0.661212 | Val Loss: 0.203181\n",
      "Epoch [200/500] | Train Loss: 0.637653 | Val Loss: 0.208533\n",
      "Epoch [300/500] | Train Loss: 0.601774 | Val Loss: 0.210712\n",
      "Epoch [400/500] | Train Loss: 0.588363 | Val Loss: 0.211932\n",
      "Epoch [500/500] | Train Loss: 0.584093 | Val Loss: 0.213787\n",
      "Epoch [100/500] | Train Loss: 0.431283 | Val Loss: 0.519159\n",
      "Epoch [200/500] | Train Loss: 0.334591 | Val Loss: 0.539690\n",
      "Epoch [300/500] | Train Loss: 0.311301 | Val Loss: 0.536200\n",
      "Epoch [400/500] | Train Loss: 0.222343 | Val Loss: 0.566527\n",
      "Epoch [500/500] | Train Loss: 0.241719 | Val Loss: 0.594771\n",
      "Epoch [100/500] | Train Loss: 0.447082 | Val Loss: 0.653375\n",
      "Epoch [200/500] | Train Loss: 0.378284 | Val Loss: 0.689701\n",
      "Epoch [300/500] | Train Loss: 0.303244 | Val Loss: 0.711483\n",
      "Epoch [400/500] | Train Loss: 0.331484 | Val Loss: 0.697679\n",
      "Epoch [500/500] | Train Loss: 0.328707 | Val Loss: 0.743994\n",
      "Epoch [100/500] | Train Loss: 0.471661 | Val Loss: 1.275985\n",
      "Epoch [200/500] | Train Loss: 0.416463 | Val Loss: 1.397748\n",
      "Epoch [300/500] | Train Loss: 0.413989 | Val Loss: 1.418979\n",
      "Epoch [400/500] | Train Loss: 0.383970 | Val Loss: 1.451741\n",
      "Epoch [500/500] | Train Loss: 0.360453 | Val Loss: 1.405117\n",
      "Epoch [100/500] | Train Loss: 0.651259 | Val Loss: 0.448568\n",
      "Epoch [200/500] | Train Loss: 0.631745 | Val Loss: 0.460594\n",
      "Epoch [300/500] | Train Loss: 0.544443 | Val Loss: 0.472481\n",
      "Epoch [400/500] | Train Loss: 0.560316 | Val Loss: 0.477801\n",
      "Epoch [500/500] | Train Loss: 0.609831 | Val Loss: 0.475959\n",
      "Epoch [100/500] | Train Loss: 0.598869 | Val Loss: 0.218103\n",
      "Epoch [200/500] | Train Loss: 0.524547 | Val Loss: 0.225627\n",
      "Epoch [300/500] | Train Loss: 0.528729 | Val Loss: 0.236787\n",
      "Epoch [400/500] | Train Loss: 0.482815 | Val Loss: 0.227461\n",
      "Epoch [500/500] | Train Loss: 0.477457 | Val Loss: 0.250014\n",
      "Epoch [100/500] | Train Loss: 0.509011 | Val Loss: 0.466500\n",
      "Epoch [200/500] | Train Loss: 0.384595 | Val Loss: 0.560582\n",
      "Epoch [300/500] | Train Loss: 0.310360 | Val Loss: 0.583677\n",
      "Epoch [400/500] | Train Loss: 0.282591 | Val Loss: 0.590606\n",
      "Epoch [500/500] | Train Loss: 0.249375 | Val Loss: 0.599816\n",
      "Epoch [100/500] | Train Loss: 0.488759 | Val Loss: 0.638601\n",
      "Epoch [200/500] | Train Loss: 0.443316 | Val Loss: 0.651090\n",
      "Epoch [300/500] | Train Loss: 0.369855 | Val Loss: 0.691593\n",
      "Epoch [400/500] | Train Loss: 0.320755 | Val Loss: 0.707092\n",
      "Epoch [500/500] | Train Loss: 0.276667 | Val Loss: 0.737071\n",
      "Epoch [100/500] | Train Loss: 0.503962 | Val Loss: 1.293641\n",
      "Epoch [200/500] | Train Loss: 0.435735 | Val Loss: 1.360359\n",
      "Epoch [300/500] | Train Loss: 0.404139 | Val Loss: 1.400795\n",
      "Epoch [400/500] | Train Loss: 0.387875 | Val Loss: 1.456603\n",
      "Epoch [500/500] | Train Loss: 0.356924 | Val Loss: 1.482652\n",
      "Epoch [100/500] | Train Loss: 0.671187 | Val Loss: 0.422212\n",
      "Epoch [200/500] | Train Loss: 0.607163 | Val Loss: 0.430389\n",
      "Epoch [300/500] | Train Loss: 0.541496 | Val Loss: 0.453921\n",
      "Epoch [400/500] | Train Loss: 0.516469 | Val Loss: 0.460837\n",
      "Epoch [500/500] | Train Loss: 0.485147 | Val Loss: 0.475478\n",
      "Epoch [100/500] | Train Loss: 0.645396 | Val Loss: 0.208394\n",
      "Epoch [200/500] | Train Loss: 0.569059 | Val Loss: 0.219977\n",
      "Epoch [300/500] | Train Loss: 0.535277 | Val Loss: 0.219685\n",
      "Epoch [400/500] | Train Loss: 0.490720 | Val Loss: 0.229770\n",
      "Epoch [500/500] | Train Loss: 0.467305 | Val Loss: 0.233102\n",
      "Epoch [100/500] | Train Loss: 0.221037 | Val Loss: 0.615285\n",
      "Epoch [200/500] | Train Loss: 0.181293 | Val Loss: 0.636838\n",
      "Epoch [300/500] | Train Loss: 0.132339 | Val Loss: 0.633407\n",
      "Epoch [400/500] | Train Loss: 0.109170 | Val Loss: 0.640858\n",
      "Epoch [500/500] | Train Loss: 0.099148 | Val Loss: 0.653614\n",
      "Epoch [100/500] | Train Loss: 0.283264 | Val Loss: 0.742296\n",
      "Epoch [200/500] | Train Loss: 0.223987 | Val Loss: 0.777208\n",
      "Epoch [300/500] | Train Loss: 0.207571 | Val Loss: 0.771867\n",
      "Epoch [400/500] | Train Loss: 0.151111 | Val Loss: 0.851884\n",
      "Epoch [500/500] | Train Loss: 0.161029 | Val Loss: 0.791772\n",
      "Epoch [100/500] | Train Loss: 0.350244 | Val Loss: 1.495243\n",
      "Epoch [200/500] | Train Loss: 0.253028 | Val Loss: 1.468151\n",
      "Epoch [300/500] | Train Loss: 0.204519 | Val Loss: 1.421633\n",
      "Epoch [400/500] | Train Loss: 0.222286 | Val Loss: 1.467607\n",
      "Epoch [500/500] | Train Loss: 0.199108 | Val Loss: 1.465583\n",
      "Epoch [100/500] | Train Loss: 0.544499 | Val Loss: 0.496184\n",
      "Epoch [200/500] | Train Loss: 0.408304 | Val Loss: 0.475188\n",
      "Epoch [300/500] | Train Loss: 0.345698 | Val Loss: 0.490175\n",
      "Epoch [400/500] | Train Loss: 0.343010 | Val Loss: 0.524672\n",
      "Epoch [500/500] | Train Loss: 0.302505 | Val Loss: 0.569473\n",
      "Epoch [100/500] | Train Loss: 0.572250 | Val Loss: 0.208462\n",
      "Epoch [200/500] | Train Loss: 0.501451 | Val Loss: 0.247482\n",
      "Epoch [300/500] | Train Loss: 0.432209 | Val Loss: 0.252871\n",
      "Epoch [400/500] | Train Loss: 0.394886 | Val Loss: 0.265014\n",
      "Epoch [500/500] | Train Loss: 0.365378 | Val Loss: 0.289302\n",
      "Epoch [100/500] | Train Loss: 0.486179 | Val Loss: 0.477430\n",
      "Epoch [200/500] | Train Loss: 0.412865 | Val Loss: 0.545646\n",
      "Epoch [300/500] | Train Loss: 0.389730 | Val Loss: 0.553048\n",
      "Epoch [400/500] | Train Loss: 0.330934 | Val Loss: 0.561726\n",
      "Epoch [500/500] | Train Loss: 0.308645 | Val Loss: 0.560271\n",
      "Epoch [100/500] | Train Loss: 0.484045 | Val Loss: 0.632929\n",
      "Epoch [200/500] | Train Loss: 0.461174 | Val Loss: 0.632879\n",
      "Epoch [300/500] | Train Loss: 0.434851 | Val Loss: 0.633382\n",
      "Epoch [400/500] | Train Loss: 0.412645 | Val Loss: 0.616227\n",
      "Epoch [500/500] | Train Loss: 0.382477 | Val Loss: 0.620566\n",
      "Epoch [100/500] | Train Loss: 0.536110 | Val Loss: 1.260608\n",
      "Epoch [200/500] | Train Loss: 0.511921 | Val Loss: 1.286892\n",
      "Epoch [300/500] | Train Loss: 0.471169 | Val Loss: 1.322850\n",
      "Epoch [400/500] | Train Loss: 0.444135 | Val Loss: 1.381452\n",
      "Epoch [500/500] | Train Loss: 0.428097 | Val Loss: 1.414966\n",
      "Epoch [100/500] | Train Loss: 0.717118 | Val Loss: 0.456712\n",
      "Epoch [200/500] | Train Loss: 0.714567 | Val Loss: 0.449050\n",
      "Epoch [300/500] | Train Loss: 0.675599 | Val Loss: 0.442729\n",
      "Epoch [400/500] | Train Loss: 0.646331 | Val Loss: 0.448092\n",
      "Epoch [500/500] | Train Loss: 0.605770 | Val Loss: 0.463071\n",
      "Epoch [100/500] | Train Loss: 0.664682 | Val Loss: 0.210357\n",
      "Epoch [200/500] | Train Loss: 0.628485 | Val Loss: 0.214094\n",
      "Epoch [300/500] | Train Loss: 0.592629 | Val Loss: 0.216311\n",
      "Epoch [400/500] | Train Loss: 0.587702 | Val Loss: 0.220290\n",
      "Epoch [500/500] | Train Loss: 0.566147 | Val Loss: 0.226799\n",
      "Epoch [100/500] | Train Loss: 0.381424 | Val Loss: 0.550170\n",
      "Epoch [200/500] | Train Loss: 0.301721 | Val Loss: 0.552636\n",
      "Epoch [300/500] | Train Loss: 0.236238 | Val Loss: 0.592816\n",
      "Epoch [400/500] | Train Loss: 0.216422 | Val Loss: 0.605492\n",
      "Epoch [500/500] | Train Loss: 0.220712 | Val Loss: 0.618532\n",
      "Epoch [100/500] | Train Loss: 0.400555 | Val Loss: 0.653463\n",
      "Epoch [200/500] | Train Loss: 0.323422 | Val Loss: 0.673209\n",
      "Epoch [300/500] | Train Loss: 0.319907 | Val Loss: 0.714133\n",
      "Epoch [400/500] | Train Loss: 0.240897 | Val Loss: 0.676953\n",
      "Epoch [500/500] | Train Loss: 0.284426 | Val Loss: 0.699185\n",
      "Epoch [100/500] | Train Loss: 0.446000 | Val Loss: 1.419412\n",
      "Epoch [200/500] | Train Loss: 0.363235 | Val Loss: 1.563661\n",
      "Epoch [300/500] | Train Loss: 0.341323 | Val Loss: 1.688764\n",
      "Epoch [400/500] | Train Loss: 0.345797 | Val Loss: 1.596466\n",
      "Epoch [500/500] | Train Loss: 0.307881 | Val Loss: 1.735022\n",
      "Epoch [100/500] | Train Loss: 0.627651 | Val Loss: 0.441502\n",
      "Epoch [200/500] | Train Loss: 0.582167 | Val Loss: 0.462423\n",
      "Epoch [300/500] | Train Loss: 0.488737 | Val Loss: 0.466897\n",
      "Epoch [400/500] | Train Loss: 0.449474 | Val Loss: 0.475122\n",
      "Epoch [500/500] | Train Loss: 0.473094 | Val Loss: 0.484985\n",
      "Epoch [100/500] | Train Loss: 0.562566 | Val Loss: 0.216097\n",
      "Epoch [200/500] | Train Loss: 0.527770 | Val Loss: 0.231297\n",
      "Epoch [300/500] | Train Loss: 0.479679 | Val Loss: 0.237988\n",
      "Epoch [400/500] | Train Loss: 0.499519 | Val Loss: 0.246531\n",
      "Epoch [500/500] | Train Loss: 0.474031 | Val Loss: 0.251599\n",
      "[Year=2018] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.644992 Test MSE=1.288785\n",
      "Year 2018 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.513820 | Val Loss: 0.856191\n",
      "Epoch [200/500] | Train Loss: 0.410208 | Val Loss: 1.052618\n",
      "Epoch [300/500] | Train Loss: 0.341936 | Val Loss: 1.195987\n",
      "Epoch [400/500] | Train Loss: 0.339085 | Val Loss: 1.282582\n",
      "Epoch [500/500] | Train Loss: 0.290026 | Val Loss: 1.309290\n",
      "Epoch [100/500] | Train Loss: 0.615777 | Val Loss: 1.099385\n",
      "Epoch [200/500] | Train Loss: 0.515705 | Val Loss: 1.149698\n",
      "Epoch [300/500] | Train Loss: 0.467892 | Val Loss: 1.227532\n",
      "Epoch [400/500] | Train Loss: 0.407505 | Val Loss: 1.255925\n",
      "Epoch [500/500] | Train Loss: 0.433161 | Val Loss: 1.317340\n",
      "Epoch [100/500] | Train Loss: 0.789553 | Val Loss: 0.316547\n",
      "Epoch [200/500] | Train Loss: 0.703855 | Val Loss: 0.330499\n",
      "Epoch [300/500] | Train Loss: 0.649206 | Val Loss: 0.350954\n",
      "Epoch [400/500] | Train Loss: 0.584814 | Val Loss: 0.369411\n",
      "Epoch [500/500] | Train Loss: 0.539236 | Val Loss: 0.380597\n",
      "Epoch [100/500] | Train Loss: 0.675178 | Val Loss: 0.463295\n",
      "Epoch [200/500] | Train Loss: 0.641256 | Val Loss: 0.487220\n",
      "Epoch [300/500] | Train Loss: 0.615747 | Val Loss: 0.486785\n",
      "Epoch [400/500] | Train Loss: 0.552947 | Val Loss: 0.482814\n",
      "Epoch [500/500] | Train Loss: 0.530409 | Val Loss: 0.464012\n",
      "Epoch [100/500] | Train Loss: 0.632774 | Val Loss: 1.126685\n",
      "Epoch [200/500] | Train Loss: 0.560926 | Val Loss: 1.192858\n",
      "Epoch [300/500] | Train Loss: 0.557030 | Val Loss: 1.256414\n",
      "Epoch [400/500] | Train Loss: 0.518936 | Val Loss: 1.269238\n",
      "Epoch [500/500] | Train Loss: 0.472636 | Val Loss: 1.308177\n",
      "Epoch [100/500] | Train Loss: 0.321519 | Val Loss: 0.964602\n",
      "Epoch [200/500] | Train Loss: 0.251669 | Val Loss: 1.052086\n",
      "Epoch [300/500] | Train Loss: 0.223889 | Val Loss: 1.104739\n",
      "Epoch [400/500] | Train Loss: 0.184681 | Val Loss: 1.131750\n",
      "Epoch [500/500] | Train Loss: 0.186475 | Val Loss: 1.079553\n",
      "Epoch [100/500] | Train Loss: 0.475779 | Val Loss: 1.164485\n",
      "Epoch [200/500] | Train Loss: 0.383401 | Val Loss: 1.331444\n",
      "Epoch [300/500] | Train Loss: 0.363476 | Val Loss: 1.310861\n",
      "Epoch [400/500] | Train Loss: 0.313944 | Val Loss: 1.327113\n",
      "Epoch [500/500] | Train Loss: 0.264767 | Val Loss: 1.441239\n",
      "Epoch [100/500] | Train Loss: 0.597249 | Val Loss: 0.344530\n",
      "Epoch [200/500] | Train Loss: 0.543953 | Val Loss: 0.374126\n",
      "Epoch [300/500] | Train Loss: 0.457764 | Val Loss: 0.344230\n",
      "Epoch [400/500] | Train Loss: 0.460917 | Val Loss: 0.366575\n",
      "Epoch [500/500] | Train Loss: 0.408787 | Val Loss: 0.392124\n",
      "Epoch [100/500] | Train Loss: 0.573073 | Val Loss: 0.486495\n",
      "Epoch [200/500] | Train Loss: 0.461548 | Val Loss: 0.543664\n",
      "Epoch [300/500] | Train Loss: 0.422132 | Val Loss: 0.566458\n",
      "Epoch [400/500] | Train Loss: 0.386447 | Val Loss: 0.513497\n",
      "Epoch [500/500] | Train Loss: 0.374799 | Val Loss: 0.540725\n",
      "Epoch [100/500] | Train Loss: 0.511493 | Val Loss: 1.415100\n",
      "Epoch [200/500] | Train Loss: 0.455413 | Val Loss: 1.418152\n",
      "Epoch [300/500] | Train Loss: 0.448518 | Val Loss: 1.487507\n",
      "Epoch [400/500] | Train Loss: 0.407721 | Val Loss: 1.520823\n",
      "Epoch [500/500] | Train Loss: 0.406002 | Val Loss: 1.484549\n",
      "Epoch [100/500] | Train Loss: 0.565070 | Val Loss: 0.823578\n",
      "Epoch [200/500] | Train Loss: 0.516162 | Val Loss: 0.840415\n",
      "Epoch [300/500] | Train Loss: 0.477984 | Val Loss: 0.834049\n",
      "Epoch [400/500] | Train Loss: 0.461704 | Val Loss: 0.864156\n",
      "Epoch [500/500] | Train Loss: 0.435584 | Val Loss: 0.963143\n",
      "Epoch [100/500] | Train Loss: 0.675826 | Val Loss: 1.078257\n",
      "Epoch [200/500] | Train Loss: 0.607781 | Val Loss: 1.093237\n",
      "Epoch [300/500] | Train Loss: 0.577975 | Val Loss: 1.115018\n",
      "Epoch [400/500] | Train Loss: 0.529125 | Val Loss: 1.112255\n",
      "Epoch [500/500] | Train Loss: 0.523536 | Val Loss: 1.129727\n",
      "Epoch [100/500] | Train Loss: 0.814651 | Val Loss: 0.310860\n",
      "Epoch [200/500] | Train Loss: 0.773190 | Val Loss: 0.312474\n",
      "Epoch [300/500] | Train Loss: 0.754204 | Val Loss: 0.313578\n",
      "Epoch [400/500] | Train Loss: 0.711309 | Val Loss: 0.315332\n",
      "Epoch [500/500] | Train Loss: 0.709110 | Val Loss: 0.320924\n",
      "Epoch [100/500] | Train Loss: 0.685286 | Val Loss: 0.471947\n",
      "Epoch [200/500] | Train Loss: 0.661152 | Val Loss: 0.471411\n",
      "Epoch [300/500] | Train Loss: 0.613757 | Val Loss: 0.494028\n",
      "Epoch [400/500] | Train Loss: 0.578234 | Val Loss: 0.512101\n",
      "Epoch [500/500] | Train Loss: 0.579531 | Val Loss: 0.536865\n",
      "Epoch [100/500] | Train Loss: 0.626490 | Val Loss: 1.130388\n",
      "Epoch [200/500] | Train Loss: 0.619339 | Val Loss: 1.190018\n",
      "Epoch [300/500] | Train Loss: 0.596668 | Val Loss: 1.214053\n",
      "Epoch [400/500] | Train Loss: 0.551880 | Val Loss: 1.226068\n",
      "Epoch [500/500] | Train Loss: 0.549208 | Val Loss: 1.213667\n",
      "Epoch [100/500] | Train Loss: 0.425910 | Val Loss: 0.821775\n",
      "Epoch [200/500] | Train Loss: 0.347760 | Val Loss: 0.877210\n",
      "Epoch [300/500] | Train Loss: 0.312565 | Val Loss: 0.875345\n",
      "Epoch [400/500] | Train Loss: 0.276889 | Val Loss: 0.891677\n",
      "Epoch [500/500] | Train Loss: 0.254001 | Val Loss: 0.879563\n",
      "Epoch [100/500] | Train Loss: 0.609503 | Val Loss: 1.098549\n",
      "Epoch [200/500] | Train Loss: 0.526215 | Val Loss: 1.188176\n",
      "Epoch [300/500] | Train Loss: 0.462557 | Val Loss: 1.233565\n",
      "Epoch [400/500] | Train Loss: 0.393148 | Val Loss: 1.242443\n",
      "Epoch [500/500] | Train Loss: 0.385039 | Val Loss: 1.246467\n",
      "Epoch [100/500] | Train Loss: 0.700795 | Val Loss: 0.331171\n",
      "Epoch [200/500] | Train Loss: 0.634034 | Val Loss: 0.361865\n",
      "Epoch [300/500] | Train Loss: 0.561651 | Val Loss: 0.370838\n",
      "Epoch [400/500] | Train Loss: 0.522529 | Val Loss: 0.361275\n",
      "Epoch [500/500] | Train Loss: 0.487318 | Val Loss: 0.371131\n",
      "Epoch [100/500] | Train Loss: 0.593892 | Val Loss: 0.490805\n",
      "Epoch [200/500] | Train Loss: 0.546526 | Val Loss: 0.432772\n",
      "Epoch [300/500] | Train Loss: 0.508540 | Val Loss: 0.448279\n",
      "Epoch [400/500] | Train Loss: 0.499820 | Val Loss: 0.503396\n",
      "Epoch [500/500] | Train Loss: 0.483170 | Val Loss: 0.491929\n",
      "Epoch [100/500] | Train Loss: 0.583190 | Val Loss: 1.262466\n",
      "Epoch [200/500] | Train Loss: 0.534246 | Val Loss: 1.279778\n",
      "Epoch [300/500] | Train Loss: 0.495774 | Val Loss: 1.328423\n",
      "Epoch [400/500] | Train Loss: 0.465721 | Val Loss: 1.311278\n",
      "Epoch [500/500] | Train Loss: 0.464918 | Val Loss: 1.320000\n",
      "Epoch [100/500] | Train Loss: 0.538320 | Val Loss: 0.855523\n",
      "Epoch [200/500] | Train Loss: 0.344756 | Val Loss: 0.926686\n",
      "Epoch [300/500] | Train Loss: 0.285539 | Val Loss: 1.026088\n",
      "Epoch [400/500] | Train Loss: 0.220894 | Val Loss: 1.104623\n",
      "Epoch [500/500] | Train Loss: 0.212586 | Val Loss: 1.097092\n",
      "Epoch [100/500] | Train Loss: 0.610103 | Val Loss: 1.118939\n",
      "Epoch [200/500] | Train Loss: 0.543041 | Val Loss: 1.148469\n",
      "Epoch [300/500] | Train Loss: 0.457642 | Val Loss: 1.252570\n",
      "Epoch [400/500] | Train Loss: 0.385214 | Val Loss: 1.330708\n",
      "Epoch [500/500] | Train Loss: 0.375962 | Val Loss: 1.387524\n",
      "Epoch [100/500] | Train Loss: 0.771796 | Val Loss: 0.314425\n",
      "Epoch [200/500] | Train Loss: 0.673537 | Val Loss: 0.325619\n",
      "Epoch [300/500] | Train Loss: 0.634035 | Val Loss: 0.346350\n",
      "Epoch [400/500] | Train Loss: 0.546478 | Val Loss: 0.346072\n",
      "Epoch [500/500] | Train Loss: 0.523847 | Val Loss: 0.368582\n",
      "Epoch [100/500] | Train Loss: 0.643865 | Val Loss: 0.465439\n",
      "Epoch [200/500] | Train Loss: 0.571970 | Val Loss: 0.494548\n",
      "Epoch [300/500] | Train Loss: 0.535448 | Val Loss: 0.567924\n",
      "Epoch [400/500] | Train Loss: 0.469111 | Val Loss: 0.585249\n",
      "Epoch [500/500] | Train Loss: 0.454113 | Val Loss: 0.593711\n",
      "Epoch [100/500] | Train Loss: 0.610608 | Val Loss: 1.154010\n",
      "Epoch [200/500] | Train Loss: 0.522781 | Val Loss: 1.327419\n",
      "Epoch [300/500] | Train Loss: 0.494933 | Val Loss: 1.403577\n",
      "Epoch [400/500] | Train Loss: 0.446567 | Val Loss: 1.478690\n",
      "Epoch [500/500] | Train Loss: 0.427147 | Val Loss: 1.513116\n",
      "Epoch [100/500] | Train Loss: 0.329328 | Val Loss: 1.149330\n",
      "Epoch [200/500] | Train Loss: 0.212098 | Val Loss: 1.273352\n",
      "Epoch [300/500] | Train Loss: 0.177906 | Val Loss: 1.163532\n",
      "Epoch [400/500] | Train Loss: 0.177901 | Val Loss: 1.134422\n",
      "Epoch [500/500] | Train Loss: 0.106691 | Val Loss: 1.098296\n",
      "Epoch [100/500] | Train Loss: 0.469437 | Val Loss: 1.212271\n",
      "Epoch [200/500] | Train Loss: 0.381943 | Val Loss: 1.276736\n",
      "Epoch [300/500] | Train Loss: 0.298799 | Val Loss: 1.389357\n",
      "Epoch [400/500] | Train Loss: 0.232426 | Val Loss: 1.406114\n",
      "Epoch [500/500] | Train Loss: 0.192970 | Val Loss: 1.427264\n",
      "Epoch [100/500] | Train Loss: 0.543237 | Val Loss: 0.355347\n",
      "Epoch [200/500] | Train Loss: 0.437319 | Val Loss: 0.366138\n",
      "Epoch [300/500] | Train Loss: 0.386329 | Val Loss: 0.402256\n",
      "Epoch [400/500] | Train Loss: 0.335658 | Val Loss: 0.477416\n",
      "Epoch [500/500] | Train Loss: 0.327731 | Val Loss: 0.442589\n",
      "Epoch [100/500] | Train Loss: 0.513311 | Val Loss: 0.474260\n",
      "Epoch [200/500] | Train Loss: 0.420469 | Val Loss: 0.528505\n",
      "Epoch [300/500] | Train Loss: 0.344855 | Val Loss: 0.654708\n",
      "Epoch [400/500] | Train Loss: 0.319759 | Val Loss: 0.605656\n",
      "Epoch [500/500] | Train Loss: 0.312607 | Val Loss: 0.659610\n",
      "Epoch [100/500] | Train Loss: 0.445774 | Val Loss: 1.549965\n",
      "Epoch [200/500] | Train Loss: 0.380909 | Val Loss: 1.639874\n",
      "Epoch [300/500] | Train Loss: 0.342189 | Val Loss: 1.608472\n",
      "Epoch [400/500] | Train Loss: 0.335731 | Val Loss: 1.672546\n",
      "Epoch [500/500] | Train Loss: 0.297800 | Val Loss: 1.783580\n",
      "Epoch [100/500] | Train Loss: 0.533914 | Val Loss: 0.835331\n",
      "Epoch [200/500] | Train Loss: 0.499869 | Val Loss: 0.871731\n",
      "Epoch [300/500] | Train Loss: 0.494700 | Val Loss: 0.934870\n",
      "Epoch [400/500] | Train Loss: 0.397007 | Val Loss: 1.018152\n",
      "Epoch [500/500] | Train Loss: 0.342170 | Val Loss: 1.061958\n",
      "Epoch [100/500] | Train Loss: 0.649038 | Val Loss: 1.080673\n",
      "Epoch [200/500] | Train Loss: 0.571645 | Val Loss: 1.122363\n",
      "Epoch [300/500] | Train Loss: 0.541328 | Val Loss: 1.141176\n",
      "Epoch [400/500] | Train Loss: 0.490280 | Val Loss: 1.150146\n",
      "Epoch [500/500] | Train Loss: 0.478294 | Val Loss: 1.169831\n",
      "Epoch [100/500] | Train Loss: 0.787665 | Val Loss: 0.315374\n",
      "Epoch [200/500] | Train Loss: 0.706397 | Val Loss: 0.316766\n",
      "Epoch [300/500] | Train Loss: 0.674994 | Val Loss: 0.321320\n",
      "Epoch [400/500] | Train Loss: 0.651624 | Val Loss: 0.344719\n",
      "Epoch [500/500] | Train Loss: 0.584444 | Val Loss: 0.351014\n",
      "Epoch [100/500] | Train Loss: 0.674464 | Val Loss: 0.476399\n",
      "Epoch [200/500] | Train Loss: 0.623099 | Val Loss: 0.474400\n",
      "Epoch [300/500] | Train Loss: 0.591651 | Val Loss: 0.511712\n",
      "Epoch [400/500] | Train Loss: 0.588886 | Val Loss: 0.497426\n",
      "Epoch [500/500] | Train Loss: 0.521591 | Val Loss: 0.503975\n",
      "Epoch [100/500] | Train Loss: 0.623086 | Val Loss: 1.158127\n",
      "Epoch [200/500] | Train Loss: 0.596810 | Val Loss: 1.242333\n",
      "Epoch [300/500] | Train Loss: 0.555835 | Val Loss: 1.292038\n",
      "Epoch [400/500] | Train Loss: 0.521456 | Val Loss: 1.297365\n",
      "Epoch [500/500] | Train Loss: 0.494377 | Val Loss: 1.364588\n",
      "Epoch [100/500] | Train Loss: 0.426005 | Val Loss: 0.914325\n",
      "Epoch [200/500] | Train Loss: 0.307572 | Val Loss: 0.945675\n",
      "Epoch [300/500] | Train Loss: 0.245083 | Val Loss: 1.000506\n",
      "Epoch [400/500] | Train Loss: 0.217904 | Val Loss: 0.995418\n",
      "Epoch [500/500] | Train Loss: 0.203191 | Val Loss: 1.005027\n",
      "Epoch [100/500] | Train Loss: 0.546723 | Val Loss: 1.215178\n",
      "Epoch [200/500] | Train Loss: 0.446526 | Val Loss: 1.354956\n",
      "Epoch [300/500] | Train Loss: 0.363482 | Val Loss: 1.289600\n",
      "Epoch [400/500] | Train Loss: 0.341648 | Val Loss: 1.257056\n",
      "Epoch [500/500] | Train Loss: 0.320600 | Val Loss: 1.286356\n",
      "Epoch [100/500] | Train Loss: 0.682259 | Val Loss: 0.340619\n",
      "Epoch [200/500] | Train Loss: 0.562002 | Val Loss: 0.356995\n",
      "Epoch [300/500] | Train Loss: 0.537441 | Val Loss: 0.366361\n",
      "Epoch [400/500] | Train Loss: 0.514418 | Val Loss: 0.350845\n",
      "Epoch [500/500] | Train Loss: 0.479485 | Val Loss: 0.383493\n",
      "Epoch [100/500] | Train Loss: 0.558976 | Val Loss: 0.561866\n",
      "Epoch [200/500] | Train Loss: 0.489134 | Val Loss: 0.519459\n",
      "Epoch [300/500] | Train Loss: 0.468651 | Val Loss: 0.521286\n",
      "Epoch [400/500] | Train Loss: 0.421371 | Val Loss: 0.533599\n",
      "Epoch [500/500] | Train Loss: 0.425378 | Val Loss: 0.526577\n",
      "Epoch [100/500] | Train Loss: 0.592288 | Val Loss: 1.227437\n",
      "Epoch [200/500] | Train Loss: 0.501916 | Val Loss: 1.281152\n",
      "Epoch [300/500] | Train Loss: 0.487533 | Val Loss: 1.306998\n",
      "Epoch [400/500] | Train Loss: 0.443828 | Val Loss: 1.365366\n",
      "Epoch [500/500] | Train Loss: 0.432800 | Val Loss: 1.351809\n",
      "[Year=2019] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.832865 Test MSE=0.763038\n",
      "Year 2019 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.785140 | Val Loss: 0.975737\n",
      "Epoch [200/500] | Train Loss: 0.676676 | Val Loss: 1.086973\n",
      "Epoch [300/500] | Train Loss: 0.641623 | Val Loss: 1.066227\n",
      "Epoch [400/500] | Train Loss: 0.546260 | Val Loss: 1.106516\n",
      "Epoch [500/500] | Train Loss: 0.476912 | Val Loss: 1.145054\n",
      "Epoch [100/500] | Train Loss: 0.843959 | Val Loss: 0.329575\n",
      "Epoch [200/500] | Train Loss: 0.717273 | Val Loss: 0.348467\n",
      "Epoch [300/500] | Train Loss: 0.621714 | Val Loss: 0.365252\n",
      "Epoch [400/500] | Train Loss: 0.587877 | Val Loss: 0.364371\n",
      "Epoch [500/500] | Train Loss: 0.544733 | Val Loss: 0.382740\n",
      "Epoch [100/500] | Train Loss: 0.669875 | Val Loss: 0.679468\n",
      "Epoch [200/500] | Train Loss: 0.619554 | Val Loss: 0.687129\n",
      "Epoch [300/500] | Train Loss: 0.577063 | Val Loss: 0.678016\n",
      "Epoch [400/500] | Train Loss: 0.554840 | Val Loss: 0.693813\n",
      "Epoch [500/500] | Train Loss: 0.523112 | Val Loss: 0.717524\n",
      "Epoch [100/500] | Train Loss: 0.660426 | Val Loss: 1.093709\n",
      "Epoch [200/500] | Train Loss: 0.606672 | Val Loss: 1.253309\n",
      "Epoch [300/500] | Train Loss: 0.530644 | Val Loss: 1.353146\n",
      "Epoch [400/500] | Train Loss: 0.497804 | Val Loss: 1.408007\n",
      "Epoch [500/500] | Train Loss: 0.475850 | Val Loss: 1.475298\n",
      "Epoch [100/500] | Train Loss: 0.741731 | Val Loss: 0.629036\n",
      "Epoch [200/500] | Train Loss: 0.679096 | Val Loss: 0.647543\n",
      "Epoch [300/500] | Train Loss: 0.661975 | Val Loss: 0.660319\n",
      "Epoch [400/500] | Train Loss: 0.603160 | Val Loss: 0.659575\n",
      "Epoch [500/500] | Train Loss: 0.577621 | Val Loss: 0.658738\n",
      "Epoch [100/500] | Train Loss: 0.420958 | Val Loss: 1.195755\n",
      "Epoch [200/500] | Train Loss: 0.312157 | Val Loss: 1.219613\n",
      "Epoch [300/500] | Train Loss: 0.316442 | Val Loss: 1.303401\n",
      "Epoch [400/500] | Train Loss: 0.298026 | Val Loss: 1.322242\n",
      "Epoch [500/500] | Train Loss: 0.206318 | Val Loss: 1.286379\n",
      "Epoch [100/500] | Train Loss: 0.657678 | Val Loss: 0.351549\n",
      "Epoch [200/500] | Train Loss: 0.542568 | Val Loss: 0.408499\n",
      "Epoch [300/500] | Train Loss: 0.401643 | Val Loss: 0.409665\n",
      "Epoch [400/500] | Train Loss: 0.408666 | Val Loss: 0.466851\n",
      "Epoch [500/500] | Train Loss: 0.386177 | Val Loss: 0.441450\n",
      "Epoch [100/500] | Train Loss: 0.550532 | Val Loss: 0.713187\n",
      "Epoch [200/500] | Train Loss: 0.426402 | Val Loss: 0.733378\n",
      "Epoch [300/500] | Train Loss: 0.368374 | Val Loss: 0.803328\n",
      "Epoch [400/500] | Train Loss: 0.360678 | Val Loss: 0.866087\n",
      "Epoch [500/500] | Train Loss: 0.292781 | Val Loss: 0.851871\n",
      "Epoch [100/500] | Train Loss: 0.526445 | Val Loss: 1.354633\n",
      "Epoch [200/500] | Train Loss: 0.450653 | Val Loss: 1.441310\n",
      "Epoch [300/500] | Train Loss: 0.392996 | Val Loss: 1.431585\n",
      "Epoch [400/500] | Train Loss: 0.393405 | Val Loss: 1.525463\n",
      "Epoch [500/500] | Train Loss: 0.348506 | Val Loss: 1.457800\n",
      "Epoch [100/500] | Train Loss: 0.661101 | Val Loss: 0.630005\n",
      "Epoch [200/500] | Train Loss: 0.524248 | Val Loss: 0.738447\n",
      "Epoch [300/500] | Train Loss: 0.477633 | Val Loss: 0.744845\n",
      "Epoch [400/500] | Train Loss: 0.495169 | Val Loss: 0.796046\n",
      "Epoch [500/500] | Train Loss: 0.446889 | Val Loss: 0.816429\n",
      "Epoch [100/500] | Train Loss: 0.859354 | Val Loss: 0.931656\n",
      "Epoch [200/500] | Train Loss: 0.673391 | Val Loss: 0.990330\n",
      "Epoch [300/500] | Train Loss: 0.696760 | Val Loss: 1.008499\n",
      "Epoch [400/500] | Train Loss: 0.633580 | Val Loss: 1.021826\n",
      "Epoch [500/500] | Train Loss: 0.539917 | Val Loss: 1.066326\n",
      "Epoch [100/500] | Train Loss: 0.857991 | Val Loss: 0.333307\n",
      "Epoch [200/500] | Train Loss: 0.783276 | Val Loss: 0.337345\n",
      "Epoch [300/500] | Train Loss: 0.773800 | Val Loss: 0.345968\n",
      "Epoch [400/500] | Train Loss: 0.722137 | Val Loss: 0.350106\n",
      "Epoch [500/500] | Train Loss: 0.682270 | Val Loss: 0.362767\n",
      "Epoch [100/500] | Train Loss: 0.702434 | Val Loss: 0.677144\n",
      "Epoch [200/500] | Train Loss: 0.649658 | Val Loss: 0.698698\n",
      "Epoch [300/500] | Train Loss: 0.657998 | Val Loss: 0.696179\n",
      "Epoch [400/500] | Train Loss: 0.652506 | Val Loss: 0.703425\n",
      "Epoch [500/500] | Train Loss: 0.579715 | Val Loss: 0.699029\n",
      "Epoch [100/500] | Train Loss: 0.696869 | Val Loss: 1.051763\n",
      "Epoch [200/500] | Train Loss: 0.664787 | Val Loss: 1.117582\n",
      "Epoch [300/500] | Train Loss: 0.620444 | Val Loss: 1.197423\n",
      "Epoch [400/500] | Train Loss: 0.584780 | Val Loss: 1.252560\n",
      "Epoch [500/500] | Train Loss: 0.549118 | Val Loss: 1.295441\n",
      "Epoch [100/500] | Train Loss: 0.755086 | Val Loss: 0.635939\n",
      "Epoch [200/500] | Train Loss: 0.742387 | Val Loss: 0.630306\n",
      "Epoch [300/500] | Train Loss: 0.731635 | Val Loss: 0.631434\n",
      "Epoch [400/500] | Train Loss: 0.707645 | Val Loss: 0.635279\n",
      "Epoch [500/500] | Train Loss: 0.692106 | Val Loss: 0.635611\n",
      "Epoch [100/500] | Train Loss: 0.660831 | Val Loss: 1.008486\n",
      "Epoch [200/500] | Train Loss: 0.584466 | Val Loss: 1.100255\n",
      "Epoch [300/500] | Train Loss: 0.438196 | Val Loss: 1.094156\n",
      "Epoch [400/500] | Train Loss: 0.505346 | Val Loss: 1.210692\n",
      "Epoch [500/500] | Train Loss: 0.479866 | Val Loss: 1.132406\n",
      "Epoch [100/500] | Train Loss: 0.751068 | Val Loss: 0.342660\n",
      "Epoch [200/500] | Train Loss: 0.650911 | Val Loss: 0.343714\n",
      "Epoch [300/500] | Train Loss: 0.586456 | Val Loss: 0.353973\n",
      "Epoch [400/500] | Train Loss: 0.576630 | Val Loss: 0.361934\n",
      "Epoch [500/500] | Train Loss: 0.533528 | Val Loss: 0.379744\n",
      "Epoch [100/500] | Train Loss: 0.635406 | Val Loss: 0.675492\n",
      "Epoch [200/500] | Train Loss: 0.576267 | Val Loss: 0.688007\n",
      "Epoch [300/500] | Train Loss: 0.555353 | Val Loss: 0.724711\n",
      "Epoch [400/500] | Train Loss: 0.513441 | Val Loss: 0.738449\n",
      "Epoch [500/500] | Train Loss: 0.475349 | Val Loss: 0.663218\n",
      "Epoch [100/500] | Train Loss: 0.607026 | Val Loss: 1.168984\n",
      "Epoch [200/500] | Train Loss: 0.544749 | Val Loss: 1.278813\n",
      "Epoch [300/500] | Train Loss: 0.554492 | Val Loss: 1.230990\n",
      "Epoch [400/500] | Train Loss: 0.541286 | Val Loss: 1.392631\n",
      "Epoch [500/500] | Train Loss: 0.505849 | Val Loss: 1.280496\n",
      "Epoch [100/500] | Train Loss: 0.627054 | Val Loss: 0.675601\n",
      "Epoch [200/500] | Train Loss: 0.594008 | Val Loss: 0.679303\n",
      "Epoch [300/500] | Train Loss: 0.579429 | Val Loss: 0.688259\n",
      "Epoch [400/500] | Train Loss: 0.568143 | Val Loss: 0.672386\n",
      "Epoch [500/500] | Train Loss: 0.531950 | Val Loss: 0.688347\n",
      "Epoch [100/500] | Train Loss: 0.656453 | Val Loss: 1.077240\n",
      "Epoch [200/500] | Train Loss: 0.539168 | Val Loss: 1.143929\n",
      "Epoch [300/500] | Train Loss: 0.507452 | Val Loss: 1.193606\n",
      "Epoch [400/500] | Train Loss: 0.412143 | Val Loss: 1.198197\n",
      "Epoch [500/500] | Train Loss: 0.359679 | Val Loss: 1.265482\n",
      "Epoch [100/500] | Train Loss: 0.802797 | Val Loss: 0.327663\n",
      "Epoch [200/500] | Train Loss: 0.644637 | Val Loss: 0.358429\n",
      "Epoch [300/500] | Train Loss: 0.512273 | Val Loss: 0.381881\n",
      "Epoch [400/500] | Train Loss: 0.430849 | Val Loss: 0.404693\n",
      "Epoch [500/500] | Train Loss: 0.464981 | Val Loss: 0.408659\n",
      "Epoch [100/500] | Train Loss: 0.633943 | Val Loss: 0.694128\n",
      "Epoch [200/500] | Train Loss: 0.512563 | Val Loss: 0.743994\n",
      "Epoch [300/500] | Train Loss: 0.465212 | Val Loss: 0.790603\n",
      "Epoch [400/500] | Train Loss: 0.430822 | Val Loss: 0.776726\n",
      "Epoch [500/500] | Train Loss: 0.380957 | Val Loss: 0.788432\n",
      "Epoch [100/500] | Train Loss: 0.655356 | Val Loss: 1.139366\n",
      "Epoch [200/500] | Train Loss: 0.546472 | Val Loss: 1.224196\n",
      "Epoch [300/500] | Train Loss: 0.497991 | Val Loss: 1.251710\n",
      "Epoch [400/500] | Train Loss: 0.467070 | Val Loss: 1.324091\n",
      "Epoch [500/500] | Train Loss: 0.431900 | Val Loss: 1.332756\n",
      "Epoch [100/500] | Train Loss: 0.760539 | Val Loss: 0.637643\n",
      "Epoch [200/500] | Train Loss: 0.714114 | Val Loss: 0.633119\n",
      "Epoch [300/500] | Train Loss: 0.605139 | Val Loss: 0.661597\n",
      "Epoch [400/500] | Train Loss: 0.548114 | Val Loss: 0.710938\n",
      "Epoch [500/500] | Train Loss: 0.531182 | Val Loss: 0.736084\n",
      "Epoch [100/500] | Train Loss: 0.420050 | Val Loss: 1.168169\n",
      "Epoch [200/500] | Train Loss: 0.319792 | Val Loss: 1.264478\n",
      "Epoch [300/500] | Train Loss: 0.264011 | Val Loss: 1.294697\n",
      "Epoch [400/500] | Train Loss: 0.245535 | Val Loss: 1.375915\n",
      "Epoch [500/500] | Train Loss: 0.154806 | Val Loss: 1.248631\n",
      "Epoch [100/500] | Train Loss: 0.568905 | Val Loss: 0.376306\n",
      "Epoch [200/500] | Train Loss: 0.475591 | Val Loss: 0.443371\n",
      "Epoch [300/500] | Train Loss: 0.410719 | Val Loss: 0.441663\n",
      "Epoch [400/500] | Train Loss: 0.384507 | Val Loss: 0.438696\n",
      "Epoch [500/500] | Train Loss: 0.334868 | Val Loss: 0.506531\n",
      "Epoch [100/500] | Train Loss: 0.467083 | Val Loss: 0.768787\n",
      "Epoch [200/500] | Train Loss: 0.378912 | Val Loss: 0.827891\n",
      "Epoch [300/500] | Train Loss: 0.333299 | Val Loss: 0.888127\n",
      "Epoch [400/500] | Train Loss: 0.306561 | Val Loss: 0.841020\n",
      "Epoch [500/500] | Train Loss: 0.366012 | Val Loss: 0.849156\n",
      "Epoch [100/500] | Train Loss: 0.531811 | Val Loss: 1.337818\n",
      "Epoch [200/500] | Train Loss: 0.450041 | Val Loss: 1.558942\n",
      "Epoch [300/500] | Train Loss: 0.380038 | Val Loss: 1.591810\n",
      "Epoch [400/500] | Train Loss: 0.358184 | Val Loss: 1.484652\n",
      "Epoch [500/500] | Train Loss: 0.325684 | Val Loss: 1.560112\n",
      "Epoch [100/500] | Train Loss: 0.537397 | Val Loss: 0.748021\n",
      "Epoch [200/500] | Train Loss: 0.450398 | Val Loss: 0.728427\n",
      "Epoch [300/500] | Train Loss: 0.426740 | Val Loss: 0.739162\n",
      "Epoch [400/500] | Train Loss: 0.385731 | Val Loss: 0.806927\n",
      "Epoch [500/500] | Train Loss: 0.402121 | Val Loss: 0.823893\n",
      "Epoch [100/500] | Train Loss: 0.806327 | Val Loss: 1.019422\n",
      "Epoch [200/500] | Train Loss: 0.706020 | Val Loss: 1.061527\n",
      "Epoch [300/500] | Train Loss: 0.573910 | Val Loss: 1.092390\n",
      "Epoch [400/500] | Train Loss: 0.499101 | Val Loss: 1.087285\n",
      "Epoch [500/500] | Train Loss: 0.510347 | Val Loss: 1.120365\n",
      "Epoch [100/500] | Train Loss: 0.853945 | Val Loss: 0.335691\n",
      "Epoch [200/500] | Train Loss: 0.824934 | Val Loss: 0.345306\n",
      "Epoch [300/500] | Train Loss: 0.715659 | Val Loss: 0.354732\n",
      "Epoch [400/500] | Train Loss: 0.639411 | Val Loss: 0.365787\n",
      "Epoch [500/500] | Train Loss: 0.579596 | Val Loss: 0.364006\n",
      "Epoch [100/500] | Train Loss: 0.687517 | Val Loss: 0.671070\n",
      "Epoch [200/500] | Train Loss: 0.656671 | Val Loss: 0.677483\n",
      "Epoch [300/500] | Train Loss: 0.552084 | Val Loss: 0.697026\n",
      "Epoch [400/500] | Train Loss: 0.525195 | Val Loss: 0.714585\n",
      "Epoch [500/500] | Train Loss: 0.520248 | Val Loss: 0.725422\n",
      "Epoch [100/500] | Train Loss: 0.671807 | Val Loss: 1.077666\n",
      "Epoch [200/500] | Train Loss: 0.617255 | Val Loss: 1.240247\n",
      "Epoch [300/500] | Train Loss: 0.540761 | Val Loss: 1.333242\n",
      "Epoch [400/500] | Train Loss: 0.530614 | Val Loss: 1.387782\n",
      "Epoch [500/500] | Train Loss: 0.499759 | Val Loss: 1.438490\n",
      "Epoch [100/500] | Train Loss: 0.750731 | Val Loss: 0.635756\n",
      "Epoch [200/500] | Train Loss: 0.710205 | Val Loss: 0.641095\n",
      "Epoch [300/500] | Train Loss: 0.647838 | Val Loss: 0.664202\n",
      "Epoch [400/500] | Train Loss: 0.637369 | Val Loss: 0.683137\n",
      "Epoch [500/500] | Train Loss: 0.629693 | Val Loss: 0.690470\n",
      "Epoch [100/500] | Train Loss: 0.611666 | Val Loss: 1.113720\n",
      "Epoch [200/500] | Train Loss: 0.462941 | Val Loss: 1.194262\n",
      "Epoch [300/500] | Train Loss: 0.372440 | Val Loss: 1.237891\n",
      "Epoch [400/500] | Train Loss: 0.333851 | Val Loss: 1.205466\n",
      "Epoch [500/500] | Train Loss: 0.291952 | Val Loss: 1.169052\n",
      "Epoch [100/500] | Train Loss: 0.652106 | Val Loss: 0.357284\n",
      "Epoch [200/500] | Train Loss: 0.583632 | Val Loss: 0.367130\n",
      "Epoch [300/500] | Train Loss: 0.485039 | Val Loss: 0.380343\n",
      "Epoch [400/500] | Train Loss: 0.495092 | Val Loss: 0.390789\n",
      "Epoch [500/500] | Train Loss: 0.420910 | Val Loss: 0.404133\n",
      "Epoch [100/500] | Train Loss: 0.585721 | Val Loss: 0.706932\n",
      "Epoch [200/500] | Train Loss: 0.497555 | Val Loss: 0.676743\n",
      "Epoch [300/500] | Train Loss: 0.471950 | Val Loss: 0.750182\n",
      "Epoch [400/500] | Train Loss: 0.458787 | Val Loss: 0.773109\n",
      "Epoch [500/500] | Train Loss: 0.439121 | Val Loss: 0.794816\n",
      "Epoch [100/500] | Train Loss: 0.584161 | Val Loss: 1.191281\n",
      "Epoch [200/500] | Train Loss: 0.496834 | Val Loss: 1.184234\n",
      "Epoch [300/500] | Train Loss: 0.460248 | Val Loss: 1.284729\n",
      "Epoch [400/500] | Train Loss: 0.447235 | Val Loss: 1.262229\n",
      "Epoch [500/500] | Train Loss: 0.448726 | Val Loss: 1.227308\n",
      "Epoch [100/500] | Train Loss: 0.651233 | Val Loss: 0.678341\n",
      "Epoch [200/500] | Train Loss: 0.583746 | Val Loss: 0.685815\n",
      "Epoch [300/500] | Train Loss: 0.544308 | Val Loss: 0.722322\n",
      "Epoch [400/500] | Train Loss: 0.517588 | Val Loss: 0.705641\n",
      "Epoch [500/500] | Train Loss: 0.524694 | Val Loss: 0.723296\n",
      "[Year=2020] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=0.811835 Test MSE=5.084241\n",
      "Year 2020 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.800350 | Val Loss: 0.270758\n",
      "Epoch [200/500] | Train Loss: 0.650279 | Val Loss: 0.315252\n",
      "Epoch [300/500] | Train Loss: 0.549716 | Val Loss: 0.330297\n",
      "Epoch [400/500] | Train Loss: 0.502580 | Val Loss: 0.316294\n",
      "Epoch [500/500] | Train Loss: 0.403573 | Val Loss: 0.331582\n",
      "Epoch [100/500] | Train Loss: 0.510553 | Val Loss: 0.714463\n",
      "Epoch [200/500] | Train Loss: 0.439820 | Val Loss: 0.799924\n",
      "Epoch [300/500] | Train Loss: 0.385025 | Val Loss: 0.855392\n",
      "Epoch [400/500] | Train Loss: 0.366051 | Val Loss: 0.833850\n",
      "Epoch [500/500] | Train Loss: 0.338452 | Val Loss: 0.861802\n",
      "Epoch [100/500] | Train Loss: 0.559584 | Val Loss: 1.110859\n",
      "Epoch [200/500] | Train Loss: 0.461743 | Val Loss: 1.254419\n",
      "Epoch [300/500] | Train Loss: 0.434678 | Val Loss: 1.297509\n",
      "Epoch [400/500] | Train Loss: 0.406317 | Val Loss: 1.348700\n",
      "Epoch [500/500] | Train Loss: 0.395620 | Val Loss: 1.326198\n",
      "Epoch [100/500] | Train Loss: 0.704844 | Val Loss: 1.080639\n",
      "Epoch [200/500] | Train Loss: 0.648678 | Val Loss: 1.100383\n",
      "Epoch [300/500] | Train Loss: 0.556691 | Val Loss: 1.286471\n",
      "Epoch [400/500] | Train Loss: 0.516498 | Val Loss: 1.405068\n",
      "Epoch [500/500] | Train Loss: 0.497473 | Val Loss: 1.478844\n",
      "Epoch [100/500] | Train Loss: 0.764604 | Val Loss: 5.193349\n",
      "Epoch [200/500] | Train Loss: 0.688071 | Val Loss: 5.067553\n",
      "Epoch [300/500] | Train Loss: 0.632648 | Val Loss: 5.332990\n",
      "Epoch [400/500] | Train Loss: 0.583259 | Val Loss: 5.608016\n",
      "Epoch [500/500] | Train Loss: 0.547200 | Val Loss: 5.846045\n",
      "Epoch [100/500] | Train Loss: 0.412774 | Val Loss: 0.390148\n",
      "Epoch [200/500] | Train Loss: 0.221369 | Val Loss: 0.385837\n",
      "Epoch [300/500] | Train Loss: 0.242463 | Val Loss: 0.433257\n",
      "Epoch [400/500] | Train Loss: 0.245078 | Val Loss: 0.441414\n",
      "Epoch [500/500] | Train Loss: 0.182158 | Val Loss: 0.475724\n",
      "Epoch [100/500] | Train Loss: 0.374573 | Val Loss: 0.762210\n",
      "Epoch [200/500] | Train Loss: 0.329942 | Val Loss: 0.737210\n",
      "Epoch [300/500] | Train Loss: 0.270470 | Val Loss: 0.735780\n",
      "Epoch [400/500] | Train Loss: 0.237635 | Val Loss: 0.685057\n",
      "Epoch [500/500] | Train Loss: 0.220499 | Val Loss: 0.720853\n",
      "Epoch [100/500] | Train Loss: 0.365076 | Val Loss: 1.263189\n",
      "Epoch [200/500] | Train Loss: 0.324678 | Val Loss: 1.228279\n",
      "Epoch [300/500] | Train Loss: 0.297170 | Val Loss: 1.217191\n",
      "Epoch [400/500] | Train Loss: 0.279670 | Val Loss: 1.303028\n",
      "Epoch [500/500] | Train Loss: 0.268894 | Val Loss: 1.260979\n",
      "Epoch [100/500] | Train Loss: 0.507680 | Val Loss: 1.357199\n",
      "Epoch [200/500] | Train Loss: 0.475446 | Val Loss: 1.369795\n",
      "Epoch [300/500] | Train Loss: 0.429416 | Val Loss: 1.465099\n",
      "Epoch [400/500] | Train Loss: 0.394491 | Val Loss: 1.362246\n",
      "Epoch [500/500] | Train Loss: 0.425149 | Val Loss: 1.415638\n",
      "Epoch [100/500] | Train Loss: 0.564903 | Val Loss: 5.850550\n",
      "Epoch [200/500] | Train Loss: 0.453316 | Val Loss: 5.974974\n",
      "Epoch [300/500] | Train Loss: 0.458472 | Val Loss: 5.905099\n",
      "Epoch [400/500] | Train Loss: 0.436550 | Val Loss: 5.719228\n",
      "Epoch [500/500] | Train Loss: 0.409110 | Val Loss: 5.508234\n",
      "Epoch [100/500] | Train Loss: 0.767789 | Val Loss: 0.275644\n",
      "Epoch [200/500] | Train Loss: 0.740616 | Val Loss: 0.311281\n",
      "Epoch [300/500] | Train Loss: 0.661467 | Val Loss: 0.318824\n",
      "Epoch [400/500] | Train Loss: 0.554172 | Val Loss: 0.311868\n",
      "Epoch [500/500] | Train Loss: 0.550322 | Val Loss: 0.323563\n",
      "Epoch [100/500] | Train Loss: 0.527241 | Val Loss: 0.699207\n",
      "Epoch [200/500] | Train Loss: 0.500129 | Val Loss: 0.718013\n",
      "Epoch [300/500] | Train Loss: 0.480769 | Val Loss: 0.721100\n",
      "Epoch [400/500] | Train Loss: 0.437711 | Val Loss: 0.712438\n",
      "Epoch [500/500] | Train Loss: 0.428090 | Val Loss: 0.735309\n",
      "Epoch [100/500] | Train Loss: 0.571053 | Val Loss: 1.072008\n",
      "Epoch [200/500] | Train Loss: 0.559143 | Val Loss: 1.121510\n",
      "Epoch [300/500] | Train Loss: 0.510033 | Val Loss: 1.228301\n",
      "Epoch [400/500] | Train Loss: 0.498602 | Val Loss: 1.243477\n",
      "Epoch [500/500] | Train Loss: 0.486293 | Val Loss: 1.312382\n",
      "Epoch [100/500] | Train Loss: 0.693424 | Val Loss: 1.081462\n",
      "Epoch [200/500] | Train Loss: 0.673291 | Val Loss: 1.096517\n",
      "Epoch [300/500] | Train Loss: 0.635797 | Val Loss: 1.145660\n",
      "Epoch [400/500] | Train Loss: 0.598609 | Val Loss: 1.219696\n",
      "Epoch [500/500] | Train Loss: 0.579535 | Val Loss: 1.281277\n",
      "Epoch [100/500] | Train Loss: 0.778555 | Val Loss: 5.003779\n",
      "Epoch [200/500] | Train Loss: 0.751718 | Val Loss: 4.796797\n",
      "Epoch [300/500] | Train Loss: 0.700520 | Val Loss: 4.771285\n",
      "Epoch [400/500] | Train Loss: 0.673684 | Val Loss: 4.985503\n",
      "Epoch [500/500] | Train Loss: 0.668132 | Val Loss: 5.254730\n",
      "Epoch [100/500] | Train Loss: 0.543725 | Val Loss: 0.304358\n",
      "Epoch [200/500] | Train Loss: 0.381195 | Val Loss: 0.329691\n",
      "Epoch [300/500] | Train Loss: 0.381303 | Val Loss: 0.317432\n",
      "Epoch [400/500] | Train Loss: 0.342361 | Val Loss: 0.336239\n",
      "Epoch [500/500] | Train Loss: 0.332446 | Val Loss: 0.356798\n",
      "Epoch [100/500] | Train Loss: 0.421473 | Val Loss: 0.705649\n",
      "Epoch [200/500] | Train Loss: 0.367002 | Val Loss: 0.731422\n",
      "Epoch [300/500] | Train Loss: 0.315598 | Val Loss: 0.740653\n",
      "Epoch [400/500] | Train Loss: 0.307490 | Val Loss: 0.710713\n",
      "Epoch [500/500] | Train Loss: 0.303839 | Val Loss: 0.717447\n",
      "Epoch [100/500] | Train Loss: 0.534418 | Val Loss: 1.169666\n",
      "Epoch [200/500] | Train Loss: 0.449138 | Val Loss: 1.304799\n",
      "Epoch [300/500] | Train Loss: 0.450715 | Val Loss: 1.139092\n",
      "Epoch [400/500] | Train Loss: 0.380183 | Val Loss: 1.124811\n",
      "Epoch [500/500] | Train Loss: 0.372923 | Val Loss: 1.110466\n",
      "Epoch [100/500] | Train Loss: 0.618098 | Val Loss: 1.111752\n",
      "Epoch [200/500] | Train Loss: 0.591749 | Val Loss: 1.081179\n",
      "Epoch [300/500] | Train Loss: 0.548926 | Val Loss: 1.298468\n",
      "Epoch [400/500] | Train Loss: 0.541448 | Val Loss: 1.160045\n",
      "Epoch [500/500] | Train Loss: 0.480200 | Val Loss: 1.210282\n",
      "Epoch [100/500] | Train Loss: 0.697006 | Val Loss: 5.688924\n",
      "Epoch [200/500] | Train Loss: 0.662297 | Val Loss: 6.576086\n",
      "Epoch [300/500] | Train Loss: 0.621650 | Val Loss: 7.065866\n",
      "Epoch [400/500] | Train Loss: 0.560702 | Val Loss: 6.571856\n",
      "Epoch [500/500] | Train Loss: 0.532265 | Val Loss: 5.817035\n",
      "Epoch [100/500] | Train Loss: 0.685718 | Val Loss: 0.290290\n",
      "Epoch [200/500] | Train Loss: 0.474530 | Val Loss: 0.330884\n",
      "Epoch [300/500] | Train Loss: 0.417587 | Val Loss: 0.337514\n",
      "Epoch [400/500] | Train Loss: 0.355827 | Val Loss: 0.358269\n",
      "Epoch [500/500] | Train Loss: 0.338655 | Val Loss: 0.350225\n",
      "Epoch [100/500] | Train Loss: 0.476387 | Val Loss: 0.697607\n",
      "Epoch [200/500] | Train Loss: 0.398981 | Val Loss: 0.753801\n",
      "Epoch [300/500] | Train Loss: 0.371926 | Val Loss: 0.815372\n",
      "Epoch [400/500] | Train Loss: 0.315302 | Val Loss: 0.826667\n",
      "Epoch [500/500] | Train Loss: 0.316843 | Val Loss: 0.816374\n",
      "Epoch [100/500] | Train Loss: 0.512617 | Val Loss: 1.134357\n",
      "Epoch [200/500] | Train Loss: 0.427940 | Val Loss: 1.211868\n",
      "Epoch [300/500] | Train Loss: 0.400905 | Val Loss: 1.198622\n",
      "Epoch [400/500] | Train Loss: 0.360473 | Val Loss: 1.244974\n",
      "Epoch [500/500] | Train Loss: 0.345518 | Val Loss: 1.243152\n",
      "Epoch [100/500] | Train Loss: 0.661750 | Val Loss: 1.102330\n",
      "Epoch [200/500] | Train Loss: 0.540356 | Val Loss: 1.214338\n",
      "Epoch [300/500] | Train Loss: 0.511382 | Val Loss: 1.192062\n",
      "Epoch [400/500] | Train Loss: 0.508441 | Val Loss: 1.234483\n",
      "Epoch [500/500] | Train Loss: 0.454514 | Val Loss: 1.171941\n",
      "Epoch [100/500] | Train Loss: 0.706117 | Val Loss: 5.103482\n",
      "Epoch [200/500] | Train Loss: 0.638696 | Val Loss: 6.166066\n",
      "Epoch [300/500] | Train Loss: 0.569332 | Val Loss: 6.677333\n",
      "Epoch [400/500] | Train Loss: 0.512423 | Val Loss: 7.133159\n",
      "Epoch [500/500] | Train Loss: 0.487781 | Val Loss: 7.644936\n",
      "Epoch [100/500] | Train Loss: 0.395058 | Val Loss: 0.332690\n",
      "Epoch [200/500] | Train Loss: 0.305983 | Val Loss: 0.370814\n",
      "Epoch [300/500] | Train Loss: 0.202531 | Val Loss: 0.441649\n",
      "Epoch [400/500] | Train Loss: 0.153461 | Val Loss: 0.448505\n",
      "Epoch [500/500] | Train Loss: 0.134618 | Val Loss: 0.435270\n",
      "Epoch [100/500] | Train Loss: 0.291917 | Val Loss: 0.777353\n",
      "Epoch [200/500] | Train Loss: 0.211666 | Val Loss: 0.767846\n",
      "Epoch [300/500] | Train Loss: 0.184761 | Val Loss: 0.709232\n",
      "Epoch [400/500] | Train Loss: 0.175451 | Val Loss: 0.714960\n",
      "Epoch [500/500] | Train Loss: 0.174466 | Val Loss: 0.711958\n",
      "Epoch [100/500] | Train Loss: 0.366215 | Val Loss: 1.205213\n",
      "Epoch [200/500] | Train Loss: 0.292303 | Val Loss: 1.245294\n",
      "Epoch [300/500] | Train Loss: 0.272252 | Val Loss: 1.329538\n",
      "Epoch [400/500] | Train Loss: 0.221278 | Val Loss: 1.434437\n",
      "Epoch [500/500] | Train Loss: 0.212203 | Val Loss: 1.496311\n",
      "Epoch [100/500] | Train Loss: 0.537876 | Val Loss: 1.154842\n",
      "Epoch [200/500] | Train Loss: 0.405056 | Val Loss: 1.463583\n",
      "Epoch [300/500] | Train Loss: 0.343438 | Val Loss: 1.484213\n",
      "Epoch [400/500] | Train Loss: 0.342401 | Val Loss: 1.307146\n",
      "Epoch [500/500] | Train Loss: 0.334338 | Val Loss: 1.354684\n",
      "Epoch [100/500] | Train Loss: 0.676137 | Val Loss: 5.490161\n",
      "Epoch [200/500] | Train Loss: 0.529820 | Val Loss: 5.495156\n",
      "Epoch [300/500] | Train Loss: 0.464207 | Val Loss: 6.457735\n",
      "Epoch [400/500] | Train Loss: 0.439235 | Val Loss: 7.788135\n",
      "Epoch [500/500] | Train Loss: 0.427607 | Val Loss: 7.317039\n",
      "Epoch [100/500] | Train Loss: 0.725194 | Val Loss: 0.288339\n",
      "Epoch [200/500] | Train Loss: 0.634272 | Val Loss: 0.313869\n",
      "Epoch [300/500] | Train Loss: 0.560537 | Val Loss: 0.317908\n",
      "Epoch [400/500] | Train Loss: 0.534610 | Val Loss: 0.318668\n",
      "Epoch [500/500] | Train Loss: 0.450123 | Val Loss: 0.332046\n",
      "Epoch [100/500] | Train Loss: 0.564950 | Val Loss: 0.702418\n",
      "Epoch [200/500] | Train Loss: 0.489101 | Val Loss: 0.708859\n",
      "Epoch [300/500] | Train Loss: 0.435952 | Val Loss: 0.705520\n",
      "Epoch [400/500] | Train Loss: 0.424518 | Val Loss: 0.757678\n",
      "Epoch [500/500] | Train Loss: 0.362278 | Val Loss: 0.754386\n",
      "Epoch [100/500] | Train Loss: 0.556883 | Val Loss: 1.108127\n",
      "Epoch [200/500] | Train Loss: 0.516560 | Val Loss: 1.182834\n",
      "Epoch [300/500] | Train Loss: 0.448627 | Val Loss: 1.173130\n",
      "Epoch [400/500] | Train Loss: 0.428846 | Val Loss: 1.202798\n",
      "Epoch [500/500] | Train Loss: 0.409606 | Val Loss: 1.211155\n",
      "Epoch [100/500] | Train Loss: 0.694240 | Val Loss: 1.078816\n",
      "Epoch [200/500] | Train Loss: 0.653266 | Val Loss: 1.164649\n",
      "Epoch [300/500] | Train Loss: 0.582785 | Val Loss: 1.264746\n",
      "Epoch [400/500] | Train Loss: 0.558341 | Val Loss: 1.226624\n",
      "Epoch [500/500] | Train Loss: 0.546498 | Val Loss: 1.237079\n",
      "Epoch [100/500] | Train Loss: 0.767604 | Val Loss: 5.030105\n",
      "Epoch [200/500] | Train Loss: 0.744823 | Val Loss: 5.039063\n",
      "Epoch [300/500] | Train Loss: 0.689084 | Val Loss: 5.440516\n",
      "Epoch [400/500] | Train Loss: 0.624361 | Val Loss: 5.645839\n",
      "Epoch [500/500] | Train Loss: 0.595026 | Val Loss: 6.071873\n",
      "Epoch [100/500] | Train Loss: 0.383434 | Val Loss: 0.355436\n",
      "Epoch [200/500] | Train Loss: 0.341813 | Val Loss: 0.375568\n",
      "Epoch [300/500] | Train Loss: 0.325282 | Val Loss: 0.408175\n",
      "Epoch [400/500] | Train Loss: 0.317815 | Val Loss: 0.438385\n",
      "Epoch [500/500] | Train Loss: 0.264147 | Val Loss: 0.354536\n",
      "Epoch [100/500] | Train Loss: 0.341304 | Val Loss: 0.723075\n",
      "Epoch [200/500] | Train Loss: 0.332705 | Val Loss: 0.792081\n",
      "Epoch [300/500] | Train Loss: 0.271028 | Val Loss: 0.764557\n",
      "Epoch [400/500] | Train Loss: 0.264774 | Val Loss: 0.716421\n",
      "Epoch [500/500] | Train Loss: 0.243615 | Val Loss: 0.725420\n",
      "Epoch [100/500] | Train Loss: 0.429564 | Val Loss: 1.210145\n",
      "Epoch [200/500] | Train Loss: 0.365627 | Val Loss: 1.198310\n",
      "Epoch [300/500] | Train Loss: 0.342113 | Val Loss: 1.204504\n",
      "Epoch [400/500] | Train Loss: 0.321123 | Val Loss: 1.214584\n",
      "Epoch [500/500] | Train Loss: 0.298296 | Val Loss: 1.256001\n",
      "Epoch [100/500] | Train Loss: 0.563975 | Val Loss: 1.354003\n",
      "Epoch [200/500] | Train Loss: 0.497293 | Val Loss: 1.409985\n",
      "Epoch [300/500] | Train Loss: 0.442348 | Val Loss: 1.301529\n",
      "Epoch [400/500] | Train Loss: 0.457734 | Val Loss: 1.413468\n",
      "Epoch [500/500] | Train Loss: 0.429321 | Val Loss: 1.341312\n",
      "Epoch [100/500] | Train Loss: 0.664394 | Val Loss: 6.156040\n",
      "Epoch [200/500] | Train Loss: 0.569685 | Val Loss: 6.810943\n",
      "Epoch [300/500] | Train Loss: 0.540943 | Val Loss: 6.571882\n",
      "Epoch [400/500] | Train Loss: 0.515082 | Val Loss: 6.221426\n",
      "Epoch [500/500] | Train Loss: 0.509833 | Val Loss: 6.191245\n",
      "[Year=2021] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.781452 Test MSE=0.796836\n",
      "Year 2021 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.196901 | Val Loss: 0.735797\n",
      "Epoch [200/500] | Train Loss: 0.174017 | Val Loss: 0.758550\n",
      "Epoch [300/500] | Train Loss: 0.151054 | Val Loss: 0.784546\n",
      "Epoch [400/500] | Train Loss: 0.152305 | Val Loss: 0.803654\n",
      "Epoch [500/500] | Train Loss: 0.130104 | Val Loss: 0.824760\n",
      "Epoch [100/500] | Train Loss: 0.453802 | Val Loss: 1.176618\n",
      "Epoch [200/500] | Train Loss: 0.427180 | Val Loss: 1.260380\n",
      "Epoch [300/500] | Train Loss: 0.370086 | Val Loss: 1.368511\n",
      "Epoch [400/500] | Train Loss: 0.319619 | Val Loss: 1.452738\n",
      "Epoch [500/500] | Train Loss: 0.306368 | Val Loss: 1.469339\n",
      "Epoch [100/500] | Train Loss: 0.668474 | Val Loss: 5.176178\n",
      "Epoch [200/500] | Train Loss: 0.564539 | Val Loss: 5.765591\n",
      "Epoch [300/500] | Train Loss: 0.497162 | Val Loss: 6.099627\n",
      "Epoch [400/500] | Train Loss: 0.423112 | Val Loss: 6.620262\n",
      "Epoch [500/500] | Train Loss: 0.460071 | Val Loss: 6.580445\n",
      "Epoch [100/500] | Train Loss: 1.435902 | Val Loss: 1.623397\n",
      "Epoch [200/500] | Train Loss: 1.036343 | Val Loss: 1.672039\n",
      "Epoch [300/500] | Train Loss: 1.030968 | Val Loss: 1.664719\n",
      "Epoch [400/500] | Train Loss: 0.900300 | Val Loss: 1.626655\n",
      "Epoch [500/500] | Train Loss: 0.882329 | Val Loss: 1.670394\n",
      "Epoch [100/500] | Train Loss: 1.402538 | Val Loss: 0.685540\n",
      "Epoch [200/500] | Train Loss: 1.238586 | Val Loss: 0.662178\n",
      "Epoch [300/500] | Train Loss: 1.149991 | Val Loss: 0.673399\n",
      "Epoch [400/500] | Train Loss: 1.063613 | Val Loss: 0.669381\n",
      "Epoch [500/500] | Train Loss: 0.899742 | Val Loss: 0.660003\n",
      "Epoch [100/500] | Train Loss: 0.167198 | Val Loss: 0.739312\n",
      "Epoch [200/500] | Train Loss: 0.134472 | Val Loss: 0.702468\n",
      "Epoch [300/500] | Train Loss: 0.122061 | Val Loss: 0.728910\n",
      "Epoch [400/500] | Train Loss: 0.101930 | Val Loss: 0.716874\n",
      "Epoch [500/500] | Train Loss: 0.101730 | Val Loss: 0.744361\n",
      "Epoch [100/500] | Train Loss: 0.301516 | Val Loss: 1.412557\n",
      "Epoch [200/500] | Train Loss: 0.226464 | Val Loss: 1.500230\n",
      "Epoch [300/500] | Train Loss: 0.179958 | Val Loss: 1.504200\n",
      "Epoch [400/500] | Train Loss: 0.200127 | Val Loss: 1.552098\n",
      "Epoch [500/500] | Train Loss: 0.181200 | Val Loss: 1.493337\n",
      "Epoch [100/500] | Train Loss: 0.531184 | Val Loss: 6.851882\n",
      "Epoch [200/500] | Train Loss: 0.393877 | Val Loss: 7.540083\n",
      "Epoch [300/500] | Train Loss: 0.352279 | Val Loss: 8.165396\n",
      "Epoch [400/500] | Train Loss: 0.328985 | Val Loss: 6.577367\n",
      "Epoch [500/500] | Train Loss: 0.277862 | Val Loss: 6.778799\n",
      "Epoch [100/500] | Train Loss: 0.873109 | Val Loss: 1.680049\n",
      "Epoch [200/500] | Train Loss: 0.713101 | Val Loss: 1.689532\n",
      "Epoch [300/500] | Train Loss: 0.623850 | Val Loss: 1.699111\n",
      "Epoch [400/500] | Train Loss: 0.766560 | Val Loss: 1.786997\n",
      "Epoch [500/500] | Train Loss: 0.673033 | Val Loss: 1.724336\n",
      "Epoch [100/500] | Train Loss: 1.103714 | Val Loss: 0.660585\n",
      "Epoch [200/500] | Train Loss: 0.964382 | Val Loss: 0.652443\n",
      "Epoch [300/500] | Train Loss: 0.898049 | Val Loss: 0.644491\n",
      "Epoch [400/500] | Train Loss: 0.815142 | Val Loss: 0.647831\n",
      "Epoch [500/500] | Train Loss: 0.804457 | Val Loss: 0.653501\n",
      "Epoch [100/500] | Train Loss: 0.214935 | Val Loss: 0.719847\n",
      "Epoch [200/500] | Train Loss: 0.194004 | Val Loss: 0.766687\n",
      "Epoch [300/500] | Train Loss: 0.179176 | Val Loss: 0.768734\n",
      "Epoch [400/500] | Train Loss: 0.173898 | Val Loss: 0.774149\n",
      "Epoch [500/500] | Train Loss: 0.162125 | Val Loss: 0.770420\n",
      "Epoch [100/500] | Train Loss: 0.436584 | Val Loss: 1.226953\n",
      "Epoch [200/500] | Train Loss: 0.376199 | Val Loss: 1.341591\n",
      "Epoch [300/500] | Train Loss: 0.383269 | Val Loss: 1.381277\n",
      "Epoch [400/500] | Train Loss: 0.386337 | Val Loss: 1.411876\n",
      "Epoch [500/500] | Train Loss: 0.311172 | Val Loss: 1.453626\n",
      "Epoch [100/500] | Train Loss: 0.701255 | Val Loss: 4.861873\n",
      "Epoch [200/500] | Train Loss: 0.657443 | Val Loss: 4.798878\n",
      "Epoch [300/500] | Train Loss: 0.635662 | Val Loss: 4.915328\n",
      "Epoch [400/500] | Train Loss: 0.643406 | Val Loss: 4.731296\n",
      "Epoch [500/500] | Train Loss: 0.579729 | Val Loss: 4.612944\n",
      "Epoch [100/500] | Train Loss: 1.555467 | Val Loss: 1.480862\n",
      "Epoch [200/500] | Train Loss: 1.249585 | Val Loss: 1.514893\n",
      "Epoch [300/500] | Train Loss: 1.245970 | Val Loss: 1.513502\n",
      "Epoch [400/500] | Train Loss: 1.179178 | Val Loss: 1.561439\n",
      "Epoch [500/500] | Train Loss: 1.068093 | Val Loss: 1.560861\n",
      "Epoch [100/500] | Train Loss: 1.639435 | Val Loss: 0.672166\n",
      "Epoch [200/500] | Train Loss: 1.513189 | Val Loss: 0.664619\n",
      "Epoch [300/500] | Train Loss: 1.445818 | Val Loss: 0.664445\n",
      "Epoch [400/500] | Train Loss: 1.386727 | Val Loss: 0.667106\n",
      "Epoch [500/500] | Train Loss: 1.378695 | Val Loss: 0.671371\n",
      "Epoch [100/500] | Train Loss: 0.186885 | Val Loss: 0.872689\n",
      "Epoch [200/500] | Train Loss: 0.166043 | Val Loss: 0.847252\n",
      "Epoch [300/500] | Train Loss: 0.123205 | Val Loss: 0.852814\n",
      "Epoch [400/500] | Train Loss: 0.117262 | Val Loss: 0.808491\n",
      "Epoch [500/500] | Train Loss: 0.110357 | Val Loss: 0.774385\n",
      "Epoch [100/500] | Train Loss: 0.314274 | Val Loss: 1.280143\n",
      "Epoch [200/500] | Train Loss: 0.288541 | Val Loss: 1.317104\n",
      "Epoch [300/500] | Train Loss: 0.279978 | Val Loss: 1.408458\n",
      "Epoch [400/500] | Train Loss: 0.268536 | Val Loss: 1.430504\n",
      "Epoch [500/500] | Train Loss: 0.244183 | Val Loss: 1.333396\n",
      "Epoch [100/500] | Train Loss: 0.541345 | Val Loss: 4.883714\n",
      "Epoch [200/500] | Train Loss: 0.551135 | Val Loss: 4.858458\n",
      "Epoch [300/500] | Train Loss: 0.433185 | Val Loss: 5.256763\n",
      "Epoch [400/500] | Train Loss: 0.488640 | Val Loss: 5.182456\n",
      "Epoch [500/500] | Train Loss: 0.485661 | Val Loss: 5.201081\n",
      "Epoch [100/500] | Train Loss: 1.216823 | Val Loss: 1.562913\n",
      "Epoch [200/500] | Train Loss: 0.924386 | Val Loss: 1.594549\n",
      "Epoch [300/500] | Train Loss: 0.927145 | Val Loss: 1.649205\n",
      "Epoch [400/500] | Train Loss: 1.003530 | Val Loss: 1.597642\n",
      "Epoch [500/500] | Train Loss: 0.886966 | Val Loss: 1.622399\n",
      "Epoch [100/500] | Train Loss: 1.397179 | Val Loss: 0.659723\n",
      "Epoch [200/500] | Train Loss: 1.234953 | Val Loss: 0.662302\n",
      "Epoch [300/500] | Train Loss: 0.957727 | Val Loss: 0.650076\n",
      "Epoch [400/500] | Train Loss: 0.996605 | Val Loss: 0.651285\n",
      "Epoch [500/500] | Train Loss: 0.943235 | Val Loss: 0.657857\n",
      "Epoch [100/500] | Train Loss: 0.197592 | Val Loss: 0.741236\n",
      "Epoch [200/500] | Train Loss: 0.159465 | Val Loss: 0.820068\n",
      "Epoch [300/500] | Train Loss: 0.125916 | Val Loss: 0.833368\n",
      "Epoch [400/500] | Train Loss: 0.114678 | Val Loss: 0.820332\n",
      "Epoch [500/500] | Train Loss: 0.093020 | Val Loss: 0.834688\n",
      "Epoch [100/500] | Train Loss: 0.384499 | Val Loss: 1.317774\n",
      "Epoch [200/500] | Train Loss: 0.306558 | Val Loss: 1.487366\n",
      "Epoch [300/500] | Train Loss: 0.268723 | Val Loss: 1.484841\n",
      "Epoch [400/500] | Train Loss: 0.251164 | Val Loss: 1.540499\n",
      "Epoch [500/500] | Train Loss: 0.203752 | Val Loss: 1.561880\n",
      "Epoch [100/500] | Train Loss: 0.661798 | Val Loss: 5.012880\n",
      "Epoch [200/500] | Train Loss: 0.568124 | Val Loss: 6.120184\n",
      "Epoch [300/500] | Train Loss: 0.469935 | Val Loss: 7.847794\n",
      "Epoch [400/500] | Train Loss: 0.429615 | Val Loss: 7.470593\n",
      "Epoch [500/500] | Train Loss: 0.380443 | Val Loss: 7.607564\n",
      "Epoch [100/500] | Train Loss: 1.394131 | Val Loss: 1.535618\n",
      "Epoch [200/500] | Train Loss: 0.991406 | Val Loss: 1.681760\n",
      "Epoch [300/500] | Train Loss: 0.870523 | Val Loss: 1.715720\n",
      "Epoch [400/500] | Train Loss: 0.774321 | Val Loss: 1.668006\n",
      "Epoch [500/500] | Train Loss: 0.774061 | Val Loss: 1.616237\n",
      "Epoch [100/500] | Train Loss: 1.370998 | Val Loss: 0.666457\n",
      "Epoch [200/500] | Train Loss: 1.306323 | Val Loss: 0.656996\n",
      "Epoch [300/500] | Train Loss: 1.130744 | Val Loss: 0.643944\n",
      "Epoch [400/500] | Train Loss: 0.980411 | Val Loss: 0.657050\n",
      "Epoch [500/500] | Train Loss: 0.923933 | Val Loss: 0.671159\n",
      "Epoch [100/500] | Train Loss: 0.135132 | Val Loss: 0.670732\n",
      "Epoch [200/500] | Train Loss: 0.085298 | Val Loss: 0.750767\n",
      "Epoch [300/500] | Train Loss: 0.058264 | Val Loss: 0.787768\n",
      "Epoch [400/500] | Train Loss: 0.066099 | Val Loss: 0.786595\n",
      "Epoch [500/500] | Train Loss: 0.073123 | Val Loss: 0.812275\n",
      "Epoch [100/500] | Train Loss: 0.257850 | Val Loss: 1.502351\n",
      "Epoch [200/500] | Train Loss: 0.222209 | Val Loss: 1.582123\n",
      "Epoch [300/500] | Train Loss: 0.173447 | Val Loss: 1.726050\n",
      "Epoch [400/500] | Train Loss: 0.182074 | Val Loss: 1.685962\n",
      "Epoch [500/500] | Train Loss: 0.169313 | Val Loss: 1.748522\n",
      "Epoch [100/500] | Train Loss: 0.473689 | Val Loss: 5.391284\n",
      "Epoch [200/500] | Train Loss: 0.326293 | Val Loss: 5.837617\n",
      "Epoch [300/500] | Train Loss: 0.287290 | Val Loss: 6.386994\n",
      "Epoch [400/500] | Train Loss: 0.286213 | Val Loss: 6.136596\n",
      "Epoch [500/500] | Train Loss: 0.275690 | Val Loss: 6.376402\n",
      "Epoch [100/500] | Train Loss: 0.780506 | Val Loss: 1.734450\n",
      "Epoch [200/500] | Train Loss: 0.846226 | Val Loss: 1.738413\n",
      "Epoch [300/500] | Train Loss: 0.562441 | Val Loss: 1.787319\n",
      "Epoch [400/500] | Train Loss: 0.582336 | Val Loss: 1.721587\n",
      "Epoch [500/500] | Train Loss: 0.538125 | Val Loss: 1.794558\n",
      "Epoch [100/500] | Train Loss: 1.018688 | Val Loss: 0.684739\n",
      "Epoch [200/500] | Train Loss: 0.774275 | Val Loss: 0.725615\n",
      "Epoch [300/500] | Train Loss: 0.683104 | Val Loss: 0.710824\n",
      "Epoch [400/500] | Train Loss: 0.674308 | Val Loss: 0.727886\n",
      "Epoch [500/500] | Train Loss: 0.649360 | Val Loss: 0.790800\n",
      "Epoch [100/500] | Train Loss: 0.194568 | Val Loss: 0.730669\n",
      "Epoch [200/500] | Train Loss: 0.182857 | Val Loss: 0.768565\n",
      "Epoch [300/500] | Train Loss: 0.149458 | Val Loss: 0.774935\n",
      "Epoch [400/500] | Train Loss: 0.139717 | Val Loss: 0.799629\n",
      "Epoch [500/500] | Train Loss: 0.114380 | Val Loss: 0.807307\n",
      "Epoch [100/500] | Train Loss: 0.447074 | Val Loss: 1.191809\n",
      "Epoch [200/500] | Train Loss: 0.406168 | Val Loss: 1.288400\n",
      "Epoch [300/500] | Train Loss: 0.340691 | Val Loss: 1.428762\n",
      "Epoch [400/500] | Train Loss: 0.314124 | Val Loss: 1.406225\n",
      "Epoch [500/500] | Train Loss: 0.311331 | Val Loss: 1.411455\n",
      "Epoch [100/500] | Train Loss: 0.695463 | Val Loss: 4.946631\n",
      "Epoch [200/500] | Train Loss: 0.633286 | Val Loss: 5.129923\n",
      "Epoch [300/500] | Train Loss: 0.593502 | Val Loss: 5.406081\n",
      "Epoch [400/500] | Train Loss: 0.514015 | Val Loss: 6.078513\n",
      "Epoch [500/500] | Train Loss: 0.485110 | Val Loss: 6.379933\n",
      "Epoch [100/500] | Train Loss: 1.573246 | Val Loss: 1.561394\n",
      "Epoch [200/500] | Train Loss: 1.289888 | Val Loss: 1.574962\n",
      "Epoch [300/500] | Train Loss: 1.118077 | Val Loss: 1.624528\n",
      "Epoch [400/500] | Train Loss: 1.011617 | Val Loss: 1.638266\n",
      "Epoch [500/500] | Train Loss: 0.990728 | Val Loss: 1.642035\n",
      "Epoch [100/500] | Train Loss: 1.442871 | Val Loss: 0.680011\n",
      "Epoch [200/500] | Train Loss: 1.341245 | Val Loss: 0.644437\n",
      "Epoch [300/500] | Train Loss: 1.380683 | Val Loss: 0.639859\n",
      "Epoch [400/500] | Train Loss: 1.204398 | Val Loss: 0.644502\n",
      "Epoch [500/500] | Train Loss: 1.158347 | Val Loss: 0.645223\n",
      "Epoch [100/500] | Train Loss: 0.137445 | Val Loss: 0.752438\n",
      "Epoch [200/500] | Train Loss: 0.114610 | Val Loss: 0.772577\n",
      "Epoch [300/500] | Train Loss: 0.089150 | Val Loss: 0.798026\n",
      "Epoch [400/500] | Train Loss: 0.092268 | Val Loss: 0.813604\n",
      "Epoch [500/500] | Train Loss: 0.094373 | Val Loss: 0.724917\n",
      "Epoch [100/500] | Train Loss: 0.282248 | Val Loss: 1.434778\n",
      "Epoch [200/500] | Train Loss: 0.266900 | Val Loss: 1.404376\n",
      "Epoch [300/500] | Train Loss: 0.228557 | Val Loss: 1.428512\n",
      "Epoch [400/500] | Train Loss: 0.212213 | Val Loss: 1.418022\n",
      "Epoch [500/500] | Train Loss: 0.194387 | Val Loss: 1.431084\n",
      "Epoch [100/500] | Train Loss: 0.511511 | Val Loss: 5.264484\n",
      "Epoch [200/500] | Train Loss: 0.427812 | Val Loss: 5.533611\n",
      "Epoch [300/500] | Train Loss: 0.451836 | Val Loss: 5.573192\n",
      "Epoch [400/500] | Train Loss: 0.417332 | Val Loss: 5.622699\n",
      "Epoch [500/500] | Train Loss: 0.382275 | Val Loss: 5.649785\n",
      "Epoch [100/500] | Train Loss: 0.979972 | Val Loss: 1.641333\n",
      "Epoch [200/500] | Train Loss: 0.916304 | Val Loss: 1.666692\n",
      "Epoch [300/500] | Train Loss: 0.828421 | Val Loss: 1.635873\n",
      "Epoch [400/500] | Train Loss: 0.893163 | Val Loss: 1.711525\n",
      "Epoch [500/500] | Train Loss: 0.729139 | Val Loss: 1.747670\n",
      "Epoch [100/500] | Train Loss: 1.024194 | Val Loss: 0.667403\n",
      "Epoch [200/500] | Train Loss: 0.983898 | Val Loss: 0.660479\n",
      "Epoch [300/500] | Train Loss: 0.857891 | Val Loss: 0.667940\n",
      "Epoch [400/500] | Train Loss: 0.901644 | Val Loss: 0.667253\n",
      "Epoch [500/500] | Train Loss: 0.867398 | Val Loss: 0.688105\n",
      "[Year=2022] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=1.813845 Test MSE=2.678152\n",
      "Year 2022 done.\n",
      "---------------------------------------------------\n",
      "Epoch [100/500] | Train Loss: 0.777629 | Val Loss: 1.281792\n",
      "Epoch [200/500] | Train Loss: 0.606116 | Val Loss: 1.533751\n",
      "Epoch [300/500] | Train Loss: 0.394387 | Val Loss: 1.661300\n",
      "Epoch [400/500] | Train Loss: 0.407041 | Val Loss: 1.731045\n",
      "Epoch [500/500] | Train Loss: 0.339848 | Val Loss: 1.756505\n",
      "Epoch [100/500] | Train Loss: 0.998019 | Val Loss: 5.174795\n",
      "Epoch [200/500] | Train Loss: 0.902004 | Val Loss: 5.591435\n",
      "Epoch [300/500] | Train Loss: 0.734775 | Val Loss: 6.000496\n",
      "Epoch [400/500] | Train Loss: 0.679706 | Val Loss: 6.142822\n",
      "Epoch [500/500] | Train Loss: 0.627224 | Val Loss: 6.164551\n",
      "Epoch [100/500] | Train Loss: 2.104867 | Val Loss: 1.080598\n",
      "Epoch [200/500] | Train Loss: 1.653914 | Val Loss: 1.123831\n",
      "Epoch [300/500] | Train Loss: 1.491861 | Val Loss: 1.143276\n",
      "Epoch [400/500] | Train Loss: 1.489240 | Val Loss: 1.140886\n",
      "Epoch [500/500] | Train Loss: 1.259594 | Val Loss: 1.151466\n",
      "Epoch [100/500] | Train Loss: 1.879460 | Val Loss: 1.014387\n",
      "Epoch [200/500] | Train Loss: 1.637123 | Val Loss: 0.971695\n",
      "Epoch [300/500] | Train Loss: 1.386387 | Val Loss: 0.975839\n",
      "Epoch [400/500] | Train Loss: 1.364456 | Val Loss: 0.970649\n",
      "Epoch [500/500] | Train Loss: 1.294976 | Val Loss: 0.996210\n",
      "Epoch [100/500] | Train Loss: 1.633751 | Val Loss: 2.810985\n",
      "Epoch [200/500] | Train Loss: 1.349909 | Val Loss: 2.797472\n",
      "Epoch [300/500] | Train Loss: 1.323815 | Val Loss: 2.848214\n",
      "Epoch [400/500] | Train Loss: 1.148694 | Val Loss: 2.872780\n",
      "Epoch [500/500] | Train Loss: 1.193451 | Val Loss: 2.884564\n",
      "Epoch [100/500] | Train Loss: 0.396720 | Val Loss: 1.698390\n",
      "Epoch [200/500] | Train Loss: 0.311205 | Val Loss: 1.776297\n",
      "Epoch [300/500] | Train Loss: 0.228096 | Val Loss: 1.773167\n",
      "Epoch [400/500] | Train Loss: 0.205750 | Val Loss: 1.729238\n",
      "Epoch [500/500] | Train Loss: 0.221556 | Val Loss: 1.666318\n",
      "Epoch [100/500] | Train Loss: 0.605829 | Val Loss: 7.147203\n",
      "Epoch [200/500] | Train Loss: 0.521649 | Val Loss: 7.681464\n",
      "Epoch [300/500] | Train Loss: 0.465942 | Val Loss: 7.773202\n",
      "Epoch [400/500] | Train Loss: 0.368411 | Val Loss: 7.662955\n",
      "Epoch [500/500] | Train Loss: 0.455977 | Val Loss: 7.487692\n",
      "Epoch [100/500] | Train Loss: 1.415988 | Val Loss: 1.148807\n",
      "Epoch [200/500] | Train Loss: 1.109629 | Val Loss: 1.165553\n",
      "Epoch [300/500] | Train Loss: 1.160544 | Val Loss: 1.155262\n",
      "Epoch [400/500] | Train Loss: 0.986343 | Val Loss: 1.216976\n",
      "Epoch [500/500] | Train Loss: 0.744267 | Val Loss: 1.176432\n",
      "Epoch [100/500] | Train Loss: 1.160582 | Val Loss: 0.935046\n",
      "Epoch [200/500] | Train Loss: 1.084212 | Val Loss: 1.012206\n",
      "Epoch [300/500] | Train Loss: 1.066119 | Val Loss: 0.976539\n",
      "Epoch [400/500] | Train Loss: 0.870233 | Val Loss: 1.040038\n",
      "Epoch [500/500] | Train Loss: 0.970859 | Val Loss: 1.054548\n",
      "Epoch [100/500] | Train Loss: 1.194387 | Val Loss: 2.954044\n",
      "Epoch [200/500] | Train Loss: 1.010919 | Val Loss: 3.149054\n",
      "Epoch [300/500] | Train Loss: 0.948298 | Val Loss: 3.226095\n",
      "Epoch [400/500] | Train Loss: 0.866001 | Val Loss: 3.340783\n",
      "Epoch [500/500] | Train Loss: 0.883512 | Val Loss: 3.329531\n",
      "Epoch [100/500] | Train Loss: 0.880418 | Val Loss: 1.188807\n",
      "Epoch [200/500] | Train Loss: 0.713461 | Val Loss: 1.301779\n",
      "Epoch [300/500] | Train Loss: 0.659126 | Val Loss: 1.405571\n",
      "Epoch [400/500] | Train Loss: 0.572797 | Val Loss: 1.492764\n",
      "Epoch [500/500] | Train Loss: 0.491772 | Val Loss: 1.516468\n",
      "Epoch [100/500] | Train Loss: 1.037478 | Val Loss: 5.240551\n",
      "Epoch [200/500] | Train Loss: 0.984893 | Val Loss: 5.246115\n",
      "Epoch [300/500] | Train Loss: 0.942082 | Val Loss: 5.370042\n",
      "Epoch [400/500] | Train Loss: 0.892733 | Val Loss: 5.328564\n",
      "Epoch [500/500] | Train Loss: 0.795568 | Val Loss: 5.540740\n",
      "Epoch [100/500] | Train Loss: 2.224076 | Val Loss: 1.098832\n",
      "Epoch [200/500] | Train Loss: 2.076291 | Val Loss: 1.126622\n",
      "Epoch [300/500] | Train Loss: 1.713051 | Val Loss: 1.091765\n",
      "Epoch [400/500] | Train Loss: 1.563595 | Val Loss: 1.092565\n",
      "Epoch [500/500] | Train Loss: 1.730748 | Val Loss: 1.110631\n",
      "Epoch [100/500] | Train Loss: 1.844385 | Val Loss: 0.966052\n",
      "Epoch [200/500] | Train Loss: 1.693485 | Val Loss: 0.927552\n",
      "Epoch [300/500] | Train Loss: 1.511955 | Val Loss: 0.930353\n",
      "Epoch [400/500] | Train Loss: 1.458574 | Val Loss: 0.924640\n",
      "Epoch [500/500] | Train Loss: 1.480783 | Val Loss: 0.923568\n",
      "Epoch [100/500] | Train Loss: 1.707460 | Val Loss: 2.772191\n",
      "Epoch [200/500] | Train Loss: 1.545764 | Val Loss: 2.804013\n",
      "Epoch [300/500] | Train Loss: 1.396074 | Val Loss: 2.825689\n",
      "Epoch [400/500] | Train Loss: 1.353042 | Val Loss: 2.790212\n",
      "Epoch [500/500] | Train Loss: 1.321558 | Val Loss: 2.789142\n",
      "Epoch [100/500] | Train Loss: 0.675649 | Val Loss: 1.606770\n",
      "Epoch [200/500] | Train Loss: 0.463771 | Val Loss: 1.718798\n",
      "Epoch [300/500] | Train Loss: 0.398212 | Val Loss: 1.650153\n",
      "Epoch [400/500] | Train Loss: 0.329918 | Val Loss: 1.604098\n",
      "Epoch [500/500] | Train Loss: 0.380952 | Val Loss: 1.642356\n",
      "Epoch [100/500] | Train Loss: 0.897333 | Val Loss: 5.559878\n",
      "Epoch [200/500] | Train Loss: 0.701255 | Val Loss: 6.312707\n",
      "Epoch [300/500] | Train Loss: 0.646024 | Val Loss: 7.041903\n",
      "Epoch [400/500] | Train Loss: 0.692002 | Val Loss: 6.641263\n",
      "Epoch [500/500] | Train Loss: 0.660886 | Val Loss: 6.194904\n",
      "Epoch [100/500] | Train Loss: 1.657910 | Val Loss: 1.150369\n",
      "Epoch [200/500] | Train Loss: 1.346423 | Val Loss: 1.174811\n",
      "Epoch [300/500] | Train Loss: 1.176024 | Val Loss: 1.140434\n",
      "Epoch [400/500] | Train Loss: 1.250532 | Val Loss: 1.102962\n",
      "Epoch [500/500] | Train Loss: 1.051738 | Val Loss: 1.128178\n",
      "Epoch [100/500] | Train Loss: 1.638084 | Val Loss: 0.937988\n",
      "Epoch [200/500] | Train Loss: 1.342649 | Val Loss: 0.923953\n",
      "Epoch [300/500] | Train Loss: 1.226965 | Val Loss: 0.915856\n",
      "Epoch [400/500] | Train Loss: 1.228950 | Val Loss: 0.940019\n",
      "Epoch [500/500] | Train Loss: 1.140247 | Val Loss: 0.904909\n",
      "Epoch [100/500] | Train Loss: 1.513372 | Val Loss: 2.835679\n",
      "Epoch [200/500] | Train Loss: 1.348307 | Val Loss: 2.736754\n",
      "Epoch [300/500] | Train Loss: 1.224060 | Val Loss: 2.841892\n",
      "Epoch [400/500] | Train Loss: 1.096782 | Val Loss: 3.021622\n",
      "Epoch [500/500] | Train Loss: 1.164585 | Val Loss: 3.063820\n",
      "Epoch [100/500] | Train Loss: 0.730707 | Val Loss: 1.327384\n",
      "Epoch [200/500] | Train Loss: 0.473521 | Val Loss: 1.613882\n",
      "Epoch [300/500] | Train Loss: 0.373006 | Val Loss: 1.674065\n",
      "Epoch [400/500] | Train Loss: 0.330709 | Val Loss: 1.561528\n",
      "Epoch [500/500] | Train Loss: 0.318157 | Val Loss: 1.638850\n",
      "Epoch [100/500] | Train Loss: 0.930684 | Val Loss: 5.562774\n",
      "Epoch [200/500] | Train Loss: 0.778419 | Val Loss: 6.242723\n",
      "Epoch [300/500] | Train Loss: 0.674227 | Val Loss: 6.320255\n",
      "Epoch [400/500] | Train Loss: 0.632400 | Val Loss: 6.629730\n",
      "Epoch [500/500] | Train Loss: 0.573812 | Val Loss: 6.554073\n",
      "Epoch [100/500] | Train Loss: 1.994033 | Val Loss: 1.110772\n",
      "Epoch [200/500] | Train Loss: 1.477877 | Val Loss: 1.165842\n",
      "Epoch [300/500] | Train Loss: 1.367603 | Val Loss: 1.210435\n",
      "Epoch [400/500] | Train Loss: 1.168726 | Val Loss: 1.170909\n",
      "Epoch [500/500] | Train Loss: 1.012579 | Val Loss: 1.189676\n",
      "Epoch [100/500] | Train Loss: 1.568036 | Val Loss: 0.964513\n",
      "Epoch [200/500] | Train Loss: 1.332332 | Val Loss: 0.920673\n",
      "Epoch [300/500] | Train Loss: 1.257107 | Val Loss: 0.933026\n",
      "Epoch [400/500] | Train Loss: 1.215172 | Val Loss: 0.947755\n",
      "Epoch [500/500] | Train Loss: 1.087934 | Val Loss: 0.955750\n",
      "Epoch [100/500] | Train Loss: 1.611756 | Val Loss: 2.829758\n",
      "Epoch [200/500] | Train Loss: 1.351112 | Val Loss: 2.835529\n",
      "Epoch [300/500] | Train Loss: 1.183267 | Val Loss: 2.896091\n",
      "Epoch [400/500] | Train Loss: 1.115928 | Val Loss: 2.995192\n",
      "Epoch [500/500] | Train Loss: 1.070733 | Val Loss: 3.081714\n",
      "Epoch [100/500] | Train Loss: 0.333718 | Val Loss: 1.946119\n",
      "Epoch [200/500] | Train Loss: 0.234191 | Val Loss: 1.997747\n",
      "Epoch [300/500] | Train Loss: 0.205798 | Val Loss: 2.129731\n",
      "Epoch [400/500] | Train Loss: 0.289299 | Val Loss: 2.078769\n",
      "Epoch [500/500] | Train Loss: 0.112159 | Val Loss: 1.958548\n",
      "Epoch [100/500] | Train Loss: 0.683288 | Val Loss: 6.550436\n",
      "Epoch [200/500] | Train Loss: 0.433526 | Val Loss: 6.341939\n",
      "Epoch [300/500] | Train Loss: 0.337139 | Val Loss: 5.908922\n",
      "Epoch [400/500] | Train Loss: 0.365796 | Val Loss: 6.098944\n",
      "Epoch [500/500] | Train Loss: 0.298753 | Val Loss: 5.879233\n",
      "Epoch [100/500] | Train Loss: 1.474648 | Val Loss: 1.219841\n",
      "Epoch [200/500] | Train Loss: 1.127086 | Val Loss: 1.216982\n",
      "Epoch [300/500] | Train Loss: 0.954335 | Val Loss: 1.237662\n",
      "Epoch [400/500] | Train Loss: 0.791195 | Val Loss: 1.197533\n",
      "Epoch [500/500] | Train Loss: 0.940265 | Val Loss: 1.255877\n",
      "Epoch [100/500] | Train Loss: 1.152879 | Val Loss: 0.911803\n",
      "Epoch [200/500] | Train Loss: 1.036950 | Val Loss: 1.013396\n",
      "Epoch [300/500] | Train Loss: 0.920943 | Val Loss: 0.962451\n",
      "Epoch [400/500] | Train Loss: 0.884539 | Val Loss: 0.962575\n",
      "Epoch [500/500] | Train Loss: 0.859572 | Val Loss: 0.965918\n",
      "Epoch [100/500] | Train Loss: 1.165848 | Val Loss: 2.804704\n",
      "Epoch [200/500] | Train Loss: 1.036918 | Val Loss: 3.226057\n",
      "Epoch [300/500] | Train Loss: 0.903375 | Val Loss: 3.240070\n",
      "Epoch [400/500] | Train Loss: 0.909394 | Val Loss: 3.156012\n",
      "Epoch [500/500] | Train Loss: 0.858151 | Val Loss: 3.230643\n",
      "Epoch [100/500] | Train Loss: 0.867850 | Val Loss: 1.231125\n",
      "Epoch [200/500] | Train Loss: 0.614868 | Val Loss: 1.393907\n",
      "Epoch [300/500] | Train Loss: 0.515725 | Val Loss: 1.570023\n",
      "Epoch [400/500] | Train Loss: 0.434072 | Val Loss: 1.541858\n",
      "Epoch [500/500] | Train Loss: 0.388896 | Val Loss: 1.589884\n",
      "Epoch [100/500] | Train Loss: 1.002495 | Val Loss: 5.362169\n",
      "Epoch [200/500] | Train Loss: 0.904735 | Val Loss: 5.640718\n",
      "Epoch [300/500] | Train Loss: 0.922101 | Val Loss: 5.305623\n",
      "Epoch [400/500] | Train Loss: 0.766933 | Val Loss: 5.434458\n",
      "Epoch [500/500] | Train Loss: 0.706939 | Val Loss: 5.746542\n",
      "Epoch [100/500] | Train Loss: 2.245081 | Val Loss: 1.066735\n",
      "Epoch [200/500] | Train Loss: 1.947063 | Val Loss: 1.105665\n",
      "Epoch [300/500] | Train Loss: 1.695797 | Val Loss: 1.105618\n",
      "Epoch [400/500] | Train Loss: 1.417401 | Val Loss: 1.126854\n",
      "Epoch [500/500] | Train Loss: 1.381576 | Val Loss: 1.131448\n",
      "Epoch [100/500] | Train Loss: 1.857973 | Val Loss: 0.960529\n",
      "Epoch [200/500] | Train Loss: 1.731645 | Val Loss: 0.943066\n",
      "Epoch [300/500] | Train Loss: 1.545605 | Val Loss: 0.962388\n",
      "Epoch [400/500] | Train Loss: 1.305994 | Val Loss: 0.968760\n",
      "Epoch [500/500] | Train Loss: 1.310313 | Val Loss: 0.938486\n",
      "Epoch [100/500] | Train Loss: 1.650972 | Val Loss: 2.798867\n",
      "Epoch [200/500] | Train Loss: 1.522657 | Val Loss: 2.765702\n",
      "Epoch [300/500] | Train Loss: 1.345029 | Val Loss: 2.730717\n",
      "Epoch [400/500] | Train Loss: 1.411656 | Val Loss: 2.815115\n",
      "Epoch [500/500] | Train Loss: 1.324904 | Val Loss: 2.752179\n",
      "Epoch [100/500] | Train Loss: 0.511210 | Val Loss: 1.508351\n",
      "Epoch [200/500] | Train Loss: 0.371772 | Val Loss: 1.667631\n",
      "Epoch [300/500] | Train Loss: 0.335040 | Val Loss: 1.760408\n",
      "Epoch [400/500] | Train Loss: 0.396880 | Val Loss: 1.755813\n",
      "Epoch [500/500] | Train Loss: 0.294098 | Val Loss: 1.610995\n",
      "Epoch [100/500] | Train Loss: 0.760111 | Val Loss: 5.392139\n",
      "Epoch [200/500] | Train Loss: 0.723878 | Val Loss: 5.051568\n",
      "Epoch [300/500] | Train Loss: 0.558538 | Val Loss: 5.312463\n",
      "Epoch [400/500] | Train Loss: 0.510234 | Val Loss: 5.644885\n",
      "Epoch [500/500] | Train Loss: 0.571753 | Val Loss: 5.412271\n",
      "Epoch [100/500] | Train Loss: 1.469173 | Val Loss: 1.099630\n",
      "Epoch [200/500] | Train Loss: 1.401789 | Val Loss: 1.052135\n",
      "Epoch [300/500] | Train Loss: 1.208445 | Val Loss: 1.084552\n",
      "Epoch [400/500] | Train Loss: 1.207512 | Val Loss: 1.107443\n",
      "Epoch [500/500] | Train Loss: 1.035868 | Val Loss: 1.137382\n",
      "Epoch [100/500] | Train Loss: 1.276843 | Val Loss: 0.946700\n",
      "Epoch [200/500] | Train Loss: 1.285372 | Val Loss: 0.962575\n",
      "Epoch [300/500] | Train Loss: 1.161607 | Val Loss: 0.979743\n",
      "Epoch [400/500] | Train Loss: 1.080029 | Val Loss: 0.989140\n",
      "Epoch [500/500] | Train Loss: 1.009638 | Val Loss: 0.963885\n",
      "Epoch [100/500] | Train Loss: 1.315222 | Val Loss: 2.845531\n",
      "Epoch [200/500] | Train Loss: 1.236019 | Val Loss: 2.965836\n",
      "Epoch [300/500] | Train Loss: 1.166960 | Val Loss: 2.937870\n",
      "Epoch [400/500] | Train Loss: 1.241231 | Val Loss: 2.968275\n",
      "Epoch [500/500] | Train Loss: 1.021569 | Val Loss: 2.959661\n",
      "[Year=2023] Best Params={'num_epochs': 500, 'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001} CV-MSE=2.376110 Test MSE=1.063514\n",
      "Year 2023 done.\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [f'lag_{i}' for i in range(1, 6)]\n",
    "target_col = 'Return'\n",
    "\n",
    "param_grid = {\n",
    "    'num_epochs':   [500],\n",
    "    'hidden_size':  [32, 64],\n",
    "    'dropout_rate': [0.1, 0.2],\n",
    "    'learning_rate':[0.001, 0.01],\n",
    "}\n",
    "\n",
    "rolling_results = []\n",
    "all_predictions = []\n",
    "\n",
    "# Each window: 4 years train, 1 year validation, 1 year test\n",
    "min_year = df_lags5['Year'].min()\n",
    "max_year = df_lags5['Year'].max()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for test_year in range(min_year + 5, max_year + 1):\n",
    "    train_years = list(range(test_year - 5, test_year - 1))  # e.g. [test_year-5 .. test_year-2]\n",
    "    val_year = test_year - 1\n",
    "    \n",
    "    # Masks\n",
    "    train_mask = df_lags5['Year'].isin(train_years)\n",
    "    val_mask   = (df_lags5['Year'] == val_year)\n",
    "    test_mask  = (df_lags5['Year'] == test_year)\n",
    "    \n",
    "    # Slices\n",
    "    X_train = df_lags5.loc[train_mask, feature_cols]\n",
    "    y_train = df_lags5.loc[train_mask, target_col]\n",
    "\n",
    "    X_val   = df_lags5.loc[val_mask, feature_cols]\n",
    "    y_val   = df_lags5.loc[val_mask, target_col]\n",
    "\n",
    "    X_test  = df_lags5.loc[test_mask, feature_cols]\n",
    "    y_test  = df_lags5.loc[test_mask, target_col]\n",
    "    \n",
    "    # Combine train+val\n",
    "    X_train_val = pd.concat([X_train, X_val], axis=0)\n",
    "    y_train_val = pd.concat([y_train, y_val], axis=0)\n",
    "    \n",
    "    # ----------------------\n",
    "    # TimeSeriesSplit for the grid search\n",
    "    # ----------------------\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    # Flatten param_grid into a list of param dicts\n",
    "    from itertools import product\n",
    "    param_list = []\n",
    "    for (ne, hs, dr, lr) in product(\n",
    "        param_grid['num_epochs'],\n",
    "        param_grid['hidden_size'],\n",
    "        param_grid['dropout_rate'],\n",
    "        param_grid['learning_rate']\n",
    "    ):\n",
    "        param_list.append({\n",
    "            'num_epochs': ne,\n",
    "            'hidden_size': hs,\n",
    "            'dropout_rate': dr,\n",
    "            'learning_rate': lr\n",
    "        })\n",
    "\n",
    "    best_val_mse = float('inf')\n",
    "    best_params  = None\n",
    "\n",
    "    Xtv = X_train_val.reset_index(drop=True)\n",
    "    ytv = y_train_val.reset_index(drop=True)\n",
    "    \n",
    "    # Manual grid search\n",
    "    for params in param_list:\n",
    "        fold_mses = []\n",
    "        for train_index, val_index in tscv.split(Xtv):\n",
    "            X_train_fold = Xtv.iloc[train_index]\n",
    "            y_train_fold = ytv.iloc[train_index]\n",
    "            X_val_fold   = Xtv.iloc[val_index]\n",
    "            y_val_fold   = ytv.iloc[val_index]\n",
    "\n",
    "            model_fold, mse_val = train_model(\n",
    "                num_epochs   = params['num_epochs'],\n",
    "                hidden_size  = params['hidden_size'],\n",
    "                dropout_rate = params['dropout_rate'],\n",
    "                learning_rate= params['learning_rate'],\n",
    "                X_train_fold = X_train_fold,\n",
    "                y_train_fold = y_train_fold,\n",
    "                X_val_fold   = X_val_fold,\n",
    "                y_val_fold   = y_val_fold,\n",
    "                device=device\n",
    "            )\n",
    "            fold_mses.append(mse_val)\n",
    "\n",
    "        avg_mse = np.mean(fold_mses)\n",
    "        if avg_mse < best_val_mse:\n",
    "            best_val_mse = avg_mse\n",
    "            best_params  = params.copy()\n",
    "\n",
    "    # ---------------\n",
    "    # Retrain final model on full train+val with best_params\n",
    "    # ---------------\n",
    "    final_num_epochs   = best_params['num_epochs']\n",
    "    final_hidden_size  = best_params['hidden_size']\n",
    "    final_dropout_rate = best_params['dropout_rate']\n",
    "    final_learning_rate= best_params['learning_rate']\n",
    "\n",
    "    # Convert train+val to torch\n",
    "    Xtv_torch = torch.tensor(X_train_val.values, dtype=torch.float32).to(device)\n",
    "    ytv_torch = torch.tensor(y_train_val.values.reshape(-1,1), dtype=torch.float32).to(device)\n",
    "\n",
    "    input_dim = Xtv_torch.shape[1]\n",
    "    final_model = SimpleNN(input_dim, final_hidden_size, final_dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(final_model.parameters(), lr=final_learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    final_model.train()\n",
    "    for epoch in range(final_num_epochs):\n",
    "        y_pred = final_model(Xtv_torch)\n",
    "        loss   = criterion(y_pred, ytv_torch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # ---------------\n",
    "    # Evaluate on test\n",
    "    # ---------------\n",
    "    X_test_torch = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "    final_model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds_test_torch = final_model(X_test_torch).cpu().numpy().ravel()\n",
    "\n",
    "    test_mse = mean_squared_error(y_test, preds_test_torch)\n",
    "\n",
    "    print(f\"[Year={test_year}] Best Params={best_params} CV-MSE={best_val_mse:.6f} Test MSE={test_mse:.6f}\")\n",
    "\n",
    "    # Store rolling result\n",
    "    rolling_results.append({\n",
    "        'test_year': test_year,\n",
    "        'train_years': train_years,\n",
    "        'val_year': val_year,\n",
    "        'best_params': best_params,\n",
    "        'cv_mse': best_val_mse,\n",
    "        'test_mse': test_mse\n",
    "    })\n",
    "\n",
    "    # Store predictions\n",
    "    df_test_window = df_lags5.loc[test_mask, ['Date', 'idxd', 'Return']].copy()\n",
    "    df_test_window['prediction'] = preds_test_torch\n",
    "    df_test_window['test_year'] = test_year\n",
    "    all_predictions.append(df_test_window)\n",
    "    # print year is done\n",
    "    print(f\"Year {test_year} done.\")\n",
    "    print(\"---------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rolling Window Results (summary) ===\n",
      "    test_year               train_years  val_year  \\\n",
      "0        1932  [1927, 1928, 1929, 1930]      1931   \n",
      "1        1933  [1928, 1929, 1930, 1931]      1932   \n",
      "2        1934  [1929, 1930, 1931, 1932]      1933   \n",
      "3        1935  [1930, 1931, 1932, 1933]      1934   \n",
      "4        1936  [1931, 1932, 1933, 1934]      1935   \n",
      "..        ...                       ...       ...   \n",
      "87       2019  [2014, 2015, 2016, 2017]      2018   \n",
      "88       2020  [2015, 2016, 2017, 2018]      2019   \n",
      "89       2021  [2016, 2017, 2018, 2019]      2020   \n",
      "90       2022  [2017, 2018, 2019, 2020]      2021   \n",
      "91       2023  [2018, 2019, 2020, 2021]      2022   \n",
      "\n",
      "                                          best_params    cv_mse  test_mse  \n",
      "0   {'num_epochs': 500, 'hidden_size': 32, 'dropou...  2.799084  8.607568  \n",
      "1   {'num_epochs': 500, 'hidden_size': 32, 'dropou...  4.877116  6.882683  \n",
      "2   {'num_epochs': 500, 'hidden_size': 32, 'dropou...  5.794985  1.903509  \n",
      "3   {'num_epochs': 500, 'hidden_size': 32, 'dropou...  5.287065  0.882330  \n",
      "4   {'num_epochs': 500, 'hidden_size': 32, 'dropou...  4.476451  0.772208  \n",
      "..                                                ...       ...       ...  \n",
      "87  {'num_epochs': 500, 'hidden_size': 32, 'dropou...  0.832865  0.763038  \n",
      "88  {'num_epochs': 500, 'hidden_size': 32, 'dropou...  0.811835  5.084241  \n",
      "89  {'num_epochs': 500, 'hidden_size': 32, 'dropou...  1.781452  0.796836  \n",
      "90  {'num_epochs': 500, 'hidden_size': 32, 'dropou...  1.813845  2.678152  \n",
      "91  {'num_epochs': 500, 'hidden_size': 32, 'dropou...  2.376110  1.063514  \n",
      "\n",
      "[92 rows x 6 columns]\n",
      "\n",
      "=== Sample of combined predictions ===\n",
      "       date  idxd  actual  prediction  test_year\n",
      "0  19320102  1636   -3.47   -0.004918       1932\n",
      "1  19320104  1637   -2.99   -0.310362       1932\n",
      "2  19320105  1638   -0.37    0.462464       1932\n",
      "3  19320106  1639    6.44    0.027494       1932\n",
      "4  19320107  1640    1.99    1.162990       1932\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.concat(all_predictions, ignore_index=True)\n",
    "results_df.rename(columns={'Return': 'actual'}, inplace=True)\n",
    "results_df = results_df[['Date', 'idxd', 'actual', 'prediction', 'test_year']]\n",
    "results_df.columns = ['date', 'idxd', 'actual', 'prediction', 'test_year']\n",
    "\n",
    "rolling_results_df = pd.DataFrame(rolling_results)\n",
    "\n",
    "print(\"\\n=== Rolling Window Results (summary) ===\")\n",
    "print(rolling_results_df)\n",
    "\n",
    "print(\"\\n=== Sample of combined predictions ===\")\n",
    "print(results_df.head())\n",
    "\n",
    "# Save predictions if desired\n",
    "results_df.to_csv(\"/Users/ryanhuang/Developer/transformers/results/RollingNNBlock5.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3l_SWIMjwvF9",
    "outputId": "bd8d7e13-37d5-402e-a27a-6ca6824b91e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 actual   R-squared:                       0.005\n",
      "Model:                            OLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     54.37\n",
      "Date:                Fri, 14 Mar 2025   Prob (F-statistic):           2.76e-24\n",
      "Time:                        17:38:33   Log-Likelihood:                -35023.\n",
      "No. Observations:               23844   AIC:                         7.005e+04\n",
      "Df Residuals:                   23841   BIC:                         7.008e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const             0.0285      0.007      4.173      0.000       0.015       0.042\n",
      "prediction        0.1661      0.023      7.344      0.000       0.122       0.210\n",
      "Lagged_Actual     0.0397      0.007      6.054      0.000       0.027       0.053\n",
      "==============================================================================\n",
      "Omnibus:                     5358.089   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           252208.118\n",
      "Skew:                          -0.161   Prob(JB):                         0.00\n",
      "Kurtosis:                      18.930   Cond. No.                         3.53\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "df1 = results_df\n",
    "\n",
    "# Create a lagged version of the actual values\n",
    "df1['Lagged_Actual'] = df1['actual'].shift(1)\n",
    "\n",
    "# Convert columns to numeric, especially 'Prediction'\n",
    "df1['Prediction'] = pd.to_numeric(df1['prediction'], errors='coerce')\n",
    "\n",
    "# Drop any rows with NaN values after conversion\n",
    "df1 = df1.dropna(subset=['actual', 'prediction', 'Lagged_Actual'])\n",
    "\n",
    "# Define the dependent and independent variables\n",
    "X = df1[['prediction', 'Lagged_Actual']]  # Independent variables\n",
    "# X = df1[['prediction']]  # Independent variables\n",
    "\n",
    "y = df1['actual']  # Dependent variable\n",
    "\n",
    "# Add a constant to the independent variables (for intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# print(y)\n",
    "# print(X)\n",
    "\n",
    "# # Check the shapes\n",
    "# print(X.shape, y.shape)\n",
    "\n",
    "# # Check data types\n",
    "# print(X.dtypes)\n",
    "# print(y.dtypes)\n",
    "\n",
    "\n",
    "# Run the regression\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Optionally, print the summary of the regression\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6PzXjOIochM",
    "outputId": "e7f55364-f773-4eb0-a71e-2b6172fcf650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First Half Results ===\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 actual   R-squared:                       0.017\n",
      "Model:                            OLS   Adj. R-squared:                  0.017\n",
      "Method:                 Least Squares   F-statistic:                     105.4\n",
      "Date:                Fri, 14 Mar 2025   Prob (F-statistic):           4.09e-46\n",
      "Time:                        17:38:36   Log-Likelihood:                -17097.\n",
      "No. Observations:               11922   AIC:                         3.420e+04\n",
      "Df Residuals:                   11919   BIC:                         3.422e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const             0.0275      0.009      2.950      0.003       0.009       0.046\n",
      "Prediction        0.1801      0.033      5.416      0.000       0.115       0.245\n",
      "Lagged_Actual     0.1059      0.010     11.072      0.000       0.087       0.125\n",
      "==============================================================================\n",
      "Omnibus:                     2943.417   Durbin-Watson:                   1.994\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           126041.854\n",
      "Skew:                           0.409   Prob(JB):                         0.00\n",
      "Kurtosis:                      18.908   Cond. No.                         3.73\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "=== Second Half Results ===\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 actual   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     7.077\n",
      "Date:                Fri, 14 Mar 2025   Prob (F-statistic):           0.000848\n",
      "Time:                        17:38:36   Log-Likelihood:                -17850.\n",
      "No. Observations:               11922   AIC:                         3.571e+04\n",
      "Df Residuals:                   11919   BIC:                         3.573e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const             0.0306      0.010      3.078      0.002       0.011       0.050\n",
      "Prediction        0.0987      0.031      3.143      0.002       0.037       0.160\n",
      "Lagged_Actual    -0.0201      0.009     -2.190      0.029      -0.038      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                     3328.440   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           120246.769\n",
      "Skew:                          -0.660   Prob(JB):                         0.00\n",
      "Kurtosis:                      18.502   Cond. No.                         3.44\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ----------------------\n",
    "# 1. Prepare the dataset\n",
    "# ----------------------\n",
    "df1 = results_df.copy()\n",
    "\n",
    "# Create a lagged version of 'actual'\n",
    "df1['Lagged_Actual'] = df1['actual'].shift(1)\n",
    "\n",
    "# Convert 'prediction' to numeric\n",
    "df1['Prediction'] = pd.to_numeric(df1['prediction'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df1 = df1.dropna(subset=['actual', 'Prediction', 'Lagged_Actual'])\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Split data into two halves\n",
    "# ---------------------------\n",
    "n = len(df1)\n",
    "midpoint = n // 2  # integer division\n",
    "\n",
    "df1_first_half = df1.iloc[:midpoint].copy()\n",
    "df1_second_half = df1.iloc[midpoint:].copy()\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Define X and y for each half\n",
    "# ---------------------------\n",
    "# Example: X includes 'Prediction' and 'Lagged_Actual'\n",
    "X1 = df1_first_half[['Prediction', 'Lagged_Actual']]\n",
    "y1 = df1_first_half['actual']\n",
    "\n",
    "X2 = df1_second_half[['Prediction', 'Lagged_Actual']]\n",
    "y2 = df1_second_half['actual']\n",
    "\n",
    "# Add a constant for the intercept\n",
    "X1 = sm.add_constant(X1)\n",
    "X2 = sm.add_constant(X2)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Fit OLS models and summarize\n",
    "# ---------------------------\n",
    "model_first_half = sm.OLS(y1, X1).fit()\n",
    "model_second_half = sm.OLS(y2, X2).fit()\n",
    "\n",
    "print(\"=== First Half Results ===\")\n",
    "print(model_first_half.summary())\n",
    "print(\"\\n=== Second Half Results ===\")\n",
    "print(model_second_half.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xOSyHjOmnbbN",
    "outputId": "853e2345-8777-4521-f125-5d964b13c91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 actual   R-squared:                       0.005\n",
      "Model:                            OLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     18.42\n",
      "Date:                Fri, 14 Mar 2025   Prob (F-statistic):           1.80e-21\n",
      "Time:                        17:38:40   Log-Likelihood:                -34994.\n",
      "No. Observations:               23840   AIC:                         7.000e+04\n",
      "Df Residuals:                   23833   BIC:                         7.006e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           0.0289      0.007      4.226      0.000       0.015       0.042\n",
      "Prediction      0.1596      0.023      6.976      0.000       0.115       0.204\n",
      "Lag1_Actual     0.0399      0.007      6.069      0.000       0.027       0.053\n",
      "Lag2_Actual    -0.0125      0.007     -1.920      0.055      -0.025       0.000\n",
      "Lag3_Actual    -0.0004      0.006     -0.068      0.946      -0.013       0.012\n",
      "Lag4_Actual     0.0013      0.006      0.208      0.835      -0.011       0.014\n",
      "Lag5_Actual    -0.0017      0.006     -0.261      0.794      -0.014       0.011\n",
      "==============================================================================\n",
      "Omnibus:                     5393.108   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           252874.286\n",
      "Skew:                          -0.185   Prob(JB):                         0.00\n",
      "Kurtosis:                      18.951   Cond. No.                         3.71\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df1 = results_df.copy()\n",
    "\n",
    "# Create 5 lagged versions of the 'actual' values\n",
    "df1['Lag1_Actual'] = df1['actual'].shift(1)\n",
    "df1['Lag2_Actual'] = df1['actual'].shift(2)\n",
    "df1['Lag3_Actual'] = df1['actual'].shift(3)\n",
    "df1['Lag4_Actual'] = df1['actual'].shift(4)\n",
    "df1['Lag5_Actual'] = df1['actual'].shift(5)\n",
    "\n",
    "# Convert 'prediction' column to numeric (in case it's not)\n",
    "df1['Prediction'] = pd.to_numeric(df1['prediction'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in required columns\n",
    "# (this ensures that for any row we have actual, Prediction, and all lagged values)\n",
    "df1 = df1.dropna(subset=['actual', 'Prediction',\n",
    "                         'Lag1_Actual', 'Lag2_Actual',\n",
    "                         'Lag3_Actual', 'Lag4_Actual',\n",
    "                         'Lag5_Actual'])\n",
    "\n",
    "# Define the dependent (y) and independent (X) variables\n",
    "y = df1['actual']\n",
    "\n",
    "# Here we include the original Prediction plus all 5 lags\n",
    "X = df1[['Prediction', 'Lag1_Actual', 'Lag2_Actual',\n",
    "         'Lag3_Actual', 'Lag4_Actual', 'Lag5_Actual']]\n",
    "\n",
    "\n",
    "# # Here we include the original Prediction plus all 5 lags\n",
    "# X = df1[['Lag1_Actual']]\n",
    "\n",
    "# Add a constant (intercept) to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the regression\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "rkJYGv_8_GCH",
    "outputId": "2984afcf-5d7d-4c54-aa77-b0e7f2561b83"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "df = df1\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming predictions and actuals are numpy arrays from previous calculations\n",
    "# Generate x values for the x-axis\n",
    "\n",
    "actuals = df['actual']\n",
    "predictions = df['prediction']\n",
    "\n",
    "x_values = np.arange(len(df['actual']))\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_values, actuals, label='Actual Values', color='red', marker='x', linestyle='-', markersize=4)\n",
    "plt.plot(x_values, predictions, label='Predictions', color='blue', marker='o', linestyle='-', markersize=4)\n",
    "\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Predictions vs Actual Values')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 1) Make a copy of results_df and sort by time\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df_plot \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      7\u001b[0m df_plot \u001b[38;5;241m=\u001b[39m df_plot\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxd\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 2) If 'actual' and 'prediction' are in PERCENT (2 means +2%), \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#    convert to decimal returns by dividing by 100 when doing the cumulative product.\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Make a copy of results_df and sort by time\n",
    "df_plot = results_df.copy()\n",
    "df_plot = df_plot.sort_values(\"idxd\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "# 2) If 'actual' and 'prediction' are in PERCENT (2 means +2%), \n",
    "#    convert to decimal returns by dividing by 100 when doing the cumulative product.\n",
    "df_plot['Actual_CumRet'] = (1 + df_plot['actual'] / 100).cumprod() - 1\n",
    "df_plot['Pred_CumRet']   = (1 + df_plot['prediction'] / 100).cumprod() - 1\n",
    "\n",
    "# 3) Plot cumulative returns with smaller markers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_plot['idxd'], df_plot['Actual_CumRet'], \n",
    "         label='Actual Cumulative Return', \n",
    "         marker='o',\n",
    "         markersize=2)  # <--- smaller dot size\n",
    "\n",
    "plt.plot(df_plot['idxd'], df_plot['Pred_CumRet'], \n",
    "         label='Predicted Cumulative Return', \n",
    "         marker='x',\n",
    "         markersize=2)  # <--- smaller dot size\n",
    "\n",
    "plt.title('Cumulative Return: Actual vs. Predicted')\n",
    "plt.xlabel('idxd (Time Index)')\n",
    "plt.ylabel('Cumulative Return')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
